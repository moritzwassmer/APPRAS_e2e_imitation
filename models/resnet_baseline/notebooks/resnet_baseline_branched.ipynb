{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c4750c0",
   "metadata": {},
   "source": [
    "# Model ResNet\n",
    "\n",
    "https://www.pluralsight.com/guides/introduction-to-resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e8eff3",
   "metadata": {},
   "source": [
    "#### TODOS\n",
    "1. DONE Debugging, does output make sense?\n",
    "    1. Resize images\n",
    "    2. preprocessing fixes\n",
    "    5. replace scaling by proper function\n",
    "2. try on leaderboard\n",
    "3. Include Odometry and fuse into heads\n",
    "    - Speed\n",
    "    - Location\n",
    "4. navigation\n",
    "5. controller\n",
    "6. Evaluation on Test set, Modularization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a254eb",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2969a3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL STUFF\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# GENERAL STUFF\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "#sys.path.insert(1, 'C:\\\\Users\\\\morit\\\\OneDrive\\\\UNI\\\\Master\\\\WS22\\\\APP-RAS\\\\Programming\\\\data_pipeline') # TODO\n",
    "\n",
    "# DATA ENGINEERING\n",
    "from data_pipeline.dataset_xy import CARLADatasetXY\n",
    "from data_pipeline.dataset import CARLADataset\n",
    "from data_pipeline.utils import train_test_split, create_metadata_df, measurements_to_df, render_example_video_from_folder_name\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce60a27",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "b9b42ad1",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4066654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(neurons_in, neurons_out, neurons_hidden):\n",
    "    return(nn.Sequential(\n",
    "        nn.Linear(neurons_in, neurons_hidden),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(neurons_hidden, neurons_hidden),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(neurons_hidden, neurons_out),\n",
    "        nn.Sigmoid()\n",
    "    ))\n",
    "\n",
    "def steer_head(neurons_in):# [-1,1] Range Output\n",
    "    str_head = nn.Sequential(\n",
    "        nn.Linear(neurons_in, 1),\n",
    "        nn.Tanh())\n",
    "    return str_head \n",
    "    \n",
    "def throttle_head(neurons_in):# [0,1] Range Output\n",
    "    thr_head = nn.Sequential(\n",
    "        nn.Linear(neurons_in, 1),\n",
    "        nn.Sigmoid())\n",
    "    return thr_head\n",
    "    \n",
    "def brake_head(neurons_in):# [0,1] Range Output \n",
    "    brk_head = nn.Sequential(\n",
    "        nn.Linear(neurons_in, 1),\n",
    "        nn.Sigmoid())\n",
    "    return brk_head\n",
    "    \n",
    "\n",
    "class MyResnet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ResNet Architecture with pretrained weights, also bigger resnets available\n",
    "        self.net = torchvision.models.resnet34(weights=True)\n",
    "        num_ftrs = self.net.fc.in_features\n",
    "\n",
    "        # Top layer of ResNet which you can modify. We choose Identity to use it as Input for all the heads\n",
    "        self.net.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5, inplace=False)\n",
    "            #nn.Identity()\n",
    "        )\n",
    "        \n",
    "        \"\"\"\n",
    "        # Input Layer fuer cmd, spd\n",
    "        self.cmd_input = nn.Sequential(\n",
    "            nn.Linear(7, 128),\n",
    "            nn.Tanh() #nn.LeakyReLU() # TODO\n",
    "            #nn.Dropout(p=0.5, inplace=False)\n",
    "        )\n",
    "        \"\"\"\n",
    "        \n",
    "        self.spd_input = nn.Sequential(\n",
    "            nn.Linear(1, 128),\n",
    "            nn.Tanh(), \n",
    "            nn.Linear(128, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Tanh()#nn.LeakyReLU() # TODO\n",
    "            #nn.Dropout(p=0.5, inplace=False)\n",
    "        )\n",
    "        \n",
    "        # shared MLP\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Identity()\n",
    "            \n",
    "        )\n",
    "        \"\"\"\n",
    "            nn.Linear(num_ftrs+128, num_ftrs+128),\n",
    "            nn.Tanh(), #nn.LeakyReLU()\n",
    "            nn.Dropout(p=0.1, inplace=False),\n",
    "            nn.Linear(num_ftrs+128, num_ftrs+128),\n",
    "            nn.Tanh(), #nn.LeakyReLU()\n",
    "            nn.Dropout(p=0.1, inplace=False)\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.W_list =  nn.ModuleList()\n",
    "\n",
    "        for i  in range(relation_num):\n",
    "        self.W_list.append(nn.Linear(self.dim, self.dim))\n",
    "        \"\"\"\n",
    "        self.branches_mlp =  nn.ModuleList()\n",
    "        self.branches_brake = nn.ModuleList()\n",
    "        self.branches_steer = nn.ModuleList()\n",
    "        self.branches_throttle = nn.ModuleList()\n",
    "        \n",
    "        for i in range(0,7):\n",
    "            \n",
    "            mlp_branch = mlp(num_ftrs+128, 256, 256)\n",
    "            brk = brake_head(256)\n",
    "            thr = throttle_head(256)\n",
    "            steer = steer_head(256)\n",
    "            \n",
    "            self.branches_mlp.append(mlp_branch)\n",
    "            self.branches_brake.append(brk)\n",
    "            self.branches_steer.append(steer)\n",
    "            self.branches_throttle.append(thr)\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "    # Forward Pass of the Model\n",
    "    \n",
    "    \"\"\"\n",
    "    def forward(cond, x):\n",
    "    x=self.layer1(x)\n",
    "    if cond:\n",
    "        x=self.relu(x)\n",
    "    ...\n",
    "    return x\n",
    "    \"\"\"\n",
    "    \n",
    "    def forward(self, rgb, cmd, spd):\n",
    "        rgb = self.net(rgb) # BRG\n",
    "        #rgb = self.net.fc(rgb)\n",
    "        #cmd = self.cmd_input(cmd)\n",
    "        spd = self.spd_input(spd)\n",
    "        \n",
    "        x = torch.cat((rgb, spd),1)\n",
    "        x = self.mlp(x)\n",
    "        \n",
    "        idx = torch.where(cmd[0])[0]\n",
    "        #print(idx)\n",
    "        x = self.branches_mlp[idx](x)\n",
    "        \n",
    "        brake = self.branches_brake[idx](x)\n",
    "        steer = self.branches_steer[idx](x)\n",
    "        throttle = self.branches_throttle[idx](x)\n",
    "        \n",
    "        \n",
    "        return brake, steer, throttle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beefd313",
   "metadata": {},
   "source": [
    "## Data Loaders, Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93c68e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_df_meta_for_unique_command_batches(df_meta_data, batch_size):\n",
    "    \"\"\"\n",
    "    Use this function if an model architecture is used where the prediction\n",
    "    head depend on the specific command type.\n",
    "    Returns the given df_meta_data in an adjusted version for the use of\n",
    "    branch\n",
    "    \"\"\"\n",
    "    # Add command as column to df_meta_data\n",
    "    df_meta_data = df_meta_data.copy()\n",
    "    print(\"Read all measurements from disk.\")\n",
    "    df_measurements = measurements_to_df(df_meta_data)\n",
    "    print(\"All measurements in RAM! Now rebuild batches!\")\n",
    "    df_meta_data[\"command\"] = df_measurements[\"command\"]\n",
    "    # Discard samples such that num_sample_per_command modulo batch_size = 0\n",
    "    nums_to_discard = (df_meta_data.sort_values(\"command\").value_counts(\"command\") % batch_size).sort_index().values\n",
    "    commands = np.sort(df_meta_data[\"command\"].unique())\n",
    "    for cmd_idx, cmd in enumerate(commands):\n",
    "        idxs_discard = (df_meta_data\n",
    "                        .query(\"command == @cmd\")\n",
    "                        .sample(nums_to_discard[cmd_idx])\n",
    "                        .index)\n",
    "        df_meta_data = df_meta_data.drop(index=idxs_discard)\n",
    "    # Randomly sample batches of batch_size with same command until all samples are used\n",
    "    batches_list = []\n",
    "    num_batches = int(len(df_meta_data) / batch_size)\n",
    "    # while not df_meta_data.empty:\n",
    "    for _ in tqdm(range(num_batches)):\n",
    "        # Next cmd to build batch with\n",
    "        cmd = df_meta_data.sample()[\"command\"].item()\n",
    "        df_batch = df_meta_data.query(\"command == @cmd\").sample(batch_size).copy()\n",
    "        df_meta_data = df_meta_data.drop(index=df_batch.index).reset_index(drop=True)\n",
    "        batches_list.append(df_batch)\n",
    "    \n",
    "    return pd.concat(batches_list, ignore_index=True).drop(columns=[\"command\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a3c0c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_meta= create_metadata_df(train_path, config[\"used_inputs\"])\\ntest_meta = create_metadata_df(test_path, config[\"used_inputs\"])\\n\\nfrom tqdm import tqdm\\nimport pandas as pd\\ntrain_meta= adjust_df_meta_for_unique_command_batches(train_meta, batch_size)\\ntest_meta= adjust_df_meta_for_unique_command_batches(test_meta, batch_size)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "#path_ege_data = os.path.join(\"..\", \"..\", \"data\", \"Dataset Ege\")\n",
    "train_path = \"D:\\\\data\\\\Train\"\n",
    "test_path = \"D:\\\\data\\\\Test\"\n",
    "\n",
    "config = {\"used_inputs\": [\"rgb\",\"measurements\"], \n",
    "        \"used_measurements\": [\"speed\", \"steer\", \"throttle\", \"brake\", \"command\"],\n",
    "        \"seq_len\": 1\n",
    "        }\n",
    "\n",
    "\"\"\"\n",
    "train_meta= create_metadata_df(train_path, config[\"used_inputs\"])\n",
    "test_meta = create_metadata_df(test_path, config[\"used_inputs\"])\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "train_meta= adjust_df_meta_for_unique_command_batches(train_meta, batch_size)\n",
    "test_meta= adjust_df_meta_for_unique_command_batches(test_meta, batch_size)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "606f4d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read all measurements from disk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 246281/246281 [26:07<00:00, 157.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All measurements in RAM! Now rebuild batches!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3844/3844 [02:34<00:00, 24.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read all measurements from disk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 24400/24400 [02:42<00:00, 150.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All measurements in RAM! Now rebuild batches!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 379/379 [00:02<00:00, 132.13it/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9396ef92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8728bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta = pd.read_pickle(r'train_meta.pickle')\n",
    "test_meta = pd.read_pickle(r'test_meta.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f68d67bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dir</th>\n",
       "      <th>rgb</th>\n",
       "      <th>measurements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:data\\Test\\coke_dataset_23_11\\Routes_Scenario...</td>\n",
       "      <td>0010.png</td>\n",
       "      <td>0010.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:data\\Test\\coke_dataset_23_11\\Routes_Scenario...</td>\n",
       "      <td>0157.png</td>\n",
       "      <td>0157.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:data\\Test\\coke_dataset_23_11\\Routes_Scenario...</td>\n",
       "      <td>0025.png</td>\n",
       "      <td>0025.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:data\\Test\\coke_dataset_23_11\\Routes_Scenario...</td>\n",
       "      <td>0016.png</td>\n",
       "      <td>0016.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:data\\Test\\coke_dataset_23_11\\Routes_Scenario...</td>\n",
       "      <td>0090.png</td>\n",
       "      <td>0090.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 dir       rgb measurements\n",
       "0  D:data\\Test\\coke_dataset_23_11\\Routes_Scenario...  0010.png    0010.json\n",
       "1  D:data\\Test\\coke_dataset_23_11\\Routes_Scenario...  0157.png    0157.json\n",
       "2  D:data\\Test\\coke_dataset_23_11\\Routes_Scenario...  0025.png    0025.json\n",
       "3  D:data\\Test\\coke_dataset_23_11\\Routes_Scenario...  0016.png    0016.json\n",
       "4  D:data\\Test\\coke_dataset_23_11\\Routes_Scenario...  0090.png    0090.json"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_meta.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b559b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train_meta.to_pickle(\"train_meta.pickle\")\n",
    "test_meta.to_pickle(\"test_meta.pickle\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afe8bd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CARLADataset(root_dir=train_path, df_meta_data=train_meta, config=config)\n",
    "test_dataset = CARLADataset(root_dir=test_path, df_meta_data=test_meta, config=config)\n",
    "\n",
    "#weighted_sampler = WeightedSampler(dataset=train_dataset)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3485634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3844"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa630256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebfb6bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "augumentations = torch.nn.ModuleList([\n",
    "        transforms.GaussianBlur(9),\n",
    "        transforms.ColorJitter(brightness=1.0, contrast=0.5, saturation=1, hue=0.1),\n",
    "        transforms.RandomErasing()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f873601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean = torch.tensor([79.6657, 81.5673, 105.6161]) BGR\n",
    "#std = torch.tensor([66.8309, 60.1001, 66.2220])\n",
    "\n",
    "mean = torch.tensor([105.6161, 81.5673, 79.6657]) # RGB\n",
    "std = torch.tensor([66.2220, 60.1001, 66.8309])\n",
    "\n",
    "\n",
    "transform_norm = transforms.Compose([\n",
    "    transforms.Normalize(mean, std),\n",
    "    transforms.Resize([224,224])\n",
    "])\n",
    "\n",
    "transform_augument = transforms.RandomApply(augumentations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1c77c4",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f57432c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morit\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyResnet(\n",
       "  (net): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (spd_input): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=128, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (5): Tanh()\n",
       "  )\n",
       "  (mlp): Sequential(\n",
       "    (0): Identity()\n",
       "  )\n",
       "  (branches_mlp): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=640, out_features=256, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (5): Sigmoid()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=640, out_features=256, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (5): Sigmoid()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=640, out_features=256, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (5): Sigmoid()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Linear(in_features=640, out_features=256, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (5): Sigmoid()\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Linear(in_features=640, out_features=256, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (5): Sigmoid()\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Linear(in_features=640, out_features=256, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (5): Sigmoid()\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Linear(in_features=640, out_features=256, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (5): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (branches_brake): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (branches_steer): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (1): Tanh()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (1): Tanh()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (1): Tanh()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (1): Tanh()\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (1): Tanh()\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (1): Tanh()\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (1): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (branches_throttle): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise Model (GPU or CPU)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "net = MyResnet().cuda() if device else net\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "505b9074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cuda_if_possible(data):\n",
    "    return data.to(device) if device else data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "263843ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(data, augument = True):\n",
    "    # further preprocessing\n",
    "    X_rgb = transform_norm(torch.squeeze(data[\"rgb\"])).float()\n",
    "    if False:#augument:\n",
    "        X_rgb = transform_augument(X_rgb)\n",
    "    labels = data[\"command\"]\n",
    "    #print(labels[0])\n",
    "    #print(labels[3])\n",
    "    #print(labels[6])\n",
    "    labels = torch.where(labels == -1, torch.tensor(0), labels).to(torch.int64) # Replace by -1 by 0\n",
    "    # Convert the labels to a one hot encoded tensor\n",
    "    one_hot = torch.nn.functional.one_hot(labels, num_classes=7)\n",
    "    X_cmd = torch.squeeze(one_hot).float()\n",
    "    X_spd = ((data[\"speed\"]-speed_mean)/speed_std).float()\n",
    "    \n",
    "    Y_throttle = data[\"throttle\"].float()\n",
    "    Y_steer = data[\"steer\"].float()\n",
    "    Y_brake = data[\"brake\"].float()\n",
    "\n",
    "    # move to GPU\n",
    "    X_rgb = to_cuda_if_possible(X_rgb)\n",
    "    X_cmd = to_cuda_if_possible(X_cmd)\n",
    "    X_spd = to_cuda_if_possible(X_spd)\n",
    "    \n",
    "    Y_throttle = to_cuda_if_possible(Y_throttle)\n",
    "    Y_steer = to_cuda_if_possible(Y_steer)\n",
    "    Y_brake = to_cuda_if_possible(Y_brake)\n",
    "\n",
    "    # compute outputs\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    Y_hat = net(X_rgb, X_cmd, X_spd)\n",
    "    Y_hat_throttle = to_cuda_if_possible(Y_hat[2])\n",
    "    Y_hat_steer = to_cuda_if_possible(Y_hat[1])\n",
    "    Y_hat_brake = to_cuda_if_possible(Y_hat[0])\n",
    "\n",
    "    # get labels from data\n",
    "    Y_throttle = to_cuda_if_possible(data[\"throttle\"].float())\n",
    "    Y_steer = to_cuda_if_possible(data[\"steer\"].float())\n",
    "    Y_brake = to_cuda_if_possible(data[\"brake\"].float())\n",
    "\n",
    "    # Calculate Loss\n",
    "    loss_throttle = 0.5*criterion(Y_hat_throttle, Y_throttle)\n",
    "    loss_steer = 0.45*criterion(Y_hat_steer, Y_steer)\n",
    "    loss_brake = 0.05*criterion(Y_hat_brake, Y_brake)\n",
    "    loss = sum([loss_throttle, loss_steer, loss_brake])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7f3d66",
   "metadata": {},
   "source": [
    "## Model Trainer Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd3eb22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_mean = 2.382234##2.250456762830466\n",
    "speed_std = 1.724884##0.30215840254891313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e39590c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "\n",
      "Epoch [1/4], Step [0/3844], Loss: 0.3037\n",
      "Epoch [1/4], Step [1/3844], Loss: 0.2881\n",
      "Epoch [1/4], Step [2/3844], Loss: 0.2748\n",
      "Epoch [1/4], Step [3/3844], Loss: 0.4646\n",
      "Epoch [1/4], Step [4/3844], Loss: 0.2157\n",
      "Epoch [1/4], Step [5/3844], Loss: 0.2647\n",
      "Epoch [1/4], Step [6/3844], Loss: 0.3594\n",
      "Epoch [1/4], Step [7/3844], Loss: 0.4003\n",
      "Epoch [1/4], Step [8/3844], Loss: 0.2429\n",
      "Epoch [1/4], Step [9/3844], Loss: 0.2481\n",
      "Epoch [1/4], Step [10/3844], Loss: 0.2402\n",
      "Epoch [1/4], Step [11/3844], Loss: 0.2576\n",
      "Epoch [1/4], Step [12/3844], Loss: 0.2826\n",
      "Epoch [1/4], Step [13/3844], Loss: 0.2473\n",
      "Epoch [1/4], Step [14/3844], Loss: 0.2437\n",
      "Epoch [1/4], Step [15/3844], Loss: 0.2746\n",
      "Epoch [1/4], Step [16/3844], Loss: 0.2917\n",
      "Epoch [1/4], Step [17/3844], Loss: 0.2307\n",
      "Epoch [1/4], Step [18/3844], Loss: 0.2250\n",
      "Epoch [1/4], Step [19/3844], Loss: 0.2184\n",
      "Epoch [1/4], Step [20/3844], Loss: 0.2127\n",
      "Epoch [1/4], Step [21/3844], Loss: 0.2103\n",
      "Epoch [1/4], Step [22/3844], Loss: 0.3162\n",
      "Epoch [1/4], Step [23/3844], Loss: 0.2529\n",
      "Epoch [1/4], Step [24/3844], Loss: 0.2241\n",
      "Epoch [1/4], Step [25/3844], Loss: 0.2226\n",
      "Epoch [1/4], Step [26/3844], Loss: 0.2938\n",
      "Epoch [1/4], Step [27/3844], Loss: 0.2201\n",
      "Epoch [1/4], Step [28/3844], Loss: 0.2173\n",
      "Epoch [1/4], Step [29/3844], Loss: 0.2717\n",
      "Epoch [1/4], Step [30/3844], Loss: 0.2296\n",
      "Epoch [1/4], Step [31/3844], Loss: 0.2364\n",
      "Epoch [1/4], Step [32/3844], Loss: 0.2543\n",
      "Epoch [1/4], Step [33/3844], Loss: 0.2230\n",
      "Epoch [1/4], Step [34/3844], Loss: 0.2962\n",
      "Epoch [1/4], Step [35/3844], Loss: 0.2353\n",
      "Epoch [1/4], Step [36/3844], Loss: 0.2384\n",
      "Epoch [1/4], Step [37/3844], Loss: 0.2343\n",
      "Epoch [1/4], Step [38/3844], Loss: 0.2144\n",
      "Epoch [1/4], Step [39/3844], Loss: 0.2121\n",
      "Epoch [1/4], Step [40/3844], Loss: 0.2803\n",
      "Epoch [1/4], Step [41/3844], Loss: 0.2159\n",
      "Epoch [1/4], Step [42/3844], Loss: 0.1845\n",
      "Epoch [1/4], Step [43/3844], Loss: 0.2313\n",
      "Epoch [1/4], Step [44/3844], Loss: 0.1982\n",
      "Epoch [1/4], Step [45/3844], Loss: 0.2152\n",
      "Epoch [1/4], Step [46/3844], Loss: 0.2215\n",
      "Epoch [1/4], Step [47/3844], Loss: 0.2250\n",
      "Epoch [1/4], Step [48/3844], Loss: 0.2239\n",
      "Epoch [1/4], Step [49/3844], Loss: 0.2226\n",
      "Epoch [1/4], Step [50/3844], Loss: 0.2242\n",
      "Epoch [1/4], Step [51/3844], Loss: 0.2267\n",
      "Epoch [1/4], Step [52/3844], Loss: 0.2249\n",
      "Epoch [1/4], Step [53/3844], Loss: 0.2272\n",
      "Epoch [1/4], Step [54/3844], Loss: 0.2538\n",
      "Epoch [1/4], Step [55/3844], Loss: 0.2132\n",
      "Epoch [1/4], Step [56/3844], Loss: 0.2294\n",
      "Epoch [1/4], Step [57/3844], Loss: 0.2748\n",
      "Epoch [1/4], Step [58/3844], Loss: 0.2247\n",
      "Epoch [1/4], Step [59/3844], Loss: 0.2177\n",
      "Epoch [1/4], Step [60/3844], Loss: 0.2117\n",
      "Epoch [1/4], Step [61/3844], Loss: 0.2286\n",
      "Epoch [1/4], Step [62/3844], Loss: 0.2140\n",
      "Epoch [1/4], Step [63/3844], Loss: 0.2433\n",
      "Epoch [1/4], Step [64/3844], Loss: 0.2192\n",
      "Epoch [1/4], Step [65/3844], Loss: 0.2265\n",
      "Epoch [1/4], Step [66/3844], Loss: 0.2753\n",
      "Epoch [1/4], Step [67/3844], Loss: 0.2330\n",
      "Epoch [1/4], Step [68/3844], Loss: 0.2259\n",
      "Epoch [1/4], Step [69/3844], Loss: 0.2700\n",
      "Epoch [1/4], Step [70/3844], Loss: 0.2114\n",
      "Epoch [1/4], Step [71/3844], Loss: 0.2048\n",
      "Epoch [1/4], Step [72/3844], Loss: 0.2122\n",
      "Epoch [1/4], Step [73/3844], Loss: 0.2559\n",
      "Epoch [1/4], Step [74/3844], Loss: 0.2141\n",
      "Epoch [1/4], Step [75/3844], Loss: 0.2252\n",
      "Epoch [1/4], Step [76/3844], Loss: 0.2310\n",
      "Epoch [1/4], Step [77/3844], Loss: 0.2583\n",
      "Epoch [1/4], Step [78/3844], Loss: 0.2131\n",
      "Epoch [1/4], Step [79/3844], Loss: 0.2443\n",
      "Epoch [1/4], Step [80/3844], Loss: 0.2128\n",
      "Epoch [1/4], Step [81/3844], Loss: 0.2340\n",
      "Epoch [1/4], Step [82/3844], Loss: 0.2115\n",
      "Epoch [1/4], Step [83/3844], Loss: 0.2181\n",
      "Epoch [1/4], Step [84/3844], Loss: 0.2234\n",
      "Epoch [1/4], Step [85/3844], Loss: 0.2226\n",
      "Epoch [1/4], Step [86/3844], Loss: 0.2211\n",
      "Epoch [1/4], Step [87/3844], Loss: 0.2579\n",
      "Epoch [1/4], Step [88/3844], Loss: 0.2498\n",
      "Epoch [1/4], Step [89/3844], Loss: 0.2373\n",
      "Epoch [1/4], Step [90/3844], Loss: 0.2032\n",
      "Epoch [1/4], Step [91/3844], Loss: 0.2081\n",
      "Epoch [1/4], Step [92/3844], Loss: 0.1959\n",
      "Epoch [1/4], Step [93/3844], Loss: 0.1996\n",
      "Epoch [1/4], Step [94/3844], Loss: 0.2538\n",
      "Epoch [1/4], Step [95/3844], Loss: 0.2513\n",
      "Epoch [1/4], Step [96/3844], Loss: 0.2452\n",
      "Epoch [1/4], Step [97/3844], Loss: 0.2117\n",
      "Epoch [1/4], Step [98/3844], Loss: 0.2455\n",
      "Epoch [1/4], Step [99/3844], Loss: 0.2332\n",
      "Epoch [1/4], Step [100/3844], Loss: 0.2194\n",
      "Epoch [1/4], Step [101/3844], Loss: 0.2063\n",
      "Epoch [1/4], Step [102/3844], Loss: 0.2117\n",
      "Epoch [1/4], Step [103/3844], Loss: 0.2234\n",
      "Epoch [1/4], Step [104/3844], Loss: 0.2433\n",
      "Epoch [1/4], Step [105/3844], Loss: 0.2051\n",
      "Epoch [1/4], Step [106/3844], Loss: 0.2021\n",
      "Epoch [1/4], Step [107/3844], Loss: 0.2118\n",
      "Epoch [1/4], Step [108/3844], Loss: 0.2108\n",
      "Epoch [1/4], Step [109/3844], Loss: 0.2488\n",
      "Epoch [1/4], Step [110/3844], Loss: 0.2321\n",
      "Epoch [1/4], Step [111/3844], Loss: 0.2149\n",
      "Epoch [1/4], Step [112/3844], Loss: 0.2191\n",
      "Epoch [1/4], Step [113/3844], Loss: 0.2112\n",
      "Epoch [1/4], Step [114/3844], Loss: 0.2163\n",
      "Epoch [1/4], Step [115/3844], Loss: 0.2207\n",
      "Epoch [1/4], Step [116/3844], Loss: 0.1996\n",
      "Epoch [1/4], Step [117/3844], Loss: 0.2102\n",
      "Epoch [1/4], Step [118/3844], Loss: 0.2323\n",
      "Epoch [1/4], Step [119/3844], Loss: 0.2005\n",
      "Epoch [1/4], Step [120/3844], Loss: 0.2119\n",
      "Epoch [1/4], Step [121/3844], Loss: 0.2361\n",
      "Epoch [1/4], Step [122/3844], Loss: 0.2269\n",
      "Epoch [1/4], Step [123/3844], Loss: 0.2676\n",
      "Epoch [1/4], Step [124/3844], Loss: 0.2259\n",
      "Epoch [1/4], Step [125/3844], Loss: 0.2209\n",
      "Epoch [1/4], Step [126/3844], Loss: 0.2312\n",
      "Epoch [1/4], Step [127/3844], Loss: 0.2190\n",
      "Epoch [1/4], Step [128/3844], Loss: 0.2181\n",
      "Epoch [1/4], Step [129/3844], Loss: 0.1988\n",
      "Epoch [1/4], Step [130/3844], Loss: 0.1969\n",
      "Epoch [1/4], Step [131/3844], Loss: 0.2087\n",
      "Epoch [1/4], Step [132/3844], Loss: 0.2670\n",
      "Epoch [1/4], Step [133/3844], Loss: 0.2022\n",
      "Epoch [1/4], Step [134/3844], Loss: 0.2225\n",
      "Epoch [1/4], Step [135/3844], Loss: 0.1969\n",
      "Epoch [1/4], Step [136/3844], Loss: 0.2044\n",
      "Epoch [1/4], Step [137/3844], Loss: 0.2495\n",
      "Epoch [1/4], Step [138/3844], Loss: 0.2056\n",
      "Epoch [1/4], Step [139/3844], Loss: 0.2161\n",
      "Epoch [1/4], Step [140/3844], Loss: 0.2193\n",
      "Epoch [1/4], Step [141/3844], Loss: 0.2085\n",
      "Epoch [1/4], Step [142/3844], Loss: 0.2385\n",
      "Epoch [1/4], Step [143/3844], Loss: 0.2024\n",
      "Epoch [1/4], Step [144/3844], Loss: 0.2159\n",
      "Epoch [1/4], Step [145/3844], Loss: 0.2128\n",
      "Epoch [1/4], Step [146/3844], Loss: 0.2018\n",
      "Epoch [1/4], Step [147/3844], Loss: 0.2177\n",
      "Epoch [1/4], Step [148/3844], Loss: 0.2154\n",
      "Epoch [1/4], Step [149/3844], Loss: 0.2493\n",
      "Epoch [1/4], Step [150/3844], Loss: 0.2164\n",
      "Epoch [1/4], Step [151/3844], Loss: 0.2139\n",
      "Epoch [1/4], Step [152/3844], Loss: 0.2164\n",
      "Epoch [1/4], Step [153/3844], Loss: 0.2201\n",
      "Epoch [1/4], Step [154/3844], Loss: 0.2359\n",
      "Epoch [1/4], Step [155/3844], Loss: 0.2038\n",
      "Epoch [1/4], Step [156/3844], Loss: 0.2165\n",
      "Epoch [1/4], Step [157/3844], Loss: 0.1965\n",
      "Epoch [1/4], Step [158/3844], Loss: 0.2171\n",
      "Epoch [1/4], Step [159/3844], Loss: 0.2106\n",
      "Epoch [1/4], Step [160/3844], Loss: 0.1994\n",
      "Epoch [1/4], Step [161/3844], Loss: 0.2163\n",
      "Epoch [1/4], Step [162/3844], Loss: 0.2785\n",
      "Epoch [1/4], Step [163/3844], Loss: 0.2332\n",
      "Epoch [1/4], Step [164/3844], Loss: 0.2092\n",
      "Epoch [1/4], Step [165/3844], Loss: 0.2367\n",
      "Epoch [1/4], Step [166/3844], Loss: 0.2240\n",
      "Epoch [1/4], Step [167/3844], Loss: 0.2184\n",
      "Epoch [1/4], Step [168/3844], Loss: 0.1875\n",
      "Epoch [1/4], Step [169/3844], Loss: 0.2096\n",
      "Epoch [1/4], Step [170/3844], Loss: 0.2031\n",
      "Epoch [1/4], Step [171/3844], Loss: 0.2139\n",
      "Epoch [1/4], Step [172/3844], Loss: 0.2064\n",
      "Epoch [1/4], Step [173/3844], Loss: 0.2244\n",
      "Epoch [1/4], Step [174/3844], Loss: 0.2558\n",
      "Epoch [1/4], Step [175/3844], Loss: 0.2233\n",
      "Epoch [1/4], Step [176/3844], Loss: 0.2136\n",
      "Epoch [1/4], Step [177/3844], Loss: 0.2181\n",
      "Epoch [1/4], Step [178/3844], Loss: 0.1862\n",
      "Epoch [1/4], Step [179/3844], Loss: 0.2480\n",
      "Epoch [1/4], Step [180/3844], Loss: 0.2160\n",
      "Epoch [1/4], Step [181/3844], Loss: 0.2205\n",
      "Epoch [1/4], Step [182/3844], Loss: 0.2331\n",
      "Epoch [1/4], Step [183/3844], Loss: 0.1919\n",
      "Epoch [1/4], Step [184/3844], Loss: 0.2029\n",
      "Epoch [1/4], Step [185/3844], Loss: 0.2254\n",
      "Epoch [1/4], Step [186/3844], Loss: 0.2322\n",
      "Epoch [1/4], Step [187/3844], Loss: 0.2076\n",
      "Epoch [1/4], Step [188/3844], Loss: 0.1989\n",
      "Epoch [1/4], Step [189/3844], Loss: 0.2114\n",
      "Epoch [1/4], Step [190/3844], Loss: 0.2047\n",
      "Epoch [1/4], Step [191/3844], Loss: 0.2175\n",
      "Epoch [1/4], Step [192/3844], Loss: 0.2172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [193/3844], Loss: 0.2017\n",
      "Epoch [1/4], Step [194/3844], Loss: 0.2046\n",
      "Epoch [1/4], Step [195/3844], Loss: 0.1947\n",
      "Epoch [1/4], Step [196/3844], Loss: 0.2202\n",
      "Epoch [1/4], Step [197/3844], Loss: 0.2199\n",
      "Epoch [1/4], Step [198/3844], Loss: 0.1962\n",
      "Epoch [1/4], Step [199/3844], Loss: 0.2135\n",
      "Epoch [1/4], Step [200/3844], Loss: 0.2173\n",
      "Epoch [1/4], Step [201/3844], Loss: 0.2470\n",
      "Epoch [1/4], Step [202/3844], Loss: 0.2102\n",
      "Epoch [1/4], Step [203/3844], Loss: 0.2161\n",
      "Epoch [1/4], Step [204/3844], Loss: 0.2078\n",
      "Epoch [1/4], Step [205/3844], Loss: 0.2135\n",
      "Epoch [1/4], Step [206/3844], Loss: 0.2086\n",
      "Epoch [1/4], Step [207/3844], Loss: 0.1974\n",
      "Epoch [1/4], Step [208/3844], Loss: 0.2058\n",
      "Epoch [1/4], Step [209/3844], Loss: 0.2099\n",
      "Epoch [1/4], Step [210/3844], Loss: 0.2039\n",
      "Epoch [1/4], Step [211/3844], Loss: 0.2101\n",
      "Epoch [1/4], Step [212/3844], Loss: 0.2158\n",
      "Epoch [1/4], Step [213/3844], Loss: 0.1650\n",
      "Epoch [1/4], Step [214/3844], Loss: 0.2194\n",
      "Epoch [1/4], Step [215/3844], Loss: 0.2116\n",
      "Epoch [1/4], Step [216/3844], Loss: 0.2035\n",
      "Epoch [1/4], Step [217/3844], Loss: 0.2021\n",
      "Epoch [1/4], Step [218/3844], Loss: 0.2073\n",
      "Epoch [1/4], Step [219/3844], Loss: 0.2176\n",
      "Epoch [1/4], Step [220/3844], Loss: 0.1984\n",
      "Epoch [1/4], Step [221/3844], Loss: 0.2035\n",
      "Epoch [1/4], Step [222/3844], Loss: 0.2408\n",
      "Epoch [1/4], Step [223/3844], Loss: 0.1720\n",
      "Epoch [1/4], Step [224/3844], Loss: 0.2126\n",
      "Epoch [1/4], Step [225/3844], Loss: 0.2491\n",
      "Epoch [1/4], Step [226/3844], Loss: 0.2462\n",
      "Epoch [1/4], Step [227/3844], Loss: 0.2135\n",
      "Epoch [1/4], Step [228/3844], Loss: 0.2171\n",
      "Epoch [1/4], Step [229/3844], Loss: 0.2268\n",
      "Epoch [1/4], Step [230/3844], Loss: 0.2085\n",
      "Epoch [1/4], Step [231/3844], Loss: 0.2094\n",
      "Epoch [1/4], Step [232/3844], Loss: 0.2067\n",
      "Epoch [1/4], Step [233/3844], Loss: 0.2038\n",
      "Epoch [1/4], Step [234/3844], Loss: 0.2485\n",
      "Epoch [1/4], Step [235/3844], Loss: 0.1849\n",
      "Epoch [1/4], Step [236/3844], Loss: 0.1992\n",
      "Epoch [1/4], Step [237/3844], Loss: 0.2020\n",
      "Epoch [1/4], Step [238/3844], Loss: 0.2001\n",
      "Epoch [1/4], Step [239/3844], Loss: 0.2240\n",
      "Epoch [1/4], Step [240/3844], Loss: 0.2235\n",
      "Epoch [1/4], Step [241/3844], Loss: 0.2045\n",
      "Epoch [1/4], Step [242/3844], Loss: 0.1929\n",
      "Epoch [1/4], Step [243/3844], Loss: 0.2044\n",
      "Epoch [1/4], Step [244/3844], Loss: 0.2148\n",
      "Epoch [1/4], Step [245/3844], Loss: 0.2005\n",
      "Epoch [1/4], Step [246/3844], Loss: 0.2515\n",
      "Epoch [1/4], Step [247/3844], Loss: 0.1824\n",
      "Epoch [1/4], Step [248/3844], Loss: 0.2183\n",
      "Epoch [1/4], Step [249/3844], Loss: 0.1931\n",
      "Epoch [1/4], Step [250/3844], Loss: 0.1903\n",
      "Epoch [1/4], Step [251/3844], Loss: 0.1926\n",
      "Epoch [1/4], Step [252/3844], Loss: 0.2096\n",
      "Epoch [1/4], Step [253/3844], Loss: 0.2142\n",
      "Epoch [1/4], Step [254/3844], Loss: 0.2162\n",
      "Epoch [1/4], Step [255/3844], Loss: 0.2257\n",
      "Epoch [1/4], Step [256/3844], Loss: 0.2366\n",
      "Epoch [1/4], Step [257/3844], Loss: 0.2224\n",
      "Epoch [1/4], Step [258/3844], Loss: 0.2640\n",
      "Epoch [1/4], Step [259/3844], Loss: 0.2226\n",
      "Epoch [1/4], Step [260/3844], Loss: 0.2130\n",
      "Epoch [1/4], Step [261/3844], Loss: 0.2017\n",
      "Epoch [1/4], Step [262/3844], Loss: 0.1816\n",
      "Epoch [1/4], Step [263/3844], Loss: 0.2066\n",
      "Epoch [1/4], Step [264/3844], Loss: 0.1952\n",
      "Epoch [1/4], Step [265/3844], Loss: 0.2105\n",
      "Epoch [1/4], Step [266/3844], Loss: 0.2034\n",
      "Epoch [1/4], Step [267/3844], Loss: 0.1861\n",
      "Epoch [1/4], Step [268/3844], Loss: 0.1925\n",
      "Epoch [1/4], Step [269/3844], Loss: 0.2048\n",
      "Epoch [1/4], Step [270/3844], Loss: 0.1928\n",
      "Epoch [1/4], Step [271/3844], Loss: 0.1829\n",
      "Epoch [1/4], Step [272/3844], Loss: 0.2113\n",
      "Epoch [1/4], Step [273/3844], Loss: 0.2035\n",
      "Epoch [1/4], Step [274/3844], Loss: 0.2328\n",
      "Epoch [1/4], Step [275/3844], Loss: 0.2064\n",
      "Epoch [1/4], Step [276/3844], Loss: 0.1955\n",
      "Epoch [1/4], Step [277/3844], Loss: 0.2284\n",
      "Epoch [1/4], Step [278/3844], Loss: 0.2022\n",
      "Epoch [1/4], Step [279/3844], Loss: 0.1970\n",
      "Epoch [1/4], Step [280/3844], Loss: 0.2245\n",
      "Epoch [1/4], Step [281/3844], Loss: 0.2529\n",
      "Epoch [1/4], Step [282/3844], Loss: 0.2165\n",
      "Epoch [1/4], Step [283/3844], Loss: 0.2238\n",
      "Epoch [1/4], Step [284/3844], Loss: 0.1857\n",
      "Epoch [1/4], Step [285/3844], Loss: 0.1938\n",
      "Epoch [1/4], Step [286/3844], Loss: 0.2020\n",
      "Epoch [1/4], Step [287/3844], Loss: 0.2145\n",
      "Epoch [1/4], Step [288/3844], Loss: 0.2279\n",
      "Epoch [1/4], Step [289/3844], Loss: 0.2044\n",
      "Epoch [1/4], Step [290/3844], Loss: 0.2050\n",
      "Epoch [1/4], Step [291/3844], Loss: 0.1815\n",
      "Epoch [1/4], Step [292/3844], Loss: 0.2070\n",
      "Epoch [1/4], Step [293/3844], Loss: 0.2007\n",
      "Epoch [1/4], Step [294/3844], Loss: 0.2056\n",
      "Epoch [1/4], Step [295/3844], Loss: 0.1932\n",
      "Epoch [1/4], Step [296/3844], Loss: 0.2045\n",
      "Epoch [1/4], Step [297/3844], Loss: 0.2081\n",
      "Epoch [1/4], Step [298/3844], Loss: 0.2040\n",
      "Epoch [1/4], Step [299/3844], Loss: 0.1879\n",
      "Epoch [1/4], Step [300/3844], Loss: 0.2530\n",
      "Epoch [1/4], Step [301/3844], Loss: 0.1960\n",
      "Epoch [1/4], Step [302/3844], Loss: 0.1586\n",
      "Epoch [1/4], Step [303/3844], Loss: 0.2009\n",
      "Epoch [1/4], Step [304/3844], Loss: 0.2183\n",
      "Epoch [1/4], Step [305/3844], Loss: 0.1958\n",
      "Epoch [1/4], Step [306/3844], Loss: 0.1846\n",
      "Epoch [1/4], Step [307/3844], Loss: 0.1761\n",
      "Epoch [1/4], Step [308/3844], Loss: 0.2459\n",
      "Epoch [1/4], Step [309/3844], Loss: 0.2202\n",
      "Epoch [1/4], Step [310/3844], Loss: 0.2001\n",
      "Epoch [1/4], Step [311/3844], Loss: 0.2164\n",
      "Epoch [1/4], Step [312/3844], Loss: 0.1939\n",
      "Epoch [1/4], Step [313/3844], Loss: 0.1904\n",
      "Epoch [1/4], Step [314/3844], Loss: 0.2098\n",
      "Epoch [1/4], Step [315/3844], Loss: 0.2536\n",
      "Epoch [1/4], Step [316/3844], Loss: 0.2018\n",
      "Epoch [1/4], Step [317/3844], Loss: 0.2172\n",
      "Epoch [1/4], Step [318/3844], Loss: 0.2294\n",
      "Epoch [1/4], Step [319/3844], Loss: 0.2057\n",
      "Epoch [1/4], Step [320/3844], Loss: 0.2109\n",
      "Epoch [1/4], Step [321/3844], Loss: 0.2044\n",
      "Epoch [1/4], Step [322/3844], Loss: 0.1936\n",
      "Epoch [1/4], Step [323/3844], Loss: 0.2161\n",
      "Epoch [1/4], Step [324/3844], Loss: 0.2022\n",
      "Epoch [1/4], Step [325/3844], Loss: 0.2580\n",
      "Epoch [1/4], Step [326/3844], Loss: 0.2123\n",
      "Epoch [1/4], Step [327/3844], Loss: 0.1871\n",
      "Epoch [1/4], Step [328/3844], Loss: 0.1740\n",
      "Epoch [1/4], Step [329/3844], Loss: 0.2413\n",
      "Epoch [1/4], Step [330/3844], Loss: 0.2263\n",
      "Epoch [1/4], Step [331/3844], Loss: 0.2110\n",
      "Epoch [1/4], Step [332/3844], Loss: 0.2153\n",
      "Epoch [1/4], Step [333/3844], Loss: 0.2281\n",
      "Epoch [1/4], Step [334/3844], Loss: 0.1982\n",
      "Epoch [1/4], Step [335/3844], Loss: 0.2106\n",
      "Epoch [1/4], Step [336/3844], Loss: 0.2037\n",
      "Epoch [1/4], Step [337/3844], Loss: 0.2216\n",
      "Epoch [1/4], Step [338/3844], Loss: 0.1999\n",
      "Epoch [1/4], Step [339/3844], Loss: 0.1659\n",
      "Epoch [1/4], Step [340/3844], Loss: 0.1990\n",
      "Epoch [1/4], Step [341/3844], Loss: 0.1642\n",
      "Epoch [1/4], Step [342/3844], Loss: 0.2213\n",
      "Epoch [1/4], Step [343/3844], Loss: 0.2128\n",
      "Epoch [1/4], Step [344/3844], Loss: 0.2066\n",
      "Epoch [1/4], Step [345/3844], Loss: 0.1841\n",
      "Epoch [1/4], Step [346/3844], Loss: 0.2070\n",
      "Epoch [1/4], Step [347/3844], Loss: 0.2177\n",
      "Epoch [1/4], Step [348/3844], Loss: 0.2000\n",
      "Epoch [1/4], Step [349/3844], Loss: 0.1845\n",
      "Epoch [1/4], Step [350/3844], Loss: 0.2501\n",
      "Epoch [1/4], Step [351/3844], Loss: 0.2055\n",
      "Epoch [1/4], Step [352/3844], Loss: 0.2048\n",
      "Epoch [1/4], Step [353/3844], Loss: 0.2061\n",
      "Epoch [1/4], Step [354/3844], Loss: 0.2033\n",
      "Epoch [1/4], Step [355/3844], Loss: 0.1971\n",
      "Epoch [1/4], Step [356/3844], Loss: 0.1938\n",
      "Epoch [1/4], Step [357/3844], Loss: 0.2349\n",
      "Epoch [1/4], Step [358/3844], Loss: 0.2576\n",
      "Epoch [1/4], Step [359/3844], Loss: 0.2490\n",
      "Epoch [1/4], Step [360/3844], Loss: 0.2086\n",
      "Epoch [1/4], Step [361/3844], Loss: 0.2188\n",
      "Epoch [1/4], Step [362/3844], Loss: 0.2303\n",
      "Epoch [1/4], Step [363/3844], Loss: 0.2163\n",
      "Epoch [1/4], Step [364/3844], Loss: 0.2196\n",
      "Epoch [1/4], Step [365/3844], Loss: 0.1934\n",
      "Epoch [1/4], Step [366/3844], Loss: 0.2185\n",
      "Epoch [1/4], Step [367/3844], Loss: 0.2066\n",
      "Epoch [1/4], Step [368/3844], Loss: 0.2508\n",
      "Epoch [1/4], Step [369/3844], Loss: 0.2099\n",
      "Epoch [1/4], Step [370/3844], Loss: 0.2030\n",
      "Epoch [1/4], Step [371/3844], Loss: 0.2084\n",
      "Epoch [1/4], Step [372/3844], Loss: 0.2040\n",
      "Epoch [1/4], Step [373/3844], Loss: 0.2108\n",
      "Epoch [1/4], Step [374/3844], Loss: 0.1923\n",
      "Epoch [1/4], Step [375/3844], Loss: 0.1731\n",
      "Epoch [1/4], Step [376/3844], Loss: 0.2304\n",
      "Epoch [1/4], Step [377/3844], Loss: 0.1684\n",
      "Epoch [1/4], Step [378/3844], Loss: 0.1982\n",
      "Epoch [1/4], Step [379/3844], Loss: 0.2382\n",
      "Epoch [1/4], Step [380/3844], Loss: 0.1894\n",
      "Epoch [1/4], Step [381/3844], Loss: 0.2099\n",
      "Epoch [1/4], Step [382/3844], Loss: 0.2265\n",
      "Epoch [1/4], Step [383/3844], Loss: 0.2021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [384/3844], Loss: 0.1764\n",
      "Epoch [1/4], Step [385/3844], Loss: 0.2012\n",
      "Epoch [1/4], Step [386/3844], Loss: 0.2232\n",
      "Epoch [1/4], Step [387/3844], Loss: 0.1939\n",
      "Epoch [1/4], Step [388/3844], Loss: 0.1995\n",
      "Epoch [1/4], Step [389/3844], Loss: 0.2007\n",
      "Epoch [1/4], Step [390/3844], Loss: 0.2161\n",
      "Epoch [1/4], Step [391/3844], Loss: 0.2053\n",
      "Epoch [1/4], Step [392/3844], Loss: 0.2046\n",
      "Epoch [1/4], Step [393/3844], Loss: 0.1924\n",
      "Epoch [1/4], Step [394/3844], Loss: 0.2152\n",
      "Epoch [1/4], Step [395/3844], Loss: 0.1814\n",
      "Epoch [1/4], Step [396/3844], Loss: 0.2101\n",
      "Epoch [1/4], Step [397/3844], Loss: 0.2362\n",
      "Epoch [1/4], Step [398/3844], Loss: 0.2135\n",
      "Epoch [1/4], Step [399/3844], Loss: 0.1960\n",
      "Epoch [1/4], Step [400/3844], Loss: 0.1793\n",
      "Epoch [1/4], Step [401/3844], Loss: 0.2095\n",
      "Epoch [1/4], Step [402/3844], Loss: 0.2080\n",
      "Epoch [1/4], Step [403/3844], Loss: 0.1684\n",
      "Epoch [1/4], Step [404/3844], Loss: 0.2069\n",
      "Epoch [1/4], Step [405/3844], Loss: 0.1849\n",
      "Epoch [1/4], Step [406/3844], Loss: 0.1888\n",
      "Epoch [1/4], Step [407/3844], Loss: 0.2175\n",
      "Epoch [1/4], Step [408/3844], Loss: 0.1992\n",
      "Epoch [1/4], Step [409/3844], Loss: 0.1790\n",
      "Epoch [1/4], Step [410/3844], Loss: 0.2154\n",
      "Epoch [1/4], Step [411/3844], Loss: 0.2057\n",
      "Epoch [1/4], Step [412/3844], Loss: 0.1885\n",
      "Epoch [1/4], Step [413/3844], Loss: 0.2030\n",
      "Epoch [1/4], Step [414/3844], Loss: 0.2557\n",
      "Epoch [1/4], Step [415/3844], Loss: 0.1419\n",
      "Epoch [1/4], Step [416/3844], Loss: 0.2187\n",
      "Epoch [1/4], Step [417/3844], Loss: 0.2286\n",
      "Epoch [1/4], Step [418/3844], Loss: 0.2253\n",
      "Epoch [1/4], Step [419/3844], Loss: 0.1926\n",
      "Epoch [1/4], Step [420/3844], Loss: 0.2073\n",
      "Epoch [1/4], Step [421/3844], Loss: 0.1837\n",
      "Epoch [1/4], Step [422/3844], Loss: 0.2160\n",
      "Epoch [1/4], Step [423/3844], Loss: 0.1591\n",
      "Epoch [1/4], Step [424/3844], Loss: 0.1920\n",
      "Epoch [1/4], Step [425/3844], Loss: 0.2005\n",
      "Epoch [1/4], Step [426/3844], Loss: 0.2034\n",
      "Epoch [1/4], Step [427/3844], Loss: 0.2232\n",
      "Epoch [1/4], Step [428/3844], Loss: 0.1986\n",
      "Epoch [1/4], Step [429/3844], Loss: 0.1950\n",
      "Epoch [1/4], Step [430/3844], Loss: 0.1822\n",
      "Epoch [1/4], Step [431/3844], Loss: 0.1975\n",
      "Epoch [1/4], Step [432/3844], Loss: 0.1932\n",
      "Epoch [1/4], Step [433/3844], Loss: 0.1969\n",
      "Epoch [1/4], Step [434/3844], Loss: 0.1764\n",
      "Epoch [1/4], Step [435/3844], Loss: 0.2128\n",
      "Epoch [1/4], Step [436/3844], Loss: 0.2093\n",
      "Epoch [1/4], Step [437/3844], Loss: 0.1994\n",
      "Epoch [1/4], Step [438/3844], Loss: 0.2034\n",
      "Epoch [1/4], Step [439/3844], Loss: 0.1889\n",
      "Epoch [1/4], Step [440/3844], Loss: 0.1838\n",
      "Epoch [1/4], Step [441/3844], Loss: 0.1868\n",
      "Epoch [1/4], Step [442/3844], Loss: 0.2657\n",
      "Epoch [1/4], Step [443/3844], Loss: 0.1721\n",
      "Epoch [1/4], Step [444/3844], Loss: 0.1739\n",
      "Epoch [1/4], Step [445/3844], Loss: 0.1731\n",
      "Epoch [1/4], Step [446/3844], Loss: 0.2231\n",
      "Epoch [1/4], Step [447/3844], Loss: 0.2343\n",
      "Epoch [1/4], Step [448/3844], Loss: 0.2315\n",
      "Epoch [1/4], Step [449/3844], Loss: 0.2644\n",
      "Epoch [1/4], Step [450/3844], Loss: 0.2408\n",
      "Epoch [1/4], Step [451/3844], Loss: 0.2235\n",
      "Epoch [1/4], Step [452/3844], Loss: 0.2154\n",
      "Epoch [1/4], Step [453/3844], Loss: 0.2266\n",
      "Epoch [1/4], Step [454/3844], Loss: 0.1966\n",
      "Epoch [1/4], Step [455/3844], Loss: 0.1907\n",
      "Epoch [1/4], Step [456/3844], Loss: 0.2136\n",
      "Epoch [1/4], Step [457/3844], Loss: 0.2082\n",
      "Epoch [1/4], Step [458/3844], Loss: 0.2232\n",
      "Epoch [1/4], Step [459/3844], Loss: 0.1865\n",
      "Epoch [1/4], Step [460/3844], Loss: 0.2207\n",
      "Epoch [1/4], Step [461/3844], Loss: 0.2315\n",
      "Epoch [1/4], Step [462/3844], Loss: 0.2456\n",
      "Epoch [1/4], Step [463/3844], Loss: 0.2218\n",
      "Epoch [1/4], Step [464/3844], Loss: 0.2088\n",
      "Epoch [1/4], Step [465/3844], Loss: 0.2312\n",
      "Epoch [1/4], Step [466/3844], Loss: 0.2200\n",
      "Epoch [1/4], Step [467/3844], Loss: 0.2259\n",
      "Epoch [1/4], Step [468/3844], Loss: 0.2106\n",
      "Epoch [1/4], Step [469/3844], Loss: 0.2278\n",
      "Epoch [1/4], Step [470/3844], Loss: 0.2152\n",
      "Epoch [1/4], Step [471/3844], Loss: 0.2044\n",
      "Epoch [1/4], Step [472/3844], Loss: 0.2278\n",
      "Epoch [1/4], Step [473/3844], Loss: 0.2010\n",
      "Epoch [1/4], Step [474/3844], Loss: 0.2131\n",
      "Epoch [1/4], Step [475/3844], Loss: 0.1873\n",
      "Epoch [1/4], Step [476/3844], Loss: 0.1947\n",
      "Epoch [1/4], Step [477/3844], Loss: 0.2447\n",
      "Epoch [1/4], Step [478/3844], Loss: 0.2276\n",
      "Epoch [1/4], Step [479/3844], Loss: 0.1953\n",
      "Epoch [1/4], Step [480/3844], Loss: 0.1957\n",
      "Epoch [1/4], Step [481/3844], Loss: 0.2007\n",
      "Epoch [1/4], Step [482/3844], Loss: 0.2055\n",
      "Epoch [1/4], Step [483/3844], Loss: 0.1976\n",
      "Epoch [1/4], Step [484/3844], Loss: 0.2162\n",
      "Epoch [1/4], Step [485/3844], Loss: 0.1835\n",
      "Epoch [1/4], Step [486/3844], Loss: 0.1863\n",
      "Epoch [1/4], Step [487/3844], Loss: 0.2225\n",
      "Epoch [1/4], Step [488/3844], Loss: 0.2084\n",
      "Epoch [1/4], Step [489/3844], Loss: 0.2080\n",
      "Epoch [1/4], Step [490/3844], Loss: 0.2032\n",
      "Epoch [1/4], Step [491/3844], Loss: 0.2028\n",
      "Epoch [1/4], Step [492/3844], Loss: 0.1892\n",
      "Epoch [1/4], Step [493/3844], Loss: 0.2094\n",
      "Epoch [1/4], Step [494/3844], Loss: 0.1722\n",
      "Epoch [1/4], Step [495/3844], Loss: 0.2007\n",
      "Epoch [1/4], Step [496/3844], Loss: 0.2151\n",
      "Epoch [1/4], Step [497/3844], Loss: 0.2399\n",
      "Epoch [1/4], Step [498/3844], Loss: 0.2170\n",
      "Epoch [1/4], Step [499/3844], Loss: 0.1968\n",
      "Epoch [1/4], Step [500/3844], Loss: 0.1763\n",
      "Epoch [1/4], Step [501/3844], Loss: 0.2101\n",
      "Epoch [1/4], Step [502/3844], Loss: 0.2159\n",
      "Epoch [1/4], Step [503/3844], Loss: 0.1976\n",
      "Epoch [1/4], Step [504/3844], Loss: 0.2080\n",
      "Epoch [1/4], Step [505/3844], Loss: 0.1966\n",
      "Epoch [1/4], Step [506/3844], Loss: 0.2044\n",
      "Epoch [1/4], Step [507/3844], Loss: 0.2589\n",
      "Epoch [1/4], Step [508/3844], Loss: 0.2456\n",
      "Epoch [1/4], Step [509/3844], Loss: 0.2215\n",
      "Epoch [1/4], Step [510/3844], Loss: 0.2117\n",
      "Epoch [1/4], Step [511/3844], Loss: 0.2095\n",
      "Epoch [1/4], Step [512/3844], Loss: 0.2003\n",
      "Epoch [1/4], Step [513/3844], Loss: 0.1801\n",
      "Epoch [1/4], Step [514/3844], Loss: 0.2162\n",
      "Epoch [1/4], Step [515/3844], Loss: 0.1623\n",
      "Epoch [1/4], Step [516/3844], Loss: 0.2042\n",
      "Epoch [1/4], Step [517/3844], Loss: 0.1837\n",
      "Epoch [1/4], Step [518/3844], Loss: 0.1930\n",
      "Epoch [1/4], Step [519/3844], Loss: 0.1784\n",
      "Epoch [1/4], Step [520/3844], Loss: 0.1978\n",
      "Epoch [1/4], Step [521/3844], Loss: 0.2143\n",
      "Epoch [1/4], Step [522/3844], Loss: 0.1768\n",
      "Epoch [1/4], Step [523/3844], Loss: 0.1664\n",
      "Epoch [1/4], Step [524/3844], Loss: 0.1991\n",
      "Epoch [1/4], Step [525/3844], Loss: 0.2052\n",
      "Epoch [1/4], Step [526/3844], Loss: 0.2042\n",
      "Epoch [1/4], Step [527/3844], Loss: 0.2081\n",
      "Epoch [1/4], Step [528/3844], Loss: 0.2006\n",
      "Epoch [1/4], Step [529/3844], Loss: 0.2078\n",
      "Epoch [1/4], Step [530/3844], Loss: 0.2036\n",
      "Epoch [1/4], Step [531/3844], Loss: 0.2136\n",
      "Epoch [1/4], Step [532/3844], Loss: 0.1888\n",
      "Epoch [1/4], Step [533/3844], Loss: 0.2085\n",
      "Epoch [1/4], Step [534/3844], Loss: 0.1797\n",
      "Epoch [1/4], Step [535/3844], Loss: 0.2196\n",
      "Epoch [1/4], Step [536/3844], Loss: 0.2086\n",
      "Epoch [1/4], Step [537/3844], Loss: 0.2504\n",
      "Epoch [1/4], Step [538/3844], Loss: 0.2011\n",
      "Epoch [1/4], Step [539/3844], Loss: 0.1864\n",
      "Epoch [1/4], Step [540/3844], Loss: 0.2023\n",
      "Epoch [1/4], Step [541/3844], Loss: 0.2240\n",
      "Epoch [1/4], Step [542/3844], Loss: 0.1924\n",
      "Epoch [1/4], Step [543/3844], Loss: 0.2050\n",
      "Epoch [1/4], Step [544/3844], Loss: 0.1660\n",
      "Epoch [1/4], Step [545/3844], Loss: 0.1691\n",
      "Epoch [1/4], Step [546/3844], Loss: 0.2197\n",
      "Epoch [1/4], Step [547/3844], Loss: 0.1813\n",
      "Epoch [1/4], Step [548/3844], Loss: 0.2138\n",
      "Epoch [1/4], Step [549/3844], Loss: 0.1883\n",
      "Epoch [1/4], Step [550/3844], Loss: 0.1977\n",
      "Epoch [1/4], Step [551/3844], Loss: 0.1937\n",
      "Epoch [1/4], Step [552/3844], Loss: 0.1938\n",
      "Epoch [1/4], Step [553/3844], Loss: 0.1935\n",
      "Epoch [1/4], Step [554/3844], Loss: 0.2072\n",
      "Epoch [1/4], Step [555/3844], Loss: 0.2138\n",
      "Epoch [1/4], Step [556/3844], Loss: 0.1988\n",
      "Epoch [1/4], Step [557/3844], Loss: 0.2053\n",
      "Epoch [1/4], Step [558/3844], Loss: 0.1816\n",
      "Epoch [1/4], Step [559/3844], Loss: 0.1798\n",
      "Epoch [1/4], Step [560/3844], Loss: 0.1848\n",
      "Epoch [1/4], Step [561/3844], Loss: 0.1774\n",
      "Epoch [1/4], Step [562/3844], Loss: 0.1841\n",
      "Epoch [1/4], Step [563/3844], Loss: 0.1970\n",
      "Epoch [1/4], Step [564/3844], Loss: 0.2136\n",
      "Epoch [1/4], Step [565/3844], Loss: 0.1804\n",
      "Epoch [1/4], Step [566/3844], Loss: 0.2173\n",
      "Epoch [1/4], Step [567/3844], Loss: 0.2087\n",
      "Epoch [1/4], Step [568/3844], Loss: 0.2096\n",
      "Epoch [1/4], Step [569/3844], Loss: 0.1703\n",
      "Epoch [1/4], Step [570/3844], Loss: 0.2105\n",
      "Epoch [1/4], Step [571/3844], Loss: 0.2120\n",
      "Epoch [1/4], Step [572/3844], Loss: 0.2280\n",
      "Epoch [1/4], Step [573/3844], Loss: 0.1958\n",
      "Epoch [1/4], Step [574/3844], Loss: 0.2254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [575/3844], Loss: 0.2131\n",
      "Epoch [1/4], Step [576/3844], Loss: 0.2042\n",
      "Epoch [1/4], Step [577/3844], Loss: 0.1966\n",
      "Epoch [1/4], Step [578/3844], Loss: 0.1906\n",
      "Epoch [1/4], Step [579/3844], Loss: 0.2161\n",
      "Epoch [1/4], Step [580/3844], Loss: 0.2361\n",
      "Epoch [1/4], Step [581/3844], Loss: 0.2288\n",
      "Epoch [1/4], Step [582/3844], Loss: 0.2085\n",
      "Epoch [1/4], Step [583/3844], Loss: 0.1952\n",
      "Epoch [1/4], Step [584/3844], Loss: 0.2160\n",
      "Epoch [1/4], Step [585/3844], Loss: 0.2070\n",
      "Epoch [1/4], Step [586/3844], Loss: 0.1922\n",
      "Epoch [1/4], Step [587/3844], Loss: 0.1963\n",
      "Epoch [1/4], Step [588/3844], Loss: 0.1818\n",
      "Epoch [1/4], Step [589/3844], Loss: 0.2247\n",
      "Epoch [1/4], Step [590/3844], Loss: 0.1996\n",
      "Epoch [1/4], Step [591/3844], Loss: 0.2045\n",
      "Epoch [1/4], Step [592/3844], Loss: 0.1687\n",
      "Epoch [1/4], Step [593/3844], Loss: 0.1462\n",
      "Epoch [1/4], Step [594/3844], Loss: 0.1729\n",
      "Epoch [1/4], Step [595/3844], Loss: 0.2077\n",
      "Epoch [1/4], Step [596/3844], Loss: 0.2225\n",
      "Epoch [1/4], Step [597/3844], Loss: 0.2161\n",
      "Epoch [1/4], Step [598/3844], Loss: 0.1964\n",
      "Epoch [1/4], Step [599/3844], Loss: 0.2064\n",
      "Epoch [1/4], Step [600/3844], Loss: 0.1514\n",
      "Epoch [1/4], Step [601/3844], Loss: 0.2315\n",
      "Epoch [1/4], Step [602/3844], Loss: 0.2278\n",
      "Epoch [1/4], Step [603/3844], Loss: 0.2157\n",
      "Epoch [1/4], Step [604/3844], Loss: 0.2048\n",
      "Epoch [1/4], Step [605/3844], Loss: 0.2208\n",
      "Epoch [1/4], Step [606/3844], Loss: 0.1623\n",
      "Epoch [1/4], Step [607/3844], Loss: 0.1544\n",
      "Epoch [1/4], Step [608/3844], Loss: 0.2021\n",
      "Epoch [1/4], Step [609/3844], Loss: 0.2052\n",
      "Epoch [1/4], Step [610/3844], Loss: 0.1548\n",
      "Epoch [1/4], Step [611/3844], Loss: 0.2193\n",
      "Epoch [1/4], Step [612/3844], Loss: 0.1948\n",
      "Epoch [1/4], Step [613/3844], Loss: 0.2095\n",
      "Epoch [1/4], Step [614/3844], Loss: 0.2039\n",
      "Epoch [1/4], Step [615/3844], Loss: 0.2051\n",
      "Epoch [1/4], Step [616/3844], Loss: 0.2097\n",
      "Epoch [1/4], Step [617/3844], Loss: 0.2167\n",
      "Epoch [1/4], Step [618/3844], Loss: 0.1853\n",
      "Epoch [1/4], Step [619/3844], Loss: 0.2142\n",
      "Epoch [1/4], Step [620/3844], Loss: 0.1928\n",
      "Epoch [1/4], Step [621/3844], Loss: 0.2076\n",
      "Epoch [1/4], Step [622/3844], Loss: 0.2062\n",
      "Epoch [1/4], Step [623/3844], Loss: 0.1973\n",
      "Epoch [1/4], Step [624/3844], Loss: 0.1985\n",
      "Epoch [1/4], Step [625/3844], Loss: 0.2055\n",
      "Epoch [1/4], Step [626/3844], Loss: 0.2105\n",
      "Epoch [1/4], Step [627/3844], Loss: 0.2242\n",
      "Epoch [1/4], Step [628/3844], Loss: 0.1940\n",
      "Epoch [1/4], Step [629/3844], Loss: 0.2076\n",
      "Epoch [1/4], Step [630/3844], Loss: 0.1834\n",
      "Epoch [1/4], Step [631/3844], Loss: 0.2360\n",
      "Epoch [1/4], Step [632/3844], Loss: 0.1946\n",
      "Epoch [1/4], Step [633/3844], Loss: 0.2104\n",
      "Epoch [1/4], Step [634/3844], Loss: 0.2012\n",
      "Epoch [1/4], Step [635/3844], Loss: 0.2836\n",
      "Epoch [1/4], Step [636/3844], Loss: 0.1742\n",
      "Epoch [1/4], Step [637/3844], Loss: 0.1664\n",
      "Epoch [1/4], Step [638/3844], Loss: 0.2638\n",
      "Epoch [1/4], Step [639/3844], Loss: 0.1882\n",
      "Epoch [1/4], Step [640/3844], Loss: 0.2065\n",
      "Epoch [1/4], Step [641/3844], Loss: 0.1886\n",
      "Epoch [1/4], Step [642/3844], Loss: 0.2142\n",
      "Epoch [1/4], Step [643/3844], Loss: 0.1568\n",
      "Epoch [1/4], Step [644/3844], Loss: 0.1807\n",
      "Epoch [1/4], Step [645/3844], Loss: 0.1976\n",
      "Epoch [1/4], Step [646/3844], Loss: 0.2005\n",
      "Epoch [1/4], Step [647/3844], Loss: 0.2048\n",
      "Epoch [1/4], Step [648/3844], Loss: 0.2271\n",
      "Epoch [1/4], Step [649/3844], Loss: 0.2092\n",
      "Epoch [1/4], Step [650/3844], Loss: 0.2005\n",
      "Epoch [1/4], Step [651/3844], Loss: 0.1947\n",
      "Epoch [1/4], Step [652/3844], Loss: 0.1863\n",
      "Epoch [1/4], Step [653/3844], Loss: 0.2030\n",
      "Epoch [1/4], Step [654/3844], Loss: 0.2024\n",
      "Epoch [1/4], Step [655/3844], Loss: 0.2039\n",
      "Epoch [1/4], Step [656/3844], Loss: 0.1938\n",
      "Epoch [1/4], Step [657/3844], Loss: 0.2121\n",
      "Epoch [1/4], Step [658/3844], Loss: 0.2102\n",
      "Epoch [1/4], Step [659/3844], Loss: 0.1450\n",
      "Epoch [1/4], Step [660/3844], Loss: 0.2013\n",
      "Epoch [1/4], Step [661/3844], Loss: 0.2036\n",
      "Epoch [1/4], Step [662/3844], Loss: 0.2195\n",
      "Epoch [1/4], Step [663/3844], Loss: 0.1910\n",
      "Epoch [1/4], Step [664/3844], Loss: 0.1959\n",
      "Epoch [1/4], Step [665/3844], Loss: 0.1953\n",
      "Epoch [1/4], Step [666/3844], Loss: 0.1945\n",
      "Epoch [1/4], Step [667/3844], Loss: 0.2007\n",
      "Epoch [1/4], Step [668/3844], Loss: 0.1915\n",
      "Epoch [1/4], Step [669/3844], Loss: 0.2045\n",
      "Epoch [1/4], Step [670/3844], Loss: 0.1658\n",
      "Epoch [1/4], Step [671/3844], Loss: 0.1883\n",
      "Epoch [1/4], Step [672/3844], Loss: 0.1870\n",
      "Epoch [1/4], Step [673/3844], Loss: 0.2134\n",
      "Epoch [1/4], Step [674/3844], Loss: 0.2070\n",
      "Epoch [1/4], Step [675/3844], Loss: 0.1532\n",
      "Epoch [1/4], Step [676/3844], Loss: 0.2945\n",
      "Epoch [1/4], Step [677/3844], Loss: 0.2146\n",
      "Epoch [1/4], Step [678/3844], Loss: 0.2824\n",
      "Epoch [1/4], Step [679/3844], Loss: 0.1868\n",
      "Epoch [1/4], Step [680/3844], Loss: 0.1997\n",
      "Epoch [1/4], Step [681/3844], Loss: 0.2521\n",
      "Epoch [1/4], Step [682/3844], Loss: 0.2052\n",
      "Epoch [1/4], Step [683/3844], Loss: 0.2618\n",
      "Epoch [1/4], Step [684/3844], Loss: 0.2343\n",
      "Epoch [1/4], Step [685/3844], Loss: 0.1924\n",
      "Epoch [1/4], Step [686/3844], Loss: 0.1919\n",
      "Epoch [1/4], Step [687/3844], Loss: 0.1730\n",
      "Epoch [1/4], Step [688/3844], Loss: 0.1716\n",
      "Epoch [1/4], Step [689/3844], Loss: 0.1972\n",
      "Epoch [1/4], Step [690/3844], Loss: 0.2142\n",
      "Epoch [1/4], Step [691/3844], Loss: 0.1452\n",
      "Epoch [1/4], Step [692/3844], Loss: 0.1935\n",
      "Epoch [1/4], Step [693/3844], Loss: 0.2005\n",
      "Epoch [1/4], Step [694/3844], Loss: 0.2052\n",
      "Epoch [1/4], Step [695/3844], Loss: 0.2239\n",
      "Epoch [1/4], Step [696/3844], Loss: 0.1949\n",
      "Epoch [1/4], Step [697/3844], Loss: 0.1797\n",
      "Epoch [1/4], Step [698/3844], Loss: 0.1913\n",
      "Epoch [1/4], Step [699/3844], Loss: 0.2497\n",
      "Epoch [1/4], Step [700/3844], Loss: 0.2006\n",
      "Epoch [1/4], Step [701/3844], Loss: 0.1915\n",
      "Epoch [1/4], Step [702/3844], Loss: 0.2033\n",
      "Epoch [1/4], Step [703/3844], Loss: 0.1900\n",
      "Epoch [1/4], Step [704/3844], Loss: 0.2111\n",
      "Epoch [1/4], Step [705/3844], Loss: 0.1685\n",
      "Epoch [1/4], Step [706/3844], Loss: 0.2024\n",
      "Epoch [1/4], Step [707/3844], Loss: 0.1965\n",
      "Epoch [1/4], Step [708/3844], Loss: 0.1959\n",
      "Epoch [1/4], Step [709/3844], Loss: 0.1639\n",
      "Epoch [1/4], Step [710/3844], Loss: 0.2091\n",
      "Epoch [1/4], Step [711/3844], Loss: 0.1945\n",
      "Epoch [1/4], Step [712/3844], Loss: 0.1855\n",
      "Epoch [1/4], Step [713/3844], Loss: 0.1886\n",
      "Epoch [1/4], Step [714/3844], Loss: 0.2509\n",
      "Epoch [1/4], Step [715/3844], Loss: 0.1731\n",
      "Epoch [1/4], Step [716/3844], Loss: 0.2023\n",
      "Epoch [1/4], Step [717/3844], Loss: 0.2010\n",
      "Epoch [1/4], Step [718/3844], Loss: 0.2050\n",
      "Epoch [1/4], Step [719/3844], Loss: 0.1405\n",
      "Epoch [1/4], Step [720/3844], Loss: 0.2003\n",
      "Epoch [1/4], Step [721/3844], Loss: 0.1941\n",
      "Epoch [1/4], Step [722/3844], Loss: 0.2118\n",
      "Epoch [1/4], Step [723/3844], Loss: 0.1908\n",
      "Epoch [1/4], Step [724/3844], Loss: 0.1981\n",
      "Epoch [1/4], Step [725/3844], Loss: 0.2024\n",
      "Epoch [1/4], Step [726/3844], Loss: 0.2227\n",
      "Epoch [1/4], Step [727/3844], Loss: 0.1747\n",
      "Epoch [1/4], Step [728/3844], Loss: 0.2155\n",
      "Epoch [1/4], Step [729/3844], Loss: 0.2043\n",
      "Epoch [1/4], Step [730/3844], Loss: 0.2088\n",
      "Epoch [1/4], Step [731/3844], Loss: 0.1989\n",
      "Epoch [1/4], Step [732/3844], Loss: 0.1943\n",
      "Epoch [1/4], Step [733/3844], Loss: 0.1982\n",
      "Epoch [1/4], Step [734/3844], Loss: 0.2108\n",
      "Epoch [1/4], Step [735/3844], Loss: 0.1923\n",
      "Epoch [1/4], Step [736/3844], Loss: 0.2437\n",
      "Epoch [1/4], Step [737/3844], Loss: 0.2017\n",
      "Epoch [1/4], Step [738/3844], Loss: 0.1937\n",
      "Epoch [1/4], Step [739/3844], Loss: 0.2209\n",
      "Epoch [1/4], Step [740/3844], Loss: 0.1952\n",
      "Epoch [1/4], Step [741/3844], Loss: 0.1525\n",
      "Epoch [1/4], Step [742/3844], Loss: 0.2031\n",
      "Epoch [1/4], Step [743/3844], Loss: 0.1975\n",
      "Epoch [1/4], Step [744/3844], Loss: 0.2036\n",
      "Epoch [1/4], Step [745/3844], Loss: 0.1602\n",
      "Epoch [1/4], Step [746/3844], Loss: 0.2024\n",
      "Epoch [1/4], Step [747/3844], Loss: 0.2158\n",
      "Epoch [1/4], Step [748/3844], Loss: 0.2302\n",
      "Epoch [1/4], Step [749/3844], Loss: 0.1913\n",
      "Epoch [1/4], Step [750/3844], Loss: 0.2017\n",
      "Epoch [1/4], Step [751/3844], Loss: 0.1869\n",
      "Epoch [1/4], Step [752/3844], Loss: 0.2066\n",
      "Epoch [1/4], Step [753/3844], Loss: 0.1631\n",
      "Epoch [1/4], Step [754/3844], Loss: 0.2052\n",
      "Epoch [1/4], Step [755/3844], Loss: 0.1948\n",
      "Epoch [1/4], Step [756/3844], Loss: 0.1761\n",
      "Epoch [1/4], Step [757/3844], Loss: 0.1958\n",
      "Epoch [1/4], Step [758/3844], Loss: 0.1667\n",
      "Epoch [1/4], Step [759/3844], Loss: 0.1956\n",
      "Epoch [1/4], Step [760/3844], Loss: 0.1665\n",
      "Epoch [1/4], Step [761/3844], Loss: 0.2208\n",
      "Epoch [1/4], Step [762/3844], Loss: 0.2396\n",
      "Epoch [1/4], Step [763/3844], Loss: 0.2015\n",
      "Epoch [1/4], Step [764/3844], Loss: 0.2161\n",
      "Epoch [1/4], Step [765/3844], Loss: 0.1518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [766/3844], Loss: 0.2028\n",
      "Epoch [1/4], Step [767/3844], Loss: 0.2250\n",
      "Epoch [1/4], Step [768/3844], Loss: 0.2201\n",
      "Epoch [1/4], Step [769/3844], Loss: 0.1909\n",
      "Epoch [1/4], Step [770/3844], Loss: 0.1858\n",
      "Epoch [1/4], Step [771/3844], Loss: 0.2025\n",
      "Epoch [1/4], Step [772/3844], Loss: 0.2159\n",
      "Epoch [1/4], Step [773/3844], Loss: 0.1990\n",
      "Epoch [1/4], Step [774/3844], Loss: 0.2220\n",
      "Epoch [1/4], Step [775/3844], Loss: 0.2051\n",
      "Epoch [1/4], Step [776/3844], Loss: 0.1959\n",
      "Epoch [1/4], Step [777/3844], Loss: 0.1862\n",
      "Epoch [1/4], Step [778/3844], Loss: 0.2038\n",
      "Epoch [1/4], Step [779/3844], Loss: 0.2187\n",
      "Epoch [1/4], Step [780/3844], Loss: 0.1910\n",
      "Epoch [1/4], Step [781/3844], Loss: 0.2582\n",
      "Epoch [1/4], Step [782/3844], Loss: 0.2402\n",
      "Epoch [1/4], Step [783/3844], Loss: 0.1939\n",
      "Epoch [1/4], Step [784/3844], Loss: 0.2011\n",
      "Epoch [1/4], Step [785/3844], Loss: 0.1807\n",
      "Epoch [1/4], Step [786/3844], Loss: 0.2019\n",
      "Epoch [1/4], Step [787/3844], Loss: 0.1635\n",
      "Epoch [1/4], Step [788/3844], Loss: 0.1915\n",
      "Epoch [1/4], Step [789/3844], Loss: 0.1914\n",
      "Epoch [1/4], Step [790/3844], Loss: 0.1954\n",
      "Epoch [1/4], Step [791/3844], Loss: 0.2507\n",
      "Epoch [1/4], Step [792/3844], Loss: 0.1804\n",
      "Epoch [1/4], Step [793/3844], Loss: 0.2033\n",
      "Epoch [1/4], Step [794/3844], Loss: 0.1958\n",
      "Epoch [1/4], Step [795/3844], Loss: 0.2298\n",
      "Epoch [1/4], Step [796/3844], Loss: 0.2079\n",
      "Epoch [1/4], Step [797/3844], Loss: 0.2051\n",
      "Epoch [1/4], Step [798/3844], Loss: 0.2075\n",
      "Epoch [1/4], Step [799/3844], Loss: 0.1967\n",
      "Epoch [1/4], Step [800/3844], Loss: 0.2116\n",
      "Epoch [1/4], Step [801/3844], Loss: 0.1807\n",
      "Epoch [1/4], Step [802/3844], Loss: 0.1979\n",
      "Epoch [1/4], Step [803/3844], Loss: 0.1829\n",
      "Epoch [1/4], Step [804/3844], Loss: 0.1901\n",
      "Epoch [1/4], Step [805/3844], Loss: 0.1675\n",
      "Epoch [1/4], Step [806/3844], Loss: 0.2036\n",
      "Epoch [1/4], Step [807/3844], Loss: 0.2010\n",
      "Epoch [1/4], Step [808/3844], Loss: 0.2509\n",
      "Epoch [1/4], Step [809/3844], Loss: 0.1955\n",
      "Epoch [1/4], Step [810/3844], Loss: 0.2483\n",
      "Epoch [1/4], Step [811/3844], Loss: 0.1969\n",
      "Epoch [1/4], Step [812/3844], Loss: 0.2010\n",
      "Epoch [1/4], Step [813/3844], Loss: 0.1344\n",
      "Epoch [1/4], Step [814/3844], Loss: 0.1892\n",
      "Epoch [1/4], Step [815/3844], Loss: 0.1867\n",
      "Epoch [1/4], Step [816/3844], Loss: 0.1996\n",
      "Epoch [1/4], Step [817/3844], Loss: 0.1751\n",
      "Epoch [1/4], Step [818/3844], Loss: 0.1952\n",
      "Epoch [1/4], Step [819/3844], Loss: 0.1964\n",
      "Epoch [1/4], Step [820/3844], Loss: 0.1915\n",
      "Epoch [1/4], Step [821/3844], Loss: 0.1929\n",
      "Epoch [1/4], Step [822/3844], Loss: 0.2092\n",
      "Epoch [1/4], Step [823/3844], Loss: 0.2082\n",
      "Epoch [1/4], Step [824/3844], Loss: 0.2049\n",
      "Epoch [1/4], Step [825/3844], Loss: 0.2035\n",
      "Epoch [1/4], Step [826/3844], Loss: 0.2612\n",
      "Epoch [1/4], Step [827/3844], Loss: 0.1669\n",
      "Epoch [1/4], Step [828/3844], Loss: 0.3037\n",
      "Epoch [1/4], Step [829/3844], Loss: 0.1407\n",
      "Epoch [1/4], Step [830/3844], Loss: 0.2164\n",
      "Epoch [1/4], Step [831/3844], Loss: 0.1912\n",
      "Epoch [1/4], Step [832/3844], Loss: 0.2019\n",
      "Epoch [1/4], Step [833/3844], Loss: 0.1991\n",
      "Epoch [1/4], Step [834/3844], Loss: 0.2007\n",
      "Epoch [1/4], Step [835/3844], Loss: 0.2048\n",
      "Epoch [1/4], Step [836/3844], Loss: 0.2151\n",
      "Epoch [1/4], Step [837/3844], Loss: 0.1903\n",
      "Epoch [1/4], Step [838/3844], Loss: 0.1847\n",
      "Epoch [1/4], Step [839/3844], Loss: 0.2116\n",
      "Epoch [1/4], Step [840/3844], Loss: 0.1938\n",
      "Epoch [1/4], Step [841/3844], Loss: 0.1901\n",
      "Epoch [1/4], Step [842/3844], Loss: 0.1820\n",
      "Epoch [1/4], Step [843/3844], Loss: 0.2137\n",
      "Epoch [1/4], Step [844/3844], Loss: 0.1985\n",
      "Epoch [1/4], Step [845/3844], Loss: 0.1609\n",
      "Epoch [1/4], Step [846/3844], Loss: 0.2180\n",
      "Epoch [1/4], Step [847/3844], Loss: 0.1796\n",
      "Epoch [1/4], Step [848/3844], Loss: 0.1905\n",
      "Epoch [1/4], Step [849/3844], Loss: 0.1985\n",
      "Epoch [1/4], Step [850/3844], Loss: 0.1911\n",
      "Epoch [1/4], Step [851/3844], Loss: 0.1507\n",
      "Epoch [1/4], Step [852/3844], Loss: 0.2165\n",
      "Epoch [1/4], Step [853/3844], Loss: 0.1976\n",
      "Epoch [1/4], Step [854/3844], Loss: 0.1951\n",
      "Epoch [1/4], Step [855/3844], Loss: 0.2573\n",
      "Epoch [1/4], Step [856/3844], Loss: 0.1700\n",
      "Epoch [1/4], Step [857/3844], Loss: 0.2057\n",
      "Epoch [1/4], Step [858/3844], Loss: 0.1919\n",
      "Epoch [1/4], Step [859/3844], Loss: 0.1863\n",
      "Epoch [1/4], Step [860/3844], Loss: 0.1944\n",
      "Epoch [1/4], Step [861/3844], Loss: 0.1568\n",
      "Epoch [1/4], Step [862/3844], Loss: 0.2040\n",
      "Epoch [1/4], Step [863/3844], Loss: 0.2031\n",
      "Epoch [1/4], Step [864/3844], Loss: 0.1980\n",
      "Epoch [1/4], Step [865/3844], Loss: 0.1988\n",
      "Epoch [1/4], Step [866/3844], Loss: 0.2287\n",
      "Epoch [1/4], Step [867/3844], Loss: 0.2554\n",
      "Epoch [1/4], Step [868/3844], Loss: 0.1896\n",
      "Epoch [1/4], Step [869/3844], Loss: 0.1612\n",
      "Epoch [1/4], Step [870/3844], Loss: 0.1871\n",
      "Epoch [1/4], Step [871/3844], Loss: 0.2006\n",
      "Epoch [1/4], Step [872/3844], Loss: 0.2361\n",
      "Epoch [1/4], Step [873/3844], Loss: 0.1411\n",
      "Epoch [1/4], Step [874/3844], Loss: 0.2071\n",
      "Epoch [1/4], Step [875/3844], Loss: 0.2180\n",
      "Epoch [1/4], Step [876/3844], Loss: 0.1955\n",
      "Epoch [1/4], Step [877/3844], Loss: 0.1895\n",
      "Epoch [1/4], Step [878/3844], Loss: 0.2234\n",
      "Epoch [1/4], Step [879/3844], Loss: 0.1885\n",
      "Epoch [1/4], Step [880/3844], Loss: 0.2071\n",
      "Epoch [1/4], Step [881/3844], Loss: 0.1967\n",
      "Epoch [1/4], Step [882/3844], Loss: 0.2052\n",
      "Epoch [1/4], Step [883/3844], Loss: 0.1989\n",
      "Epoch [1/4], Step [884/3844], Loss: 0.2072\n",
      "Epoch [1/4], Step [885/3844], Loss: 0.1935\n",
      "Epoch [1/4], Step [886/3844], Loss: 0.1868\n",
      "Epoch [1/4], Step [887/3844], Loss: 0.1917\n",
      "Epoch [1/4], Step [888/3844], Loss: 0.1802\n",
      "Epoch [1/4], Step [889/3844], Loss: 0.1939\n",
      "Epoch [1/4], Step [890/3844], Loss: 0.1387\n",
      "Epoch [1/4], Step [891/3844], Loss: 0.1798\n",
      "Epoch [1/4], Step [892/3844], Loss: 0.2077\n",
      "Epoch [1/4], Step [893/3844], Loss: 0.1342\n",
      "Epoch [1/4], Step [894/3844], Loss: 0.1846\n",
      "Epoch [1/4], Step [895/3844], Loss: 0.2152\n",
      "Epoch [1/4], Step [896/3844], Loss: 0.1612\n",
      "Epoch [1/4], Step [897/3844], Loss: 0.2026\n",
      "Epoch [1/4], Step [898/3844], Loss: 0.2069\n",
      "Epoch [1/4], Step [899/3844], Loss: 0.1865\n",
      "Epoch [1/4], Step [900/3844], Loss: 0.2080\n",
      "Epoch [1/4], Step [901/3844], Loss: 0.1790\n",
      "Epoch [1/4], Step [902/3844], Loss: 0.2192\n",
      "Epoch [1/4], Step [903/3844], Loss: 0.1930\n",
      "Epoch [1/4], Step [904/3844], Loss: 0.1637\n",
      "Epoch [1/4], Step [905/3844], Loss: 0.2083\n",
      "Epoch [1/4], Step [906/3844], Loss: 0.1812\n",
      "Epoch [1/4], Step [907/3844], Loss: 0.1940\n",
      "Epoch [1/4], Step [908/3844], Loss: 0.1897\n",
      "Epoch [1/4], Step [909/3844], Loss: 0.1874\n",
      "Epoch [1/4], Step [910/3844], Loss: 0.2125\n",
      "Epoch [1/4], Step [911/3844], Loss: 0.2204\n",
      "Epoch [1/4], Step [912/3844], Loss: 0.1806\n",
      "Epoch [1/4], Step [913/3844], Loss: 0.1994\n",
      "Epoch [1/4], Step [914/3844], Loss: 0.1933\n",
      "Epoch [1/4], Step [915/3844], Loss: 0.1650\n",
      "Epoch [1/4], Step [916/3844], Loss: 0.1946\n",
      "Epoch [1/4], Step [917/3844], Loss: 0.1970\n",
      "Epoch [1/4], Step [918/3844], Loss: 0.1855\n",
      "Epoch [1/4], Step [919/3844], Loss: 0.1915\n",
      "Epoch [1/4], Step [920/3844], Loss: 0.1477\n",
      "Epoch [1/4], Step [921/3844], Loss: 0.1477\n",
      "Epoch [1/4], Step [922/3844], Loss: 0.1893\n",
      "Epoch [1/4], Step [923/3844], Loss: 0.1363\n",
      "Epoch [1/4], Step [924/3844], Loss: 0.1955\n",
      "Epoch [1/4], Step [925/3844], Loss: 0.2022\n",
      "Epoch [1/4], Step [926/3844], Loss: 0.2233\n",
      "Epoch [1/4], Step [927/3844], Loss: 0.2031\n",
      "Epoch [1/4], Step [928/3844], Loss: 0.1617\n",
      "Epoch [1/4], Step [929/3844], Loss: 0.2012\n",
      "Epoch [1/4], Step [930/3844], Loss: 0.2002\n",
      "Epoch [1/4], Step [931/3844], Loss: 0.2169\n",
      "Epoch [1/4], Step [932/3844], Loss: 0.1500\n",
      "Epoch [1/4], Step [933/3844], Loss: 0.2077\n",
      "Epoch [1/4], Step [934/3844], Loss: 0.2133\n",
      "Epoch [1/4], Step [935/3844], Loss: 0.1956\n",
      "Epoch [1/4], Step [936/3844], Loss: 0.2030\n",
      "Epoch [1/4], Step [937/3844], Loss: 0.1958\n",
      "Epoch [1/4], Step [938/3844], Loss: 0.1819\n",
      "Epoch [1/4], Step [939/3844], Loss: 0.2337\n",
      "Epoch [1/4], Step [940/3844], Loss: 0.1968\n",
      "Epoch [1/4], Step [941/3844], Loss: 0.1899\n",
      "Epoch [1/4], Step [942/3844], Loss: 0.1980\n",
      "Epoch [1/4], Step [943/3844], Loss: 0.2249\n",
      "Epoch [1/4], Step [944/3844], Loss: 0.1991\n",
      "Epoch [1/4], Step [945/3844], Loss: 0.2012\n",
      "Epoch [1/4], Step [946/3844], Loss: 0.1939\n",
      "Epoch [1/4], Step [947/3844], Loss: 0.1883\n",
      "Epoch [1/4], Step [948/3844], Loss: 0.2545\n",
      "Epoch [1/4], Step [949/3844], Loss: 0.2035\n",
      "Epoch [1/4], Step [950/3844], Loss: 0.1568\n",
      "Epoch [1/4], Step [951/3844], Loss: 0.1707\n",
      "Epoch [1/4], Step [952/3844], Loss: 0.1594\n",
      "Epoch [1/4], Step [953/3844], Loss: 0.1976\n",
      "Epoch [1/4], Step [954/3844], Loss: 0.2095\n",
      "Epoch [1/4], Step [955/3844], Loss: 0.2065\n",
      "Epoch [1/4], Step [956/3844], Loss: 0.1861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [957/3844], Loss: 0.1800\n",
      "Epoch [1/4], Step [958/3844], Loss: 0.1886\n",
      "Epoch [1/4], Step [959/3844], Loss: 0.2239\n",
      "Epoch [1/4], Step [960/3844], Loss: 0.1910\n",
      "Epoch [1/4], Step [961/3844], Loss: 0.2033\n",
      "Epoch [1/4], Step [962/3844], Loss: 0.2051\n",
      "Epoch [1/4], Step [963/3844], Loss: 0.1695\n",
      "Epoch [1/4], Step [964/3844], Loss: 0.1803\n",
      "Epoch [1/4], Step [965/3844], Loss: 0.1558\n",
      "Epoch [1/4], Step [966/3844], Loss: 0.1991\n",
      "Epoch [1/4], Step [967/3844], Loss: 0.1926\n",
      "Epoch [1/4], Step [968/3844], Loss: 0.2062\n",
      "Epoch [1/4], Step [969/3844], Loss: 0.2038\n",
      "Epoch [1/4], Step [970/3844], Loss: 0.1935\n",
      "Epoch [1/4], Step [971/3844], Loss: 0.1929\n",
      "Epoch [1/4], Step [972/3844], Loss: 0.2047\n",
      "Epoch [1/4], Step [973/3844], Loss: 0.1983\n",
      "Epoch [1/4], Step [974/3844], Loss: 0.2333\n",
      "Epoch [1/4], Step [975/3844], Loss: 0.1971\n",
      "Epoch [1/4], Step [976/3844], Loss: 0.2361\n",
      "Epoch [1/4], Step [977/3844], Loss: 0.1991\n",
      "Epoch [1/4], Step [978/3844], Loss: 0.2037\n",
      "Epoch [1/4], Step [979/3844], Loss: 0.1960\n",
      "Epoch [1/4], Step [980/3844], Loss: 0.1876\n",
      "Epoch [1/4], Step [981/3844], Loss: 0.1847\n",
      "Epoch [1/4], Step [982/3844], Loss: 0.2231\n",
      "Epoch [1/4], Step [983/3844], Loss: 0.1841\n",
      "Epoch [1/4], Step [984/3844], Loss: 0.2031\n",
      "Epoch [1/4], Step [985/3844], Loss: 0.2029\n",
      "Epoch [1/4], Step [986/3844], Loss: 0.1433\n",
      "Epoch [1/4], Step [987/3844], Loss: 0.2703\n",
      "Epoch [1/4], Step [988/3844], Loss: 0.1959\n",
      "Epoch [1/4], Step [989/3844], Loss: 0.1854\n",
      "Epoch [1/4], Step [990/3844], Loss: 0.2154\n",
      "Epoch [1/4], Step [991/3844], Loss: 0.1933\n",
      "Epoch [1/4], Step [992/3844], Loss: 0.2600\n",
      "Epoch [1/4], Step [993/3844], Loss: 0.2386\n",
      "Epoch [1/4], Step [994/3844], Loss: 0.2169\n",
      "Epoch [1/4], Step [995/3844], Loss: 0.2362\n",
      "Epoch [1/4], Step [996/3844], Loss: 0.1972\n",
      "Epoch [1/4], Step [997/3844], Loss: 0.1954\n",
      "Epoch [1/4], Step [998/3844], Loss: 0.1844\n",
      "Epoch [1/4], Step [999/3844], Loss: 0.1843\n",
      "Epoch [1/4], Step [1000/3844], Loss: 0.1969\n",
      "Epoch [1/4], Step [1001/3844], Loss: 0.1971\n",
      "Epoch [1/4], Step [1002/3844], Loss: 0.1961\n",
      "Epoch [1/4], Step [1003/3844], Loss: 0.2023\n",
      "Epoch [1/4], Step [1004/3844], Loss: 0.1920\n",
      "Epoch [1/4], Step [1005/3844], Loss: 0.1961\n",
      "Epoch [1/4], Step [1006/3844], Loss: 0.2078\n",
      "Epoch [1/4], Step [1007/3844], Loss: 0.2316\n",
      "Epoch [1/4], Step [1008/3844], Loss: 0.2001\n",
      "Epoch [1/4], Step [1009/3844], Loss: 0.1895\n",
      "Epoch [1/4], Step [1010/3844], Loss: 0.1915\n",
      "Epoch [1/4], Step [1011/3844], Loss: 0.1901\n",
      "Epoch [1/4], Step [1012/3844], Loss: 0.2292\n",
      "Epoch [1/4], Step [1013/3844], Loss: 0.1840\n",
      "Epoch [1/4], Step [1014/3844], Loss: 0.1730\n",
      "Epoch [1/4], Step [1015/3844], Loss: 0.1983\n",
      "Epoch [1/4], Step [1016/3844], Loss: 0.1982\n",
      "Epoch [1/4], Step [1017/3844], Loss: 0.1980\n",
      "Epoch [1/4], Step [1018/3844], Loss: 0.2133\n",
      "Epoch [1/4], Step [1019/3844], Loss: 0.1685\n",
      "Epoch [1/4], Step [1020/3844], Loss: 0.2093\n",
      "Epoch [1/4], Step [1021/3844], Loss: 0.1915\n",
      "Epoch [1/4], Step [1022/3844], Loss: 0.3357\n",
      "Epoch [1/4], Step [1023/3844], Loss: 0.1787\n",
      "Epoch [1/4], Step [1024/3844], Loss: 0.1989\n",
      "Epoch [1/4], Step [1025/3844], Loss: 0.1738\n",
      "Epoch [1/4], Step [1026/3844], Loss: 0.1754\n",
      "Epoch [1/4], Step [1027/3844], Loss: 0.2015\n",
      "Epoch [1/4], Step [1028/3844], Loss: 0.2479\n",
      "Epoch [1/4], Step [1029/3844], Loss: 0.1975\n",
      "Epoch [1/4], Step [1030/3844], Loss: 0.2017\n",
      "Epoch [1/4], Step [1031/3844], Loss: 0.2335\n",
      "Epoch [1/4], Step [1032/3844], Loss: 0.1856\n",
      "Epoch [1/4], Step [1033/3844], Loss: 0.1628\n",
      "Epoch [1/4], Step [1034/3844], Loss: 0.1861\n",
      "Epoch [1/4], Step [1035/3844], Loss: 0.1945\n",
      "Epoch [1/4], Step [1036/3844], Loss: 0.1791\n",
      "Epoch [1/4], Step [1037/3844], Loss: 0.1706\n",
      "Epoch [1/4], Step [1038/3844], Loss: 0.1967\n",
      "Epoch [1/4], Step [1039/3844], Loss: 0.2084\n",
      "Epoch [1/4], Step [1040/3844], Loss: 0.1761\n",
      "Epoch [1/4], Step [1041/3844], Loss: 0.2083\n",
      "Epoch [1/4], Step [1042/3844], Loss: 0.1892\n",
      "Epoch [1/4], Step [1043/3844], Loss: 0.2870\n",
      "Epoch [1/4], Step [1044/3844], Loss: 0.1941\n",
      "Epoch [1/4], Step [1045/3844], Loss: 0.1895\n",
      "Epoch [1/4], Step [1046/3844], Loss: 0.2722\n",
      "Epoch [1/4], Step [1047/3844], Loss: 0.1632\n",
      "Epoch [1/4], Step [1048/3844], Loss: 0.1906\n",
      "Epoch [1/4], Step [1049/3844], Loss: 0.1902\n",
      "Epoch [1/4], Step [1050/3844], Loss: 0.1999\n",
      "Epoch [1/4], Step [1051/3844], Loss: 0.2055\n",
      "Epoch [1/4], Step [1052/3844], Loss: 0.1985\n",
      "Epoch [1/4], Step [1053/3844], Loss: 0.1903\n",
      "Epoch [1/4], Step [1054/3844], Loss: 0.2174\n",
      "Epoch [1/4], Step [1055/3844], Loss: 0.2722\n",
      "Epoch [1/4], Step [1056/3844], Loss: 0.2002\n",
      "Epoch [1/4], Step [1057/3844], Loss: 0.1820\n",
      "Epoch [1/4], Step [1058/3844], Loss: 0.1902\n",
      "Epoch [1/4], Step [1059/3844], Loss: 0.1861\n",
      "Epoch [1/4], Step [1060/3844], Loss: 0.2093\n",
      "Epoch [1/4], Step [1061/3844], Loss: 0.2341\n",
      "Epoch [1/4], Step [1062/3844], Loss: 0.2607\n",
      "Epoch [1/4], Step [1063/3844], Loss: 0.2031\n",
      "Epoch [1/4], Step [1064/3844], Loss: 0.2264\n",
      "Epoch [1/4], Step [1065/3844], Loss: 0.1947\n",
      "Epoch [1/4], Step [1066/3844], Loss: 0.2073\n",
      "Epoch [1/4], Step [1067/3844], Loss: 0.1884\n",
      "Epoch [1/4], Step [1068/3844], Loss: 0.1975\n",
      "Epoch [1/4], Step [1069/3844], Loss: 0.2524\n",
      "Epoch [1/4], Step [1070/3844], Loss: 0.1860\n",
      "Epoch [1/4], Step [1071/3844], Loss: 0.1897\n",
      "Epoch [1/4], Step [1072/3844], Loss: 0.1911\n",
      "Epoch [1/4], Step [1073/3844], Loss: 0.2298\n",
      "Epoch [1/4], Step [1074/3844], Loss: 0.1672\n",
      "Epoch [1/4], Step [1075/3844], Loss: 0.1888\n",
      "Epoch [1/4], Step [1076/3844], Loss: 0.1843\n",
      "Epoch [1/4], Step [1077/3844], Loss: 0.2158\n",
      "Epoch [1/4], Step [1078/3844], Loss: 0.1989\n",
      "Epoch [1/4], Step [1079/3844], Loss: 0.1832\n",
      "Epoch [1/4], Step [1080/3844], Loss: 0.1718\n",
      "Epoch [1/4], Step [1081/3844], Loss: 0.1921\n",
      "Epoch [1/4], Step [1082/3844], Loss: 0.2068\n",
      "Epoch [1/4], Step [1083/3844], Loss: 0.1647\n",
      "Epoch [1/4], Step [1084/3844], Loss: 0.2034\n",
      "Epoch [1/4], Step [1085/3844], Loss: 0.1803\n",
      "Epoch [1/4], Step [1086/3844], Loss: 0.2371\n",
      "Epoch [1/4], Step [1087/3844], Loss: 0.2128\n",
      "Epoch [1/4], Step [1088/3844], Loss: 0.1701\n",
      "Epoch [1/4], Step [1089/3844], Loss: 0.1538\n",
      "Epoch [1/4], Step [1090/3844], Loss: 0.1791\n",
      "Epoch [1/4], Step [1091/3844], Loss: 0.2108\n",
      "Epoch [1/4], Step [1092/3844], Loss: 0.2424\n",
      "Epoch [1/4], Step [1093/3844], Loss: 0.1796\n",
      "Epoch [1/4], Step [1094/3844], Loss: 0.1992\n",
      "Epoch [1/4], Step [1095/3844], Loss: 0.1999\n",
      "Epoch [1/4], Step [1096/3844], Loss: 0.1662\n",
      "Epoch [1/4], Step [1097/3844], Loss: 0.1980\n",
      "Epoch [1/4], Step [1098/3844], Loss: 0.1740\n",
      "Epoch [1/4], Step [1099/3844], Loss: 0.2048\n",
      "Epoch [1/4], Step [1100/3844], Loss: 0.2375\n",
      "Epoch [1/4], Step [1101/3844], Loss: 0.2115\n",
      "Epoch [1/4], Step [1102/3844], Loss: 0.2058\n",
      "Epoch [1/4], Step [1103/3844], Loss: 0.1911\n",
      "Epoch [1/4], Step [1104/3844], Loss: 0.1991\n",
      "Epoch [1/4], Step [1105/3844], Loss: 0.1877\n",
      "Epoch [1/4], Step [1106/3844], Loss: 0.1739\n",
      "Epoch [1/4], Step [1107/3844], Loss: 0.1853\n",
      "Epoch [1/4], Step [1108/3844], Loss: 0.1940\n",
      "Epoch [1/4], Step [1109/3844], Loss: 0.2260\n",
      "Epoch [1/4], Step [1110/3844], Loss: 0.1955\n",
      "Epoch [1/4], Step [1111/3844], Loss: 0.1698\n",
      "Epoch [1/4], Step [1112/3844], Loss: 0.1881\n",
      "Epoch [1/4], Step [1113/3844], Loss: 0.1932\n",
      "Epoch [1/4], Step [1114/3844], Loss: 0.1679\n",
      "Epoch [1/4], Step [1115/3844], Loss: 0.1925\n",
      "Epoch [1/4], Step [1116/3844], Loss: 0.1979\n",
      "Epoch [1/4], Step [1117/3844], Loss: 0.1849\n",
      "Epoch [1/4], Step [1118/3844], Loss: 0.1921\n",
      "Epoch [1/4], Step [1119/3844], Loss: 0.1854\n",
      "Epoch [1/4], Step [1120/3844], Loss: 0.2465\n",
      "Epoch [1/4], Step [1121/3844], Loss: 0.1746\n",
      "Epoch [1/4], Step [1122/3844], Loss: 0.1690\n",
      "Epoch [1/4], Step [1123/3844], Loss: 0.1651\n",
      "Epoch [1/4], Step [1124/3844], Loss: 0.1865\n",
      "Epoch [1/4], Step [1125/3844], Loss: 0.1706\n",
      "Epoch [1/4], Step [1126/3844], Loss: 0.1535\n",
      "Epoch [1/4], Step [1127/3844], Loss: 0.1808\n",
      "Epoch [1/4], Step [1128/3844], Loss: 0.1837\n",
      "Epoch [1/4], Step [1129/3844], Loss: 0.2495\n",
      "Epoch [1/4], Step [1130/3844], Loss: 0.1973\n",
      "Epoch [1/4], Step [1131/3844], Loss: 0.2424\n",
      "Epoch [1/4], Step [1132/3844], Loss: 0.2158\n",
      "Epoch [1/4], Step [1133/3844], Loss: 0.1859\n",
      "Epoch [1/4], Step [1134/3844], Loss: 0.1862\n",
      "Epoch [1/4], Step [1135/3844], Loss: 0.1823\n",
      "Epoch [1/4], Step [1136/3844], Loss: 0.1752\n",
      "Epoch [1/4], Step [1137/3844], Loss: 0.1705\n",
      "Epoch [1/4], Step [1138/3844], Loss: 0.1886\n",
      "Epoch [1/4], Step [1139/3844], Loss: 0.1999\n",
      "Epoch [1/4], Step [1140/3844], Loss: 0.1999\n",
      "Epoch [1/4], Step [1141/3844], Loss: 0.2122\n",
      "Epoch [1/4], Step [1142/3844], Loss: 0.2418\n",
      "Epoch [1/4], Step [1143/3844], Loss: 0.1766\n",
      "Epoch [1/4], Step [1144/3844], Loss: 0.1686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [1145/3844], Loss: 0.1890\n",
      "Epoch [1/4], Step [1146/3844], Loss: 0.1838\n",
      "Epoch [1/4], Step [1147/3844], Loss: 0.2078\n",
      "Epoch [1/4], Step [1148/3844], Loss: 0.1842\n",
      "Epoch [1/4], Step [1149/3844], Loss: 0.1970\n",
      "Epoch [1/4], Step [1150/3844], Loss: 0.2124\n",
      "Epoch [1/4], Step [1151/3844], Loss: 0.1812\n",
      "Epoch [1/4], Step [1152/3844], Loss: 0.1922\n",
      "Epoch [1/4], Step [1153/3844], Loss: 0.2503\n",
      "Epoch [1/4], Step [1154/3844], Loss: 0.1972\n",
      "Epoch [1/4], Step [1155/3844], Loss: 0.2193\n",
      "Epoch [1/4], Step [1156/3844], Loss: 0.1910\n",
      "Epoch [1/4], Step [1157/3844], Loss: 0.2428\n",
      "Epoch [1/4], Step [1158/3844], Loss: 0.1729\n",
      "Epoch [1/4], Step [1159/3844], Loss: 0.1832\n",
      "Epoch [1/4], Step [1160/3844], Loss: 0.3010\n",
      "Epoch [1/4], Step [1161/3844], Loss: 0.1925\n",
      "Epoch [1/4], Step [1162/3844], Loss: 0.2114\n",
      "Epoch [1/4], Step [1163/3844], Loss: 0.2011\n",
      "Epoch [1/4], Step [1164/3844], Loss: 0.1530\n",
      "Epoch [1/4], Step [1165/3844], Loss: 0.1974\n",
      "Epoch [1/4], Step [1166/3844], Loss: 0.1978\n",
      "Epoch [1/4], Step [1167/3844], Loss: 0.1582\n",
      "Epoch [1/4], Step [1168/3844], Loss: 0.1950\n",
      "Epoch [1/4], Step [1169/3844], Loss: 0.2398\n",
      "Epoch [1/4], Step [1170/3844], Loss: 0.1777\n",
      "Epoch [1/4], Step [1171/3844], Loss: 0.1998\n",
      "Epoch [1/4], Step [1172/3844], Loss: 0.1823\n",
      "Epoch [1/4], Step [1173/3844], Loss: 0.1580\n",
      "Epoch [1/4], Step [1174/3844], Loss: 0.2065\n",
      "Epoch [1/4], Step [1175/3844], Loss: 0.1749\n",
      "Epoch [1/4], Step [1176/3844], Loss: 0.1929\n",
      "Epoch [1/4], Step [1177/3844], Loss: 0.1911\n",
      "Epoch [1/4], Step [1178/3844], Loss: 0.2031\n",
      "Epoch [1/4], Step [1179/3844], Loss: 0.2210\n",
      "Epoch [1/4], Step [1180/3844], Loss: 0.2124\n",
      "Epoch [1/4], Step [1181/3844], Loss: 0.2192\n",
      "Epoch [1/4], Step [1182/3844], Loss: 0.1768\n",
      "Epoch [1/4], Step [1183/3844], Loss: 0.2716\n",
      "Epoch [1/4], Step [1184/3844], Loss: 0.1898\n",
      "Epoch [1/4], Step [1185/3844], Loss: 0.2037\n",
      "Epoch [1/4], Step [1186/3844], Loss: 0.2376\n",
      "Epoch [1/4], Step [1187/3844], Loss: 0.1848\n",
      "Epoch [1/4], Step [1188/3844], Loss: 0.1905\n",
      "Epoch [1/4], Step [1189/3844], Loss: 0.1786\n",
      "Epoch [1/4], Step [1190/3844], Loss: 0.1773\n",
      "Epoch [1/4], Step [1191/3844], Loss: 0.1973\n",
      "Epoch [1/4], Step [1192/3844], Loss: 0.1991\n",
      "Epoch [1/4], Step [1193/3844], Loss: 0.1812\n",
      "Epoch [1/4], Step [1194/3844], Loss: 0.1669\n",
      "Epoch [1/4], Step [1195/3844], Loss: 0.1577\n",
      "Epoch [1/4], Step [1196/3844], Loss: 0.1888\n",
      "Epoch [1/4], Step [1197/3844], Loss: 0.1940\n",
      "Epoch [1/4], Step [1198/3844], Loss: 0.2047\n",
      "Epoch [1/4], Step [1199/3844], Loss: 0.1731\n",
      "Epoch [1/4], Step [1200/3844], Loss: 0.2033\n",
      "Epoch [1/4], Step [1201/3844], Loss: 0.1711\n",
      "Epoch [1/4], Step [1202/3844], Loss: 0.2417\n",
      "Epoch [1/4], Step [1203/3844], Loss: 0.1903\n",
      "Epoch [1/4], Step [1204/3844], Loss: 0.1795\n",
      "Epoch [1/4], Step [1205/3844], Loss: 0.1830\n",
      "Epoch [1/4], Step [1206/3844], Loss: 0.1795\n",
      "Epoch [1/4], Step [1207/3844], Loss: 0.1557\n",
      "Epoch [1/4], Step [1208/3844], Loss: 0.1888\n",
      "Epoch [1/4], Step [1209/3844], Loss: 0.1827\n",
      "Epoch [1/4], Step [1210/3844], Loss: 0.1469\n",
      "Epoch [1/4], Step [1211/3844], Loss: 0.1908\n",
      "Epoch [1/4], Step [1212/3844], Loss: 0.2021\n",
      "Epoch [1/4], Step [1213/3844], Loss: 0.1881\n",
      "Epoch [1/4], Step [1214/3844], Loss: 0.1686\n",
      "Epoch [1/4], Step [1215/3844], Loss: 0.2180\n",
      "Epoch [1/4], Step [1216/3844], Loss: 0.1800\n",
      "Epoch [1/4], Step [1217/3844], Loss: 0.1968\n",
      "Epoch [1/4], Step [1218/3844], Loss: 0.1750\n",
      "Epoch [1/4], Step [1219/3844], Loss: 0.2020\n",
      "Epoch [1/4], Step [1220/3844], Loss: 0.1669\n",
      "Epoch [1/4], Step [1221/3844], Loss: 0.1886\n",
      "Epoch [1/4], Step [1222/3844], Loss: 0.1805\n",
      "Epoch [1/4], Step [1223/3844], Loss: 0.1712\n",
      "Epoch [1/4], Step [1224/3844], Loss: 0.2257\n",
      "Epoch [1/4], Step [1225/3844], Loss: 0.1651\n",
      "Epoch [1/4], Step [1226/3844], Loss: 0.1762\n",
      "Epoch [1/4], Step [1227/3844], Loss: 0.1906\n",
      "Epoch [1/4], Step [1228/3844], Loss: 0.1470\n",
      "Epoch [1/4], Step [1229/3844], Loss: 0.1696\n",
      "Epoch [1/4], Step [1230/3844], Loss: 0.2029\n",
      "Epoch [1/4], Step [1231/3844], Loss: 0.1930\n",
      "Epoch [1/4], Step [1232/3844], Loss: 0.2013\n",
      "Epoch [1/4], Step [1233/3844], Loss: 0.2056\n",
      "Epoch [1/4], Step [1234/3844], Loss: 0.2000\n",
      "Epoch [1/4], Step [1235/3844], Loss: 0.1709\n",
      "Epoch [1/4], Step [1236/3844], Loss: 0.1823\n",
      "Epoch [1/4], Step [1237/3844], Loss: 0.1759\n",
      "Epoch [1/4], Step [1238/3844], Loss: 0.1834\n",
      "Epoch [1/4], Step [1239/3844], Loss: 0.1902\n",
      "Epoch [1/4], Step [1240/3844], Loss: 0.1492\n",
      "Epoch [1/4], Step [1241/3844], Loss: 0.1949\n",
      "Epoch [1/4], Step [1242/3844], Loss: 0.1993\n",
      "Epoch [1/4], Step [1243/3844], Loss: 0.1750\n",
      "Epoch [1/4], Step [1244/3844], Loss: 0.1624\n",
      "Epoch [1/4], Step [1245/3844], Loss: 0.1951\n",
      "Epoch [1/4], Step [1246/3844], Loss: 0.1979\n",
      "Epoch [1/4], Step [1247/3844], Loss: 0.2326\n",
      "Epoch [1/4], Step [1248/3844], Loss: 0.1717\n",
      "Epoch [1/4], Step [1249/3844], Loss: 0.1944\n",
      "Epoch [1/4], Step [1250/3844], Loss: 0.1866\n",
      "Epoch [1/4], Step [1251/3844], Loss: 0.1973\n",
      "Epoch [1/4], Step [1252/3844], Loss: 0.1711\n",
      "Epoch [1/4], Step [1253/3844], Loss: 0.2064\n",
      "Epoch [1/4], Step [1254/3844], Loss: 0.1834\n",
      "Epoch [1/4], Step [1255/3844], Loss: 0.1579\n",
      "Epoch [1/4], Step [1256/3844], Loss: 0.1629\n",
      "Epoch [1/4], Step [1257/3844], Loss: 0.1740\n",
      "Epoch [1/4], Step [1258/3844], Loss: 0.1884\n",
      "Epoch [1/4], Step [1259/3844], Loss: 0.1780\n",
      "Epoch [1/4], Step [1260/3844], Loss: 0.1545\n",
      "Epoch [1/4], Step [1261/3844], Loss: 0.1759\n",
      "Epoch [1/4], Step [1262/3844], Loss: 0.1808\n",
      "Epoch [1/4], Step [1263/3844], Loss: 0.1978\n",
      "Epoch [1/4], Step [1264/3844], Loss: 0.1669\n",
      "Epoch [1/4], Step [1265/3844], Loss: 0.2081\n",
      "Epoch [1/4], Step [1266/3844], Loss: 0.2082\n",
      "Epoch [1/4], Step [1267/3844], Loss: 0.1524\n",
      "Epoch [1/4], Step [1268/3844], Loss: 0.1877\n",
      "Epoch [1/4], Step [1269/3844], Loss: 0.1802\n",
      "Epoch [1/4], Step [1270/3844], Loss: 0.2155\n",
      "Epoch [1/4], Step [1271/3844], Loss: 0.2074\n",
      "Epoch [1/4], Step [1272/3844], Loss: 0.2205\n",
      "Epoch [1/4], Step [1273/3844], Loss: 0.1611\n",
      "Epoch [1/4], Step [1274/3844], Loss: 0.1755\n",
      "Epoch [1/4], Step [1275/3844], Loss: 0.1980\n",
      "Epoch [1/4], Step [1276/3844], Loss: 0.2114\n",
      "Epoch [1/4], Step [1277/3844], Loss: 0.1606\n",
      "Epoch [1/4], Step [1278/3844], Loss: 0.1916\n",
      "Epoch [1/4], Step [1279/3844], Loss: 0.1705\n",
      "Epoch [1/4], Step [1280/3844], Loss: 0.1758\n",
      "Epoch [1/4], Step [1281/3844], Loss: 0.1843\n",
      "Epoch [1/4], Step [1282/3844], Loss: 0.1800\n",
      "Epoch [1/4], Step [1283/3844], Loss: 0.1919\n",
      "Epoch [1/4], Step [1284/3844], Loss: 0.1964\n",
      "Epoch [1/4], Step [1285/3844], Loss: 0.1685\n",
      "Epoch [1/4], Step [1286/3844], Loss: 0.1532\n",
      "Epoch [1/4], Step [1287/3844], Loss: 0.1767\n",
      "Epoch [1/4], Step [1288/3844], Loss: 0.1913\n",
      "Epoch [1/4], Step [1289/3844], Loss: 0.1640\n",
      "Epoch [1/4], Step [1290/3844], Loss: 0.1818\n",
      "Epoch [1/4], Step [1291/3844], Loss: 0.1847\n",
      "Epoch [1/4], Step [1292/3844], Loss: 0.1872\n",
      "Epoch [1/4], Step [1293/3844], Loss: 0.2274\n",
      "Epoch [1/4], Step [1294/3844], Loss: 0.1959\n",
      "Epoch [1/4], Step [1295/3844], Loss: 0.1760\n",
      "Epoch [1/4], Step [1296/3844], Loss: 0.1838\n",
      "Epoch [1/4], Step [1297/3844], Loss: 0.1714\n",
      "Epoch [1/4], Step [1298/3844], Loss: 0.1873\n",
      "Epoch [1/4], Step [1299/3844], Loss: 0.2448\n",
      "Epoch [1/4], Step [1300/3844], Loss: 0.1805\n",
      "Epoch [1/4], Step [1301/3844], Loss: 0.1772\n",
      "Epoch [1/4], Step [1302/3844], Loss: 0.1806\n",
      "Epoch [1/4], Step [1303/3844], Loss: 0.1711\n",
      "Epoch [1/4], Step [1304/3844], Loss: 0.1708\n",
      "Epoch [1/4], Step [1305/3844], Loss: 0.1782\n",
      "Epoch [1/4], Step [1306/3844], Loss: 0.2008\n",
      "Epoch [1/4], Step [1307/3844], Loss: 0.1570\n",
      "Epoch [1/4], Step [1308/3844], Loss: 0.2436\n",
      "Epoch [1/4], Step [1309/3844], Loss: 0.1792\n",
      "Epoch [1/4], Step [1310/3844], Loss: 0.1821\n",
      "Epoch [1/4], Step [1311/3844], Loss: 0.1963\n",
      "Epoch [1/4], Step [1312/3844], Loss: 0.1736\n",
      "Epoch [1/4], Step [1313/3844], Loss: 0.1378\n",
      "Epoch [1/4], Step [1314/3844], Loss: 0.2060\n",
      "Epoch [1/4], Step [1315/3844], Loss: 0.1897\n",
      "Epoch [1/4], Step [1316/3844], Loss: 0.1863\n",
      "Epoch [1/4], Step [1317/3844], Loss: 0.1755\n",
      "Epoch [1/4], Step [1318/3844], Loss: 0.1986\n",
      "Epoch [1/4], Step [1319/3844], Loss: 0.1586\n",
      "Epoch [1/4], Step [1320/3844], Loss: 0.1694\n",
      "Epoch [1/4], Step [1321/3844], Loss: 0.1930\n",
      "Epoch [1/4], Step [1322/3844], Loss: 0.1867\n",
      "Epoch [1/4], Step [1323/3844], Loss: 0.1822\n",
      "Epoch [1/4], Step [1324/3844], Loss: 0.1739\n",
      "Epoch [1/4], Step [1325/3844], Loss: 0.1646\n",
      "Epoch [1/4], Step [1326/3844], Loss: 0.1686\n",
      "Epoch [1/4], Step [1327/3844], Loss: 0.1881\n",
      "Epoch [1/4], Step [1328/3844], Loss: 0.1585\n",
      "Epoch [1/4], Step [1329/3844], Loss: 0.1586\n",
      "Epoch [1/4], Step [1330/3844], Loss: 0.1714\n",
      "Epoch [1/4], Step [1331/3844], Loss: 0.1780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [1332/3844], Loss: 0.1914\n",
      "Epoch [1/4], Step [1333/3844], Loss: 0.1916\n",
      "Epoch [1/4], Step [1334/3844], Loss: 0.1837\n",
      "Epoch [1/4], Step [1335/3844], Loss: 0.1644\n",
      "Epoch [1/4], Step [1336/3844], Loss: 0.1776\n",
      "Epoch [1/4], Step [1337/3844], Loss: 0.1827\n",
      "Epoch [1/4], Step [1338/3844], Loss: 0.1797\n",
      "Epoch [1/4], Step [1339/3844], Loss: 0.1687\n",
      "Epoch [1/4], Step [1340/3844], Loss: 0.1952\n",
      "Epoch [1/4], Step [1341/3844], Loss: 0.1670\n",
      "Epoch [1/4], Step [1342/3844], Loss: 0.1786\n",
      "Epoch [1/4], Step [1343/3844], Loss: 0.2434\n",
      "Epoch [1/4], Step [1344/3844], Loss: 0.1643\n",
      "Epoch [1/4], Step [1345/3844], Loss: 0.2085\n",
      "Epoch [1/4], Step [1346/3844], Loss: 0.1642\n",
      "Epoch [1/4], Step [1347/3844], Loss: 0.1521\n",
      "Epoch [1/4], Step [1348/3844], Loss: 0.1902\n",
      "Epoch [1/4], Step [1349/3844], Loss: 0.2063\n",
      "Epoch [1/4], Step [1350/3844], Loss: 0.1728\n",
      "Epoch [1/4], Step [1351/3844], Loss: 0.1800\n",
      "Epoch [1/4], Step [1352/3844], Loss: 0.1460\n",
      "Epoch [1/4], Step [1353/3844], Loss: 0.2070\n",
      "Epoch [1/4], Step [1354/3844], Loss: 0.2632\n",
      "Epoch [1/4], Step [1355/3844], Loss: 0.1762\n",
      "Epoch [1/4], Step [1356/3844], Loss: 0.1665\n",
      "Epoch [1/4], Step [1357/3844], Loss: 0.2245\n",
      "Epoch [1/4], Step [1358/3844], Loss: 0.1893\n",
      "Epoch [1/4], Step [1359/3844], Loss: 0.1717\n",
      "Epoch [1/4], Step [1360/3844], Loss: 0.1768\n",
      "Epoch [1/4], Step [1361/3844], Loss: 0.1894\n",
      "Epoch [1/4], Step [1362/3844], Loss: 0.1837\n",
      "Epoch [1/4], Step [1363/3844], Loss: 0.1875\n",
      "Epoch [1/4], Step [1364/3844], Loss: 0.1722\n",
      "Epoch [1/4], Step [1365/3844], Loss: 0.2097\n",
      "Epoch [1/4], Step [1366/3844], Loss: 0.1521\n",
      "Epoch [1/4], Step [1367/3844], Loss: 0.1824\n",
      "Epoch [1/4], Step [1368/3844], Loss: 0.1903\n",
      "Epoch [1/4], Step [1369/3844], Loss: 0.2028\n",
      "Epoch [1/4], Step [1370/3844], Loss: 0.1866\n",
      "Epoch [1/4], Step [1371/3844], Loss: 0.2469\n",
      "Epoch [1/4], Step [1372/3844], Loss: 0.1873\n",
      "Epoch [1/4], Step [1373/3844], Loss: 0.1888\n",
      "Epoch [1/4], Step [1374/3844], Loss: 0.1982\n",
      "Epoch [1/4], Step [1375/3844], Loss: 0.1401\n",
      "Epoch [1/4], Step [1376/3844], Loss: 0.1765\n",
      "Epoch [1/4], Step [1377/3844], Loss: 0.1556\n",
      "Epoch [1/4], Step [1378/3844], Loss: 0.1617\n",
      "Epoch [1/4], Step [1379/3844], Loss: 0.1985\n",
      "Epoch [1/4], Step [1380/3844], Loss: 0.1661\n",
      "Epoch [1/4], Step [1381/3844], Loss: 0.1707\n",
      "Epoch [1/4], Step [1382/3844], Loss: 0.1575\n",
      "Epoch [1/4], Step [1383/3844], Loss: 0.1772\n",
      "Epoch [1/4], Step [1384/3844], Loss: 0.2164\n",
      "Epoch [1/4], Step [1385/3844], Loss: 0.1857\n",
      "Epoch [1/4], Step [1386/3844], Loss: 0.1664\n",
      "Epoch [1/4], Step [1387/3844], Loss: 0.2056\n",
      "Epoch [1/4], Step [1388/3844], Loss: 0.1826\n",
      "Epoch [1/4], Step [1389/3844], Loss: 0.2296\n",
      "Epoch [1/4], Step [1390/3844], Loss: 0.2191\n",
      "Epoch [1/4], Step [1391/3844], Loss: 0.1861\n",
      "Epoch [1/4], Step [1392/3844], Loss: 0.1992\n",
      "Epoch [1/4], Step [1393/3844], Loss: 0.1957\n",
      "Epoch [1/4], Step [1394/3844], Loss: 0.1783\n",
      "Epoch [1/4], Step [1395/3844], Loss: 0.1599\n",
      "Epoch [1/4], Step [1396/3844], Loss: 0.1886\n",
      "Epoch [1/4], Step [1397/3844], Loss: 0.2175\n",
      "Epoch [1/4], Step [1398/3844], Loss: 0.1480\n",
      "Epoch [1/4], Step [1399/3844], Loss: 0.1950\n",
      "Epoch [1/4], Step [1400/3844], Loss: 0.2004\n",
      "Epoch [1/4], Step [1401/3844], Loss: 0.1954\n",
      "Epoch [1/4], Step [1402/3844], Loss: 0.2072\n",
      "Epoch [1/4], Step [1403/3844], Loss: 0.1703\n",
      "Epoch [1/4], Step [1404/3844], Loss: 0.1807\n",
      "Epoch [1/4], Step [1405/3844], Loss: 0.1893\n",
      "Epoch [1/4], Step [1406/3844], Loss: 0.1778\n",
      "Epoch [1/4], Step [1407/3844], Loss: 0.1879\n",
      "Epoch [1/4], Step [1408/3844], Loss: 0.2100\n",
      "Epoch [1/4], Step [1409/3844], Loss: 0.2111\n",
      "Epoch [1/4], Step [1410/3844], Loss: 0.1816\n",
      "Epoch [1/4], Step [1411/3844], Loss: 0.1432\n",
      "Epoch [1/4], Step [1412/3844], Loss: 0.1564\n",
      "Epoch [1/4], Step [1413/3844], Loss: 0.1730\n",
      "Epoch [1/4], Step [1414/3844], Loss: 0.1834\n",
      "Epoch [1/4], Step [1415/3844], Loss: 0.1554\n",
      "Epoch [1/4], Step [1416/3844], Loss: 0.1914\n",
      "Epoch [1/4], Step [1417/3844], Loss: 0.1579\n",
      "Epoch [1/4], Step [1418/3844], Loss: 0.1790\n",
      "Epoch [1/4], Step [1419/3844], Loss: 0.2443\n",
      "Epoch [1/4], Step [1420/3844], Loss: 0.1840\n",
      "Epoch [1/4], Step [1421/3844], Loss: 0.2447\n",
      "Epoch [1/4], Step [1422/3844], Loss: 0.1834\n",
      "Epoch [1/4], Step [1423/3844], Loss: 0.1311\n",
      "Epoch [1/4], Step [1424/3844], Loss: 0.2077\n",
      "Epoch [1/4], Step [1425/3844], Loss: 0.1802\n",
      "Epoch [1/4], Step [1426/3844], Loss: 0.1626\n",
      "Epoch [1/4], Step [1427/3844], Loss: 0.2220\n",
      "Epoch [1/4], Step [1428/3844], Loss: 0.1685\n",
      "Epoch [1/4], Step [1429/3844], Loss: 0.1770\n",
      "Epoch [1/4], Step [1430/3844], Loss: 0.1700\n",
      "Epoch [1/4], Step [1431/3844], Loss: 0.1689\n",
      "Epoch [1/4], Step [1432/3844], Loss: 0.2251\n",
      "Epoch [1/4], Step [1433/3844], Loss: 0.1686\n",
      "Epoch [1/4], Step [1434/3844], Loss: 0.1678\n",
      "Epoch [1/4], Step [1435/3844], Loss: 0.1936\n",
      "Epoch [1/4], Step [1436/3844], Loss: 0.1856\n",
      "Epoch [1/4], Step [1437/3844], Loss: 0.1784\n",
      "Epoch [1/4], Step [1438/3844], Loss: 0.1778\n",
      "Epoch [1/4], Step [1439/3844], Loss: 0.1700\n",
      "Epoch [1/4], Step [1440/3844], Loss: 0.2079\n",
      "Epoch [1/4], Step [1441/3844], Loss: 0.1890\n",
      "Epoch [1/4], Step [1442/3844], Loss: 0.1895\n",
      "Epoch [1/4], Step [1443/3844], Loss: 0.1714\n",
      "Epoch [1/4], Step [1444/3844], Loss: 0.2300\n",
      "Epoch [1/4], Step [1445/3844], Loss: 0.1907\n",
      "Epoch [1/4], Step [1446/3844], Loss: 0.1549\n",
      "Epoch [1/4], Step [1447/3844], Loss: 0.1801\n",
      "Epoch [1/4], Step [1448/3844], Loss: 0.1778\n",
      "Epoch [1/4], Step [1449/3844], Loss: 0.1766\n",
      "Epoch [1/4], Step [1450/3844], Loss: 0.1750\n",
      "Epoch [1/4], Step [1451/3844], Loss: 0.1512\n",
      "Epoch [1/4], Step [1452/3844], Loss: 0.1795\n",
      "Epoch [1/4], Step [1453/3844], Loss: 0.1746\n",
      "Epoch [1/4], Step [1454/3844], Loss: 0.1854\n",
      "Epoch [1/4], Step [1455/3844], Loss: 0.2000\n",
      "Epoch [1/4], Step [1456/3844], Loss: 0.1829\n",
      "Epoch [1/4], Step [1457/3844], Loss: 0.1683\n",
      "Epoch [1/4], Step [1458/3844], Loss: 0.2067\n",
      "Epoch [1/4], Step [1459/3844], Loss: 0.2390\n",
      "Epoch [1/4], Step [1460/3844], Loss: 0.1729\n",
      "Epoch [1/4], Step [1461/3844], Loss: 0.1806\n",
      "Epoch [1/4], Step [1462/3844], Loss: 0.2033\n",
      "Epoch [1/4], Step [1463/3844], Loss: 0.1576\n",
      "Epoch [1/4], Step [1464/3844], Loss: 0.1619\n",
      "Epoch [1/4], Step [1465/3844], Loss: 0.1684\n",
      "Epoch [1/4], Step [1466/3844], Loss: 0.1949\n",
      "Epoch [1/4], Step [1467/3844], Loss: 0.1556\n",
      "Epoch [1/4], Step [1468/3844], Loss: 0.1591\n",
      "Epoch [1/4], Step [1469/3844], Loss: 0.1818\n",
      "Epoch [1/4], Step [1470/3844], Loss: 0.1690\n",
      "Epoch [1/4], Step [1471/3844], Loss: 0.1723\n",
      "Epoch [1/4], Step [1472/3844], Loss: 0.1765\n",
      "Epoch [1/4], Step [1473/3844], Loss: 0.1849\n",
      "Epoch [1/4], Step [1474/3844], Loss: 0.1830\n",
      "Epoch [1/4], Step [1475/3844], Loss: 0.2055\n",
      "Epoch [1/4], Step [1476/3844], Loss: 0.1873\n",
      "Epoch [1/4], Step [1477/3844], Loss: 0.1882\n",
      "Epoch [1/4], Step [1478/3844], Loss: 0.2096\n",
      "Epoch [1/4], Step [1479/3844], Loss: 0.1889\n",
      "Epoch [1/4], Step [1480/3844], Loss: 0.1585\n",
      "Epoch [1/4], Step [1481/3844], Loss: 0.2355\n",
      "Epoch [1/4], Step [1482/3844], Loss: 0.1535\n",
      "Epoch [1/4], Step [1483/3844], Loss: 0.2016\n",
      "Epoch [1/4], Step [1484/3844], Loss: 0.1953\n",
      "Epoch [1/4], Step [1485/3844], Loss: 0.1916\n",
      "Epoch [1/4], Step [1486/3844], Loss: 0.1872\n",
      "Epoch [1/4], Step [1487/3844], Loss: 0.1732\n",
      "Epoch [1/4], Step [1488/3844], Loss: 0.1675\n",
      "Epoch [1/4], Step [1489/3844], Loss: 0.1792\n",
      "Epoch [1/4], Step [1490/3844], Loss: 0.1896\n",
      "Epoch [1/4], Step [1491/3844], Loss: 0.1807\n",
      "Epoch [1/4], Step [1492/3844], Loss: 0.2113\n",
      "Epoch [1/4], Step [1493/3844], Loss: 0.1833\n",
      "Epoch [1/4], Step [1494/3844], Loss: 0.1918\n",
      "Epoch [1/4], Step [1495/3844], Loss: 0.1776\n",
      "Epoch [1/4], Step [1496/3844], Loss: 0.1727\n",
      "Epoch [1/4], Step [1497/3844], Loss: 0.1748\n",
      "Epoch [1/4], Step [1498/3844], Loss: 0.1411\n",
      "Epoch [1/4], Step [1499/3844], Loss: 0.1902\n",
      "Epoch [1/4], Step [1500/3844], Loss: 0.1693\n",
      "Epoch [1/4], Step [1501/3844], Loss: 0.2292\n",
      "Epoch [1/4], Step [1502/3844], Loss: 0.1177\n",
      "Epoch [1/4], Step [1503/3844], Loss: 0.1681\n",
      "Epoch [1/4], Step [1504/3844], Loss: 0.1596\n",
      "Epoch [1/4], Step [1505/3844], Loss: 0.1819\n",
      "Epoch [1/4], Step [1506/3844], Loss: 0.1802\n",
      "Epoch [1/4], Step [1507/3844], Loss: 0.1610\n",
      "Epoch [1/4], Step [1508/3844], Loss: 0.1679\n",
      "Epoch [1/4], Step [1509/3844], Loss: 0.1674\n",
      "Epoch [1/4], Step [1510/3844], Loss: 0.1895\n",
      "Epoch [1/4], Step [1511/3844], Loss: 0.1685\n",
      "Epoch [1/4], Step [1512/3844], Loss: 0.1898\n",
      "Epoch [1/4], Step [1513/3844], Loss: 0.2104\n",
      "Epoch [1/4], Step [1514/3844], Loss: 0.1670\n",
      "Epoch [1/4], Step [1515/3844], Loss: 0.1876\n",
      "Epoch [1/4], Step [1516/3844], Loss: 0.1944\n",
      "Epoch [1/4], Step [1517/3844], Loss: 0.2359\n",
      "Epoch [1/4], Step [1518/3844], Loss: 0.2152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [1519/3844], Loss: 0.2130\n",
      "Epoch [1/4], Step [1520/3844], Loss: 0.1857\n",
      "Epoch [1/4], Step [1521/3844], Loss: 0.1917\n",
      "Epoch [1/4], Step [1522/3844], Loss: 0.1557\n",
      "Epoch [1/4], Step [1523/3844], Loss: 0.1501\n",
      "Epoch [1/4], Step [1524/3844], Loss: 0.1752\n",
      "Epoch [1/4], Step [1525/3844], Loss: 0.1886\n",
      "Epoch [1/4], Step [1526/3844], Loss: 0.2469\n",
      "Epoch [1/4], Step [1527/3844], Loss: 0.1861\n",
      "Epoch [1/4], Step [1528/3844], Loss: 0.1768\n",
      "Epoch [1/4], Step [1529/3844], Loss: 0.1683\n",
      "Epoch [1/4], Step [1530/3844], Loss: 0.1817\n",
      "Epoch [1/4], Step [1531/3844], Loss: 0.1678\n",
      "Epoch [1/4], Step [1532/3844], Loss: 0.1751\n",
      "Epoch [1/4], Step [1533/3844], Loss: 0.1755\n",
      "Epoch [1/4], Step [1534/3844], Loss: 0.1735\n",
      "Epoch [1/4], Step [1535/3844], Loss: 0.1889\n",
      "Epoch [1/4], Step [1536/3844], Loss: 0.1708\n",
      "Epoch [1/4], Step [1537/3844], Loss: 0.1740\n",
      "Epoch [1/4], Step [1538/3844], Loss: 0.2597\n",
      "Epoch [1/4], Step [1539/3844], Loss: 0.2321\n",
      "Epoch [1/4], Step [1540/3844], Loss: 0.1806\n",
      "Epoch [1/4], Step [1541/3844], Loss: 0.1972\n",
      "Epoch [1/4], Step [1542/3844], Loss: 0.1926\n",
      "Epoch [1/4], Step [1543/3844], Loss: 0.1802\n",
      "Epoch [1/4], Step [1544/3844], Loss: 0.1738\n",
      "Epoch [1/4], Step [1545/3844], Loss: 0.1730\n",
      "Epoch [1/4], Step [1546/3844], Loss: 0.1622\n",
      "Epoch [1/4], Step [1547/3844], Loss: 0.2312\n",
      "Epoch [1/4], Step [1548/3844], Loss: 0.1777\n",
      "Epoch [1/4], Step [1549/3844], Loss: 0.1644\n",
      "Epoch [1/4], Step [1550/3844], Loss: 0.1743\n",
      "Epoch [1/4], Step [1551/3844], Loss: 0.1781\n",
      "Epoch [1/4], Step [1552/3844], Loss: 0.1908\n",
      "Epoch [1/4], Step [1553/3844], Loss: 0.2583\n",
      "Epoch [1/4], Step [1554/3844], Loss: 0.1850\n",
      "Epoch [1/4], Step [1555/3844], Loss: 0.1805\n",
      "Epoch [1/4], Step [1556/3844], Loss: 0.1766\n",
      "Epoch [1/4], Step [1557/3844], Loss: 0.2173\n",
      "Epoch [1/4], Step [1558/3844], Loss: 0.1817\n",
      "Epoch [1/4], Step [1559/3844], Loss: 0.1748\n",
      "Epoch [1/4], Step [1560/3844], Loss: 0.1749\n",
      "Epoch [1/4], Step [1561/3844], Loss: 0.1756\n",
      "Epoch [1/4], Step [1562/3844], Loss: 0.1341\n",
      "Epoch [1/4], Step [1563/3844], Loss: 0.1803\n",
      "Epoch [1/4], Step [1564/3844], Loss: 0.1719\n",
      "Epoch [1/4], Step [1565/3844], Loss: 0.1587\n",
      "Epoch [1/4], Step [1566/3844], Loss: 0.2230\n",
      "Epoch [1/4], Step [1567/3844], Loss: 0.1821\n",
      "Epoch [1/4], Step [1568/3844], Loss: 0.1752\n",
      "Epoch [1/4], Step [1569/3844], Loss: 0.1971\n",
      "Epoch [1/4], Step [1570/3844], Loss: 0.1720\n",
      "Epoch [1/4], Step [1571/3844], Loss: 0.1619\n",
      "Epoch [1/4], Step [1572/3844], Loss: 0.1341\n",
      "Epoch [1/4], Step [1573/3844], Loss: 0.1419\n",
      "Epoch [1/4], Step [1574/3844], Loss: 0.1851\n",
      "Epoch [1/4], Step [1575/3844], Loss: 0.2212\n",
      "Epoch [1/4], Step [1576/3844], Loss: 0.1773\n",
      "Epoch [1/4], Step [1577/3844], Loss: 0.1686\n",
      "Epoch [1/4], Step [1578/3844], Loss: 0.1719\n",
      "Epoch [1/4], Step [1579/3844], Loss: 0.1793\n",
      "Epoch [1/4], Step [1580/3844], Loss: 0.1687\n",
      "Epoch [1/4], Step [1581/3844], Loss: 0.1711\n",
      "Epoch [1/4], Step [1582/3844], Loss: 0.2376\n",
      "Epoch [1/4], Step [1583/3844], Loss: 0.2463\n",
      "Epoch [1/4], Step [1584/3844], Loss: 0.1864\n",
      "Epoch [1/4], Step [1585/3844], Loss: 0.2537\n",
      "Epoch [1/4], Step [1586/3844], Loss: 0.1791\n",
      "Epoch [1/4], Step [1587/3844], Loss: 0.1800\n",
      "Epoch [1/4], Step [1588/3844], Loss: 0.1911\n",
      "Epoch [1/4], Step [1589/3844], Loss: 0.1868\n",
      "Epoch [1/4], Step [1590/3844], Loss: 0.1728\n",
      "Epoch [1/4], Step [1591/3844], Loss: 0.1900\n",
      "Epoch [1/4], Step [1592/3844], Loss: 0.1871\n",
      "Epoch [1/4], Step [1593/3844], Loss: 0.1830\n",
      "Epoch [1/4], Step [1594/3844], Loss: 0.2095\n",
      "Epoch [1/4], Step [1595/3844], Loss: 0.1596\n",
      "Epoch [1/4], Step [1596/3844], Loss: 0.1609\n",
      "Epoch [1/4], Step [1597/3844], Loss: 0.1898\n",
      "Epoch [1/4], Step [1598/3844], Loss: 0.1926\n",
      "Epoch [1/4], Step [1599/3844], Loss: 0.1651\n",
      "Epoch [1/4], Step [1600/3844], Loss: 0.1555\n",
      "Epoch [1/4], Step [1601/3844], Loss: 0.1444\n",
      "Epoch [1/4], Step [1602/3844], Loss: 0.1739\n",
      "Epoch [1/4], Step [1603/3844], Loss: 0.1755\n",
      "Epoch [1/4], Step [1604/3844], Loss: 0.2432\n",
      "Epoch [1/4], Step [1605/3844], Loss: 0.1625\n",
      "Epoch [1/4], Step [1606/3844], Loss: 0.1800\n",
      "Epoch [1/4], Step [1607/3844], Loss: 0.1831\n",
      "Epoch [1/4], Step [1608/3844], Loss: 0.1859\n",
      "Epoch [1/4], Step [1609/3844], Loss: 0.1911\n",
      "Epoch [1/4], Step [1610/3844], Loss: 0.2147\n",
      "Epoch [1/4], Step [1611/3844], Loss: 0.1918\n",
      "Epoch [1/4], Step [1612/3844], Loss: 0.2221\n",
      "Epoch [1/4], Step [1613/3844], Loss: 0.1491\n",
      "Epoch [1/4], Step [1614/3844], Loss: 0.1860\n",
      "Epoch [1/4], Step [1615/3844], Loss: 0.1867\n",
      "Epoch [1/4], Step [1616/3844], Loss: 0.1836\n",
      "Epoch [1/4], Step [1617/3844], Loss: 0.1847\n",
      "Epoch [1/4], Step [1618/3844], Loss: 0.2133\n",
      "Epoch [1/4], Step [1619/3844], Loss: 0.1612\n",
      "Epoch [1/4], Step [1620/3844], Loss: 0.2162\n",
      "Epoch [1/4], Step [1621/3844], Loss: 0.1921\n",
      "Epoch [1/4], Step [1622/3844], Loss: 0.1521\n",
      "Epoch [1/4], Step [1623/3844], Loss: 0.2031\n",
      "Epoch [1/4], Step [1624/3844], Loss: 0.1976\n",
      "Epoch [1/4], Step [1625/3844], Loss: 0.1705\n",
      "Epoch [1/4], Step [1626/3844], Loss: 0.1706\n",
      "Epoch [1/4], Step [1627/3844], Loss: 0.1574\n",
      "Epoch [1/4], Step [1628/3844], Loss: 0.2373\n",
      "Epoch [1/4], Step [1629/3844], Loss: 0.2023\n",
      "Epoch [1/4], Step [1630/3844], Loss: 0.1704\n",
      "Epoch [1/4], Step [1631/3844], Loss: 0.1909\n",
      "Epoch [1/4], Step [1632/3844], Loss: 0.1790\n",
      "Epoch [1/4], Step [1633/3844], Loss: 0.1682\n",
      "Epoch [1/4], Step [1634/3844], Loss: 0.1633\n",
      "Epoch [1/4], Step [1635/3844], Loss: 0.2123\n",
      "Epoch [1/4], Step [1636/3844], Loss: 0.1615\n",
      "Epoch [1/4], Step [1637/3844], Loss: 0.1742\n",
      "Epoch [1/4], Step [1638/3844], Loss: 0.1945\n",
      "Epoch [1/4], Step [1639/3844], Loss: 0.1959\n",
      "Epoch [1/4], Step [1640/3844], Loss: 0.1961\n",
      "Epoch [1/4], Step [1641/3844], Loss: 0.1914\n",
      "Epoch [1/4], Step [1642/3844], Loss: 0.1639\n",
      "Epoch [1/4], Step [1643/3844], Loss: 0.1897\n",
      "Epoch [1/4], Step [1644/3844], Loss: 0.1553\n",
      "Epoch [1/4], Step [1645/3844], Loss: 0.2184\n",
      "Epoch [1/4], Step [1646/3844], Loss: 0.2088\n",
      "Epoch [1/4], Step [1647/3844], Loss: 0.1911\n",
      "Epoch [1/4], Step [1648/3844], Loss: 0.1800\n",
      "Epoch [1/4], Step [1649/3844], Loss: 0.1957\n",
      "Epoch [1/4], Step [1650/3844], Loss: 0.2006\n",
      "Epoch [1/4], Step [1651/3844], Loss: 0.1818\n",
      "Epoch [1/4], Step [1652/3844], Loss: 0.1850\n",
      "Epoch [1/4], Step [1653/3844], Loss: 0.1745\n",
      "Epoch [1/4], Step [1654/3844], Loss: 0.1754\n",
      "Epoch [1/4], Step [1655/3844], Loss: 0.1545\n",
      "Epoch [1/4], Step [1656/3844], Loss: 0.1796\n",
      "Epoch [1/4], Step [1657/3844], Loss: 0.1993\n",
      "Epoch [1/4], Step [1658/3844], Loss: 0.1758\n",
      "Epoch [1/4], Step [1659/3844], Loss: 0.2158\n",
      "Epoch [1/4], Step [1660/3844], Loss: 0.1771\n",
      "Epoch [1/4], Step [1661/3844], Loss: 0.1470\n",
      "Epoch [1/4], Step [1662/3844], Loss: 0.1900\n",
      "Epoch [1/4], Step [1663/3844], Loss: 0.1748\n",
      "Epoch [1/4], Step [1664/3844], Loss: 0.1925\n",
      "Epoch [1/4], Step [1665/3844], Loss: 0.2110\n",
      "Epoch [1/4], Step [1666/3844], Loss: 0.1680\n",
      "Epoch [1/4], Step [1667/3844], Loss: 0.1587\n",
      "Epoch [1/4], Step [1668/3844], Loss: 0.1781\n",
      "Epoch [1/4], Step [1669/3844], Loss: 0.2003\n",
      "Epoch [1/4], Step [1670/3844], Loss: 0.1880\n",
      "Epoch [1/4], Step [1671/3844], Loss: 0.1861\n",
      "Epoch [1/4], Step [1672/3844], Loss: 0.2040\n",
      "Epoch [1/4], Step [1673/3844], Loss: 0.1783\n",
      "Epoch [1/4], Step [1674/3844], Loss: 0.1750\n",
      "Epoch [1/4], Step [1675/3844], Loss: 0.1610\n",
      "Epoch [1/4], Step [1676/3844], Loss: 0.1869\n",
      "Epoch [1/4], Step [1677/3844], Loss: 0.1889\n",
      "Epoch [1/4], Step [1678/3844], Loss: 0.2000\n",
      "Epoch [1/4], Step [1679/3844], Loss: 0.2026\n",
      "Epoch [1/4], Step [1680/3844], Loss: 0.1964\n",
      "Epoch [1/4], Step [1681/3844], Loss: 0.1661\n",
      "Epoch [1/4], Step [1682/3844], Loss: 0.1804\n",
      "Epoch [1/4], Step [1683/3844], Loss: 0.1921\n",
      "Epoch [1/4], Step [1684/3844], Loss: 0.1739\n",
      "Epoch [1/4], Step [1685/3844], Loss: 0.1780\n",
      "Epoch [1/4], Step [1686/3844], Loss: 0.1733\n",
      "Epoch [1/4], Step [1687/3844], Loss: 0.1573\n",
      "Epoch [1/4], Step [1688/3844], Loss: 0.1815\n",
      "Epoch [1/4], Step [1689/3844], Loss: 0.1582\n",
      "Epoch [1/4], Step [1690/3844], Loss: 0.1690\n",
      "Epoch [1/4], Step [1691/3844], Loss: 0.1824\n",
      "Epoch [1/4], Step [1692/3844], Loss: 0.1953\n",
      "Epoch [1/4], Step [1693/3844], Loss: 0.1465\n",
      "Epoch [1/4], Step [1694/3844], Loss: 0.1690\n",
      "Epoch [1/4], Step [1695/3844], Loss: 0.1919\n",
      "Epoch [1/4], Step [1696/3844], Loss: 0.1743\n",
      "Epoch [1/4], Step [1697/3844], Loss: 0.1977\n",
      "Epoch [1/4], Step [1698/3844], Loss: 0.1936\n",
      "Epoch [1/4], Step [1699/3844], Loss: 0.1682\n",
      "Epoch [1/4], Step [1700/3844], Loss: 0.1856\n",
      "Epoch [1/4], Step [1701/3844], Loss: 0.2257\n",
      "Epoch [1/4], Step [1702/3844], Loss: 0.1978\n",
      "Epoch [1/4], Step [1703/3844], Loss: 0.1619\n",
      "Epoch [1/4], Step [1704/3844], Loss: 0.2046\n",
      "Epoch [1/4], Step [1705/3844], Loss: 0.1858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [1706/3844], Loss: 0.1848\n",
      "Epoch [1/4], Step [1707/3844], Loss: 0.1810\n",
      "Epoch [1/4], Step [1708/3844], Loss: 0.1730\n",
      "Epoch [1/4], Step [1709/3844], Loss: 0.1736\n",
      "Epoch [1/4], Step [1710/3844], Loss: 0.1785\n",
      "Epoch [1/4], Step [1711/3844], Loss: 0.2268\n",
      "Epoch [1/4], Step [1712/3844], Loss: 0.1876\n",
      "Epoch [1/4], Step [1713/3844], Loss: 0.1830\n",
      "Epoch [1/4], Step [1714/3844], Loss: 0.1755\n",
      "Epoch [1/4], Step [1715/3844], Loss: 0.1646\n",
      "Epoch [1/4], Step [1716/3844], Loss: 0.1856\n",
      "Epoch [1/4], Step [1717/3844], Loss: 0.1568\n",
      "Epoch [1/4], Step [1718/3844], Loss: 0.1581\n",
      "Epoch [1/4], Step [1719/3844], Loss: 0.2112\n",
      "Epoch [1/4], Step [1720/3844], Loss: 0.1836\n",
      "Epoch [1/4], Step [1721/3844], Loss: 0.2005\n",
      "Epoch [1/4], Step [1722/3844], Loss: 0.2025\n",
      "Epoch [1/4], Step [1723/3844], Loss: 0.1751\n",
      "Epoch [1/4], Step [1724/3844], Loss: 0.1689\n",
      "Epoch [1/4], Step [1725/3844], Loss: 0.1635\n",
      "Epoch [1/4], Step [1726/3844], Loss: 0.2130\n",
      "Epoch [1/4], Step [1727/3844], Loss: 0.1842\n",
      "Epoch [1/4], Step [1728/3844], Loss: 0.1900\n",
      "Epoch [1/4], Step [1729/3844], Loss: 0.1675\n",
      "Epoch [1/4], Step [1730/3844], Loss: 0.1764\n",
      "Epoch [1/4], Step [1731/3844], Loss: 0.1801\n",
      "Epoch [1/4], Step [1732/3844], Loss: 0.1922\n",
      "Epoch [1/4], Step [1733/3844], Loss: 0.2248\n",
      "Epoch [1/4], Step [1734/3844], Loss: 0.2181\n",
      "Epoch [1/4], Step [1735/3844], Loss: 0.1946\n",
      "Epoch [1/4], Step [1736/3844], Loss: 0.1880\n",
      "Epoch [1/4], Step [1737/3844], Loss: 0.1756\n",
      "Epoch [1/4], Step [1738/3844], Loss: 0.1729\n",
      "Epoch [1/4], Step [1739/3844], Loss: 0.2373\n",
      "Epoch [1/4], Step [1740/3844], Loss: 0.1736\n",
      "Epoch [1/4], Step [1741/3844], Loss: 0.2223\n",
      "Epoch [1/4], Step [1742/3844], Loss: 0.1742\n",
      "Epoch [1/4], Step [1743/3844], Loss: 0.1645\n",
      "Epoch [1/4], Step [1744/3844], Loss: 0.1892\n",
      "Epoch [1/4], Step [1745/3844], Loss: 0.1744\n",
      "Epoch [1/4], Step [1746/3844], Loss: 0.1738\n",
      "Epoch [1/4], Step [1747/3844], Loss: 0.1664\n",
      "Epoch [1/4], Step [1748/3844], Loss: 0.2253\n",
      "Epoch [1/4], Step [1749/3844], Loss: 0.2037\n",
      "Epoch [1/4], Step [1750/3844], Loss: 0.2193\n",
      "Epoch [1/4], Step [1751/3844], Loss: 0.1698\n",
      "Epoch [1/4], Step [1752/3844], Loss: 0.1669\n",
      "Epoch [1/4], Step [1753/3844], Loss: 0.1696\n",
      "Epoch [1/4], Step [1754/3844], Loss: 0.1981\n",
      "Epoch [1/4], Step [1755/3844], Loss: 0.1657\n",
      "Epoch [1/4], Step [1756/3844], Loss: 0.1594\n",
      "Epoch [1/4], Step [1757/3844], Loss: 0.1723\n",
      "Epoch [1/4], Step [1758/3844], Loss: 0.1910\n",
      "Epoch [1/4], Step [1759/3844], Loss: 0.1856\n",
      "Epoch [1/4], Step [1760/3844], Loss: 0.1747\n",
      "Epoch [1/4], Step [1761/3844], Loss: 0.1475\n",
      "Epoch [1/4], Step [1762/3844], Loss: 0.1688\n",
      "Epoch [1/4], Step [1763/3844], Loss: 0.1920\n",
      "Epoch [1/4], Step [1764/3844], Loss: 0.1749\n",
      "Epoch [1/4], Step [1765/3844], Loss: 0.2602\n",
      "Epoch [1/4], Step [1766/3844], Loss: 0.1489\n",
      "Epoch [1/4], Step [1767/3844], Loss: 0.2169\n",
      "Epoch [1/4], Step [1768/3844], Loss: 0.1536\n",
      "Epoch [1/4], Step [1769/3844], Loss: 0.2034\n",
      "Epoch [1/4], Step [1770/3844], Loss: 0.1828\n",
      "Epoch [1/4], Step [1771/3844], Loss: 0.1917\n",
      "Epoch [1/4], Step [1772/3844], Loss: 0.2171\n",
      "Epoch [1/4], Step [1773/3844], Loss: 0.1653\n",
      "Epoch [1/4], Step [1774/3844], Loss: 0.1809\n",
      "Epoch [1/4], Step [1775/3844], Loss: 0.1771\n",
      "Epoch [1/4], Step [1776/3844], Loss: 0.2212\n",
      "Epoch [1/4], Step [1777/3844], Loss: 0.1572\n",
      "Epoch [1/4], Step [1778/3844], Loss: 0.2214\n",
      "Epoch [1/4], Step [1779/3844], Loss: 0.1808\n",
      "Epoch [1/4], Step [1780/3844], Loss: 0.1990\n",
      "Epoch [1/4], Step [1781/3844], Loss: 0.2014\n",
      "Epoch [1/4], Step [1782/3844], Loss: 0.2359\n",
      "Epoch [1/4], Step [1783/3844], Loss: 0.1672\n",
      "Epoch [1/4], Step [1784/3844], Loss: 0.2189\n",
      "Epoch [1/4], Step [1785/3844], Loss: 0.1766\n",
      "Epoch [1/4], Step [1786/3844], Loss: 0.1729\n",
      "Epoch [1/4], Step [1787/3844], Loss: 0.1370\n",
      "Epoch [1/4], Step [1788/3844], Loss: 0.1656\n",
      "Epoch [1/4], Step [1789/3844], Loss: 0.1768\n",
      "Epoch [1/4], Step [1790/3844], Loss: 0.1951\n",
      "Epoch [1/4], Step [1791/3844], Loss: 0.1961\n",
      "Epoch [1/4], Step [1792/3844], Loss: 0.1688\n",
      "Epoch [1/4], Step [1793/3844], Loss: 0.1782\n",
      "Epoch [1/4], Step [1794/3844], Loss: 0.1672\n",
      "Epoch [1/4], Step [1795/3844], Loss: 0.2133\n",
      "Epoch [1/4], Step [1796/3844], Loss: 0.1571\n",
      "Epoch [1/4], Step [1797/3844], Loss: 0.1738\n",
      "Epoch [1/4], Step [1798/3844], Loss: 0.1474\n",
      "Epoch [1/4], Step [1799/3844], Loss: 0.2180\n",
      "Epoch [1/4], Step [1800/3844], Loss: 0.2148\n",
      "Epoch [1/4], Step [1801/3844], Loss: 0.1708\n",
      "Epoch [1/4], Step [1802/3844], Loss: 0.1917\n",
      "Epoch [1/4], Step [1803/3844], Loss: 0.1740\n",
      "Epoch [1/4], Step [1804/3844], Loss: 0.1495\n",
      "Epoch [1/4], Step [1805/3844], Loss: 0.1891\n",
      "Epoch [1/4], Step [1806/3844], Loss: 0.1804\n",
      "Epoch [1/4], Step [1807/3844], Loss: 0.1489\n",
      "Epoch [1/4], Step [1808/3844], Loss: 0.1916\n",
      "Epoch [1/4], Step [1809/3844], Loss: 0.1815\n",
      "Epoch [1/4], Step [1810/3844], Loss: 0.1628\n",
      "Epoch [1/4], Step [1811/3844], Loss: 0.2373\n",
      "Epoch [1/4], Step [1812/3844], Loss: 0.1826\n",
      "Epoch [1/4], Step [1813/3844], Loss: 0.2301\n",
      "Epoch [1/4], Step [1814/3844], Loss: 0.1875\n",
      "Epoch [1/4], Step [1815/3844], Loss: 0.1689\n",
      "Epoch [1/4], Step [1816/3844], Loss: 0.1709\n",
      "Epoch [1/4], Step [1817/3844], Loss: 0.2393\n",
      "Epoch [1/4], Step [1818/3844], Loss: 0.1951\n",
      "Epoch [1/4], Step [1819/3844], Loss: 0.2226\n",
      "Epoch [1/4], Step [1820/3844], Loss: 0.1776\n",
      "Epoch [1/4], Step [1821/3844], Loss: 0.2161\n",
      "Epoch [1/4], Step [1822/3844], Loss: 0.1279\n",
      "Epoch [1/4], Step [1823/3844], Loss: 0.1652\n",
      "Epoch [1/4], Step [1824/3844], Loss: 0.2037\n",
      "Epoch [1/4], Step [1825/3844], Loss: 0.1695\n",
      "Epoch [1/4], Step [1826/3844], Loss: 0.2364\n",
      "Epoch [1/4], Step [1827/3844], Loss: 0.1988\n",
      "Epoch [1/4], Step [1828/3844], Loss: 0.1547\n",
      "Epoch [1/4], Step [1829/3844], Loss: 0.1832\n",
      "Epoch [1/4], Step [1830/3844], Loss: 0.2292\n",
      "Epoch [1/4], Step [1831/3844], Loss: 0.1532\n",
      "Epoch [1/4], Step [1832/3844], Loss: 0.2006\n",
      "Epoch [1/4], Step [1833/3844], Loss: 0.1727\n",
      "Epoch [1/4], Step [1834/3844], Loss: 0.1749\n",
      "Epoch [1/4], Step [1835/3844], Loss: 0.1575\n",
      "Epoch [1/4], Step [1836/3844], Loss: 0.1856\n",
      "Epoch [1/4], Step [1837/3844], Loss: 0.1862\n",
      "Epoch [1/4], Step [1838/3844], Loss: 0.1663\n",
      "Epoch [1/4], Step [1839/3844], Loss: 0.1427\n",
      "Epoch [1/4], Step [1840/3844], Loss: 0.2402\n",
      "Epoch [1/4], Step [1841/3844], Loss: 0.1846\n",
      "Epoch [1/4], Step [1842/3844], Loss: 0.2020\n",
      "Epoch [1/4], Step [1843/3844], Loss: 0.1855\n",
      "Epoch [1/4], Step [1844/3844], Loss: 0.2454\n",
      "Epoch [1/4], Step [1845/3844], Loss: 0.1863\n",
      "Epoch [1/4], Step [1846/3844], Loss: 0.2122\n",
      "Epoch [1/4], Step [1847/3844], Loss: 0.2026\n",
      "Epoch [1/4], Step [1848/3844], Loss: 0.1842\n",
      "Epoch [1/4], Step [1849/3844], Loss: 0.2116\n",
      "Epoch [1/4], Step [1850/3844], Loss: 0.2223\n",
      "Epoch [1/4], Step [1851/3844], Loss: 0.1745\n",
      "Epoch [1/4], Step [1852/3844], Loss: 0.1718\n",
      "Epoch [1/4], Step [1853/3844], Loss: 0.2002\n",
      "Epoch [1/4], Step [1854/3844], Loss: 0.1826\n",
      "Epoch [1/4], Step [1855/3844], Loss: 0.1828\n",
      "Epoch [1/4], Step [1856/3844], Loss: 0.1870\n",
      "Epoch [1/4], Step [1857/3844], Loss: 0.2907\n",
      "Epoch [1/4], Step [1858/3844], Loss: 0.1965\n",
      "Epoch [1/4], Step [1859/3844], Loss: 0.1748\n",
      "Epoch [1/4], Step [1860/3844], Loss: 0.1935\n",
      "Epoch [1/4], Step [1861/3844], Loss: 0.1647\n",
      "Epoch [1/4], Step [1862/3844], Loss: 0.1532\n",
      "Epoch [1/4], Step [1863/3844], Loss: 0.2009\n",
      "Epoch [1/4], Step [1864/3844], Loss: 0.1491\n",
      "Epoch [1/4], Step [1865/3844], Loss: 0.2033\n",
      "Epoch [1/4], Step [1866/3844], Loss: 0.2384\n",
      "Epoch [1/4], Step [1867/3844], Loss: 0.1634\n",
      "Epoch [1/4], Step [1868/3844], Loss: 0.1289\n",
      "Epoch [1/4], Step [1869/3844], Loss: 0.1949\n",
      "Epoch [1/4], Step [1870/3844], Loss: 0.1809\n",
      "Epoch [1/4], Step [1871/3844], Loss: 0.1593\n",
      "Epoch [1/4], Step [1872/3844], Loss: 0.1748\n",
      "Epoch [1/4], Step [1873/3844], Loss: 0.1652\n",
      "Epoch [1/4], Step [1874/3844], Loss: 0.2166\n",
      "Epoch [1/4], Step [1875/3844], Loss: 0.1405\n",
      "Epoch [1/4], Step [1876/3844], Loss: 0.2111\n",
      "Epoch [1/4], Step [1877/3844], Loss: 0.1697\n",
      "Epoch [1/4], Step [1878/3844], Loss: 0.2083\n",
      "Epoch [1/4], Step [1879/3844], Loss: 0.1515\n",
      "Epoch [1/4], Step [1880/3844], Loss: 0.1649\n",
      "Epoch [1/4], Step [1881/3844], Loss: 0.1720\n",
      "Epoch [1/4], Step [1882/3844], Loss: 0.1696\n",
      "Epoch [1/4], Step [1883/3844], Loss: 0.1960\n",
      "Epoch [1/4], Step [1884/3844], Loss: 0.1659\n",
      "Epoch [1/4], Step [1885/3844], Loss: 0.1578\n",
      "Epoch [1/4], Step [1886/3844], Loss: 0.1685\n",
      "Epoch [1/4], Step [1887/3844], Loss: 0.1823\n",
      "Epoch [1/4], Step [1888/3844], Loss: 0.1944\n",
      "Epoch [1/4], Step [1889/3844], Loss: 0.1607\n",
      "Epoch [1/4], Step [1890/3844], Loss: 0.2582\n",
      "Epoch [1/4], Step [1891/3844], Loss: 0.1709\n",
      "Epoch [1/4], Step [1892/3844], Loss: 0.1718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [1893/3844], Loss: 0.1756\n",
      "Epoch [1/4], Step [1894/3844], Loss: 0.1263\n",
      "Epoch [1/4], Step [1895/3844], Loss: 0.1860\n",
      "Epoch [1/4], Step [1896/3844], Loss: 0.1703\n",
      "Epoch [1/4], Step [1897/3844], Loss: 0.1674\n",
      "Epoch [1/4], Step [1898/3844], Loss: 0.1901\n",
      "Epoch [1/4], Step [1899/3844], Loss: 0.1720\n",
      "Epoch [1/4], Step [1900/3844], Loss: 0.2318\n",
      "Epoch [1/4], Step [1901/3844], Loss: 0.1824\n",
      "Epoch [1/4], Step [1902/3844], Loss: 0.1990\n",
      "Epoch [1/4], Step [1903/3844], Loss: 0.1628\n",
      "Epoch [1/4], Step [1904/3844], Loss: 0.2013\n",
      "Epoch [1/4], Step [1905/3844], Loss: 0.2288\n",
      "Epoch [1/4], Step [1906/3844], Loss: 0.1649\n",
      "Epoch [1/4], Step [1907/3844], Loss: 0.1815\n",
      "Epoch [1/4], Step [1908/3844], Loss: 0.1931\n",
      "Epoch [1/4], Step [1909/3844], Loss: 0.1936\n",
      "Epoch [1/4], Step [1910/3844], Loss: 0.2145\n",
      "Epoch [1/4], Step [1911/3844], Loss: 0.1736\n",
      "Epoch [1/4], Step [1912/3844], Loss: 0.1701\n",
      "Epoch [1/4], Step [1913/3844], Loss: 0.1977\n",
      "Epoch [1/4], Step [1914/3844], Loss: 0.1954\n",
      "Epoch [1/4], Step [1915/3844], Loss: 0.2067\n",
      "Epoch [1/4], Step [1916/3844], Loss: 0.1277\n",
      "Epoch [1/4], Step [1917/3844], Loss: 0.1663\n",
      "Epoch [1/4], Step [1918/3844], Loss: 0.1885\n",
      "Epoch [1/4], Step [1919/3844], Loss: 0.1640\n",
      "Epoch [1/4], Step [1920/3844], Loss: 0.1996\n",
      "Epoch [1/4], Step [1921/3844], Loss: 0.1864\n",
      "Epoch [1/4], Step [1922/3844], Loss: 0.2283\n",
      "Epoch [1/4], Step [1923/3844], Loss: 0.1896\n",
      "Epoch [1/4], Step [1924/3844], Loss: 0.1730\n",
      "Epoch [1/4], Step [1925/3844], Loss: 0.1765\n",
      "Epoch [1/4], Step [1926/3844], Loss: 0.2045\n",
      "Epoch [1/4], Step [1927/3844], Loss: 0.1893\n",
      "Epoch [1/4], Step [1928/3844], Loss: 0.1730\n",
      "Epoch [1/4], Step [1929/3844], Loss: 0.1855\n",
      "Epoch [1/4], Step [1930/3844], Loss: 0.2197\n",
      "Epoch [1/4], Step [1931/3844], Loss: 0.1730\n",
      "Epoch [1/4], Step [1932/3844], Loss: 0.2365\n",
      "Epoch [1/4], Step [1933/3844], Loss: 0.1756\n",
      "Epoch [1/4], Step [1934/3844], Loss: 0.1796\n",
      "Epoch [1/4], Step [1935/3844], Loss: 0.1609\n",
      "Epoch [1/4], Step [1936/3844], Loss: 0.1860\n",
      "Epoch [1/4], Step [1937/3844], Loss: 0.1698\n",
      "Epoch [1/4], Step [1938/3844], Loss: 0.1822\n",
      "Epoch [1/4], Step [1939/3844], Loss: 0.1935\n",
      "Epoch [1/4], Step [1940/3844], Loss: 0.1843\n",
      "Epoch [1/4], Step [1941/3844], Loss: 0.1717\n",
      "Epoch [1/4], Step [1942/3844], Loss: 0.1787\n",
      "Epoch [1/4], Step [1943/3844], Loss: 0.1640\n",
      "Epoch [1/4], Step [1944/3844], Loss: 0.2037\n",
      "Epoch [1/4], Step [1945/3844], Loss: 0.1840\n",
      "Epoch [1/4], Step [1946/3844], Loss: 0.1841\n",
      "Epoch [1/4], Step [1947/3844], Loss: 0.1743\n",
      "Epoch [1/4], Step [1948/3844], Loss: 0.1760\n",
      "Epoch [1/4], Step [1949/3844], Loss: 0.1516\n",
      "Epoch [1/4], Step [1950/3844], Loss: 0.1901\n",
      "Epoch [1/4], Step [1951/3844], Loss: 0.1769\n",
      "Epoch [1/4], Step [1952/3844], Loss: 0.1659\n",
      "Epoch [1/4], Step [1953/3844], Loss: 0.1598\n",
      "Epoch [1/4], Step [1954/3844], Loss: 0.1583\n",
      "Epoch [1/4], Step [1955/3844], Loss: 0.1823\n",
      "Epoch [1/4], Step [1956/3844], Loss: 0.1751\n",
      "Epoch [1/4], Step [1957/3844], Loss: 0.1955\n",
      "Epoch [1/4], Step [1958/3844], Loss: 0.1812\n",
      "Epoch [1/4], Step [1959/3844], Loss: 0.1884\n",
      "Epoch [1/4], Step [1960/3844], Loss: 0.1721\n",
      "Epoch [1/4], Step [1961/3844], Loss: 0.1963\n",
      "Epoch [1/4], Step [1962/3844], Loss: 0.1812\n",
      "Epoch [1/4], Step [1963/3844], Loss: 0.2136\n",
      "Epoch [1/4], Step [1964/3844], Loss: 0.1893\n",
      "Epoch [1/4], Step [1965/3844], Loss: 0.1862\n",
      "Epoch [1/4], Step [1966/3844], Loss: 0.2055\n",
      "Epoch [1/4], Step [1967/3844], Loss: 0.1554\n",
      "Epoch [1/4], Step [1968/3844], Loss: 0.1710\n",
      "Epoch [1/4], Step [1969/3844], Loss: 0.2079\n",
      "Epoch [1/4], Step [1970/3844], Loss: 0.1800\n",
      "Epoch [1/4], Step [1971/3844], Loss: 0.2004\n",
      "Epoch [1/4], Step [1972/3844], Loss: 0.1601\n",
      "Epoch [1/4], Step [1973/3844], Loss: 0.1581\n",
      "Epoch [1/4], Step [1974/3844], Loss: 0.1481\n",
      "Epoch [1/4], Step [1975/3844], Loss: 0.1887\n",
      "Epoch [1/4], Step [1976/3844], Loss: 0.1411\n",
      "Epoch [1/4], Step [1977/3844], Loss: 0.1796\n",
      "Epoch [1/4], Step [1978/3844], Loss: 0.1808\n",
      "Epoch [1/4], Step [1979/3844], Loss: 0.1425\n",
      "Epoch [1/4], Step [1980/3844], Loss: 0.1777\n",
      "Epoch [1/4], Step [1981/3844], Loss: 0.1865\n",
      "Epoch [1/4], Step [1982/3844], Loss: 0.1725\n",
      "Epoch [1/4], Step [1983/3844], Loss: 0.1982\n",
      "Epoch [1/4], Step [1984/3844], Loss: 0.1600\n",
      "Epoch [1/4], Step [1985/3844], Loss: 0.1753\n",
      "Epoch [1/4], Step [1986/3844], Loss: 0.1789\n",
      "Epoch [1/4], Step [1987/3844], Loss: 0.2661\n",
      "Epoch [1/4], Step [1988/3844], Loss: 0.1624\n",
      "Epoch [1/4], Step [1989/3844], Loss: 0.1934\n",
      "Epoch [1/4], Step [1990/3844], Loss: 0.1708\n",
      "Epoch [1/4], Step [1991/3844], Loss: 0.2052\n",
      "Epoch [1/4], Step [1992/3844], Loss: 0.1783\n",
      "Epoch [1/4], Step [1993/3844], Loss: 0.1810\n",
      "Epoch [1/4], Step [1994/3844], Loss: 0.1663\n",
      "Epoch [1/4], Step [1995/3844], Loss: 0.1787\n",
      "Epoch [1/4], Step [1996/3844], Loss: 0.1644\n",
      "Epoch [1/4], Step [1997/3844], Loss: 0.1854\n",
      "Epoch [1/4], Step [1998/3844], Loss: 0.2139\n",
      "Epoch [1/4], Step [1999/3844], Loss: 0.1656\n",
      "Epoch [1/4], Step [2000/3844], Loss: 0.1884\n",
      "Epoch [1/4], Step [2001/3844], Loss: 0.1809\n",
      "Epoch [1/4], Step [2002/3844], Loss: 0.1736\n",
      "Epoch [1/4], Step [2003/3844], Loss: 0.1519\n",
      "Epoch [1/4], Step [2004/3844], Loss: 0.1901\n",
      "Epoch [1/4], Step [2005/3844], Loss: 0.1919\n",
      "Epoch [1/4], Step [2006/3844], Loss: 0.1650\n",
      "Epoch [1/4], Step [2007/3844], Loss: 0.1566\n",
      "Epoch [1/4], Step [2008/3844], Loss: 0.1474\n",
      "Epoch [1/4], Step [2009/3844], Loss: 0.2244\n",
      "Epoch [1/4], Step [2010/3844], Loss: 0.1634\n",
      "Epoch [1/4], Step [2011/3844], Loss: 0.1602\n",
      "Epoch [1/4], Step [2012/3844], Loss: 0.1633\n",
      "Epoch [1/4], Step [2013/3844], Loss: 0.1924\n",
      "Epoch [1/4], Step [2014/3844], Loss: 0.1688\n",
      "Epoch [1/4], Step [2015/3844], Loss: 0.1769\n",
      "Epoch [1/4], Step [2016/3844], Loss: 0.2212\n",
      "Epoch [1/4], Step [2017/3844], Loss: 0.1659\n",
      "Epoch [1/4], Step [2018/3844], Loss: 0.2498\n",
      "Epoch [1/4], Step [2019/3844], Loss: 0.1631\n",
      "Epoch [1/4], Step [2020/3844], Loss: 0.1587\n",
      "Epoch [1/4], Step [2021/3844], Loss: 0.1658\n",
      "Epoch [1/4], Step [2022/3844], Loss: 0.2062\n",
      "Epoch [1/4], Step [2023/3844], Loss: 0.2166\n",
      "Epoch [1/4], Step [2024/3844], Loss: 0.1546\n",
      "Epoch [1/4], Step [2025/3844], Loss: 0.2336\n",
      "Epoch [1/4], Step [2026/3844], Loss: 0.2214\n",
      "Epoch [1/4], Step [2027/3844], Loss: 0.1713\n",
      "Epoch [1/4], Step [2028/3844], Loss: 0.1629\n",
      "Epoch [1/4], Step [2029/3844], Loss: 0.1999\n",
      "Epoch [1/4], Step [2030/3844], Loss: 0.1721\n",
      "Epoch [1/4], Step [2031/3844], Loss: 0.1979\n",
      "Epoch [1/4], Step [2032/3844], Loss: 0.1748\n",
      "Epoch [1/4], Step [2033/3844], Loss: 0.1860\n",
      "Epoch [1/4], Step [2034/3844], Loss: 0.1730\n",
      "Epoch [1/4], Step [2035/3844], Loss: 0.1861\n",
      "Epoch [1/4], Step [2036/3844], Loss: 0.1938\n",
      "Epoch [1/4], Step [2037/3844], Loss: 0.1804\n",
      "Epoch [1/4], Step [2038/3844], Loss: 0.1527\n",
      "Epoch [1/4], Step [2039/3844], Loss: 0.1792\n",
      "Epoch [1/4], Step [2040/3844], Loss: 0.1753\n",
      "Epoch [1/4], Step [2041/3844], Loss: 0.1628\n",
      "Epoch [1/4], Step [2042/3844], Loss: 0.1660\n",
      "Epoch [1/4], Step [2043/3844], Loss: 0.2405\n",
      "Epoch [1/4], Step [2044/3844], Loss: 0.2391\n",
      "Epoch [1/4], Step [2045/3844], Loss: 0.2269\n",
      "Epoch [1/4], Step [2046/3844], Loss: 0.2007\n",
      "Epoch [1/4], Step [2047/3844], Loss: 0.1864\n",
      "Epoch [1/4], Step [2048/3844], Loss: 0.1574\n",
      "Epoch [1/4], Step [2049/3844], Loss: 0.1984\n",
      "Epoch [1/4], Step [2050/3844], Loss: 0.1740\n",
      "Epoch [1/4], Step [2051/3844], Loss: 0.1742\n",
      "Epoch [1/4], Step [2052/3844], Loss: 0.1713\n",
      "Epoch [1/4], Step [2053/3844], Loss: 0.1696\n",
      "Epoch [1/4], Step [2054/3844], Loss: 0.1717\n",
      "Epoch [1/4], Step [2055/3844], Loss: 0.1810\n",
      "Epoch [1/4], Step [2056/3844], Loss: 0.1447\n",
      "Epoch [1/4], Step [2057/3844], Loss: 0.1757\n",
      "Epoch [1/4], Step [2058/3844], Loss: 0.1613\n",
      "Epoch [1/4], Step [2059/3844], Loss: 0.1618\n",
      "Epoch [1/4], Step [2060/3844], Loss: 0.1710\n",
      "Epoch [1/4], Step [2061/3844], Loss: 0.1982\n",
      "Epoch [1/4], Step [2062/3844], Loss: 0.2192\n",
      "Epoch [1/4], Step [2063/3844], Loss: 0.1948\n",
      "Epoch [1/4], Step [2064/3844], Loss: 0.1864\n",
      "Epoch [1/4], Step [2065/3844], Loss: 0.1791\n",
      "Epoch [1/4], Step [2066/3844], Loss: 0.1563\n",
      "Epoch [1/4], Step [2067/3844], Loss: 0.1994\n",
      "Epoch [1/4], Step [2068/3844], Loss: 0.1564\n",
      "Epoch [1/4], Step [2069/3844], Loss: 0.1576\n",
      "Epoch [1/4], Step [2070/3844], Loss: 0.1806\n",
      "Epoch [1/4], Step [2071/3844], Loss: 0.1474\n",
      "Epoch [1/4], Step [2072/3844], Loss: 0.2117\n",
      "Epoch [1/4], Step [2073/3844], Loss: 0.1951\n",
      "Epoch [1/4], Step [2074/3844], Loss: 0.1282\n",
      "Epoch [1/4], Step [2075/3844], Loss: 0.1505\n",
      "Epoch [1/4], Step [2076/3844], Loss: 0.1940\n",
      "Epoch [1/4], Step [2077/3844], Loss: 0.1983\n",
      "Epoch [1/4], Step [2078/3844], Loss: 0.1637\n",
      "Epoch [1/4], Step [2079/3844], Loss: 0.1892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [2080/3844], Loss: 0.1758\n",
      "Epoch [1/4], Step [2081/3844], Loss: 0.1885\n",
      "Epoch [1/4], Step [2082/3844], Loss: 0.1772\n",
      "Epoch [1/4], Step [2083/3844], Loss: 0.1891\n",
      "Epoch [1/4], Step [2084/3844], Loss: 0.1853\n",
      "Epoch [1/4], Step [2085/3844], Loss: 0.1781\n",
      "Epoch [1/4], Step [2086/3844], Loss: 0.1790\n",
      "Epoch [1/4], Step [2087/3844], Loss: 0.1792\n",
      "Epoch [1/4], Step [2088/3844], Loss: 0.1556\n",
      "Epoch [1/4], Step [2089/3844], Loss: 0.1657\n",
      "Epoch [1/4], Step [2090/3844], Loss: 0.1897\n",
      "Epoch [1/4], Step [2091/3844], Loss: 0.1803\n",
      "Epoch [1/4], Step [2092/3844], Loss: 0.1804\n",
      "Epoch [1/4], Step [2093/3844], Loss: 0.1779\n",
      "Epoch [1/4], Step [2094/3844], Loss: 0.1342\n",
      "Epoch [1/4], Step [2095/3844], Loss: 0.1437\n",
      "Epoch [1/4], Step [2096/3844], Loss: 0.1525\n",
      "Epoch [1/4], Step [2097/3844], Loss: 0.1842\n",
      "Epoch [1/4], Step [2098/3844], Loss: 0.1951\n",
      "Epoch [1/4], Step [2099/3844], Loss: 0.2095\n",
      "Epoch [1/4], Step [2100/3844], Loss: 0.1701\n",
      "Epoch [1/4], Step [2101/3844], Loss: 0.2282\n",
      "Epoch [1/4], Step [2102/3844], Loss: 0.1555\n",
      "Epoch [1/4], Step [2103/3844], Loss: 0.1879\n",
      "Epoch [1/4], Step [2104/3844], Loss: 0.1513\n",
      "Epoch [1/4], Step [2105/3844], Loss: 0.1595\n",
      "Epoch [1/4], Step [2106/3844], Loss: 0.1822\n",
      "Epoch [1/4], Step [2107/3844], Loss: 0.1809\n",
      "Epoch [1/4], Step [2108/3844], Loss: 0.1802\n",
      "Epoch [1/4], Step [2109/3844], Loss: 0.1643\n",
      "Epoch [1/4], Step [2110/3844], Loss: 0.1665\n",
      "Epoch [1/4], Step [2111/3844], Loss: 0.1621\n",
      "Epoch [1/4], Step [2112/3844], Loss: 0.1444\n",
      "Epoch [1/4], Step [2113/3844], Loss: 0.1443\n",
      "Epoch [1/4], Step [2114/3844], Loss: 0.1220\n",
      "Epoch [1/4], Step [2115/3844], Loss: 0.2273\n",
      "Epoch [1/4], Step [2116/3844], Loss: 0.1519\n",
      "Epoch [1/4], Step [2117/3844], Loss: 0.1913\n",
      "Epoch [1/4], Step [2118/3844], Loss: 0.2264\n",
      "Epoch [1/4], Step [2119/3844], Loss: 0.2014\n",
      "Epoch [1/4], Step [2120/3844], Loss: 0.1792\n",
      "Epoch [1/4], Step [2121/3844], Loss: 0.1565\n",
      "Epoch [1/4], Step [2122/3844], Loss: 0.1671\n",
      "Epoch [1/4], Step [2123/3844], Loss: 0.1892\n",
      "Epoch [1/4], Step [2124/3844], Loss: 0.1925\n",
      "Epoch [1/4], Step [2125/3844], Loss: 0.1585\n",
      "Epoch [1/4], Step [2126/3844], Loss: 0.1900\n",
      "Epoch [1/4], Step [2127/3844], Loss: 0.1811\n",
      "Epoch [1/4], Step [2128/3844], Loss: 0.1725\n",
      "Epoch [1/4], Step [2129/3844], Loss: 0.1811\n",
      "Epoch [1/4], Step [2130/3844], Loss: 0.1674\n",
      "Epoch [1/4], Step [2131/3844], Loss: 0.1860\n",
      "Epoch [1/4], Step [2132/3844], Loss: 0.1538\n",
      "Epoch [1/4], Step [2133/3844], Loss: 0.1918\n",
      "Epoch [1/4], Step [2134/3844], Loss: 0.1622\n",
      "Epoch [1/4], Step [2135/3844], Loss: 0.1711\n",
      "Epoch [1/4], Step [2136/3844], Loss: 0.1870\n",
      "Epoch [1/4], Step [2137/3844], Loss: 0.1742\n",
      "Epoch [1/4], Step [2138/3844], Loss: 0.1449\n",
      "Epoch [1/4], Step [2139/3844], Loss: 0.2161\n",
      "Epoch [1/4], Step [2140/3844], Loss: 0.1679\n",
      "Epoch [1/4], Step [2141/3844], Loss: 0.1952\n",
      "Epoch [1/4], Step [2142/3844], Loss: 0.1761\n",
      "Epoch [1/4], Step [2143/3844], Loss: 0.1935\n",
      "Epoch [1/4], Step [2144/3844], Loss: 0.2270\n",
      "Epoch [1/4], Step [2145/3844], Loss: 0.1572\n",
      "Epoch [1/4], Step [2146/3844], Loss: 0.1725\n",
      "Epoch [1/4], Step [2147/3844], Loss: 0.1832\n",
      "Epoch [1/4], Step [2148/3844], Loss: 0.1966\n",
      "Epoch [1/4], Step [2149/3844], Loss: 0.2019\n",
      "Epoch [1/4], Step [2150/3844], Loss: 0.1802\n",
      "Epoch [1/4], Step [2151/3844], Loss: 0.2313\n",
      "Epoch [1/4], Step [2152/3844], Loss: 0.1936\n",
      "Epoch [1/4], Step [2153/3844], Loss: 0.2380\n",
      "Epoch [1/4], Step [2154/3844], Loss: 0.2175\n",
      "Epoch [1/4], Step [2155/3844], Loss: 0.1921\n",
      "Epoch [1/4], Step [2156/3844], Loss: 0.1962\n",
      "Epoch [1/4], Step [2157/3844], Loss: 0.1489\n",
      "Epoch [1/4], Step [2158/3844], Loss: 0.1824\n",
      "Epoch [1/4], Step [2159/3844], Loss: 0.1937\n",
      "Epoch [1/4], Step [2160/3844], Loss: 0.1917\n",
      "Epoch [1/4], Step [2161/3844], Loss: 0.1697\n",
      "Epoch [1/4], Step [2162/3844], Loss: 0.1736\n",
      "Epoch [1/4], Step [2163/3844], Loss: 0.1743\n",
      "Epoch [1/4], Step [2164/3844], Loss: 0.1730\n",
      "Epoch [1/4], Step [2165/3844], Loss: 0.1692\n",
      "Epoch [1/4], Step [2166/3844], Loss: 0.1752\n",
      "Epoch [1/4], Step [2167/3844], Loss: 0.1780\n",
      "Epoch [1/4], Step [2168/3844], Loss: 0.2765\n",
      "Epoch [1/4], Step [2169/3844], Loss: 0.2205\n",
      "Epoch [1/4], Step [2170/3844], Loss: 0.1652\n",
      "Epoch [1/4], Step [2171/3844], Loss: 0.1891\n",
      "Epoch [1/4], Step [2172/3844], Loss: 0.2425\n",
      "Epoch [1/4], Step [2173/3844], Loss: 0.1487\n",
      "Epoch [1/4], Step [2174/3844], Loss: 0.1718\n",
      "Epoch [1/4], Step [2175/3844], Loss: 0.1480\n",
      "Epoch [1/4], Step [2176/3844], Loss: 0.1879\n",
      "Epoch [1/4], Step [2177/3844], Loss: 0.1993\n",
      "Epoch [1/4], Step [2178/3844], Loss: 0.1941\n",
      "Epoch [1/4], Step [2179/3844], Loss: 0.2077\n",
      "Epoch [1/4], Step [2180/3844], Loss: 0.1694\n",
      "Epoch [1/4], Step [2181/3844], Loss: 0.1546\n",
      "Epoch [1/4], Step [2182/3844], Loss: 0.1687\n",
      "Epoch [1/4], Step [2183/3844], Loss: 0.2328\n",
      "Epoch [1/4], Step [2184/3844], Loss: 0.1746\n",
      "Epoch [1/4], Step [2185/3844], Loss: 0.1871\n",
      "Epoch [1/4], Step [2186/3844], Loss: 0.1847\n",
      "Epoch [1/4], Step [2187/3844], Loss: 0.1710\n",
      "Epoch [1/4], Step [2188/3844], Loss: 0.2277\n",
      "Epoch [1/4], Step [2189/3844], Loss: 0.1661\n",
      "Epoch [1/4], Step [2190/3844], Loss: 0.2067\n",
      "Epoch [1/4], Step [2191/3844], Loss: 0.2202\n",
      "Epoch [1/4], Step [2192/3844], Loss: 0.2114\n",
      "Epoch [1/4], Step [2193/3844], Loss: 0.1671\n",
      "Epoch [1/4], Step [2194/3844], Loss: 0.1555\n",
      "Epoch [1/4], Step [2195/3844], Loss: 0.1596\n",
      "Epoch [1/4], Step [2196/3844], Loss: 0.1689\n",
      "Epoch [1/4], Step [2197/3844], Loss: 0.1942\n",
      "Epoch [1/4], Step [2198/3844], Loss: 0.2407\n",
      "Epoch [1/4], Step [2199/3844], Loss: 0.1770\n",
      "Epoch [1/4], Step [2200/3844], Loss: 0.1611\n",
      "Epoch [1/4], Step [2201/3844], Loss: 0.1568\n",
      "Epoch [1/4], Step [2202/3844], Loss: 0.1886\n",
      "Epoch [1/4], Step [2203/3844], Loss: 0.1842\n",
      "Epoch [1/4], Step [2204/3844], Loss: 0.1724\n",
      "Epoch [1/4], Step [2205/3844], Loss: 0.1680\n",
      "Epoch [1/4], Step [2206/3844], Loss: 0.1877\n",
      "Epoch [1/4], Step [2207/3844], Loss: 0.2077\n",
      "Epoch [1/4], Step [2208/3844], Loss: 0.1792\n",
      "Epoch [1/4], Step [2209/3844], Loss: 0.1890\n",
      "Epoch [1/4], Step [2210/3844], Loss: 0.1376\n",
      "Epoch [1/4], Step [2211/3844], Loss: 0.2495\n",
      "Epoch [1/4], Step [2212/3844], Loss: 0.1691\n",
      "Epoch [1/4], Step [2213/3844], Loss: 0.1613\n",
      "Epoch [1/4], Step [2214/3844], Loss: 0.1486\n",
      "Epoch [1/4], Step [2215/3844], Loss: 0.1777\n",
      "Epoch [1/4], Step [2216/3844], Loss: 0.1779\n",
      "Epoch [1/4], Step [2217/3844], Loss: 0.1894\n",
      "Epoch [1/4], Step [2218/3844], Loss: 0.2234\n",
      "Epoch [1/4], Step [2219/3844], Loss: 0.1387\n",
      "Epoch [1/4], Step [2220/3844], Loss: 0.1814\n",
      "Epoch [1/4], Step [2221/3844], Loss: 0.1927\n",
      "Epoch [1/4], Step [2222/3844], Loss: 0.1878\n",
      "Epoch [1/4], Step [2223/3844], Loss: 0.1700\n",
      "Epoch [1/4], Step [2224/3844], Loss: 0.1608\n",
      "Epoch [1/4], Step [2225/3844], Loss: 0.1765\n",
      "Epoch [1/4], Step [2226/3844], Loss: 0.1695\n",
      "Epoch [1/4], Step [2227/3844], Loss: 0.2229\n",
      "Epoch [1/4], Step [2228/3844], Loss: 0.1680\n",
      "Epoch [1/4], Step [2229/3844], Loss: 0.1641\n",
      "Epoch [1/4], Step [2230/3844], Loss: 0.2004\n",
      "Epoch [1/4], Step [2231/3844], Loss: 0.1920\n",
      "Epoch [1/4], Step [2232/3844], Loss: 0.1779\n",
      "Epoch [1/4], Step [2233/3844], Loss: 0.1693\n",
      "Epoch [1/4], Step [2234/3844], Loss: 0.1606\n",
      "Epoch [1/4], Step [2235/3844], Loss: 0.1743\n",
      "Epoch [1/4], Step [2236/3844], Loss: 0.2262\n",
      "Epoch [1/4], Step [2237/3844], Loss: 0.1598\n",
      "Epoch [1/4], Step [2238/3844], Loss: 0.1692\n",
      "Epoch [1/4], Step [2239/3844], Loss: 0.2078\n",
      "Epoch [1/4], Step [2240/3844], Loss: 0.1396\n",
      "Epoch [1/4], Step [2241/3844], Loss: 0.1580\n",
      "Epoch [1/4], Step [2242/3844], Loss: 0.1673\n",
      "Epoch [1/4], Step [2243/3844], Loss: 0.1546\n",
      "Epoch [1/4], Step [2244/3844], Loss: 0.2058\n",
      "Epoch [1/4], Step [2245/3844], Loss: 0.1973\n",
      "Epoch [1/4], Step [2246/3844], Loss: 0.2304\n",
      "Epoch [1/4], Step [2247/3844], Loss: 0.1758\n",
      "Epoch [1/4], Step [2248/3844], Loss: 0.1862\n",
      "Epoch [1/4], Step [2249/3844], Loss: 0.2139\n",
      "Epoch [1/4], Step [2250/3844], Loss: 0.2298\n",
      "Epoch [1/4], Step [2251/3844], Loss: 0.1811\n",
      "Epoch [1/4], Step [2252/3844], Loss: 0.1653\n",
      "Epoch [1/4], Step [2253/3844], Loss: 0.1794\n",
      "Epoch [1/4], Step [2254/3844], Loss: 0.2248\n",
      "Epoch [1/4], Step [2255/3844], Loss: 0.1605\n",
      "Epoch [1/4], Step [2256/3844], Loss: 0.1201\n",
      "Epoch [1/4], Step [2257/3844], Loss: 0.1776\n",
      "Epoch [1/4], Step [2258/3844], Loss: 0.1947\n",
      "Epoch [1/4], Step [2259/3844], Loss: 0.1839\n",
      "Epoch [1/4], Step [2260/3844], Loss: 0.1784\n",
      "Epoch [1/4], Step [2261/3844], Loss: 0.1356\n",
      "Epoch [1/4], Step [2262/3844], Loss: 0.2055\n",
      "Epoch [1/4], Step [2263/3844], Loss: 0.1733\n",
      "Epoch [1/4], Step [2264/3844], Loss: 0.1855\n",
      "Epoch [1/4], Step [2265/3844], Loss: 0.1609\n",
      "Epoch [1/4], Step [2266/3844], Loss: 0.1475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [2267/3844], Loss: 0.1866\n",
      "Epoch [1/4], Step [2268/3844], Loss: 0.1644\n",
      "Epoch [1/4], Step [2269/3844], Loss: 0.1667\n",
      "Epoch [1/4], Step [2270/3844], Loss: 0.1825\n",
      "Epoch [1/4], Step [2271/3844], Loss: 0.1757\n",
      "Epoch [1/4], Step [2272/3844], Loss: 0.1767\n",
      "Epoch [1/4], Step [2273/3844], Loss: 0.1809\n",
      "Epoch [1/4], Step [2274/3844], Loss: 0.2077\n",
      "Epoch [1/4], Step [2275/3844], Loss: 0.1954\n",
      "Epoch [1/4], Step [2276/3844], Loss: 0.1629\n",
      "Epoch [1/4], Step [2277/3844], Loss: 0.1605\n",
      "Epoch [1/4], Step [2278/3844], Loss: 0.1644\n",
      "Epoch [1/4], Step [2279/3844], Loss: 0.2036\n",
      "Epoch [1/4], Step [2280/3844], Loss: 0.1902\n",
      "Epoch [1/4], Step [2281/3844], Loss: 0.1453\n",
      "Epoch [1/4], Step [2282/3844], Loss: 0.1523\n",
      "Epoch [1/4], Step [2283/3844], Loss: 0.1784\n",
      "Epoch [1/4], Step [2284/3844], Loss: 0.1617\n",
      "Epoch [1/4], Step [2285/3844], Loss: 0.1796\n",
      "Epoch [1/4], Step [2286/3844], Loss: 0.1979\n",
      "Epoch [1/4], Step [2287/3844], Loss: 0.1885\n",
      "Epoch [1/4], Step [2288/3844], Loss: 0.1862\n",
      "Epoch [1/4], Step [2289/3844], Loss: 0.1771\n",
      "Epoch [1/4], Step [2290/3844], Loss: 0.1942\n",
      "Epoch [1/4], Step [2291/3844], Loss: 0.1661\n",
      "Epoch [1/4], Step [2292/3844], Loss: 0.1690\n",
      "Epoch [1/4], Step [2293/3844], Loss: 0.1910\n",
      "Epoch [1/4], Step [2294/3844], Loss: 0.2006\n",
      "Epoch [1/4], Step [2295/3844], Loss: 0.1494\n",
      "Epoch [1/4], Step [2296/3844], Loss: 0.1527\n",
      "Epoch [1/4], Step [2297/3844], Loss: 0.1557\n",
      "Epoch [1/4], Step [2298/3844], Loss: 0.1693\n",
      "Epoch [1/4], Step [2299/3844], Loss: 0.1812\n",
      "Epoch [1/4], Step [2300/3844], Loss: 0.1721\n",
      "Epoch [1/4], Step [2301/3844], Loss: 0.2139\n",
      "Epoch [1/4], Step [2302/3844], Loss: 0.1851\n",
      "Epoch [1/4], Step [2303/3844], Loss: 0.1536\n",
      "Epoch [1/4], Step [2304/3844], Loss: 0.2107\n",
      "Epoch [1/4], Step [2305/3844], Loss: 0.2084\n",
      "Epoch [1/4], Step [2306/3844], Loss: 0.1576\n",
      "Epoch [1/4], Step [2307/3844], Loss: 0.1772\n",
      "Epoch [1/4], Step [2308/3844], Loss: 0.1812\n",
      "Epoch [1/4], Step [2309/3844], Loss: 0.1805\n",
      "Epoch [1/4], Step [2310/3844], Loss: 0.1779\n",
      "Epoch [1/4], Step [2311/3844], Loss: 0.2406\n",
      "Epoch [1/4], Step [2312/3844], Loss: 0.1925\n",
      "Epoch [1/4], Step [2313/3844], Loss: 0.1842\n",
      "Epoch [1/4], Step [2314/3844], Loss: 0.1624\n",
      "Epoch [1/4], Step [2315/3844], Loss: 0.1989\n",
      "Epoch [1/4], Step [2316/3844], Loss: 0.1579\n",
      "Epoch [1/4], Step [2317/3844], Loss: 0.1754\n",
      "Epoch [1/4], Step [2318/3844], Loss: 0.1955\n",
      "Epoch [1/4], Step [2319/3844], Loss: 0.2090\n",
      "Epoch [1/4], Step [2320/3844], Loss: 0.2261\n",
      "Epoch [1/4], Step [2321/3844], Loss: 0.1596\n",
      "Epoch [1/4], Step [2322/3844], Loss: 0.1646\n",
      "Epoch [1/4], Step [2323/3844], Loss: 0.2170\n",
      "Epoch [1/4], Step [2324/3844], Loss: 0.1322\n",
      "Epoch [1/4], Step [2325/3844], Loss: 0.2014\n",
      "Epoch [1/4], Step [2326/3844], Loss: 0.1484\n",
      "Epoch [1/4], Step [2327/3844], Loss: 0.1393\n",
      "Epoch [1/4], Step [2328/3844], Loss: 0.1903\n",
      "Epoch [1/4], Step [2329/3844], Loss: 0.2020\n",
      "Epoch [1/4], Step [2330/3844], Loss: 0.1695\n",
      "Epoch [1/4], Step [2331/3844], Loss: 0.1740\n",
      "Epoch [1/4], Step [2332/3844], Loss: 0.1801\n",
      "Epoch [1/4], Step [2333/3844], Loss: 0.1629\n",
      "Epoch [1/4], Step [2334/3844], Loss: 0.1768\n",
      "Epoch [1/4], Step [2335/3844], Loss: 0.1996\n",
      "Epoch [1/4], Step [2336/3844], Loss: 0.1688\n",
      "Epoch [1/4], Step [2337/3844], Loss: 0.1725\n",
      "Epoch [1/4], Step [2338/3844], Loss: 0.1343\n",
      "Epoch [1/4], Step [2339/3844], Loss: 0.1724\n",
      "Epoch [1/4], Step [2340/3844], Loss: 0.1818\n",
      "Epoch [1/4], Step [2341/3844], Loss: 0.1559\n",
      "Epoch [1/4], Step [2342/3844], Loss: 0.1302\n",
      "Epoch [1/4], Step [2343/3844], Loss: 0.2435\n",
      "Epoch [1/4], Step [2344/3844], Loss: 0.2287\n",
      "Epoch [1/4], Step [2345/3844], Loss: 0.1792\n",
      "Epoch [1/4], Step [2346/3844], Loss: 0.1824\n",
      "Epoch [1/4], Step [2347/3844], Loss: 0.1499\n",
      "Epoch [1/4], Step [2348/3844], Loss: 0.1859\n",
      "Epoch [1/4], Step [2349/3844], Loss: 0.1801\n",
      "Epoch [1/4], Step [2350/3844], Loss: 0.2031\n",
      "Epoch [1/4], Step [2351/3844], Loss: 0.2311\n",
      "Epoch [1/4], Step [2352/3844], Loss: 0.1773\n",
      "Epoch [1/4], Step [2353/3844], Loss: 0.1746\n",
      "Epoch [1/4], Step [2354/3844], Loss: 0.1147\n",
      "Epoch [1/4], Step [2355/3844], Loss: 0.2314\n",
      "Epoch [1/4], Step [2356/3844], Loss: 0.1630\n",
      "Epoch [1/4], Step [2357/3844], Loss: 0.1775\n",
      "Epoch [1/4], Step [2358/3844], Loss: 0.1782\n",
      "Epoch [1/4], Step [2359/3844], Loss: 0.1865\n",
      "Epoch [1/4], Step [2360/3844], Loss: 0.1831\n",
      "Epoch [1/4], Step [2361/3844], Loss: 0.2349\n",
      "Epoch [1/4], Step [2362/3844], Loss: 0.1662\n",
      "Epoch [1/4], Step [2363/3844], Loss: 0.1393\n",
      "Epoch [1/4], Step [2364/3844], Loss: 0.1599\n",
      "Epoch [1/4], Step [2365/3844], Loss: 0.1685\n",
      "Epoch [1/4], Step [2366/3844], Loss: 0.1666\n",
      "Epoch [1/4], Step [2367/3844], Loss: 0.1687\n",
      "Epoch [1/4], Step [2368/3844], Loss: 0.2850\n",
      "Epoch [1/4], Step [2369/3844], Loss: 0.1799\n",
      "Epoch [1/4], Step [2370/3844], Loss: 0.1736\n",
      "Epoch [1/4], Step [2371/3844], Loss: 0.1987\n",
      "Epoch [1/4], Step [2372/3844], Loss: 0.2030\n",
      "Epoch [1/4], Step [2373/3844], Loss: 0.2082\n",
      "Epoch [1/4], Step [2374/3844], Loss: 0.1823\n",
      "Epoch [1/4], Step [2375/3844], Loss: 0.1981\n",
      "Epoch [1/4], Step [2376/3844], Loss: 0.1642\n",
      "Epoch [1/4], Step [2377/3844], Loss: 0.1693\n",
      "Epoch [1/4], Step [2378/3844], Loss: 0.1524\n",
      "Epoch [1/4], Step [2379/3844], Loss: 0.1717\n",
      "Epoch [1/4], Step [2380/3844], Loss: 0.1845\n",
      "Epoch [1/4], Step [2381/3844], Loss: 0.1805\n",
      "Epoch [1/4], Step [2382/3844], Loss: 0.1458\n",
      "Epoch [1/4], Step [2383/3844], Loss: 0.2112\n",
      "Epoch [1/4], Step [2384/3844], Loss: 0.1832\n",
      "Epoch [1/4], Step [2385/3844], Loss: 0.1487\n",
      "Epoch [1/4], Step [2386/3844], Loss: 0.1951\n",
      "Epoch [1/4], Step [2387/3844], Loss: 0.1349\n",
      "Epoch [1/4], Step [2388/3844], Loss: 0.1382\n",
      "Epoch [1/4], Step [2389/3844], Loss: 0.1550\n",
      "Epoch [1/4], Step [2390/3844], Loss: 0.1836\n",
      "Epoch [1/4], Step [2391/3844], Loss: 0.2048\n",
      "Epoch [1/4], Step [2392/3844], Loss: 0.1943\n",
      "Epoch [1/4], Step [2393/3844], Loss: 0.1437\n",
      "Epoch [1/4], Step [2394/3844], Loss: 0.1932\n",
      "Epoch [1/4], Step [2395/3844], Loss: 0.1407\n",
      "Epoch [1/4], Step [2396/3844], Loss: 0.1702\n",
      "Epoch [1/4], Step [2397/3844], Loss: 0.1686\n",
      "Epoch [1/4], Step [2398/3844], Loss: 0.1877\n",
      "Epoch [1/4], Step [2399/3844], Loss: 0.2397\n",
      "Epoch [1/4], Step [2400/3844], Loss: 0.1668\n",
      "Epoch [1/4], Step [2401/3844], Loss: 0.1487\n",
      "Epoch [1/4], Step [2402/3844], Loss: 0.1552\n",
      "Epoch [1/4], Step [2403/3844], Loss: 0.1504\n",
      "Epoch [1/4], Step [2404/3844], Loss: 0.1972\n",
      "Epoch [1/4], Step [2405/3844], Loss: 0.1863\n",
      "Epoch [1/4], Step [2406/3844], Loss: 0.1968\n",
      "Epoch [1/4], Step [2407/3844], Loss: 0.1570\n",
      "Epoch [1/4], Step [2408/3844], Loss: 0.1687\n",
      "Epoch [1/4], Step [2409/3844], Loss: 0.1783\n",
      "Epoch [1/4], Step [2410/3844], Loss: 0.1668\n",
      "Epoch [1/4], Step [2411/3844], Loss: 0.1628\n",
      "Epoch [1/4], Step [2412/3844], Loss: 0.2098\n",
      "Epoch [1/4], Step [2413/3844], Loss: 0.1747\n",
      "Epoch [1/4], Step [2414/3844], Loss: 0.2001\n",
      "Epoch [1/4], Step [2415/3844], Loss: 0.1794\n",
      "Epoch [1/4], Step [2416/3844], Loss: 0.1524\n",
      "Epoch [1/4], Step [2417/3844], Loss: 0.1898\n",
      "Epoch [1/4], Step [2418/3844], Loss: 0.1422\n",
      "Epoch [1/4], Step [2419/3844], Loss: 0.1943\n",
      "Epoch [1/4], Step [2420/3844], Loss: 0.1665\n",
      "Epoch [1/4], Step [2421/3844], Loss: 0.2074\n",
      "Epoch [1/4], Step [2422/3844], Loss: 0.1659\n",
      "Epoch [1/4], Step [2423/3844], Loss: 0.1618\n",
      "Epoch [1/4], Step [2424/3844], Loss: 0.1578\n",
      "Epoch [1/4], Step [2425/3844], Loss: 0.2028\n",
      "Epoch [1/4], Step [2426/3844], Loss: 0.1752\n",
      "Epoch [1/4], Step [2427/3844], Loss: 0.1674\n",
      "Epoch [1/4], Step [2428/3844], Loss: 0.1897\n",
      "Epoch [1/4], Step [2429/3844], Loss: 0.1452\n",
      "Epoch [1/4], Step [2430/3844], Loss: 0.1686\n",
      "Epoch [1/4], Step [2431/3844], Loss: 0.1661\n",
      "Epoch [1/4], Step [2432/3844], Loss: 0.1660\n",
      "Epoch [1/4], Step [2433/3844], Loss: 0.1843\n",
      "Epoch [1/4], Step [2434/3844], Loss: 0.1745\n",
      "Epoch [1/4], Step [2435/3844], Loss: 0.1766\n",
      "Epoch [1/4], Step [2436/3844], Loss: 0.2535\n",
      "Epoch [1/4], Step [2437/3844], Loss: 0.2397\n",
      "Epoch [1/4], Step [2438/3844], Loss: 0.2119\n",
      "Epoch [1/4], Step [2439/3844], Loss: 0.1876\n",
      "Epoch [1/4], Step [2440/3844], Loss: 0.1466\n",
      "Epoch [1/4], Step [2441/3844], Loss: 0.2072\n",
      "Epoch [1/4], Step [2442/3844], Loss: 0.2150\n",
      "Epoch [1/4], Step [2443/3844], Loss: 0.1623\n",
      "Epoch [1/4], Step [2444/3844], Loss: 0.1797\n",
      "Epoch [1/4], Step [2445/3844], Loss: 0.1821\n",
      "Epoch [1/4], Step [2446/3844], Loss: 0.1677\n",
      "Epoch [1/4], Step [2447/3844], Loss: 0.1664\n",
      "Epoch [1/4], Step [2448/3844], Loss: 0.1737\n",
      "Epoch [1/4], Step [2449/3844], Loss: 0.1649\n",
      "Epoch [1/4], Step [2450/3844], Loss: 0.1502\n",
      "Epoch [1/4], Step [2451/3844], Loss: 0.1299\n",
      "Epoch [1/4], Step [2452/3844], Loss: 0.2107\n",
      "Epoch [1/4], Step [2453/3844], Loss: 0.1927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [2454/3844], Loss: 0.1741\n",
      "Epoch [1/4], Step [2455/3844], Loss: 0.1527\n",
      "Epoch [1/4], Step [2456/3844], Loss: 0.1819\n",
      "Epoch [1/4], Step [2457/3844], Loss: 0.1571\n",
      "Epoch [1/4], Step [2458/3844], Loss: 0.1299\n",
      "Epoch [1/4], Step [2459/3844], Loss: 0.1905\n",
      "Epoch [1/4], Step [2460/3844], Loss: 0.1862\n",
      "Epoch [1/4], Step [2461/3844], Loss: 0.2412\n",
      "Epoch [1/4], Step [2462/3844], Loss: 0.1491\n",
      "Epoch [1/4], Step [2463/3844], Loss: 0.1539\n",
      "Epoch [1/4], Step [2464/3844], Loss: 0.3128\n",
      "Epoch [1/4], Step [2465/3844], Loss: 0.1388\n",
      "Epoch [1/4], Step [2466/3844], Loss: 0.2976\n",
      "Epoch [1/4], Step [2467/3844], Loss: 0.2272\n",
      "Epoch [1/4], Step [2468/3844], Loss: 0.1849\n",
      "Epoch [1/4], Step [2469/3844], Loss: 0.1604\n",
      "Epoch [1/4], Step [2470/3844], Loss: 0.1855\n",
      "Epoch [1/4], Step [2471/3844], Loss: 0.1991\n",
      "Epoch [1/4], Step [2472/3844], Loss: 0.1547\n",
      "Epoch [1/4], Step [2473/3844], Loss: 0.1423\n",
      "Epoch [1/4], Step [2474/3844], Loss: 0.1710\n",
      "Epoch [1/4], Step [2475/3844], Loss: 0.1989\n",
      "Epoch [1/4], Step [2476/3844], Loss: 0.2055\n",
      "Epoch [1/4], Step [2477/3844], Loss: 0.1484\n",
      "Epoch [1/4], Step [2478/3844], Loss: 0.1372\n",
      "Epoch [1/4], Step [2479/3844], Loss: 0.1749\n",
      "Epoch [1/4], Step [2480/3844], Loss: 0.1892\n",
      "Epoch [1/4], Step [2481/3844], Loss: 0.2407\n",
      "Epoch [1/4], Step [2482/3844], Loss: 0.2061\n",
      "Epoch [1/4], Step [2483/3844], Loss: 0.2178\n",
      "Epoch [1/4], Step [2484/3844], Loss: 0.1948\n",
      "Epoch [1/4], Step [2485/3844], Loss: 0.2308\n",
      "Epoch [1/4], Step [2486/3844], Loss: 0.1643\n",
      "Epoch [1/4], Step [2487/3844], Loss: 0.2320\n",
      "Epoch [1/4], Step [2488/3844], Loss: 0.1880\n",
      "Epoch [1/4], Step [2489/3844], Loss: 0.1846\n",
      "Epoch [1/4], Step [2490/3844], Loss: 0.1943\n",
      "Epoch [1/4], Step [2491/3844], Loss: 0.1682\n",
      "Epoch [1/4], Step [2492/3844], Loss: 0.1742\n",
      "Epoch [1/4], Step [2493/3844], Loss: 0.1770\n",
      "Epoch [1/4], Step [2494/3844], Loss: 0.1694\n",
      "Epoch [1/4], Step [2495/3844], Loss: 0.1837\n",
      "Epoch [1/4], Step [2496/3844], Loss: 0.1530\n",
      "Epoch [1/4], Step [2497/3844], Loss: 0.1895\n",
      "Epoch [1/4], Step [2498/3844], Loss: 0.1788\n",
      "Epoch [1/4], Step [2499/3844], Loss: 0.1758\n",
      "Epoch [1/4], Step [2500/3844], Loss: 0.1915\n",
      "Epoch [1/4], Step [2501/3844], Loss: 0.2011\n",
      "Epoch [1/4], Step [2502/3844], Loss: 0.1648\n",
      "Epoch [1/4], Step [2503/3844], Loss: 0.1802\n",
      "Epoch [1/4], Step [2504/3844], Loss: 0.1890\n",
      "Epoch [1/4], Step [2505/3844], Loss: 0.2294\n",
      "Epoch [1/4], Step [2506/3844], Loss: 0.1756\n",
      "Epoch [1/4], Step [2507/3844], Loss: 0.2129\n",
      "Epoch [1/4], Step [2508/3844], Loss: 0.1749\n",
      "Epoch [1/4], Step [2509/3844], Loss: 0.2273\n",
      "Epoch [1/4], Step [2510/3844], Loss: 0.1847\n",
      "Epoch [1/4], Step [2511/3844], Loss: 0.1918\n",
      "Epoch [1/4], Step [2512/3844], Loss: 0.1984\n",
      "Epoch [1/4], Step [2513/3844], Loss: 0.1743\n",
      "Epoch [1/4], Step [2514/3844], Loss: 0.2403\n",
      "Epoch [1/4], Step [2515/3844], Loss: 0.2013\n",
      "Epoch [1/4], Step [2516/3844], Loss: 0.1757\n",
      "Epoch [1/4], Step [2517/3844], Loss: 0.1768\n",
      "Epoch [1/4], Step [2518/3844], Loss: 0.1502\n",
      "Epoch [1/4], Step [2519/3844], Loss: 0.1698\n",
      "Epoch [1/4], Step [2520/3844], Loss: 0.1506\n",
      "Epoch [1/4], Step [2521/3844], Loss: 0.1734\n",
      "Epoch [1/4], Step [2522/3844], Loss: 0.1601\n",
      "Epoch [1/4], Step [2523/3844], Loss: 0.1593\n",
      "Epoch [1/4], Step [2524/3844], Loss: 0.1820\n",
      "Epoch [1/4], Step [2525/3844], Loss: 0.1822\n",
      "Epoch [1/4], Step [2526/3844], Loss: 0.1567\n",
      "Epoch [1/4], Step [2527/3844], Loss: 0.1796\n",
      "Epoch [1/4], Step [2528/3844], Loss: 0.1310\n",
      "Epoch [1/4], Step [2529/3844], Loss: 0.1663\n",
      "Epoch [1/4], Step [2530/3844], Loss: 0.1881\n",
      "Epoch [1/4], Step [2531/3844], Loss: 0.1885\n",
      "Epoch [1/4], Step [2532/3844], Loss: 0.1538\n",
      "Epoch [1/4], Step [2533/3844], Loss: 0.2019\n",
      "Epoch [1/4], Step [2534/3844], Loss: 0.1583\n",
      "Epoch [1/4], Step [2535/3844], Loss: 0.2214\n",
      "Epoch [1/4], Step [2536/3844], Loss: 0.2245\n",
      "Epoch [1/4], Step [2537/3844], Loss: 0.1733\n",
      "Epoch [1/4], Step [2538/3844], Loss: 0.1818\n",
      "Epoch [1/4], Step [2539/3844], Loss: 0.1569\n",
      "Epoch [1/4], Step [2540/3844], Loss: 0.1422\n",
      "Epoch [1/4], Step [2541/3844], Loss: 0.1922\n",
      "Epoch [1/4], Step [2542/3844], Loss: 0.1450\n",
      "Epoch [1/4], Step [2543/3844], Loss: 0.1767\n",
      "Epoch [1/4], Step [2544/3844], Loss: 0.1541\n",
      "Epoch [1/4], Step [2545/3844], Loss: 0.1506\n",
      "Epoch [1/4], Step [2546/3844], Loss: 0.1813\n",
      "Epoch [1/4], Step [2547/3844], Loss: 0.1662\n",
      "Epoch [1/4], Step [2548/3844], Loss: 0.1643\n",
      "Epoch [1/4], Step [2549/3844], Loss: 0.1686\n",
      "Epoch [1/4], Step [2550/3844], Loss: 0.1381\n",
      "Epoch [1/4], Step [2551/3844], Loss: 0.1872\n",
      "Epoch [1/4], Step [2552/3844], Loss: 0.1673\n",
      "Epoch [1/4], Step [2553/3844], Loss: 0.1772\n",
      "Epoch [1/4], Step [2554/3844], Loss: 0.1506\n",
      "Epoch [1/4], Step [2555/3844], Loss: 0.1731\n",
      "Epoch [1/4], Step [2556/3844], Loss: 0.1690\n",
      "Epoch [1/4], Step [2557/3844], Loss: 0.1914\n",
      "Epoch [1/4], Step [2558/3844], Loss: 0.2187\n",
      "Epoch [1/4], Step [2559/3844], Loss: 0.1690\n",
      "Epoch [1/4], Step [2560/3844], Loss: 0.1814\n",
      "Epoch [1/4], Step [2561/3844], Loss: 0.1957\n",
      "Epoch [1/4], Step [2562/3844], Loss: 0.2125\n",
      "Epoch [1/4], Step [2563/3844], Loss: 0.1785\n",
      "Epoch [1/4], Step [2564/3844], Loss: 0.2034\n",
      "Epoch [1/4], Step [2565/3844], Loss: 0.1904\n",
      "Epoch [1/4], Step [2566/3844], Loss: 0.1949\n",
      "Epoch [1/4], Step [2567/3844], Loss: 0.1615\n",
      "Epoch [1/4], Step [2568/3844], Loss: 0.1518\n",
      "Epoch [1/4], Step [2569/3844], Loss: 0.1920\n",
      "Epoch [1/4], Step [2570/3844], Loss: 0.2070\n",
      "Epoch [1/4], Step [2571/3844], Loss: 0.1930\n",
      "Epoch [1/4], Step [2572/3844], Loss: 0.1777\n",
      "Epoch [1/4], Step [2573/3844], Loss: 0.1744\n",
      "Epoch [1/4], Step [2574/3844], Loss: 0.1897\n",
      "Epoch [1/4], Step [2575/3844], Loss: 0.2071\n",
      "Epoch [1/4], Step [2576/3844], Loss: 0.1656\n",
      "Epoch [1/4], Step [2577/3844], Loss: 0.1975\n",
      "Epoch [1/4], Step [2578/3844], Loss: 0.1858\n",
      "Epoch [1/4], Step [2579/3844], Loss: 0.1616\n",
      "Epoch [1/4], Step [2580/3844], Loss: 0.2007\n",
      "Epoch [1/4], Step [2581/3844], Loss: 0.1812\n",
      "Epoch [1/4], Step [2582/3844], Loss: 0.1793\n",
      "Epoch [1/4], Step [2583/3844], Loss: 0.1906\n",
      "Epoch [1/4], Step [2584/3844], Loss: 0.1597\n",
      "Epoch [1/4], Step [2585/3844], Loss: 0.2344\n",
      "Epoch [1/4], Step [2586/3844], Loss: 0.1815\n",
      "Epoch [1/4], Step [2587/3844], Loss: 0.2572\n",
      "Epoch [1/4], Step [2588/3844], Loss: 0.1913\n",
      "Epoch [1/4], Step [2589/3844], Loss: 0.1770\n",
      "Epoch [1/4], Step [2590/3844], Loss: 0.1469\n",
      "Epoch [1/4], Step [2591/3844], Loss: 0.2417\n",
      "Epoch [1/4], Step [2592/3844], Loss: 0.2396\n",
      "Epoch [1/4], Step [2593/3844], Loss: 0.1766\n",
      "Epoch [1/4], Step [2594/3844], Loss: 0.1728\n",
      "Epoch [1/4], Step [2595/3844], Loss: 0.1372\n",
      "Epoch [1/4], Step [2596/3844], Loss: 0.2273\n",
      "Epoch [1/4], Step [2597/3844], Loss: 0.2273\n",
      "Epoch [1/4], Step [2598/3844], Loss: 0.1795\n",
      "Epoch [1/4], Step [2599/3844], Loss: 0.1386\n",
      "Epoch [1/4], Step [2600/3844], Loss: 0.1717\n",
      "Epoch [1/4], Step [2601/3844], Loss: 0.1948\n",
      "Epoch [1/4], Step [2602/3844], Loss: 0.1941\n",
      "Epoch [1/4], Step [2603/3844], Loss: 0.1944\n",
      "Epoch [1/4], Step [2604/3844], Loss: 0.1535\n",
      "Epoch [1/4], Step [2605/3844], Loss: 0.1778\n",
      "Epoch [1/4], Step [2606/3844], Loss: 0.1654\n",
      "Epoch [1/4], Step [2607/3844], Loss: 0.1809\n",
      "Epoch [1/4], Step [2608/3844], Loss: 0.1941\n",
      "Epoch [1/4], Step [2609/3844], Loss: 0.1769\n",
      "Epoch [1/4], Step [2610/3844], Loss: 0.1785\n",
      "Epoch [1/4], Step [2611/3844], Loss: 0.1560\n",
      "Epoch [1/4], Step [2612/3844], Loss: 0.1755\n",
      "Epoch [1/4], Step [2613/3844], Loss: 0.1569\n",
      "Epoch [1/4], Step [2614/3844], Loss: 0.1476\n",
      "Epoch [1/4], Step [2615/3844], Loss: 0.1652\n",
      "Epoch [1/4], Step [2616/3844], Loss: 0.1552\n",
      "Epoch [1/4], Step [2617/3844], Loss: 0.1711\n",
      "Epoch [1/4], Step [2618/3844], Loss: 0.1420\n",
      "Epoch [1/4], Step [2619/3844], Loss: 0.1783\n",
      "Epoch [1/4], Step [2620/3844], Loss: 0.2289\n",
      "Epoch [1/4], Step [2621/3844], Loss: 0.1583\n",
      "Epoch [1/4], Step [2622/3844], Loss: 0.1706\n",
      "Epoch [1/4], Step [2623/3844], Loss: 0.1958\n",
      "Epoch [1/4], Step [2624/3844], Loss: 0.1712\n",
      "Epoch [1/4], Step [2625/3844], Loss: 0.1740\n",
      "Epoch [1/4], Step [2626/3844], Loss: 0.2061\n",
      "Epoch [1/4], Step [2627/3844], Loss: 0.1446\n",
      "Epoch [1/4], Step [2628/3844], Loss: 0.2041\n",
      "Epoch [1/4], Step [2629/3844], Loss: 0.2215\n",
      "Epoch [1/4], Step [2630/3844], Loss: 0.1600\n",
      "Epoch [1/4], Step [2631/3844], Loss: 0.1563\n",
      "Epoch [1/4], Step [2632/3844], Loss: 0.2074\n",
      "Epoch [1/4], Step [2633/3844], Loss: 0.2293\n",
      "Epoch [1/4], Step [2634/3844], Loss: 0.1732\n",
      "Epoch [1/4], Step [2635/3844], Loss: 0.1615\n",
      "Epoch [1/4], Step [2636/3844], Loss: 0.1754\n",
      "Epoch [1/4], Step [2637/3844], Loss: 0.1514\n",
      "Epoch [1/4], Step [2638/3844], Loss: 0.1334\n",
      "Epoch [1/4], Step [2639/3844], Loss: 0.1670\n",
      "Epoch [1/4], Step [2640/3844], Loss: 0.1896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [2641/3844], Loss: 0.2942\n",
      "Epoch [1/4], Step [2642/3844], Loss: 0.1974\n",
      "Epoch [1/4], Step [2643/3844], Loss: 0.1866\n",
      "Epoch [1/4], Step [2644/3844], Loss: 0.1771\n",
      "Epoch [1/4], Step [2645/3844], Loss: 0.1878\n",
      "Epoch [1/4], Step [2646/3844], Loss: 0.1848\n",
      "Epoch [1/4], Step [2647/3844], Loss: 0.1771\n",
      "Epoch [1/4], Step [2648/3844], Loss: 0.1407\n",
      "Epoch [1/4], Step [2649/3844], Loss: 0.1467\n",
      "Epoch [1/4], Step [2650/3844], Loss: 0.2114\n",
      "Epoch [1/4], Step [2651/3844], Loss: 0.1900\n",
      "Epoch [1/4], Step [2652/3844], Loss: 0.1912\n",
      "Epoch [1/4], Step [2653/3844], Loss: 0.1589\n",
      "Epoch [1/4], Step [2654/3844], Loss: 0.1444\n",
      "Epoch [1/4], Step [2655/3844], Loss: 0.1904\n",
      "Epoch [1/4], Step [2656/3844], Loss: 0.2377\n",
      "Epoch [1/4], Step [2657/3844], Loss: 0.2338\n",
      "Epoch [1/4], Step [2658/3844], Loss: 0.1569\n",
      "Epoch [1/4], Step [2659/3844], Loss: 0.1682\n",
      "Epoch [1/4], Step [2660/3844], Loss: 0.1863\n",
      "Epoch [1/4], Step [2661/3844], Loss: 0.1590\n",
      "Epoch [1/4], Step [2662/3844], Loss: 0.1639\n",
      "Epoch [1/4], Step [2663/3844], Loss: 0.1963\n",
      "Epoch [1/4], Step [2664/3844], Loss: 0.1844\n",
      "Epoch [1/4], Step [2665/3844], Loss: 0.1813\n",
      "Epoch [1/4], Step [2666/3844], Loss: 0.1572\n",
      "Epoch [1/4], Step [2667/3844], Loss: 0.1632\n",
      "Epoch [1/4], Step [2668/3844], Loss: 0.1587\n",
      "Epoch [1/4], Step [2669/3844], Loss: 0.1580\n",
      "Epoch [1/4], Step [2670/3844], Loss: 0.1717\n",
      "Epoch [1/4], Step [2671/3844], Loss: 0.1431\n",
      "Epoch [1/4], Step [2672/3844], Loss: 0.2021\n",
      "Epoch [1/4], Step [2673/3844], Loss: 0.2243\n",
      "Epoch [1/4], Step [2674/3844], Loss: 0.1597\n",
      "Epoch [1/4], Step [2675/3844], Loss: 0.1576\n",
      "Epoch [1/4], Step [2676/3844], Loss: 0.1719\n",
      "Epoch [1/4], Step [2677/3844], Loss: 0.1557\n",
      "Epoch [1/4], Step [2678/3844], Loss: 0.2379\n",
      "Epoch [1/4], Step [2679/3844], Loss: 0.1721\n",
      "Epoch [1/4], Step [2680/3844], Loss: 0.1453\n",
      "Epoch [1/4], Step [2681/3844], Loss: 0.1706\n",
      "Epoch [1/4], Step [2682/3844], Loss: 0.1747\n",
      "Epoch [1/4], Step [2683/3844], Loss: 0.1573\n",
      "Epoch [1/4], Step [2684/3844], Loss: 0.2206\n",
      "Epoch [1/4], Step [2685/3844], Loss: 0.1864\n",
      "Epoch [1/4], Step [2686/3844], Loss: 0.1647\n",
      "Epoch [1/4], Step [2687/3844], Loss: 0.2312\n",
      "Epoch [1/4], Step [2688/3844], Loss: 0.2082\n",
      "Epoch [1/4], Step [2689/3844], Loss: 0.1593\n",
      "Epoch [1/4], Step [2690/3844], Loss: 0.1791\n",
      "Epoch [1/4], Step [2691/3844], Loss: 0.2351\n",
      "Epoch [1/4], Step [2692/3844], Loss: 0.1851\n",
      "Epoch [1/4], Step [2693/3844], Loss: 0.2103\n",
      "Epoch [1/4], Step [2694/3844], Loss: 0.1970\n",
      "Epoch [1/4], Step [2695/3844], Loss: 0.1565\n",
      "Epoch [1/4], Step [2696/3844], Loss: 0.1682\n",
      "Epoch [1/4], Step [2697/3844], Loss: 0.1983\n",
      "Epoch [1/4], Step [2698/3844], Loss: 0.1990\n",
      "Epoch [1/4], Step [2699/3844], Loss: 0.1604\n",
      "Epoch [1/4], Step [2700/3844], Loss: 0.1919\n",
      "Epoch [1/4], Step [2701/3844], Loss: 0.1686\n",
      "Epoch [1/4], Step [2702/3844], Loss: 0.1449\n",
      "Epoch [1/4], Step [2703/3844], Loss: 0.2106\n",
      "Epoch [1/4], Step [2704/3844], Loss: 0.1946\n",
      "Epoch [1/4], Step [2705/3844], Loss: 0.1953\n",
      "Epoch [1/4], Step [2706/3844], Loss: 0.1876\n",
      "Epoch [1/4], Step [2707/3844], Loss: 0.1667\n",
      "Epoch [1/4], Step [2708/3844], Loss: 0.2028\n",
      "Epoch [1/4], Step [2709/3844], Loss: 0.1663\n",
      "Epoch [1/4], Step [2710/3844], Loss: 0.1675\n",
      "Epoch [1/4], Step [2711/3844], Loss: 0.1763\n",
      "Epoch [1/4], Step [2712/3844], Loss: 0.1680\n",
      "Epoch [1/4], Step [2713/3844], Loss: 0.2313\n",
      "Epoch [1/4], Step [2714/3844], Loss: 0.1771\n",
      "Epoch [1/4], Step [2715/3844], Loss: 0.1559\n",
      "Epoch [1/4], Step [2716/3844], Loss: 0.2010\n",
      "Epoch [1/4], Step [2717/3844], Loss: 0.1846\n",
      "Epoch [1/4], Step [2718/3844], Loss: 0.1625\n",
      "Epoch [1/4], Step [2719/3844], Loss: 0.1831\n",
      "Epoch [1/4], Step [2720/3844], Loss: 0.1808\n",
      "Epoch [1/4], Step [2721/3844], Loss: 0.1817\n",
      "Epoch [1/4], Step [2722/3844], Loss: 0.2041\n",
      "Epoch [1/4], Step [2723/3844], Loss: 0.1688\n",
      "Epoch [1/4], Step [2724/3844], Loss: 0.2121\n",
      "Epoch [1/4], Step [2725/3844], Loss: 0.1550\n",
      "Epoch [1/4], Step [2726/3844], Loss: 0.1881\n",
      "Epoch [1/4], Step [2727/3844], Loss: 0.1993\n",
      "Epoch [1/4], Step [2728/3844], Loss: 0.1782\n",
      "Epoch [1/4], Step [2729/3844], Loss: 0.1885\n",
      "Epoch [1/4], Step [2730/3844], Loss: 0.1481\n",
      "Epoch [1/4], Step [2731/3844], Loss: 0.1663\n",
      "Epoch [1/4], Step [2732/3844], Loss: 0.1206\n",
      "Epoch [1/4], Step [2733/3844], Loss: 0.1919\n",
      "Epoch [1/4], Step [2734/3844], Loss: 0.1831\n",
      "Epoch [1/4], Step [2735/3844], Loss: 0.1891\n",
      "Epoch [1/4], Step [2736/3844], Loss: 0.1883\n",
      "Epoch [1/4], Step [2737/3844], Loss: 0.1671\n",
      "Epoch [1/4], Step [2738/3844], Loss: 0.1818\n",
      "Epoch [1/4], Step [2739/3844], Loss: 0.1921\n",
      "Epoch [1/4], Step [2740/3844], Loss: 0.2059\n",
      "Epoch [1/4], Step [2741/3844], Loss: 0.1820\n",
      "Epoch [1/4], Step [2742/3844], Loss: 0.1701\n",
      "Epoch [1/4], Step [2743/3844], Loss: 0.1637\n",
      "Epoch [1/4], Step [2744/3844], Loss: 0.1741\n",
      "Epoch [1/4], Step [2745/3844], Loss: 0.1691\n",
      "Epoch [1/4], Step [2746/3844], Loss: 0.1825\n",
      "Epoch [1/4], Step [2747/3844], Loss: 0.2304\n",
      "Epoch [1/4], Step [2748/3844], Loss: 0.1738\n",
      "Epoch [1/4], Step [2749/3844], Loss: 0.1637\n",
      "Epoch [1/4], Step [2750/3844], Loss: 0.1861\n",
      "Epoch [1/4], Step [2751/3844], Loss: 0.1693\n",
      "Epoch [1/4], Step [2752/3844], Loss: 0.1415\n",
      "Epoch [1/4], Step [2753/3844], Loss: 0.1790\n",
      "Epoch [1/4], Step [2754/3844], Loss: 0.1677\n",
      "Epoch [1/4], Step [2755/3844], Loss: 0.1651\n",
      "Epoch [1/4], Step [2756/3844], Loss: 0.1306\n",
      "Epoch [1/4], Step [2757/3844], Loss: 0.1539\n",
      "Epoch [1/4], Step [2758/3844], Loss: 0.1832\n",
      "Epoch [1/4], Step [2759/3844], Loss: 0.1437\n",
      "Epoch [1/4], Step [2760/3844], Loss: 0.1440\n",
      "Epoch [1/4], Step [2761/3844], Loss: 0.1677\n",
      "Epoch [1/4], Step [2762/3844], Loss: 0.1869\n",
      "Epoch [1/4], Step [2763/3844], Loss: 0.1747\n",
      "Epoch [1/4], Step [2764/3844], Loss: 0.1585\n",
      "Epoch [1/4], Step [2765/3844], Loss: 0.1714\n",
      "Epoch [1/4], Step [2766/3844], Loss: 0.1477\n",
      "Epoch [1/4], Step [2767/3844], Loss: 0.1643\n",
      "Epoch [1/4], Step [2768/3844], Loss: 0.2091\n",
      "Epoch [1/4], Step [2769/3844], Loss: 0.1819\n",
      "Epoch [1/4], Step [2770/3844], Loss: 0.1759\n",
      "Epoch [1/4], Step [2771/3844], Loss: 0.1530\n",
      "Epoch [1/4], Step [2772/3844], Loss: 0.2054\n",
      "Epoch [1/4], Step [2773/3844], Loss: 0.1749\n",
      "Epoch [1/4], Step [2774/3844], Loss: 0.1524\n",
      "Epoch [1/4], Step [2775/3844], Loss: 0.2417\n",
      "Epoch [1/4], Step [2776/3844], Loss: 0.1710\n",
      "Epoch [1/4], Step [2777/3844], Loss: 0.2406\n",
      "Epoch [1/4], Step [2778/3844], Loss: 0.1943\n",
      "Epoch [1/4], Step [2779/3844], Loss: 0.2192\n",
      "Epoch [1/4], Step [2780/3844], Loss: 0.1665\n",
      "Epoch [1/4], Step [2781/3844], Loss: 0.1808\n",
      "Epoch [1/4], Step [2782/3844], Loss: 0.1813\n",
      "Epoch [1/4], Step [2783/3844], Loss: 0.1756\n",
      "Epoch [1/4], Step [2784/3844], Loss: 0.1663\n",
      "Epoch [1/4], Step [2785/3844], Loss: 0.1948\n",
      "Epoch [1/4], Step [2786/3844], Loss: 0.1891\n",
      "Epoch [1/4], Step [2787/3844], Loss: 0.1479\n",
      "Epoch [1/4], Step [2788/3844], Loss: 0.1795\n",
      "Epoch [1/4], Step [2789/3844], Loss: 0.1929\n",
      "Epoch [1/4], Step [2790/3844], Loss: 0.1617\n",
      "Epoch [1/4], Step [2791/3844], Loss: 0.1563\n",
      "Epoch [1/4], Step [2792/3844], Loss: 0.1550\n",
      "Epoch [1/4], Step [2793/3844], Loss: 0.1978\n",
      "Epoch [1/4], Step [2794/3844], Loss: 0.2255\n",
      "Epoch [1/4], Step [2795/3844], Loss: 0.1457\n",
      "Epoch [1/4], Step [2796/3844], Loss: 0.2349\n",
      "Epoch [1/4], Step [2797/3844], Loss: 0.1696\n",
      "Epoch [1/4], Step [2798/3844], Loss: 0.1406\n",
      "Epoch [1/4], Step [2799/3844], Loss: 0.1602\n",
      "Epoch [1/4], Step [2800/3844], Loss: 0.2084\n",
      "Epoch [1/4], Step [2801/3844], Loss: 0.2290\n",
      "Epoch [1/4], Step [2802/3844], Loss: 0.1789\n",
      "Epoch [1/4], Step [2803/3844], Loss: 0.1685\n",
      "Epoch [1/4], Step [2804/3844], Loss: 0.2297\n",
      "Epoch [1/4], Step [2805/3844], Loss: 0.1670\n",
      "Epoch [1/4], Step [2806/3844], Loss: 0.1599\n",
      "Epoch [1/4], Step [2807/3844], Loss: 0.1755\n",
      "Epoch [1/4], Step [2808/3844], Loss: 0.1649\n",
      "Epoch [1/4], Step [2809/3844], Loss: 0.1584\n",
      "Epoch [1/4], Step [2810/3844], Loss: 0.1988\n",
      "Epoch [1/4], Step [2811/3844], Loss: 0.1840\n",
      "Epoch [1/4], Step [2812/3844], Loss: 0.1903\n",
      "Epoch [1/4], Step [2813/3844], Loss: 0.1524\n",
      "Epoch [1/4], Step [2814/3844], Loss: 0.1727\n",
      "Epoch [1/4], Step [2815/3844], Loss: 0.1677\n",
      "Epoch [1/4], Step [2816/3844], Loss: 0.1889\n",
      "Epoch [1/4], Step [2817/3844], Loss: 0.1997\n",
      "Epoch [1/4], Step [2818/3844], Loss: 0.2262\n",
      "Epoch [1/4], Step [2819/3844], Loss: 0.1964\n",
      "Epoch [1/4], Step [2820/3844], Loss: 0.1545\n",
      "Epoch [1/4], Step [2821/3844], Loss: 0.1716\n",
      "Epoch [1/4], Step [2822/3844], Loss: 0.1985\n",
      "Epoch [1/4], Step [2823/3844], Loss: 0.1745\n",
      "Epoch [1/4], Step [2824/3844], Loss: 0.1683\n",
      "Epoch [1/4], Step [2825/3844], Loss: 0.1729\n",
      "Epoch [1/4], Step [2826/3844], Loss: 0.1766\n",
      "Epoch [1/4], Step [2827/3844], Loss: 0.1877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [2828/3844], Loss: 0.1796\n",
      "Epoch [1/4], Step [2829/3844], Loss: 0.1486\n",
      "Epoch [1/4], Step [2830/3844], Loss: 0.1936\n",
      "Epoch [1/4], Step [2831/3844], Loss: 0.1739\n",
      "Epoch [1/4], Step [2832/3844], Loss: 0.1588\n",
      "Epoch [1/4], Step [2833/3844], Loss: 0.1854\n",
      "Epoch [1/4], Step [2834/3844], Loss: 0.1706\n",
      "Epoch [1/4], Step [2835/3844], Loss: 0.1624\n",
      "Epoch [1/4], Step [2836/3844], Loss: 0.1941\n",
      "Epoch [1/4], Step [2837/3844], Loss: 0.1639\n",
      "Epoch [1/4], Step [2838/3844], Loss: 0.1618\n",
      "Epoch [1/4], Step [2839/3844], Loss: 0.1537\n",
      "Epoch [1/4], Step [2840/3844], Loss: 0.1623\n",
      "Epoch [1/4], Step [2841/3844], Loss: 0.2094\n",
      "Epoch [1/4], Step [2842/3844], Loss: 0.1721\n",
      "Epoch [1/4], Step [2843/3844], Loss: 0.1424\n",
      "Epoch [1/4], Step [2844/3844], Loss: 0.1972\n",
      "Epoch [1/4], Step [2845/3844], Loss: 0.2088\n",
      "Epoch [1/4], Step [2846/3844], Loss: 0.1941\n",
      "Epoch [1/4], Step [2847/3844], Loss: 0.1952\n",
      "Epoch [1/4], Step [2848/3844], Loss: 0.2027\n",
      "Epoch [1/4], Step [2849/3844], Loss: 0.2224\n",
      "Epoch [1/4], Step [2850/3844], Loss: 0.1612\n",
      "Epoch [1/4], Step [2851/3844], Loss: 0.1758\n",
      "Epoch [1/4], Step [2852/3844], Loss: 0.1755\n",
      "Epoch [1/4], Step [2853/3844], Loss: 0.1625\n",
      "Epoch [1/4], Step [2854/3844], Loss: 0.1952\n",
      "Epoch [1/4], Step [2855/3844], Loss: 0.1868\n",
      "Epoch [1/4], Step [2856/3844], Loss: 0.1553\n",
      "Epoch [1/4], Step [2857/3844], Loss: 0.1802\n",
      "Epoch [1/4], Step [2858/3844], Loss: 0.1753\n",
      "Epoch [1/4], Step [2859/3844], Loss: 0.1788\n",
      "Epoch [1/4], Step [2860/3844], Loss: 0.2987\n",
      "Epoch [1/4], Step [2861/3844], Loss: 0.1992\n",
      "Epoch [1/4], Step [2862/3844], Loss: 0.1993\n",
      "Epoch [1/4], Step [2863/3844], Loss: 0.2348\n",
      "Epoch [1/4], Step [2864/3844], Loss: 0.1320\n",
      "Epoch [1/4], Step [2865/3844], Loss: 0.2663\n",
      "Epoch [1/4], Step [2866/3844], Loss: 0.1813\n",
      "Epoch [1/4], Step [2867/3844], Loss: 0.1717\n",
      "Epoch [1/4], Step [2868/3844], Loss: 0.1943\n",
      "Epoch [1/4], Step [2869/3844], Loss: 0.1829\n",
      "Epoch [1/4], Step [2870/3844], Loss: 0.1497\n",
      "Epoch [1/4], Step [2871/3844], Loss: 0.1371\n",
      "Epoch [1/4], Step [2872/3844], Loss: 0.1747\n",
      "Epoch [1/4], Step [2873/3844], Loss: 0.1434\n",
      "Epoch [1/4], Step [2874/3844], Loss: 0.1803\n",
      "Epoch [1/4], Step [2875/3844], Loss: 0.1556\n",
      "Epoch [1/4], Step [2876/3844], Loss: 0.1551\n",
      "Epoch [1/4], Step [2877/3844], Loss: 0.1677\n",
      "Epoch [1/4], Step [2878/3844], Loss: 0.1862\n",
      "Epoch [1/4], Step [2879/3844], Loss: 0.2106\n",
      "Epoch [1/4], Step [2880/3844], Loss: 0.2159\n",
      "Epoch [1/4], Step [2881/3844], Loss: 0.1619\n",
      "Epoch [1/4], Step [2882/3844], Loss: 0.1329\n",
      "Epoch [1/4], Step [2883/3844], Loss: 0.2036\n",
      "Epoch [1/4], Step [2884/3844], Loss: 0.1386\n",
      "Epoch [1/4], Step [2885/3844], Loss: 0.1907\n",
      "Epoch [1/4], Step [2886/3844], Loss: 0.1580\n",
      "Epoch [1/4], Step [2887/3844], Loss: 0.1832\n",
      "Epoch [1/4], Step [2888/3844], Loss: 0.1702\n",
      "Epoch [1/4], Step [2889/3844], Loss: 0.1801\n",
      "Epoch [1/4], Step [2890/3844], Loss: 0.1762\n",
      "Epoch [1/4], Step [2891/3844], Loss: 0.1506\n",
      "Epoch [1/4], Step [2892/3844], Loss: 0.1523\n",
      "Epoch [1/4], Step [2893/3844], Loss: 0.1663\n",
      "Epoch [1/4], Step [2894/3844], Loss: 0.1897\n",
      "Epoch [1/4], Step [2895/3844], Loss: 0.1316\n",
      "Epoch [1/4], Step [2896/3844], Loss: 0.1674\n",
      "Epoch [1/4], Step [2897/3844], Loss: 0.1768\n",
      "Epoch [1/4], Step [2898/3844], Loss: 0.1386\n",
      "Epoch [1/4], Step [2899/3844], Loss: 0.2093\n",
      "Epoch [1/4], Step [2900/3844], Loss: 0.1461\n",
      "Epoch [1/4], Step [2901/3844], Loss: 0.1552\n",
      "Epoch [1/4], Step [2902/3844], Loss: 0.1612\n",
      "Epoch [1/4], Step [2903/3844], Loss: 0.1962\n",
      "Epoch [1/4], Step [2904/3844], Loss: 0.1749\n",
      "Epoch [1/4], Step [2905/3844], Loss: 0.1598\n",
      "Epoch [1/4], Step [2906/3844], Loss: 0.1692\n",
      "Epoch [1/4], Step [2907/3844], Loss: 0.1675\n",
      "Epoch [1/4], Step [2908/3844], Loss: 0.1580\n",
      "Epoch [1/4], Step [2909/3844], Loss: 0.1581\n",
      "Epoch [1/4], Step [2910/3844], Loss: 0.1900\n",
      "Epoch [1/4], Step [2911/3844], Loss: 0.1809\n",
      "Epoch [1/4], Step [2912/3844], Loss: 0.1509\n",
      "Epoch [1/4], Step [2913/3844], Loss: 0.1540\n",
      "Epoch [1/4], Step [2914/3844], Loss: 0.1507\n",
      "Epoch [1/4], Step [2915/3844], Loss: 0.1620\n",
      "Epoch [1/4], Step [2916/3844], Loss: 0.1766\n",
      "Epoch [1/4], Step [2917/3844], Loss: 0.1276\n",
      "Epoch [1/4], Step [2918/3844], Loss: 0.1558\n",
      "Epoch [1/4], Step [2919/3844], Loss: 0.1682\n",
      "Epoch [1/4], Step [2920/3844], Loss: 0.1855\n",
      "Epoch [1/4], Step [2921/3844], Loss: 0.1612\n",
      "Epoch [1/4], Step [2922/3844], Loss: 0.1541\n",
      "Epoch [1/4], Step [2923/3844], Loss: 0.1471\n",
      "Epoch [1/4], Step [2924/3844], Loss: 0.1580\n",
      "Epoch [1/4], Step [2925/3844], Loss: 0.1544\n",
      "Epoch [1/4], Step [2926/3844], Loss: 0.1742\n",
      "Epoch [1/4], Step [2927/3844], Loss: 0.2040\n",
      "Epoch [1/4], Step [2928/3844], Loss: 0.1667\n",
      "Epoch [1/4], Step [2929/3844], Loss: 0.1932\n",
      "Epoch [1/4], Step [2930/3844], Loss: 0.1966\n",
      "Epoch [1/4], Step [2931/3844], Loss: 0.1725\n",
      "Epoch [1/4], Step [2932/3844], Loss: 0.1823\n",
      "Epoch [1/4], Step [2933/3844], Loss: 0.2443\n",
      "Epoch [1/4], Step [2934/3844], Loss: 0.2124\n",
      "Epoch [1/4], Step [2935/3844], Loss: 0.1547\n",
      "Epoch [1/4], Step [2936/3844], Loss: 0.1540\n",
      "Epoch [1/4], Step [2937/3844], Loss: 0.2338\n",
      "Epoch [1/4], Step [2938/3844], Loss: 0.1422\n",
      "Epoch [1/4], Step [2939/3844], Loss: 0.1639\n",
      "Epoch [1/4], Step [2940/3844], Loss: 0.1889\n",
      "Epoch [1/4], Step [2941/3844], Loss: 0.1829\n",
      "Epoch [1/4], Step [2942/3844], Loss: 0.1877\n",
      "Epoch [1/4], Step [2943/3844], Loss: 0.1731\n",
      "Epoch [1/4], Step [2944/3844], Loss: 0.2053\n",
      "Epoch [1/4], Step [2945/3844], Loss: 0.1912\n",
      "Epoch [1/4], Step [2946/3844], Loss: 0.1465\n",
      "Epoch [1/4], Step [2947/3844], Loss: 0.1879\n",
      "Epoch [1/4], Step [2948/3844], Loss: 0.1989\n",
      "Epoch [1/4], Step [2949/3844], Loss: 0.1692\n",
      "Epoch [1/4], Step [2950/3844], Loss: 0.1899\n",
      "Epoch [1/4], Step [2951/3844], Loss: 0.2298\n",
      "Epoch [1/4], Step [2952/3844], Loss: 0.1296\n",
      "Epoch [1/4], Step [2953/3844], Loss: 0.1901\n",
      "Epoch [1/4], Step [2954/3844], Loss: 0.1739\n",
      "Epoch [1/4], Step [2955/3844], Loss: 0.1673\n",
      "Epoch [1/4], Step [2956/3844], Loss: 0.2220\n",
      "Epoch [1/4], Step [2957/3844], Loss: 0.1798\n",
      "Epoch [1/4], Step [2958/3844], Loss: 0.1761\n",
      "Epoch [1/4], Step [2959/3844], Loss: 0.1371\n",
      "Epoch [1/4], Step [2960/3844], Loss: 0.1741\n",
      "Epoch [1/4], Step [2961/3844], Loss: 0.1568\n",
      "Epoch [1/4], Step [2962/3844], Loss: 0.1655\n",
      "Epoch [1/4], Step [2963/3844], Loss: 0.1837\n",
      "Epoch [1/4], Step [2964/3844], Loss: 0.1939\n",
      "Epoch [1/4], Step [2965/3844], Loss: 0.1976\n",
      "Epoch [1/4], Step [2966/3844], Loss: 0.2028\n",
      "Epoch [1/4], Step [2967/3844], Loss: 0.1976\n",
      "Epoch [1/4], Step [2968/3844], Loss: 0.1766\n",
      "Epoch [1/4], Step [2969/3844], Loss: 0.1998\n",
      "Epoch [1/4], Step [2970/3844], Loss: 0.1762\n",
      "Epoch [1/4], Step [2971/3844], Loss: 0.1640\n",
      "Epoch [1/4], Step [2972/3844], Loss: 0.1688\n",
      "Epoch [1/4], Step [2973/3844], Loss: 0.1187\n",
      "Epoch [1/4], Step [2974/3844], Loss: 0.1769\n",
      "Epoch [1/4], Step [2975/3844], Loss: 0.1821\n",
      "Epoch [1/4], Step [2976/3844], Loss: 0.1660\n",
      "Epoch [1/4], Step [2977/3844], Loss: 0.1552\n",
      "Epoch [1/4], Step [2978/3844], Loss: 0.1976\n",
      "Epoch [1/4], Step [2979/3844], Loss: 0.2394\n",
      "Epoch [1/4], Step [2980/3844], Loss: 0.1730\n",
      "Epoch [1/4], Step [2981/3844], Loss: 0.1682\n",
      "Epoch [1/4], Step [2982/3844], Loss: 0.1588\n",
      "Epoch [1/4], Step [2983/3844], Loss: 0.1973\n",
      "Epoch [1/4], Step [2984/3844], Loss: 0.1516\n",
      "Epoch [1/4], Step [2985/3844], Loss: 0.1937\n",
      "Epoch [1/4], Step [2986/3844], Loss: 0.2190\n",
      "Epoch [1/4], Step [2987/3844], Loss: 0.1934\n",
      "Epoch [1/4], Step [2988/3844], Loss: 0.1880\n",
      "Epoch [1/4], Step [2989/3844], Loss: 0.1747\n",
      "Epoch [1/4], Step [2990/3844], Loss: 0.1777\n",
      "Epoch [1/4], Step [2991/3844], Loss: 0.1358\n",
      "Epoch [1/4], Step [2992/3844], Loss: 0.1797\n",
      "Epoch [1/4], Step [2993/3844], Loss: 0.2313\n",
      "Epoch [1/4], Step [2994/3844], Loss: 0.1301\n",
      "Epoch [1/4], Step [2995/3844], Loss: 0.2205\n",
      "Epoch [1/4], Step [2996/3844], Loss: 0.1686\n",
      "Epoch [1/4], Step [2997/3844], Loss: 0.1677\n",
      "Epoch [1/4], Step [2998/3844], Loss: 0.1671\n",
      "Epoch [1/4], Step [2999/3844], Loss: 0.1631\n",
      "Epoch [1/4], Step [3000/3844], Loss: 0.1589\n",
      "Epoch [1/4], Step [3001/3844], Loss: 0.1484\n",
      "Epoch [1/4], Step [3002/3844], Loss: 0.1571\n",
      "Epoch [1/4], Step [3003/3844], Loss: 0.1615\n",
      "Epoch [1/4], Step [3004/3844], Loss: 0.1310\n",
      "Epoch [1/4], Step [3005/3844], Loss: 0.1842\n",
      "Epoch [1/4], Step [3006/3844], Loss: 0.1968\n",
      "Epoch [1/4], Step [3007/3844], Loss: 0.1550\n",
      "Epoch [1/4], Step [3008/3844], Loss: 0.1724\n",
      "Epoch [1/4], Step [3009/3844], Loss: 0.1481\n",
      "Epoch [1/4], Step [3010/3844], Loss: 0.1573\n",
      "Epoch [1/4], Step [3011/3844], Loss: 0.1378\n",
      "Epoch [1/4], Step [3012/3844], Loss: 0.1850\n",
      "Epoch [1/4], Step [3013/3844], Loss: 0.2050\n",
      "Epoch [1/4], Step [3014/3844], Loss: 0.1605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [3015/3844], Loss: 0.1565\n",
      "Epoch [1/4], Step [3016/3844], Loss: 0.1444\n",
      "Epoch [1/4], Step [3017/3844], Loss: 0.1638\n",
      "Epoch [1/4], Step [3018/3844], Loss: 0.1568\n",
      "Epoch [1/4], Step [3019/3844], Loss: 0.1528\n",
      "Epoch [1/4], Step [3020/3844], Loss: 0.1815\n",
      "Epoch [1/4], Step [3021/3844], Loss: 0.2231\n",
      "Epoch [1/4], Step [3022/3844], Loss: 0.1833\n",
      "Epoch [1/4], Step [3023/3844], Loss: 0.1782\n",
      "Epoch [1/4], Step [3024/3844], Loss: 0.1594\n",
      "Epoch [1/4], Step [3025/3844], Loss: 0.1773\n",
      "Epoch [1/4], Step [3026/3844], Loss: 0.1486\n",
      "Epoch [1/4], Step [3027/3844], Loss: 0.2059\n",
      "Epoch [1/4], Step [3028/3844], Loss: 0.1476\n",
      "Epoch [1/4], Step [3029/3844], Loss: 0.1718\n",
      "Epoch [1/4], Step [3030/3844], Loss: 0.1791\n",
      "Epoch [1/4], Step [3031/3844], Loss: 0.1485\n",
      "Epoch [1/4], Step [3032/3844], Loss: 0.1565\n",
      "Epoch [1/4], Step [3033/3844], Loss: 0.1722\n",
      "Epoch [1/4], Step [3034/3844], Loss: 0.1279\n",
      "Epoch [1/4], Step [3035/3844], Loss: 0.2279\n",
      "Epoch [1/4], Step [3036/3844], Loss: 0.1267\n",
      "Epoch [1/4], Step [3037/3844], Loss: 0.1572\n",
      "Epoch [1/4], Step [3038/3844], Loss: 0.1484\n",
      "Epoch [1/4], Step [3039/3844], Loss: 0.1425\n",
      "Epoch [1/4], Step [3040/3844], Loss: 0.1651\n",
      "Epoch [1/4], Step [3041/3844], Loss: 0.1649\n",
      "Epoch [1/4], Step [3042/3844], Loss: 0.1551\n",
      "Epoch [1/4], Step [3043/3844], Loss: 0.1666\n",
      "Epoch [1/4], Step [3044/3844], Loss: 0.1869\n",
      "Epoch [1/4], Step [3045/3844], Loss: 0.1851\n",
      "Epoch [1/4], Step [3046/3844], Loss: 0.1551\n",
      "Epoch [1/4], Step [3047/3844], Loss: 0.2175\n",
      "Epoch [1/4], Step [3048/3844], Loss: 0.1852\n",
      "Epoch [1/4], Step [3049/3844], Loss: 0.1718\n",
      "Epoch [1/4], Step [3050/3844], Loss: 0.1443\n",
      "Epoch [1/4], Step [3051/3844], Loss: 0.1829\n",
      "Epoch [1/4], Step [3052/3844], Loss: 0.1394\n",
      "Epoch [1/4], Step [3053/3844], Loss: 0.1782\n",
      "Epoch [1/4], Step [3054/3844], Loss: 0.1433\n",
      "Epoch [1/4], Step [3055/3844], Loss: 0.1700\n",
      "Epoch [1/4], Step [3056/3844], Loss: 0.1762\n",
      "Epoch [1/4], Step [3057/3844], Loss: 0.1773\n",
      "Epoch [1/4], Step [3058/3844], Loss: 0.1391\n",
      "Epoch [1/4], Step [3059/3844], Loss: 0.1988\n",
      "Epoch [1/4], Step [3060/3844], Loss: 0.2032\n",
      "Epoch [1/4], Step [3061/3844], Loss: 0.1672\n",
      "Epoch [1/4], Step [3062/3844], Loss: 0.1900\n",
      "Epoch [1/4], Step [3063/3844], Loss: 0.1511\n",
      "Epoch [1/4], Step [3064/3844], Loss: 0.1406\n",
      "Epoch [1/4], Step [3065/3844], Loss: 0.1549\n",
      "Epoch [1/4], Step [3066/3844], Loss: 0.1468\n",
      "Epoch [1/4], Step [3067/3844], Loss: 0.1326\n",
      "Epoch [1/4], Step [3068/3844], Loss: 0.1704\n",
      "Epoch [1/4], Step [3069/3844], Loss: 0.1733\n",
      "Epoch [1/4], Step [3070/3844], Loss: 0.1592\n",
      "Epoch [1/4], Step [3071/3844], Loss: 0.1909\n",
      "Epoch [1/4], Step [3072/3844], Loss: 0.1436\n",
      "Epoch [1/4], Step [3073/3844], Loss: 0.1540\n",
      "Epoch [1/4], Step [3074/3844], Loss: 0.1212\n",
      "Epoch [1/4], Step [3075/3844], Loss: 0.1233\n",
      "Epoch [1/4], Step [3076/3844], Loss: 0.1727\n",
      "Epoch [1/4], Step [3077/3844], Loss: 0.1800\n",
      "Epoch [1/4], Step [3078/3844], Loss: 0.1651\n",
      "Epoch [1/4], Step [3079/3844], Loss: 0.2287\n",
      "Epoch [1/4], Step [3080/3844], Loss: 0.1786\n",
      "Epoch [1/4], Step [3081/3844], Loss: 0.2463\n",
      "Epoch [1/4], Step [3082/3844], Loss: 0.1398\n",
      "Epoch [1/4], Step [3083/3844], Loss: 0.1651\n",
      "Epoch [1/4], Step [3084/3844], Loss: 0.1503\n",
      "Epoch [1/4], Step [3085/3844], Loss: 0.1526\n",
      "Epoch [1/4], Step [3086/3844], Loss: 0.1800\n",
      "Epoch [1/4], Step [3087/3844], Loss: 0.1793\n",
      "Epoch [1/4], Step [3088/3844], Loss: 0.1871\n",
      "Epoch [1/4], Step [3089/3844], Loss: 0.1419\n",
      "Epoch [1/4], Step [3090/3844], Loss: 0.2306\n",
      "Epoch [1/4], Step [3091/3844], Loss: 0.1874\n",
      "Epoch [1/4], Step [3092/3844], Loss: 0.1635\n",
      "Epoch [1/4], Step [3093/3844], Loss: 0.1914\n",
      "Epoch [1/4], Step [3094/3844], Loss: 0.1773\n",
      "Epoch [1/4], Step [3095/3844], Loss: 0.1653\n",
      "Epoch [1/4], Step [3096/3844], Loss: 0.2387\n",
      "Epoch [1/4], Step [3097/3844], Loss: 0.1716\n",
      "Epoch [1/4], Step [3098/3844], Loss: 0.1543\n",
      "Epoch [1/4], Step [3099/3844], Loss: 0.2019\n",
      "Epoch [1/4], Step [3100/3844], Loss: 0.2567\n",
      "Epoch [1/4], Step [3101/3844], Loss: 0.2413\n",
      "Epoch [1/4], Step [3102/3844], Loss: 0.1860\n",
      "Epoch [1/4], Step [3103/3844], Loss: 0.2444\n",
      "Epoch [1/4], Step [3104/3844], Loss: 0.1349\n",
      "Epoch [1/4], Step [3105/3844], Loss: 0.1444\n",
      "Epoch [1/4], Step [3106/3844], Loss: 0.1783\n",
      "Epoch [1/4], Step [3107/3844], Loss: 0.1776\n",
      "Epoch [1/4], Step [3108/3844], Loss: 0.1974\n",
      "Epoch [1/4], Step [3109/3844], Loss: 0.1732\n",
      "Epoch [1/4], Step [3110/3844], Loss: 0.1580\n",
      "Epoch [1/4], Step [3111/3844], Loss: 0.1775\n",
      "Epoch [1/4], Step [3112/3844], Loss: 0.1491\n",
      "Epoch [1/4], Step [3113/3844], Loss: 0.1835\n",
      "Epoch [1/4], Step [3114/3844], Loss: 0.1656\n",
      "Epoch [1/4], Step [3115/3844], Loss: 0.1761\n",
      "Epoch [1/4], Step [3116/3844], Loss: 0.1711\n",
      "Epoch [1/4], Step [3117/3844], Loss: 0.1710\n",
      "Epoch [1/4], Step [3118/3844], Loss: 0.1756\n",
      "Epoch [1/4], Step [3119/3844], Loss: 0.2173\n",
      "Epoch [1/4], Step [3120/3844], Loss: 0.1658\n",
      "Epoch [1/4], Step [3121/3844], Loss: 0.1785\n",
      "Epoch [1/4], Step [3122/3844], Loss: 0.1564\n",
      "Epoch [1/4], Step [3123/3844], Loss: 0.1907\n",
      "Epoch [1/4], Step [3124/3844], Loss: 0.1628\n",
      "Epoch [1/4], Step [3125/3844], Loss: 0.1970\n",
      "Epoch [1/4], Step [3126/3844], Loss: 0.1914\n",
      "Epoch [1/4], Step [3127/3844], Loss: 0.1912\n",
      "Epoch [1/4], Step [3128/3844], Loss: 0.1653\n",
      "Epoch [1/4], Step [3129/3844], Loss: 0.1727\n",
      "Epoch [1/4], Step [3130/3844], Loss: 0.1610\n",
      "Epoch [1/4], Step [3131/3844], Loss: 0.1556\n",
      "Epoch [1/4], Step [3132/3844], Loss: 0.1602\n",
      "Epoch [1/4], Step [3133/3844], Loss: 0.1568\n",
      "Epoch [1/4], Step [3134/3844], Loss: 0.1615\n",
      "Epoch [1/4], Step [3135/3844], Loss: 0.1636\n",
      "Epoch [1/4], Step [3136/3844], Loss: 0.1803\n",
      "Epoch [1/4], Step [3137/3844], Loss: 0.1466\n",
      "Epoch [1/4], Step [3138/3844], Loss: 0.1728\n",
      "Epoch [1/4], Step [3139/3844], Loss: 0.1679\n",
      "Epoch [1/4], Step [3140/3844], Loss: 0.1467\n",
      "Epoch [1/4], Step [3141/3844], Loss: 0.1468\n",
      "Epoch [1/4], Step [3142/3844], Loss: 0.1890\n",
      "Epoch [1/4], Step [3143/3844], Loss: 0.1399\n",
      "Epoch [1/4], Step [3144/3844], Loss: 0.2393\n",
      "Epoch [1/4], Step [3145/3844], Loss: 0.1572\n",
      "Epoch [1/4], Step [3146/3844], Loss: 0.1483\n",
      "Epoch [1/4], Step [3147/3844], Loss: 0.1922\n",
      "Epoch [1/4], Step [3148/3844], Loss: 0.1500\n",
      "Epoch [1/4], Step [3149/3844], Loss: 0.1630\n",
      "Epoch [1/4], Step [3150/3844], Loss: 0.1667\n",
      "Epoch [1/4], Step [3151/3844], Loss: 0.2479\n",
      "Epoch [1/4], Step [3152/3844], Loss: 0.1631\n",
      "Epoch [1/4], Step [3153/3844], Loss: 0.2219\n",
      "Epoch [1/4], Step [3154/3844], Loss: 0.1794\n",
      "Epoch [1/4], Step [3155/3844], Loss: 0.1742\n",
      "Epoch [1/4], Step [3156/3844], Loss: 0.1605\n",
      "Epoch [1/4], Step [3157/3844], Loss: 0.1357\n",
      "Epoch [1/4], Step [3158/3844], Loss: 0.1451\n",
      "Epoch [1/4], Step [3159/3844], Loss: 0.1835\n",
      "Epoch [1/4], Step [3160/3844], Loss: 0.1701\n",
      "Epoch [1/4], Step [3161/3844], Loss: 0.1556\n",
      "Epoch [1/4], Step [3162/3844], Loss: 0.1815\n",
      "Epoch [1/4], Step [3163/3844], Loss: 0.1762\n",
      "Epoch [1/4], Step [3164/3844], Loss: 0.2199\n",
      "Epoch [1/4], Step [3165/3844], Loss: 0.1564\n",
      "Epoch [1/4], Step [3166/3844], Loss: 0.1559\n",
      "Epoch [1/4], Step [3167/3844], Loss: 0.2157\n",
      "Epoch [1/4], Step [3168/3844], Loss: 0.1470\n",
      "Epoch [1/4], Step [3169/3844], Loss: 0.1780\n",
      "Epoch [1/4], Step [3170/3844], Loss: 0.1513\n",
      "Epoch [1/4], Step [3171/3844], Loss: 0.1673\n",
      "Epoch [1/4], Step [3172/3844], Loss: 0.1466\n",
      "Epoch [1/4], Step [3173/3844], Loss: 0.1666\n",
      "Epoch [1/4], Step [3174/3844], Loss: 0.1701\n",
      "Epoch [1/4], Step [3175/3844], Loss: 0.1768\n",
      "Epoch [1/4], Step [3176/3844], Loss: 0.1643\n",
      "Epoch [1/4], Step [3177/3844], Loss: 0.1863\n",
      "Epoch [1/4], Step [3178/3844], Loss: 0.1715\n",
      "Epoch [1/4], Step [3179/3844], Loss: 0.1517\n",
      "Epoch [1/4], Step [3180/3844], Loss: 0.1492\n",
      "Epoch [1/4], Step [3181/3844], Loss: 0.1836\n",
      "Epoch [1/4], Step [3182/3844], Loss: 0.1706\n",
      "Epoch [1/4], Step [3183/3844], Loss: 0.2194\n",
      "Epoch [1/4], Step [3184/3844], Loss: 0.1786\n",
      "Epoch [1/4], Step [3185/3844], Loss: 0.2171\n",
      "Epoch [1/4], Step [3186/3844], Loss: 0.1698\n",
      "Epoch [1/4], Step [3187/3844], Loss: 0.1503\n",
      "Epoch [1/4], Step [3188/3844], Loss: 0.1573\n",
      "Epoch [1/4], Step [3189/3844], Loss: 0.2168\n",
      "Epoch [1/4], Step [3190/3844], Loss: 0.1412\n",
      "Epoch [1/4], Step [3191/3844], Loss: 0.1691\n",
      "Epoch [1/4], Step [3192/3844], Loss: 0.1766\n",
      "Epoch [1/4], Step [3193/3844], Loss: 0.1509\n",
      "Epoch [1/4], Step [3194/3844], Loss: 0.1701\n",
      "Epoch [1/4], Step [3195/3844], Loss: 0.1947\n",
      "Epoch [1/4], Step [3196/3844], Loss: 0.1724\n",
      "Epoch [1/4], Step [3197/3844], Loss: 0.1315\n",
      "Epoch [1/4], Step [3198/3844], Loss: 0.2306\n",
      "Epoch [1/4], Step [3199/3844], Loss: 0.1629\n",
      "Epoch [1/4], Step [3200/3844], Loss: 0.2131\n",
      "Epoch [1/4], Step [3201/3844], Loss: 0.1696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [3202/3844], Loss: 0.1543\n",
      "Epoch [1/4], Step [3203/3844], Loss: 0.1894\n",
      "Epoch [1/4], Step [3204/3844], Loss: 0.1675\n",
      "Epoch [1/4], Step [3205/3844], Loss: 0.1990\n",
      "Epoch [1/4], Step [3206/3844], Loss: 0.2277\n",
      "Epoch [1/4], Step [3207/3844], Loss: 0.1744\n",
      "Epoch [1/4], Step [3208/3844], Loss: 0.1522\n",
      "Epoch [1/4], Step [3209/3844], Loss: 0.1461\n",
      "Epoch [1/4], Step [3210/3844], Loss: 0.2238\n",
      "Epoch [1/4], Step [3211/3844], Loss: 0.1661\n",
      "Epoch [1/4], Step [3212/3844], Loss: 0.1657\n",
      "Epoch [1/4], Step [3213/3844], Loss: 0.1610\n",
      "Epoch [1/4], Step [3214/3844], Loss: 0.1635\n",
      "Epoch [1/4], Step [3215/3844], Loss: 0.2106\n",
      "Epoch [1/4], Step [3216/3844], Loss: 0.1583\n",
      "Epoch [1/4], Step [3217/3844], Loss: 0.1936\n",
      "Epoch [1/4], Step [3218/3844], Loss: 0.1953\n",
      "Epoch [1/4], Step [3219/3844], Loss: 0.1615\n",
      "Epoch [1/4], Step [3220/3844], Loss: 0.1751\n",
      "Epoch [1/4], Step [3221/3844], Loss: 0.1824\n",
      "Epoch [1/4], Step [3222/3844], Loss: 0.1533\n",
      "Epoch [1/4], Step [3223/3844], Loss: 0.2312\n",
      "Epoch [1/4], Step [3224/3844], Loss: 0.1746\n",
      "Epoch [1/4], Step [3225/3844], Loss: 0.1559\n",
      "Epoch [1/4], Step [3226/3844], Loss: 0.1468\n",
      "Epoch [1/4], Step [3227/3844], Loss: 0.1881\n",
      "Epoch [1/4], Step [3228/3844], Loss: 0.2191\n",
      "Epoch [1/4], Step [3229/3844], Loss: 0.1651\n",
      "Epoch [1/4], Step [3230/3844], Loss: 0.1539\n",
      "Epoch [1/4], Step [3231/3844], Loss: 0.2085\n",
      "Epoch [1/4], Step [3232/3844], Loss: 0.2114\n",
      "Epoch [1/4], Step [3233/3844], Loss: 0.1650\n",
      "Epoch [1/4], Step [3234/3844], Loss: 0.1763\n",
      "Epoch [1/4], Step [3235/3844], Loss: 0.1824\n",
      "Epoch [1/4], Step [3236/3844], Loss: 0.1653\n",
      "Epoch [1/4], Step [3237/3844], Loss: 0.1510\n",
      "Epoch [1/4], Step [3238/3844], Loss: 0.1528\n",
      "Epoch [1/4], Step [3239/3844], Loss: 0.1719\n",
      "Epoch [1/4], Step [3240/3844], Loss: 0.1604\n",
      "Epoch [1/4], Step [3241/3844], Loss: 0.1437\n",
      "Epoch [1/4], Step [3242/3844], Loss: 0.1959\n",
      "Epoch [1/4], Step [3243/3844], Loss: 0.1631\n",
      "Epoch [1/4], Step [3244/3844], Loss: 0.1872\n",
      "Epoch [1/4], Step [3245/3844], Loss: 0.1830\n",
      "Epoch [1/4], Step [3246/3844], Loss: 0.1733\n",
      "Epoch [1/4], Step [3247/3844], Loss: 0.1643\n",
      "Epoch [1/4], Step [3248/3844], Loss: 0.1540\n",
      "Epoch [1/4], Step [3249/3844], Loss: 0.1728\n",
      "Epoch [1/4], Step [3250/3844], Loss: 0.1846\n",
      "Epoch [1/4], Step [3251/3844], Loss: 0.2043\n",
      "Epoch [1/4], Step [3252/3844], Loss: 0.1841\n",
      "Epoch [1/4], Step [3253/3844], Loss: 0.1538\n",
      "Epoch [1/4], Step [3254/3844], Loss: 0.1581\n",
      "Epoch [1/4], Step [3255/3844], Loss: 0.2208\n",
      "Epoch [1/4], Step [3256/3844], Loss: 0.1635\n",
      "Epoch [1/4], Step [3257/3844], Loss: 0.1712\n",
      "Epoch [1/4], Step [3258/3844], Loss: 0.1682\n",
      "Epoch [1/4], Step [3259/3844], Loss: 0.1600\n",
      "Epoch [1/4], Step [3260/3844], Loss: 0.1810\n",
      "Epoch [1/4], Step [3261/3844], Loss: 0.1327\n",
      "Epoch [1/4], Step [3262/3844], Loss: 0.1944\n",
      "Epoch [1/4], Step [3263/3844], Loss: 0.1674\n",
      "Epoch [1/4], Step [3264/3844], Loss: 0.1909\n",
      "Epoch [1/4], Step [3265/3844], Loss: 0.2026\n",
      "Epoch [1/4], Step [3266/3844], Loss: 0.1657\n",
      "Epoch [1/4], Step [3267/3844], Loss: 0.1548\n",
      "Epoch [1/4], Step [3268/3844], Loss: 0.1682\n",
      "Epoch [1/4], Step [3269/3844], Loss: 0.1700\n",
      "Epoch [1/4], Step [3270/3844], Loss: 0.1796\n",
      "Epoch [1/4], Step [3271/3844], Loss: 0.2289\n",
      "Epoch [1/4], Step [3272/3844], Loss: 0.1382\n",
      "Epoch [1/4], Step [3273/3844], Loss: 0.1583\n",
      "Epoch [1/4], Step [3274/3844], Loss: 0.1787\n",
      "Epoch [1/4], Step [3275/3844], Loss: 0.1768\n",
      "Epoch [1/4], Step [3276/3844], Loss: 0.1689\n",
      "Epoch [1/4], Step [3277/3844], Loss: 0.1445\n",
      "Epoch [1/4], Step [3278/3844], Loss: 0.1520\n",
      "Epoch [1/4], Step [3279/3844], Loss: 0.1976\n",
      "Epoch [1/4], Step [3280/3844], Loss: 0.2017\n",
      "Epoch [1/4], Step [3281/3844], Loss: 0.1452\n",
      "Epoch [1/4], Step [3282/3844], Loss: 0.1838\n",
      "Epoch [1/4], Step [3283/3844], Loss: 0.1712\n",
      "Epoch [1/4], Step [3284/3844], Loss: 0.1880\n",
      "Epoch [1/4], Step [3285/3844], Loss: 0.1478\n",
      "Epoch [1/4], Step [3286/3844], Loss: 0.1141\n",
      "Epoch [1/4], Step [3287/3844], Loss: 0.1341\n",
      "Epoch [1/4], Step [3288/3844], Loss: 0.1779\n",
      "Epoch [1/4], Step [3289/3844], Loss: 0.1777\n",
      "Epoch [1/4], Step [3290/3844], Loss: 0.1405\n",
      "Epoch [1/4], Step [3291/3844], Loss: 0.2084\n",
      "Epoch [1/4], Step [3292/3844], Loss: 0.1200\n",
      "Epoch [1/4], Step [3293/3844], Loss: 0.1789\n",
      "Epoch [1/4], Step [3294/3844], Loss: 0.1623\n",
      "Epoch [1/4], Step [3295/3844], Loss: 0.2079\n",
      "Epoch [1/4], Step [3296/3844], Loss: 0.1607\n",
      "Epoch [1/4], Step [3297/3844], Loss: 0.1997\n",
      "Epoch [1/4], Step [3298/3844], Loss: 0.1492\n",
      "Epoch [1/4], Step [3299/3844], Loss: 0.1722\n",
      "Epoch [1/4], Step [3300/3844], Loss: 0.1585\n",
      "Epoch [1/4], Step [3301/3844], Loss: 0.2045\n",
      "Epoch [1/4], Step [3302/3844], Loss: 0.1440\n",
      "Epoch [1/4], Step [3303/3844], Loss: 0.1761\n",
      "Epoch [1/4], Step [3304/3844], Loss: 0.1779\n",
      "Epoch [1/4], Step [3305/3844], Loss: 0.1611\n",
      "Epoch [1/4], Step [3306/3844], Loss: 0.1741\n",
      "Epoch [1/4], Step [3307/3844], Loss: 0.1398\n",
      "Epoch [1/4], Step [3308/3844], Loss: 0.1846\n",
      "Epoch [1/4], Step [3309/3844], Loss: 0.1742\n",
      "Epoch [1/4], Step [3310/3844], Loss: 0.1755\n",
      "Epoch [1/4], Step [3311/3844], Loss: 0.1709\n",
      "Epoch [1/4], Step [3312/3844], Loss: 0.1515\n",
      "Epoch [1/4], Step [3313/3844], Loss: 0.1736\n",
      "Epoch [1/4], Step [3314/3844], Loss: 0.1856\n",
      "Epoch [1/4], Step [3315/3844], Loss: 0.1651\n",
      "Epoch [1/4], Step [3316/3844], Loss: 0.1384\n",
      "Epoch [1/4], Step [3317/3844], Loss: 0.2178\n",
      "Epoch [1/4], Step [3318/3844], Loss: 0.1263\n",
      "Epoch [1/4], Step [3319/3844], Loss: 0.2272\n",
      "Epoch [1/4], Step [3320/3844], Loss: 0.1846\n",
      "Epoch [1/4], Step [3321/3844], Loss: 0.1644\n",
      "Epoch [1/4], Step [3322/3844], Loss: 0.1621\n",
      "Epoch [1/4], Step [3323/3844], Loss: 0.1617\n",
      "Epoch [1/4], Step [3324/3844], Loss: 0.1828\n",
      "Epoch [1/4], Step [3325/3844], Loss: 0.1745\n",
      "Epoch [1/4], Step [3326/3844], Loss: 0.1659\n",
      "Epoch [1/4], Step [3327/3844], Loss: 0.1490\n",
      "Epoch [1/4], Step [3328/3844], Loss: 0.1662\n",
      "Epoch [1/4], Step [3329/3844], Loss: 0.1238\n",
      "Epoch [1/4], Step [3330/3844], Loss: 0.1590\n",
      "Epoch [1/4], Step [3331/3844], Loss: 0.1446\n",
      "Epoch [1/4], Step [3332/3844], Loss: 0.1913\n",
      "Epoch [1/4], Step [3333/3844], Loss: 0.2392\n",
      "Epoch [1/4], Step [3334/3844], Loss: 0.1712\n",
      "Epoch [1/4], Step [3335/3844], Loss: 0.1819\n",
      "Epoch [1/4], Step [3336/3844], Loss: 0.1425\n",
      "Epoch [1/4], Step [3337/3844], Loss: 0.1718\n",
      "Epoch [1/4], Step [3338/3844], Loss: 0.1407\n",
      "Epoch [1/4], Step [3339/3844], Loss: 0.1625\n",
      "Epoch [1/4], Step [3340/3844], Loss: 0.1550\n",
      "Epoch [1/4], Step [3341/3844], Loss: 0.1900\n",
      "Epoch [1/4], Step [3342/3844], Loss: 0.2390\n",
      "Epoch [1/4], Step [3343/3844], Loss: 0.1670\n",
      "Epoch [1/4], Step [3344/3844], Loss: 0.1627\n",
      "Epoch [1/4], Step [3345/3844], Loss: 0.1675\n",
      "Epoch [1/4], Step [3346/3844], Loss: 0.1637\n",
      "Epoch [1/4], Step [3347/3844], Loss: 0.1539\n",
      "Epoch [1/4], Step [3348/3844], Loss: 0.1166\n",
      "Epoch [1/4], Step [3349/3844], Loss: 0.1771\n",
      "Epoch [1/4], Step [3350/3844], Loss: 0.2278\n",
      "Epoch [1/4], Step [3351/3844], Loss: 0.2283\n",
      "Epoch [1/4], Step [3352/3844], Loss: 0.1675\n",
      "Epoch [1/4], Step [3353/3844], Loss: 0.2176\n",
      "Epoch [1/4], Step [3354/3844], Loss: 0.1751\n",
      "Epoch [1/4], Step [3355/3844], Loss: 0.1873\n",
      "Epoch [1/4], Step [3356/3844], Loss: 0.1870\n",
      "Epoch [1/4], Step [3357/3844], Loss: 0.1810\n",
      "Epoch [1/4], Step [3358/3844], Loss: 0.1928\n",
      "Epoch [1/4], Step [3359/3844], Loss: 0.1757\n",
      "Epoch [1/4], Step [3360/3844], Loss: 0.1578\n",
      "Epoch [1/4], Step [3361/3844], Loss: 0.1602\n",
      "Epoch [1/4], Step [3362/3844], Loss: 0.1835\n",
      "Epoch [1/4], Step [3363/3844], Loss: 0.1622\n",
      "Epoch [1/4], Step [3364/3844], Loss: 0.1578\n",
      "Epoch [1/4], Step [3365/3844], Loss: 0.2075\n",
      "Epoch [1/4], Step [3366/3844], Loss: 0.1820\n",
      "Epoch [1/4], Step [3367/3844], Loss: 0.1608\n",
      "Epoch [1/4], Step [3368/3844], Loss: 0.1565\n",
      "Epoch [1/4], Step [3369/3844], Loss: 0.1762\n",
      "Epoch [1/4], Step [3370/3844], Loss: 0.1461\n",
      "Epoch [1/4], Step [3371/3844], Loss: 0.1344\n",
      "Epoch [1/4], Step [3372/3844], Loss: 0.2208\n",
      "Epoch [1/4], Step [3373/3844], Loss: 0.1435\n",
      "Epoch [1/4], Step [3374/3844], Loss: 0.1722\n",
      "Epoch [1/4], Step [3375/3844], Loss: 0.1533\n",
      "Epoch [1/4], Step [3376/3844], Loss: 0.1578\n",
      "Epoch [1/4], Step [3377/3844], Loss: 0.2025\n",
      "Epoch [1/4], Step [3378/3844], Loss: 0.1710\n",
      "Epoch [1/4], Step [3379/3844], Loss: 0.1529\n",
      "Epoch [1/4], Step [3380/3844], Loss: 0.2005\n",
      "Epoch [1/4], Step [3381/3844], Loss: 0.1709\n",
      "Epoch [1/4], Step [3382/3844], Loss: 0.1420\n",
      "Epoch [1/4], Step [3383/3844], Loss: 0.1316\n",
      "Epoch [1/4], Step [3384/3844], Loss: 0.1764\n",
      "Epoch [1/4], Step [3385/3844], Loss: 0.1477\n",
      "Epoch [1/4], Step [3386/3844], Loss: 0.1860\n",
      "Epoch [1/4], Step [3387/3844], Loss: 0.1861\n",
      "Epoch [1/4], Step [3388/3844], Loss: 0.1661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [3389/3844], Loss: 0.1362\n",
      "Epoch [1/4], Step [3390/3844], Loss: 0.1983\n",
      "Epoch [1/4], Step [3391/3844], Loss: 0.1406\n",
      "Epoch [1/4], Step [3392/3844], Loss: 0.2811\n",
      "Epoch [1/4], Step [3393/3844], Loss: 0.1742\n",
      "Epoch [1/4], Step [3394/3844], Loss: 0.1886\n",
      "Epoch [1/4], Step [3395/3844], Loss: 0.1410\n",
      "Epoch [1/4], Step [3396/3844], Loss: 0.2179\n",
      "Epoch [1/4], Step [3397/3844], Loss: 0.1764\n",
      "Epoch [1/4], Step [3398/3844], Loss: 0.1379\n",
      "Epoch [1/4], Step [3399/3844], Loss: 0.1953\n",
      "Epoch [1/4], Step [3400/3844], Loss: 0.1377\n",
      "Epoch [1/4], Step [3401/3844], Loss: 0.1574\n",
      "Epoch [1/4], Step [3402/3844], Loss: 0.1514\n",
      "Epoch [1/4], Step [3403/3844], Loss: 0.1655\n",
      "Epoch [1/4], Step [3404/3844], Loss: 0.1780\n",
      "Epoch [1/4], Step [3405/3844], Loss: 0.1591\n",
      "Epoch [1/4], Step [3406/3844], Loss: 0.1672\n",
      "Epoch [1/4], Step [3407/3844], Loss: 0.1922\n",
      "Epoch [1/4], Step [3408/3844], Loss: 0.1591\n",
      "Epoch [1/4], Step [3409/3844], Loss: 0.1623\n",
      "Epoch [1/4], Step [3410/3844], Loss: 0.1981\n",
      "Epoch [1/4], Step [3411/3844], Loss: 0.1239\n",
      "Epoch [1/4], Step [3412/3844], Loss: 0.1846\n",
      "Epoch [1/4], Step [3413/3844], Loss: 0.1512\n",
      "Epoch [1/4], Step [3414/3844], Loss: 0.1755\n",
      "Epoch [1/4], Step [3415/3844], Loss: 0.1338\n",
      "Epoch [1/4], Step [3416/3844], Loss: 0.1716\n",
      "Epoch [1/4], Step [3417/3844], Loss: 0.1625\n",
      "Epoch [1/4], Step [3418/3844], Loss: 0.1791\n",
      "Epoch [1/4], Step [3419/3844], Loss: 0.1712\n",
      "Epoch [1/4], Step [3420/3844], Loss: 0.1386\n",
      "Epoch [1/4], Step [3421/3844], Loss: 0.1804\n",
      "Epoch [1/4], Step [3422/3844], Loss: 0.1303\n",
      "Epoch [1/4], Step [3423/3844], Loss: 0.1493\n",
      "Epoch [1/4], Step [3424/3844], Loss: 0.2372\n",
      "Epoch [1/4], Step [3425/3844], Loss: 0.1779\n",
      "Epoch [1/4], Step [3426/3844], Loss: 0.1610\n",
      "Epoch [1/4], Step [3427/3844], Loss: 0.1705\n",
      "Epoch [1/4], Step [3428/3844], Loss: 0.2071\n",
      "Epoch [1/4], Step [3429/3844], Loss: 0.1680\n",
      "Epoch [1/4], Step [3430/3844], Loss: 0.2090\n",
      "Epoch [1/4], Step [3431/3844], Loss: 0.1616\n",
      "Epoch [1/4], Step [3432/3844], Loss: 0.1531\n",
      "Epoch [1/4], Step [3433/3844], Loss: 0.1670\n",
      "Epoch [1/4], Step [3434/3844], Loss: 0.1965\n",
      "Epoch [1/4], Step [3435/3844], Loss: 0.1834\n",
      "Epoch [1/4], Step [3436/3844], Loss: 0.1474\n",
      "Epoch [1/4], Step [3437/3844], Loss: 0.2276\n",
      "Epoch [1/4], Step [3438/3844], Loss: 0.1764\n",
      "Epoch [1/4], Step [3439/3844], Loss: 0.1572\n",
      "Epoch [1/4], Step [3440/3844], Loss: 0.1668\n",
      "Epoch [1/4], Step [3441/3844], Loss: 0.1669\n",
      "Epoch [1/4], Step [3442/3844], Loss: 0.2276\n",
      "Epoch [1/4], Step [3443/3844], Loss: 0.1631\n",
      "Epoch [1/4], Step [3444/3844], Loss: 0.1757\n",
      "Epoch [1/4], Step [3445/3844], Loss: 0.1704\n",
      "Epoch [1/4], Step [3446/3844], Loss: 0.1699\n",
      "Epoch [1/4], Step [3447/3844], Loss: 0.1762\n",
      "Epoch [1/4], Step [3448/3844], Loss: 0.1939\n",
      "Epoch [1/4], Step [3449/3844], Loss: 0.1775\n",
      "Epoch [1/4], Step [3450/3844], Loss: 0.1776\n",
      "Epoch [1/4], Step [3451/3844], Loss: 0.2035\n",
      "Epoch [1/4], Step [3452/3844], Loss: 0.2076\n",
      "Epoch [1/4], Step [3453/3844], Loss: 0.1624\n",
      "Epoch [1/4], Step [3454/3844], Loss: 0.1520\n",
      "Epoch [1/4], Step [3455/3844], Loss: 0.1649\n",
      "Epoch [1/4], Step [3456/3844], Loss: 0.1967\n",
      "Epoch [1/4], Step [3457/3844], Loss: 0.1578\n",
      "Epoch [1/4], Step [3458/3844], Loss: 0.2272\n",
      "Epoch [1/4], Step [3459/3844], Loss: 0.1905\n",
      "Epoch [1/4], Step [3460/3844], Loss: 0.2198\n",
      "Epoch [1/4], Step [3461/3844], Loss: 0.2238\n",
      "Epoch [1/4], Step [3462/3844], Loss: 0.1984\n",
      "Epoch [1/4], Step [3463/3844], Loss: 0.1606\n",
      "Epoch [1/4], Step [3464/3844], Loss: 0.1533\n",
      "Epoch [1/4], Step [3465/3844], Loss: 0.1616\n",
      "Epoch [1/4], Step [3466/3844], Loss: 0.1958\n",
      "Epoch [1/4], Step [3467/3844], Loss: 0.1385\n",
      "Epoch [1/4], Step [3468/3844], Loss: 0.2330\n",
      "Epoch [1/4], Step [3469/3844], Loss: 0.1536\n",
      "Epoch [1/4], Step [3470/3844], Loss: 0.1849\n",
      "Epoch [1/4], Step [3471/3844], Loss: 0.1678\n",
      "Epoch [1/4], Step [3472/3844], Loss: 0.1710\n",
      "Epoch [1/4], Step [3473/3844], Loss: 0.1520\n",
      "Epoch [1/4], Step [3474/3844], Loss: 0.1540\n",
      "Epoch [1/4], Step [3475/3844], Loss: 0.2000\n",
      "Epoch [1/4], Step [3476/3844], Loss: 0.1461\n",
      "Epoch [1/4], Step [3477/3844], Loss: 0.1436\n",
      "Epoch [1/4], Step [3478/3844], Loss: 0.1626\n",
      "Epoch [1/4], Step [3479/3844], Loss: 0.1626\n",
      "Epoch [1/4], Step [3480/3844], Loss: 0.1793\n",
      "Epoch [1/4], Step [3481/3844], Loss: 0.1806\n",
      "Epoch [1/4], Step [3482/3844], Loss: 0.1654\n",
      "Epoch [1/4], Step [3483/3844], Loss: 0.1440\n",
      "Epoch [1/4], Step [3484/3844], Loss: 0.1494\n",
      "Epoch [1/4], Step [3485/3844], Loss: 0.1805\n",
      "Epoch [1/4], Step [3486/3844], Loss: 0.1407\n",
      "Epoch [1/4], Step [3487/3844], Loss: 0.1472\n",
      "Epoch [1/4], Step [3488/3844], Loss: 0.1786\n",
      "Epoch [1/4], Step [3489/3844], Loss: 0.1757\n",
      "Epoch [1/4], Step [3490/3844], Loss: 0.1533\n",
      "Epoch [1/4], Step [3491/3844], Loss: 0.1920\n",
      "Epoch [1/4], Step [3492/3844], Loss: 0.1680\n",
      "Epoch [1/4], Step [3493/3844], Loss: 0.1890\n",
      "Epoch [1/4], Step [3494/3844], Loss: 0.1641\n",
      "Epoch [1/4], Step [3495/3844], Loss: 0.1571\n",
      "Epoch [1/4], Step [3496/3844], Loss: 0.1371\n",
      "Epoch [1/4], Step [3497/3844], Loss: 0.1559\n",
      "Epoch [1/4], Step [3498/3844], Loss: 0.1983\n",
      "Epoch [1/4], Step [3499/3844], Loss: 0.1763\n",
      "Epoch [1/4], Step [3500/3844], Loss: 0.1948\n",
      "Epoch [1/4], Step [3501/3844], Loss: 0.1689\n",
      "Epoch [1/4], Step [3502/3844], Loss: 0.1730\n",
      "Epoch [1/4], Step [3503/3844], Loss: 0.1948\n",
      "Epoch [1/4], Step [3504/3844], Loss: 0.1568\n",
      "Epoch [1/4], Step [3505/3844], Loss: 0.2154\n",
      "Epoch [1/4], Step [3506/3844], Loss: 0.1724\n",
      "Epoch [1/4], Step [3507/3844], Loss: 0.1832\n",
      "Epoch [1/4], Step [3508/3844], Loss: 0.1678\n",
      "Epoch [1/4], Step [3509/3844], Loss: 0.1942\n",
      "Epoch [1/4], Step [3510/3844], Loss: 0.2089\n",
      "Epoch [1/4], Step [3511/3844], Loss: 0.1857\n",
      "Epoch [1/4], Step [3512/3844], Loss: 0.2226\n",
      "Epoch [1/4], Step [3513/3844], Loss: 0.1520\n",
      "Epoch [1/4], Step [3514/3844], Loss: 0.1491\n",
      "Epoch [1/4], Step [3515/3844], Loss: 0.1459\n",
      "Epoch [1/4], Step [3516/3844], Loss: 0.1711\n",
      "Epoch [1/4], Step [3517/3844], Loss: 0.1557\n",
      "Epoch [1/4], Step [3518/3844], Loss: 0.1608\n",
      "Epoch [1/4], Step [3519/3844], Loss: 0.1914\n",
      "Epoch [1/4], Step [3520/3844], Loss: 0.1544\n",
      "Epoch [1/4], Step [3521/3844], Loss: 0.2194\n",
      "Epoch [1/4], Step [3522/3844], Loss: 0.1471\n",
      "Epoch [1/4], Step [3523/3844], Loss: 0.1654\n",
      "Epoch [1/4], Step [3524/3844], Loss: 0.1596\n",
      "Epoch [1/4], Step [3525/3844], Loss: 0.1495\n",
      "Epoch [1/4], Step [3526/3844], Loss: 0.2329\n",
      "Epoch [1/4], Step [3527/3844], Loss: 0.1738\n",
      "Epoch [1/4], Step [3528/3844], Loss: 0.1876\n",
      "Epoch [1/4], Step [3529/3844], Loss: 0.1223\n",
      "Epoch [1/4], Step [3530/3844], Loss: 0.1994\n",
      "Epoch [1/4], Step [3531/3844], Loss: 0.2326\n",
      "Epoch [1/4], Step [3532/3844], Loss: 0.1708\n",
      "Epoch [1/4], Step [3533/3844], Loss: 0.1773\n",
      "Epoch [1/4], Step [3534/3844], Loss: 0.2319\n",
      "Epoch [1/4], Step [3535/3844], Loss: 0.1789\n",
      "Epoch [1/4], Step [3536/3844], Loss: 0.1865\n",
      "Epoch [1/4], Step [3537/3844], Loss: 0.1395\n",
      "Epoch [1/4], Step [3538/3844], Loss: 0.1705\n",
      "Epoch [1/4], Step [3539/3844], Loss: 0.1708\n",
      "Epoch [1/4], Step [3540/3844], Loss: 0.1706\n",
      "Epoch [1/4], Step [3541/3844], Loss: 0.1995\n",
      "Epoch [1/4], Step [3542/3844], Loss: 0.1287\n",
      "Epoch [1/4], Step [3543/3844], Loss: 0.2021\n",
      "Epoch [1/4], Step [3544/3844], Loss: 0.2253\n",
      "Epoch [1/4], Step [3545/3844], Loss: 0.1452\n",
      "Epoch [1/4], Step [3546/3844], Loss: 0.1851\n",
      "Epoch [1/4], Step [3547/3844], Loss: 0.1650\n",
      "Epoch [1/4], Step [3548/3844], Loss: 0.1853\n",
      "Epoch [1/4], Step [3549/3844], Loss: 0.1646\n",
      "Epoch [1/4], Step [3550/3844], Loss: 0.1655\n",
      "Epoch [1/4], Step [3551/3844], Loss: 0.2202\n",
      "Epoch [1/4], Step [3552/3844], Loss: 0.1717\n",
      "Epoch [1/4], Step [3553/3844], Loss: 0.1714\n",
      "Epoch [1/4], Step [3554/3844], Loss: 0.1750\n",
      "Epoch [1/4], Step [3555/3844], Loss: 0.1667\n",
      "Epoch [1/4], Step [3556/3844], Loss: 0.1338\n",
      "Epoch [1/4], Step [3557/3844], Loss: 0.1765\n",
      "Epoch [1/4], Step [3558/3844], Loss: 0.1646\n",
      "Epoch [1/4], Step [3559/3844], Loss: 0.2122\n",
      "Epoch [1/4], Step [3560/3844], Loss: 0.1639\n",
      "Epoch [1/4], Step [3561/3844], Loss: 0.1788\n",
      "Epoch [1/4], Step [3562/3844], Loss: 0.1471\n",
      "Epoch [1/4], Step [3563/3844], Loss: 0.2249\n",
      "Epoch [1/4], Step [3564/3844], Loss: 0.1519\n",
      "Epoch [1/4], Step [3565/3844], Loss: 0.2178\n",
      "Epoch [1/4], Step [3566/3844], Loss: 0.1468\n",
      "Epoch [1/4], Step [3567/3844], Loss: 0.1623\n",
      "Epoch [1/4], Step [3568/3844], Loss: 0.1623\n",
      "Epoch [1/4], Step [3569/3844], Loss: 0.1714\n",
      "Epoch [1/4], Step [3570/3844], Loss: 0.1818\n",
      "Epoch [1/4], Step [3571/3844], Loss: 0.1730\n",
      "Epoch [1/4], Step [3572/3844], Loss: 0.1401\n",
      "Epoch [1/4], Step [3573/3844], Loss: 0.1404\n",
      "Epoch [1/4], Step [3574/3844], Loss: 0.1877\n",
      "Epoch [1/4], Step [3575/3844], Loss: 0.1355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [3576/3844], Loss: 0.1930\n",
      "Epoch [1/4], Step [3577/3844], Loss: 0.1368\n",
      "Epoch [1/4], Step [3578/3844], Loss: 0.1711\n",
      "Epoch [1/4], Step [3579/3844], Loss: 0.1502\n",
      "Epoch [1/4], Step [3580/3844], Loss: 0.1119\n",
      "Epoch [1/4], Step [3581/3844], Loss: 0.1495\n",
      "Epoch [1/4], Step [3582/3844], Loss: 0.1908\n",
      "Epoch [1/4], Step [3583/3844], Loss: 0.1650\n",
      "Epoch [1/4], Step [3584/3844], Loss: 0.1454\n",
      "Epoch [1/4], Step [3585/3844], Loss: 0.1529\n",
      "Epoch [1/4], Step [3586/3844], Loss: 0.1573\n",
      "Epoch [1/4], Step [3587/3844], Loss: 0.1563\n",
      "Epoch [1/4], Step [3588/3844], Loss: 0.1670\n",
      "Epoch [1/4], Step [3589/3844], Loss: 0.1439\n",
      "Epoch [1/4], Step [3590/3844], Loss: 0.1771\n",
      "Epoch [1/4], Step [3591/3844], Loss: 0.1682\n",
      "Epoch [1/4], Step [3592/3844], Loss: 0.1712\n",
      "Epoch [1/4], Step [3593/3844], Loss: 0.1988\n",
      "Epoch [1/4], Step [3594/3844], Loss: 0.1546\n",
      "Epoch [1/4], Step [3595/3844], Loss: 0.1626\n",
      "Epoch [1/4], Step [3596/3844], Loss: 0.2281\n",
      "Epoch [1/4], Step [3597/3844], Loss: 0.1848\n",
      "Epoch [1/4], Step [3598/3844], Loss: 0.2367\n",
      "Epoch [1/4], Step [3599/3844], Loss: 0.1664\n",
      "Epoch [1/4], Step [3600/3844], Loss: 0.1916\n",
      "Epoch [1/4], Step [3601/3844], Loss: 0.1697\n",
      "Epoch [1/4], Step [3602/3844], Loss: 0.1485\n",
      "Epoch [1/4], Step [3603/3844], Loss: 0.1539\n",
      "Epoch [1/4], Step [3604/3844], Loss: 0.1332\n",
      "Epoch [1/4], Step [3605/3844], Loss: 0.1626\n",
      "Epoch [1/4], Step [3606/3844], Loss: 0.1574\n",
      "Epoch [1/4], Step [3607/3844], Loss: 0.1536\n",
      "Epoch [1/4], Step [3608/3844], Loss: 0.1711\n",
      "Epoch [1/4], Step [3609/3844], Loss: 0.1577\n",
      "Epoch [1/4], Step [3610/3844], Loss: 0.1338\n",
      "Epoch [1/4], Step [3611/3844], Loss: 0.1661\n",
      "Epoch [1/4], Step [3612/3844], Loss: 0.1378\n",
      "Epoch [1/4], Step [3613/3844], Loss: 0.1848\n",
      "Epoch [1/4], Step [3614/3844], Loss: 0.1697\n",
      "Epoch [1/4], Step [3615/3844], Loss: 0.1872\n",
      "Epoch [1/4], Step [3616/3844], Loss: 0.1670\n",
      "Epoch [1/4], Step [3617/3844], Loss: 0.2308\n",
      "Epoch [1/4], Step [3618/3844], Loss: 0.1558\n",
      "Epoch [1/4], Step [3619/3844], Loss: 0.1477\n",
      "Epoch [1/4], Step [3620/3844], Loss: 0.1788\n",
      "Epoch [1/4], Step [3621/3844], Loss: 0.1407\n",
      "Epoch [1/4], Step [3622/3844], Loss: 0.1745\n",
      "Epoch [1/4], Step [3623/3844], Loss: 0.1829\n",
      "Epoch [1/4], Step [3624/3844], Loss: 0.1857\n",
      "Epoch [1/4], Step [3625/3844], Loss: 0.1653\n",
      "Epoch [1/4], Step [3626/3844], Loss: 0.1846\n",
      "Epoch [1/4], Step [3627/3844], Loss: 0.1708\n",
      "Epoch [1/4], Step [3628/3844], Loss: 0.1798\n",
      "Epoch [1/4], Step [3629/3844], Loss: 0.1611\n",
      "Epoch [1/4], Step [3630/3844], Loss: 0.1514\n",
      "Epoch [1/4], Step [3631/3844], Loss: 0.1728\n",
      "Epoch [1/4], Step [3632/3844], Loss: 0.1736\n",
      "Epoch [1/4], Step [3633/3844], Loss: 0.1724\n",
      "Epoch [1/4], Step [3634/3844], Loss: 0.1608\n",
      "Epoch [1/4], Step [3635/3844], Loss: 0.1353\n",
      "Epoch [1/4], Step [3636/3844], Loss: 0.1494\n",
      "Epoch [1/4], Step [3637/3844], Loss: 0.1578\n",
      "Epoch [1/4], Step [3638/3844], Loss: 0.1539\n",
      "Epoch [1/4], Step [3639/3844], Loss: 0.2047\n",
      "Epoch [1/4], Step [3640/3844], Loss: 0.1579\n",
      "Epoch [1/4], Step [3641/3844], Loss: 0.1682\n",
      "Epoch [1/4], Step [3642/3844], Loss: 0.1581\n",
      "Epoch [1/4], Step [3643/3844], Loss: 0.1578\n",
      "Epoch [1/4], Step [3644/3844], Loss: 0.2015\n",
      "Epoch [1/4], Step [3645/3844], Loss: 0.1503\n",
      "Epoch [1/4], Step [3646/3844], Loss: 0.1742\n",
      "Epoch [1/4], Step [3647/3844], Loss: 0.1599\n",
      "Epoch [1/4], Step [3648/3844], Loss: 0.1513\n",
      "Epoch [1/4], Step [3649/3844], Loss: 0.1508\n",
      "Epoch [1/4], Step [3650/3844], Loss: 0.1867\n",
      "Epoch [1/4], Step [3651/3844], Loss: 0.2162\n",
      "Epoch [1/4], Step [3652/3844], Loss: 0.1721\n",
      "Epoch [1/4], Step [3653/3844], Loss: 0.1592\n",
      "Epoch [1/4], Step [3654/3844], Loss: 0.1842\n",
      "Epoch [1/4], Step [3655/3844], Loss: 0.1312\n",
      "Epoch [1/4], Step [3656/3844], Loss: 0.1493\n",
      "Epoch [1/4], Step [3657/3844], Loss: 0.0924\n",
      "Epoch [1/4], Step [3658/3844], Loss: 0.2352\n",
      "Epoch [1/4], Step [3659/3844], Loss: 0.2283\n",
      "Epoch [1/4], Step [3660/3844], Loss: 0.1883\n",
      "Epoch [1/4], Step [3661/3844], Loss: 0.1545\n",
      "Epoch [1/4], Step [3662/3844], Loss: 0.1532\n",
      "Epoch [1/4], Step [3663/3844], Loss: 0.1536\n",
      "Epoch [1/4], Step [3664/3844], Loss: 0.1677\n",
      "Epoch [1/4], Step [3665/3844], Loss: 0.1526\n",
      "Epoch [1/4], Step [3666/3844], Loss: 0.2020\n",
      "Epoch [1/4], Step [3667/3844], Loss: 0.1678\n",
      "Epoch [1/4], Step [3668/3844], Loss: 0.1693\n",
      "Epoch [1/4], Step [3669/3844], Loss: 0.2666\n",
      "Epoch [1/4], Step [3670/3844], Loss: 0.1586\n",
      "Epoch [1/4], Step [3671/3844], Loss: 0.1680\n",
      "Epoch [1/4], Step [3672/3844], Loss: 0.1725\n",
      "Epoch [1/4], Step [3673/3844], Loss: 0.1631\n",
      "Epoch [1/4], Step [3674/3844], Loss: 0.1600\n",
      "Epoch [1/4], Step [3675/3844], Loss: 0.1699\n",
      "Epoch [1/4], Step [3676/3844], Loss: 0.1583\n",
      "Epoch [1/4], Step [3677/3844], Loss: 0.1696\n",
      "Epoch [1/4], Step [3678/3844], Loss: 0.1663\n",
      "Epoch [1/4], Step [3679/3844], Loss: 0.1415\n",
      "Epoch [1/4], Step [3680/3844], Loss: 0.1689\n",
      "Epoch [1/4], Step [3681/3844], Loss: 0.1621\n",
      "Epoch [1/4], Step [3682/3844], Loss: 0.0962\n",
      "Epoch [1/4], Step [3683/3844], Loss: 0.1394\n",
      "Epoch [1/4], Step [3684/3844], Loss: 0.1706\n",
      "Epoch [1/4], Step [3685/3844], Loss: 0.1243\n",
      "Epoch [1/4], Step [3686/3844], Loss: 0.1525\n",
      "Epoch [1/4], Step [3687/3844], Loss: 0.1558\n",
      "Epoch [1/4], Step [3688/3844], Loss: 0.1519\n",
      "Epoch [1/4], Step [3689/3844], Loss: 0.1624\n",
      "Epoch [1/4], Step [3690/3844], Loss: 0.1525\n",
      "Epoch [1/4], Step [3691/3844], Loss: 0.1713\n",
      "Epoch [1/4], Step [3692/3844], Loss: 0.1709\n",
      "Epoch [1/4], Step [3693/3844], Loss: 0.1480\n",
      "Epoch [1/4], Step [3694/3844], Loss: 0.1860\n",
      "Epoch [1/4], Step [3695/3844], Loss: 0.1563\n",
      "Epoch [1/4], Step [3696/3844], Loss: 0.1932\n",
      "Epoch [1/4], Step [3697/3844], Loss: 0.1612\n",
      "Epoch [1/4], Step [3698/3844], Loss: 0.1646\n",
      "Epoch [1/4], Step [3699/3844], Loss: 0.1691\n",
      "Epoch [1/4], Step [3700/3844], Loss: 0.1470\n",
      "Epoch [1/4], Step [3701/3844], Loss: 0.1737\n",
      "Epoch [1/4], Step [3702/3844], Loss: 0.1144\n",
      "Epoch [1/4], Step [3703/3844], Loss: 0.1446\n",
      "Epoch [1/4], Step [3704/3844], Loss: 0.1724\n",
      "Epoch [1/4], Step [3705/3844], Loss: 0.1720\n",
      "Epoch [1/4], Step [3706/3844], Loss: 0.1507\n",
      "Epoch [1/4], Step [3707/3844], Loss: 0.1628\n",
      "Epoch [1/4], Step [3708/3844], Loss: 0.1479\n",
      "Epoch [1/4], Step [3709/3844], Loss: 0.1362\n",
      "Epoch [1/4], Step [3710/3844], Loss: 0.1802\n",
      "Epoch [1/4], Step [3711/3844], Loss: 0.1779\n",
      "Epoch [1/4], Step [3712/3844], Loss: 0.1487\n",
      "Epoch [1/4], Step [3713/3844], Loss: 0.2133\n",
      "Epoch [1/4], Step [3714/3844], Loss: 0.1379\n",
      "Epoch [1/4], Step [3715/3844], Loss: 0.1619\n",
      "Epoch [1/4], Step [3716/3844], Loss: 0.1720\n",
      "Epoch [1/4], Step [3717/3844], Loss: 0.1807\n",
      "Epoch [1/4], Step [3718/3844], Loss: 0.2331\n",
      "Epoch [1/4], Step [3719/3844], Loss: 0.1470\n",
      "Epoch [1/4], Step [3720/3844], Loss: 0.1446\n",
      "Epoch [1/4], Step [3721/3844], Loss: 0.1641\n",
      "Epoch [1/4], Step [3722/3844], Loss: 0.1636\n",
      "Epoch [1/4], Step [3723/3844], Loss: 0.1571\n",
      "Epoch [1/4], Step [3724/3844], Loss: 0.1610\n",
      "Epoch [1/4], Step [3725/3844], Loss: 0.1613\n",
      "Epoch [1/4], Step [3726/3844], Loss: 0.1345\n",
      "Epoch [1/4], Step [3727/3844], Loss: 0.1585\n",
      "Epoch [1/4], Step [3728/3844], Loss: 0.1978\n",
      "Epoch [1/4], Step [3729/3844], Loss: 0.1407\n",
      "Epoch [1/4], Step [3730/3844], Loss: 0.2458\n",
      "Epoch [1/4], Step [3731/3844], Loss: 0.1844\n",
      "Epoch [1/4], Step [3732/3844], Loss: 0.1609\n",
      "Epoch [1/4], Step [3733/3844], Loss: 0.1492\n",
      "Epoch [1/4], Step [3734/3844], Loss: 0.1505\n",
      "Epoch [1/4], Step [3735/3844], Loss: 0.2127\n",
      "Epoch [1/4], Step [3736/3844], Loss: 0.1609\n",
      "Epoch [1/4], Step [3737/3844], Loss: 0.1864\n",
      "Epoch [1/4], Step [3738/3844], Loss: 0.1968\n",
      "Epoch [1/4], Step [3739/3844], Loss: 0.1898\n",
      "Epoch [1/4], Step [3740/3844], Loss: 0.1802\n",
      "Epoch [1/4], Step [3741/3844], Loss: 0.1546\n",
      "Epoch [1/4], Step [3742/3844], Loss: 0.1820\n",
      "Epoch [1/4], Step [3743/3844], Loss: 0.1417\n",
      "Epoch [1/4], Step [3744/3844], Loss: 0.1256\n",
      "Epoch [1/4], Step [3745/3844], Loss: 0.1279\n",
      "Epoch [1/4], Step [3746/3844], Loss: 0.1734\n",
      "Epoch [1/4], Step [3747/3844], Loss: 0.1608\n",
      "Epoch [1/4], Step [3748/3844], Loss: 0.1540\n",
      "Epoch [1/4], Step [3749/3844], Loss: 0.1484\n",
      "Epoch [1/4], Step [3750/3844], Loss: 0.1160\n",
      "Epoch [1/4], Step [3751/3844], Loss: 0.1521\n",
      "Epoch [1/4], Step [3752/3844], Loss: 0.2089\n",
      "Epoch [1/4], Step [3753/3844], Loss: 0.1581\n",
      "Epoch [1/4], Step [3754/3844], Loss: 0.1558\n",
      "Epoch [1/4], Step [3755/3844], Loss: 0.1384\n",
      "Epoch [1/4], Step [3756/3844], Loss: 0.1610\n",
      "Epoch [1/4], Step [3757/3844], Loss: 0.1402\n",
      "Epoch [1/4], Step [3758/3844], Loss: 0.1535\n",
      "Epoch [1/4], Step [3759/3844], Loss: 0.1546\n",
      "Epoch [1/4], Step [3760/3844], Loss: 0.1926\n",
      "Epoch [1/4], Step [3761/3844], Loss: 0.1013\n",
      "Epoch [1/4], Step [3762/3844], Loss: 0.1313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [3763/3844], Loss: 0.1807\n",
      "Epoch [1/4], Step [3764/3844], Loss: 0.2270\n",
      "Epoch [1/4], Step [3765/3844], Loss: 0.1636\n",
      "Epoch [1/4], Step [3766/3844], Loss: 0.1622\n",
      "Epoch [1/4], Step [3767/3844], Loss: 0.1483\n",
      "Epoch [1/4], Step [3768/3844], Loss: 0.2176\n",
      "Epoch [1/4], Step [3769/3844], Loss: 0.1541\n",
      "Epoch [1/4], Step [3770/3844], Loss: 0.1623\n",
      "Epoch [1/4], Step [3771/3844], Loss: 0.1649\n",
      "Epoch [1/4], Step [3772/3844], Loss: 0.2157\n",
      "Epoch [1/4], Step [3773/3844], Loss: 0.1729\n",
      "Epoch [1/4], Step [3774/3844], Loss: 0.1670\n",
      "Epoch [1/4], Step [3775/3844], Loss: 0.1675\n",
      "Epoch [1/4], Step [3776/3844], Loss: 0.1613\n",
      "Epoch [1/4], Step [3777/3844], Loss: 0.1402\n",
      "Epoch [1/4], Step [3778/3844], Loss: 0.1522\n",
      "Epoch [1/4], Step [3779/3844], Loss: 0.1589\n",
      "Epoch [1/4], Step [3780/3844], Loss: 0.1768\n",
      "Epoch [1/4], Step [3781/3844], Loss: 0.1544\n",
      "Epoch [1/4], Step [3782/3844], Loss: 0.1433\n",
      "Epoch [1/4], Step [3783/3844], Loss: 0.1557\n",
      "Epoch [1/4], Step [3784/3844], Loss: 0.1589\n",
      "Epoch [1/4], Step [3785/3844], Loss: 0.1591\n",
      "Epoch [1/4], Step [3786/3844], Loss: 0.1613\n",
      "Epoch [1/4], Step [3787/3844], Loss: 0.1593\n",
      "Epoch [1/4], Step [3788/3844], Loss: 0.1147\n",
      "Epoch [1/4], Step [3789/3844], Loss: 0.1517\n",
      "Epoch [1/4], Step [3790/3844], Loss: 0.1238\n",
      "Epoch [1/4], Step [3791/3844], Loss: 0.1461\n",
      "Epoch [1/4], Step [3792/3844], Loss: 0.1658\n",
      "Epoch [1/4], Step [3793/3844], Loss: 0.1384\n",
      "Epoch [1/4], Step [3794/3844], Loss: 0.1513\n",
      "Epoch [1/4], Step [3795/3844], Loss: 0.1581\n",
      "Epoch [1/4], Step [3796/3844], Loss: 0.1729\n",
      "Epoch [1/4], Step [3797/3844], Loss: 0.1901\n",
      "Epoch [1/4], Step [3798/3844], Loss: 0.1626\n",
      "Epoch [1/4], Step [3799/3844], Loss: 0.1615\n",
      "Epoch [1/4], Step [3800/3844], Loss: 0.1515\n",
      "Epoch [1/4], Step [3801/3844], Loss: 0.1670\n",
      "Epoch [1/4], Step [3802/3844], Loss: 0.1454\n",
      "Epoch [1/4], Step [3803/3844], Loss: 0.1640\n",
      "Epoch [1/4], Step [3804/3844], Loss: 0.1471\n",
      "Epoch [1/4], Step [3805/3844], Loss: 0.1529\n",
      "Epoch [1/4], Step [3806/3844], Loss: 0.1576\n",
      "Epoch [1/4], Step [3807/3844], Loss: 0.1452\n",
      "Epoch [1/4], Step [3808/3844], Loss: 0.2332\n",
      "Epoch [1/4], Step [3809/3844], Loss: 0.1315\n",
      "Epoch [1/4], Step [3810/3844], Loss: 0.1660\n",
      "Epoch [1/4], Step [3811/3844], Loss: 0.1658\n",
      "Epoch [1/4], Step [3812/3844], Loss: 0.1500\n",
      "Epoch [1/4], Step [3813/3844], Loss: 0.1400\n",
      "Epoch [1/4], Step [3814/3844], Loss: 0.1595\n",
      "Epoch [1/4], Step [3815/3844], Loss: 0.1596\n",
      "Epoch [1/4], Step [3816/3844], Loss: 0.1342\n",
      "Epoch [1/4], Step [3817/3844], Loss: 0.1451\n",
      "Epoch [1/4], Step [3818/3844], Loss: 0.1514\n",
      "Epoch [1/4], Step [3819/3844], Loss: 0.1642\n",
      "Epoch [1/4], Step [3820/3844], Loss: 0.1506\n",
      "Epoch [1/4], Step [3821/3844], Loss: 0.1384\n",
      "Epoch [1/4], Step [3822/3844], Loss: 0.1407\n",
      "Epoch [1/4], Step [3823/3844], Loss: 0.1596\n",
      "Epoch [1/4], Step [3824/3844], Loss: 0.1426\n",
      "Epoch [1/4], Step [3825/3844], Loss: 0.1346\n",
      "Epoch [1/4], Step [3826/3844], Loss: 0.1728\n",
      "Epoch [1/4], Step [3827/3844], Loss: 0.1366\n",
      "Epoch [1/4], Step [3828/3844], Loss: 0.0970\n",
      "Epoch [1/4], Step [3829/3844], Loss: 0.1989\n",
      "Epoch [1/4], Step [3830/3844], Loss: 0.1627\n",
      "Epoch [1/4], Step [3831/3844], Loss: 0.1450\n",
      "Epoch [1/4], Step [3832/3844], Loss: 0.1263\n",
      "Epoch [1/4], Step [3833/3844], Loss: 0.1307\n",
      "Epoch [1/4], Step [3834/3844], Loss: 0.1553\n",
      "Epoch [1/4], Step [3835/3844], Loss: 0.1241\n",
      "Epoch [1/4], Step [3836/3844], Loss: 0.1570\n",
      "Epoch [1/4], Step [3837/3844], Loss: 0.1368\n",
      "Epoch [1/4], Step [3838/3844], Loss: 0.1646\n",
      "Epoch [1/4], Step [3839/3844], Loss: 0.1297\n",
      "Epoch [1/4], Step [3840/3844], Loss: 0.2192\n",
      "Epoch [1/4], Step [3841/3844], Loss: 0.1473\n",
      "Epoch [1/4], Step [3842/3844], Loss: 0.1495\n",
      "Epoch [1/4], Step [3843/3844], Loss: 0.1371\n",
      "\n",
      "train-loss: 0.1868,\n",
      "Validation [1/4], Step [0/379], Loss: 0.0999\n",
      "Validation [1/4], Step [1/379], Loss: 0.0988\n",
      "Validation [1/4], Step [2/379], Loss: 0.1186\n",
      "Validation [1/4], Step [3/379], Loss: 0.1089\n",
      "Validation [1/4], Step [4/379], Loss: 0.1221\n",
      "Validation [1/4], Step [5/379], Loss: 0.0977\n",
      "Validation [1/4], Step [6/379], Loss: 0.1026\n",
      "Validation [1/4], Step [7/379], Loss: 0.1042\n",
      "Validation [1/4], Step [8/379], Loss: 0.1195\n",
      "Validation [1/4], Step [9/379], Loss: 0.1050\n",
      "Validation [1/4], Step [10/379], Loss: 0.1063\n",
      "Validation [1/4], Step [11/379], Loss: 0.1022\n",
      "Validation [1/4], Step [12/379], Loss: 0.1034\n",
      "Validation [1/4], Step [13/379], Loss: 0.1150\n",
      "Validation [1/4], Step [14/379], Loss: 0.0977\n",
      "Validation [1/4], Step [15/379], Loss: 0.1206\n",
      "Validation [1/4], Step [16/379], Loss: 0.1087\n",
      "Validation [1/4], Step [17/379], Loss: 0.1068\n",
      "Validation [1/4], Step [18/379], Loss: 0.0932\n",
      "Validation [1/4], Step [19/379], Loss: 0.1234\n",
      "Validation [1/4], Step [20/379], Loss: 0.0989\n",
      "Validation [1/4], Step [21/379], Loss: 0.1065\n",
      "Validation [1/4], Step [22/379], Loss: 0.1168\n",
      "Validation [1/4], Step [23/379], Loss: 0.1065\n",
      "Validation [1/4], Step [24/379], Loss: 0.1043\n",
      "Validation [1/4], Step [25/379], Loss: 0.0947\n",
      "Validation [1/4], Step [26/379], Loss: 0.0905\n",
      "Validation [1/4], Step [27/379], Loss: 0.1091\n",
      "Validation [1/4], Step [28/379], Loss: 0.1038\n",
      "Validation [1/4], Step [29/379], Loss: 0.1091\n",
      "Validation [1/4], Step [30/379], Loss: 0.1038\n",
      "Validation [1/4], Step [31/379], Loss: 0.1050\n",
      "Validation [1/4], Step [32/379], Loss: 0.1020\n",
      "Validation [1/4], Step [33/379], Loss: 0.1158\n",
      "Validation [1/4], Step [34/379], Loss: 0.1138\n",
      "Validation [1/4], Step [35/379], Loss: 0.1148\n",
      "Validation [1/4], Step [36/379], Loss: 0.1004\n",
      "Validation [1/4], Step [37/379], Loss: 0.0991\n",
      "Validation [1/4], Step [38/379], Loss: 0.0978\n",
      "Validation [1/4], Step [39/379], Loss: 0.1157\n",
      "Validation [1/4], Step [40/379], Loss: 0.1113\n",
      "Validation [1/4], Step [41/379], Loss: 0.1012\n",
      "Validation [1/4], Step [42/379], Loss: 0.0933\n",
      "Validation [1/4], Step [43/379], Loss: 0.1072\n",
      "Validation [1/4], Step [44/379], Loss: 0.0945\n",
      "Validation [1/4], Step [45/379], Loss: 0.1130\n",
      "Validation [1/4], Step [46/379], Loss: 0.1168\n",
      "Validation [1/4], Step [47/379], Loss: 0.1252\n",
      "Validation [1/4], Step [48/379], Loss: 0.1151\n",
      "Validation [1/4], Step [49/379], Loss: 0.0925\n",
      "Validation [1/4], Step [50/379], Loss: 0.0943\n",
      "Validation [1/4], Step [51/379], Loss: 0.1224\n",
      "Validation [1/4], Step [52/379], Loss: 0.1163\n",
      "Validation [1/4], Step [53/379], Loss: 0.0862\n",
      "Validation [1/4], Step [54/379], Loss: 0.1108\n",
      "Validation [1/4], Step [55/379], Loss: 0.1114\n",
      "Validation [1/4], Step [56/379], Loss: 0.1080\n",
      "Validation [1/4], Step [57/379], Loss: 0.1056\n",
      "Validation [1/4], Step [58/379], Loss: 0.1040\n",
      "Validation [1/4], Step [59/379], Loss: 0.1082\n",
      "Validation [1/4], Step [60/379], Loss: 0.1051\n",
      "Validation [1/4], Step [61/379], Loss: 0.1089\n",
      "Validation [1/4], Step [62/379], Loss: 0.0999\n",
      "Validation [1/4], Step [63/379], Loss: 0.1008\n",
      "Validation [1/4], Step [64/379], Loss: 0.0973\n",
      "Validation [1/4], Step [65/379], Loss: 0.1048\n",
      "Validation [1/4], Step [66/379], Loss: 0.0986\n",
      "Validation [1/4], Step [67/379], Loss: 0.1039\n",
      "Validation [1/4], Step [68/379], Loss: 0.1150\n",
      "Validation [1/4], Step [69/379], Loss: 0.1076\n",
      "Validation [1/4], Step [70/379], Loss: 0.0948\n",
      "Validation [1/4], Step [71/379], Loss: 0.1180\n",
      "Validation [1/4], Step [72/379], Loss: 0.1177\n",
      "Validation [1/4], Step [73/379], Loss: 0.1035\n",
      "Validation [1/4], Step [74/379], Loss: 0.0942\n",
      "Validation [1/4], Step [75/379], Loss: 0.1081\n",
      "Validation [1/4], Step [76/379], Loss: 0.1044\n",
      "Validation [1/4], Step [77/379], Loss: 0.1099\n",
      "Validation [1/4], Step [78/379], Loss: 0.0924\n",
      "Validation [1/4], Step [79/379], Loss: 0.1194\n",
      "Validation [1/4], Step [80/379], Loss: 0.0989\n",
      "Validation [1/4], Step [81/379], Loss: 0.1109\n",
      "Validation [1/4], Step [82/379], Loss: 0.1111\n",
      "Validation [1/4], Step [83/379], Loss: 0.0942\n",
      "Validation [1/4], Step [84/379], Loss: 0.1101\n",
      "Validation [1/4], Step [85/379], Loss: 0.1001\n",
      "Validation [1/4], Step [86/379], Loss: 0.1047\n",
      "Validation [1/4], Step [87/379], Loss: 0.1128\n",
      "Validation [1/4], Step [88/379], Loss: 0.1116\n",
      "Validation [1/4], Step [89/379], Loss: 0.1275\n",
      "Validation [1/4], Step [90/379], Loss: 0.0982\n",
      "Validation [1/4], Step [91/379], Loss: 0.1057\n",
      "Validation [1/4], Step [92/379], Loss: 0.1177\n",
      "Validation [1/4], Step [93/379], Loss: 0.1052\n",
      "Validation [1/4], Step [94/379], Loss: 0.1106\n",
      "Validation [1/4], Step [95/379], Loss: 0.1080\n",
      "Validation [1/4], Step [96/379], Loss: 0.0928\n",
      "Validation [1/4], Step [97/379], Loss: 0.0926\n",
      "Validation [1/4], Step [98/379], Loss: 0.1026\n",
      "Validation [1/4], Step [99/379], Loss: 0.1083\n",
      "Validation [1/4], Step [100/379], Loss: 0.1047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation [1/4], Step [101/379], Loss: 0.1126\n",
      "Validation [1/4], Step [102/379], Loss: 0.1297\n",
      "Validation [1/4], Step [103/379], Loss: 0.1106\n",
      "Validation [1/4], Step [104/379], Loss: 0.1028\n",
      "Validation [1/4], Step [105/379], Loss: 0.1008\n",
      "Validation [1/4], Step [106/379], Loss: 0.1011\n",
      "Validation [1/4], Step [107/379], Loss: 0.1116\n",
      "Validation [1/4], Step [108/379], Loss: 0.1010\n",
      "Validation [1/4], Step [109/379], Loss: 0.0877\n",
      "Validation [1/4], Step [110/379], Loss: 0.1209\n",
      "Validation [1/4], Step [111/379], Loss: 0.1297\n",
      "Validation [1/4], Step [112/379], Loss: 0.1004\n",
      "Validation [1/4], Step [113/379], Loss: 0.1166\n",
      "Validation [1/4], Step [114/379], Loss: 0.1226\n",
      "Validation [1/4], Step [115/379], Loss: 0.1025\n",
      "Validation [1/4], Step [116/379], Loss: 0.1023\n",
      "Validation [1/4], Step [117/379], Loss: 0.1139\n",
      "Validation [1/4], Step [118/379], Loss: 0.0941\n",
      "Validation [1/4], Step [119/379], Loss: 0.0939\n",
      "Validation [1/4], Step [120/379], Loss: 0.1052\n",
      "Validation [1/4], Step [121/379], Loss: 0.1202\n",
      "Validation [1/4], Step [122/379], Loss: 0.1047\n",
      "Validation [1/4], Step [123/379], Loss: 0.1006\n",
      "Validation [1/4], Step [124/379], Loss: 0.1021\n",
      "Validation [1/4], Step [125/379], Loss: 0.1344\n",
      "Validation [1/4], Step [126/379], Loss: 0.1107\n",
      "Validation [1/4], Step [127/379], Loss: 0.1062\n",
      "Validation [1/4], Step [128/379], Loss: 0.1169\n",
      "Validation [1/4], Step [129/379], Loss: 0.1064\n",
      "Validation [1/4], Step [130/379], Loss: 0.1249\n",
      "Validation [1/4], Step [131/379], Loss: 0.1126\n",
      "Validation [1/4], Step [132/379], Loss: 0.1124\n",
      "Validation [1/4], Step [133/379], Loss: 0.0935\n",
      "Validation [1/4], Step [134/379], Loss: 0.1012\n",
      "Validation [1/4], Step [135/379], Loss: 0.0984\n",
      "Validation [1/4], Step [136/379], Loss: 0.0882\n",
      "Validation [1/4], Step [137/379], Loss: 0.0972\n",
      "Validation [1/4], Step [138/379], Loss: 0.0949\n",
      "Validation [1/4], Step [139/379], Loss: 0.1028\n",
      "Validation [1/4], Step [140/379], Loss: 0.1073\n",
      "Validation [1/4], Step [141/379], Loss: 0.1208\n",
      "Validation [1/4], Step [142/379], Loss: 0.1041\n",
      "Validation [1/4], Step [143/379], Loss: 0.1074\n",
      "Validation [1/4], Step [144/379], Loss: 0.0936\n",
      "Validation [1/4], Step [145/379], Loss: 0.1145\n",
      "Validation [1/4], Step [146/379], Loss: 0.1162\n",
      "Validation [1/4], Step [147/379], Loss: 0.1272\n",
      "Validation [1/4], Step [148/379], Loss: 0.1078\n",
      "Validation [1/4], Step [149/379], Loss: 0.1021\n",
      "Validation [1/4], Step [150/379], Loss: 0.0908\n",
      "Validation [1/4], Step [151/379], Loss: 0.1118\n",
      "Validation [1/4], Step [152/379], Loss: 0.1052\n",
      "Validation [1/4], Step [153/379], Loss: 0.0913\n",
      "Validation [1/4], Step [154/379], Loss: 0.1171\n",
      "Validation [1/4], Step [155/379], Loss: 0.1081\n",
      "Validation [1/4], Step [156/379], Loss: 0.1270\n",
      "Validation [1/4], Step [157/379], Loss: 0.1033\n",
      "Validation [1/4], Step [158/379], Loss: 0.0994\n",
      "Validation [1/4], Step [159/379], Loss: 0.1073\n",
      "Validation [1/4], Step [160/379], Loss: 0.1060\n",
      "Validation [1/4], Step [161/379], Loss: 0.1150\n",
      "Validation [1/4], Step [162/379], Loss: 0.0972\n",
      "Validation [1/4], Step [163/379], Loss: 0.1037\n",
      "Validation [1/4], Step [164/379], Loss: 0.1044\n",
      "Validation [1/4], Step [165/379], Loss: 0.0952\n",
      "Validation [1/4], Step [166/379], Loss: 0.1228\n",
      "Validation [1/4], Step [167/379], Loss: 0.1123\n",
      "Validation [1/4], Step [168/379], Loss: 0.1112\n",
      "Validation [1/4], Step [169/379], Loss: 0.0996\n",
      "Validation [1/4], Step [170/379], Loss: 0.1030\n",
      "Validation [1/4], Step [171/379], Loss: 0.1076\n",
      "Validation [1/4], Step [172/379], Loss: 0.1231\n",
      "Validation [1/4], Step [173/379], Loss: 0.1092\n",
      "Validation [1/4], Step [174/379], Loss: 0.1168\n",
      "Validation [1/4], Step [175/379], Loss: 0.1077\n",
      "Validation [1/4], Step [176/379], Loss: 0.1061\n",
      "Validation [1/4], Step [177/379], Loss: 0.1128\n",
      "Validation [1/4], Step [178/379], Loss: 0.1036\n",
      "Validation [1/4], Step [179/379], Loss: 0.0938\n",
      "Validation [1/4], Step [180/379], Loss: 0.1102\n",
      "Validation [1/4], Step [181/379], Loss: 0.1038\n",
      "Validation [1/4], Step [182/379], Loss: 0.1046\n",
      "Validation [1/4], Step [183/379], Loss: 0.1019\n",
      "Validation [1/4], Step [184/379], Loss: 0.1196\n",
      "Validation [1/4], Step [185/379], Loss: 0.1130\n",
      "Validation [1/4], Step [186/379], Loss: 0.0960\n",
      "Validation [1/4], Step [187/379], Loss: 0.0999\n",
      "Validation [1/4], Step [188/379], Loss: 0.1055\n",
      "Validation [1/4], Step [189/379], Loss: 0.1066\n",
      "Validation [1/4], Step [190/379], Loss: 0.1107\n",
      "Validation [1/4], Step [191/379], Loss: 0.1049\n",
      "Validation [1/4], Step [192/379], Loss: 0.1014\n",
      "Validation [1/4], Step [193/379], Loss: 0.1188\n",
      "Validation [1/4], Step [194/379], Loss: 0.1088\n",
      "Validation [1/4], Step [195/379], Loss: 0.1156\n",
      "Validation [1/4], Step [196/379], Loss: 0.1134\n",
      "Validation [1/4], Step [197/379], Loss: 0.1076\n",
      "Validation [1/4], Step [198/379], Loss: 0.1099\n",
      "Validation [1/4], Step [199/379], Loss: 0.0922\n",
      "Validation [1/4], Step [200/379], Loss: 0.1126\n",
      "Validation [1/4], Step [201/379], Loss: 0.0977\n",
      "Validation [1/4], Step [202/379], Loss: 0.1074\n",
      "Validation [1/4], Step [203/379], Loss: 0.1042\n",
      "Validation [1/4], Step [204/379], Loss: 0.1065\n",
      "Validation [1/4], Step [205/379], Loss: 0.1188\n",
      "Validation [1/4], Step [206/379], Loss: 0.1090\n",
      "Validation [1/4], Step [207/379], Loss: 0.1165\n",
      "Validation [1/4], Step [208/379], Loss: 0.1064\n",
      "Validation [1/4], Step [209/379], Loss: 0.1023\n",
      "Validation [1/4], Step [210/379], Loss: 0.1126\n",
      "Validation [1/4], Step [211/379], Loss: 0.0963\n",
      "Validation [1/4], Step [212/379], Loss: 0.1132\n",
      "Validation [1/4], Step [213/379], Loss: 0.1117\n",
      "Validation [1/4], Step [214/379], Loss: 0.1080\n",
      "Validation [1/4], Step [215/379], Loss: 0.0929\n",
      "Validation [1/4], Step [216/379], Loss: 0.1127\n",
      "Validation [1/4], Step [217/379], Loss: 0.1115\n",
      "Validation [1/4], Step [218/379], Loss: 0.1229\n",
      "Validation [1/4], Step [219/379], Loss: 0.1149\n",
      "Validation [1/4], Step [220/379], Loss: 0.1058\n",
      "Validation [1/4], Step [221/379], Loss: 0.0987\n",
      "Validation [1/4], Step [222/379], Loss: 0.1080\n",
      "Validation [1/4], Step [223/379], Loss: 0.1004\n",
      "Validation [1/4], Step [224/379], Loss: 0.0972\n",
      "Validation [1/4], Step [225/379], Loss: 0.1036\n",
      "Validation [1/4], Step [226/379], Loss: 0.1042\n",
      "Validation [1/4], Step [227/379], Loss: 0.1015\n",
      "Validation [1/4], Step [228/379], Loss: 0.1272\n",
      "Validation [1/4], Step [229/379], Loss: 0.1022\n",
      "Validation [1/4], Step [230/379], Loss: 0.1049\n",
      "Validation [1/4], Step [231/379], Loss: 0.1020\n",
      "Validation [1/4], Step [232/379], Loss: 0.1040\n",
      "Validation [1/4], Step [233/379], Loss: 0.1225\n",
      "Validation [1/4], Step [234/379], Loss: 0.1229\n",
      "Validation [1/4], Step [235/379], Loss: 0.0959\n",
      "Validation [1/4], Step [236/379], Loss: 0.1198\n",
      "Validation [1/4], Step [237/379], Loss: 0.1010\n",
      "Validation [1/4], Step [238/379], Loss: 0.1124\n",
      "Validation [1/4], Step [239/379], Loss: 0.1204\n",
      "Validation [1/4], Step [240/379], Loss: 0.0957\n",
      "Validation [1/4], Step [241/379], Loss: 0.0924\n",
      "Validation [1/4], Step [242/379], Loss: 0.1274\n",
      "Validation [1/4], Step [243/379], Loss: 0.1059\n",
      "Validation [1/4], Step [244/379], Loss: 0.1010\n",
      "Validation [1/4], Step [245/379], Loss: 0.0999\n",
      "Validation [1/4], Step [246/379], Loss: 0.1108\n",
      "Validation [1/4], Step [247/379], Loss: 0.0983\n",
      "Validation [1/4], Step [248/379], Loss: 0.1168\n",
      "Validation [1/4], Step [249/379], Loss: 0.1048\n",
      "Validation [1/4], Step [250/379], Loss: 0.1244\n",
      "Validation [1/4], Step [251/379], Loss: 0.1108\n",
      "Validation [1/4], Step [252/379], Loss: 0.1188\n",
      "Validation [1/4], Step [253/379], Loss: 0.0999\n",
      "Validation [1/4], Step [254/379], Loss: 0.0956\n",
      "Validation [1/4], Step [255/379], Loss: 0.1210\n",
      "Validation [1/4], Step [256/379], Loss: 0.1090\n",
      "Validation [1/4], Step [257/379], Loss: 0.1126\n",
      "Validation [1/4], Step [258/379], Loss: 0.1142\n",
      "Validation [1/4], Step [259/379], Loss: 0.1024\n",
      "Validation [1/4], Step [260/379], Loss: 0.1252\n",
      "Validation [1/4], Step [261/379], Loss: 0.0926\n",
      "Validation [1/4], Step [262/379], Loss: 0.1065\n",
      "Validation [1/4], Step [263/379], Loss: 0.0923\n",
      "Validation [1/4], Step [264/379], Loss: 0.0912\n",
      "Validation [1/4], Step [265/379], Loss: 0.0977\n",
      "Validation [1/4], Step [266/379], Loss: 0.1110\n",
      "Validation [1/4], Step [267/379], Loss: 0.1034\n",
      "Validation [1/4], Step [268/379], Loss: 0.1071\n",
      "Validation [1/4], Step [269/379], Loss: 0.1106\n",
      "Validation [1/4], Step [270/379], Loss: 0.1138\n",
      "Validation [1/4], Step [271/379], Loss: 0.1060\n",
      "Validation [1/4], Step [272/379], Loss: 0.1021\n",
      "Validation [1/4], Step [273/379], Loss: 0.1066\n",
      "Validation [1/4], Step [274/379], Loss: 0.1264\n",
      "Validation [1/4], Step [275/379], Loss: 0.1191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation [1/4], Step [276/379], Loss: 0.1093\n",
      "Validation [1/4], Step [277/379], Loss: 0.1023\n",
      "Validation [1/4], Step [278/379], Loss: 0.1089\n",
      "Validation [1/4], Step [279/379], Loss: 0.0951\n",
      "Validation [1/4], Step [280/379], Loss: 0.0970\n",
      "Validation [1/4], Step [281/379], Loss: 0.1150\n",
      "Validation [1/4], Step [282/379], Loss: 0.1030\n",
      "Validation [1/4], Step [283/379], Loss: 0.1019\n",
      "Validation [1/4], Step [284/379], Loss: 0.1003\n",
      "Validation [1/4], Step [285/379], Loss: 0.1119\n",
      "Validation [1/4], Step [286/379], Loss: 0.1065\n",
      "Validation [1/4], Step [287/379], Loss: 0.1168\n",
      "Validation [1/4], Step [288/379], Loss: 0.1079\n",
      "Validation [1/4], Step [289/379], Loss: 0.1154\n",
      "Validation [1/4], Step [290/379], Loss: 0.1080\n",
      "Validation [1/4], Step [291/379], Loss: 0.1206\n",
      "Validation [1/4], Step [292/379], Loss: 0.1015\n",
      "Validation [1/4], Step [293/379], Loss: 0.1038\n",
      "Validation [1/4], Step [294/379], Loss: 0.1156\n",
      "Validation [1/4], Step [295/379], Loss: 0.1060\n",
      "Validation [1/4], Step [296/379], Loss: 0.1139\n",
      "Validation [1/4], Step [297/379], Loss: 0.1025\n",
      "Validation [1/4], Step [298/379], Loss: 0.1067\n",
      "Validation [1/4], Step [299/379], Loss: 0.1120\n",
      "Validation [1/4], Step [300/379], Loss: 0.1023\n",
      "Validation [1/4], Step [301/379], Loss: 0.1131\n",
      "Validation [1/4], Step [302/379], Loss: 0.1060\n",
      "Validation [1/4], Step [303/379], Loss: 0.0968\n",
      "Validation [1/4], Step [304/379], Loss: 0.1125\n",
      "Validation [1/4], Step [305/379], Loss: 0.1117\n",
      "Validation [1/4], Step [306/379], Loss: 0.1032\n",
      "Validation [1/4], Step [307/379], Loss: 0.1169\n",
      "Validation [1/4], Step [308/379], Loss: 0.0988\n",
      "Validation [1/4], Step [309/379], Loss: 0.0935\n",
      "Validation [1/4], Step [310/379], Loss: 0.1086\n",
      "Validation [1/4], Step [311/379], Loss: 0.0957\n",
      "Validation [1/4], Step [312/379], Loss: 0.1112\n",
      "Validation [1/4], Step [313/379], Loss: 0.1116\n",
      "Validation [1/4], Step [314/379], Loss: 0.0934\n",
      "Validation [1/4], Step [315/379], Loss: 0.1041\n",
      "Validation [1/4], Step [316/379], Loss: 0.1092\n",
      "Validation [1/4], Step [317/379], Loss: 0.1082\n",
      "Validation [1/4], Step [318/379], Loss: 0.1034\n",
      "Validation [1/4], Step [319/379], Loss: 0.1203\n",
      "Validation [1/4], Step [320/379], Loss: 0.0937\n",
      "Validation [1/4], Step [321/379], Loss: 0.1052\n",
      "Validation [1/4], Step [322/379], Loss: 0.1065\n",
      "Validation [1/4], Step [323/379], Loss: 0.1038\n",
      "Validation [1/4], Step [324/379], Loss: 0.1015\n",
      "Validation [1/4], Step [325/379], Loss: 0.1131\n",
      "Validation [1/4], Step [326/379], Loss: 0.1039\n",
      "Validation [1/4], Step [327/379], Loss: 0.0943\n",
      "Validation [1/4], Step [328/379], Loss: 0.1086\n",
      "Validation [1/4], Step [329/379], Loss: 0.0959\n",
      "Validation [1/4], Step [330/379], Loss: 0.0965\n",
      "Validation [1/4], Step [331/379], Loss: 0.1065\n",
      "Validation [1/4], Step [332/379], Loss: 0.1139\n",
      "Validation [1/4], Step [333/379], Loss: 0.1092\n",
      "Validation [1/4], Step [334/379], Loss: 0.1179\n",
      "Validation [1/4], Step [335/379], Loss: 0.1121\n",
      "Validation [1/4], Step [336/379], Loss: 0.1168\n",
      "Validation [1/4], Step [337/379], Loss: 0.0918\n",
      "Validation [1/4], Step [338/379], Loss: 0.1037\n",
      "Validation [1/4], Step [339/379], Loss: 0.0970\n",
      "Validation [1/4], Step [340/379], Loss: 0.1074\n",
      "Validation [1/4], Step [341/379], Loss: 0.0950\n",
      "Validation [1/4], Step [342/379], Loss: 0.1110\n",
      "Validation [1/4], Step [343/379], Loss: 0.1228\n",
      "Validation [1/4], Step [344/379], Loss: 0.1037\n",
      "Validation [1/4], Step [345/379], Loss: 0.1143\n",
      "Validation [1/4], Step [346/379], Loss: 0.1084\n",
      "Validation [1/4], Step [347/379], Loss: 0.0965\n",
      "Validation [1/4], Step [348/379], Loss: 0.0965\n",
      "Validation [1/4], Step [349/379], Loss: 0.1047\n",
      "Validation [1/4], Step [350/379], Loss: 0.1323\n",
      "Validation [1/4], Step [351/379], Loss: 0.1174\n",
      "Validation [1/4], Step [352/379], Loss: 0.1208\n",
      "Validation [1/4], Step [353/379], Loss: 0.1146\n",
      "Validation [1/4], Step [354/379], Loss: 0.0916\n",
      "Validation [1/4], Step [355/379], Loss: 0.0956\n",
      "Validation [1/4], Step [356/379], Loss: 0.1079\n",
      "Validation [1/4], Step [357/379], Loss: 0.1139\n",
      "Validation [1/4], Step [358/379], Loss: 0.1172\n",
      "Validation [1/4], Step [359/379], Loss: 0.0990\n",
      "Validation [1/4], Step [360/379], Loss: 0.1187\n",
      "Validation [1/4], Step [361/379], Loss: 0.1272\n",
      "Validation [1/4], Step [362/379], Loss: 0.1085\n",
      "Validation [1/4], Step [363/379], Loss: 0.0979\n",
      "Validation [1/4], Step [364/379], Loss: 0.1107\n",
      "Validation [1/4], Step [365/379], Loss: 0.1140\n",
      "Validation [1/4], Step [366/379], Loss: 0.1064\n",
      "Validation [1/4], Step [367/379], Loss: 0.1279\n",
      "Validation [1/4], Step [368/379], Loss: 0.1102\n",
      "Validation [1/4], Step [369/379], Loss: 0.1052\n",
      "Validation [1/4], Step [370/379], Loss: 0.1070\n",
      "Validation [1/4], Step [371/379], Loss: 0.1092\n",
      "Validation [1/4], Step [372/379], Loss: 0.1128\n",
      "Validation [1/4], Step [373/379], Loss: 0.1236\n",
      "Validation [1/4], Step [374/379], Loss: 0.1070\n",
      "Validation [1/4], Step [375/379], Loss: 0.0927\n",
      "Validation [1/4], Step [376/379], Loss: 0.0983\n",
      "Validation [1/4], Step [377/379], Loss: 0.1206\n",
      "Validation [1/4], Step [378/379], Loss: 0.1064\n",
      "validation loss: 0.1073, \n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 2\n",
      "\n",
      "Epoch [2/4], Step [0/3844], Loss: 0.1490\n",
      "Epoch [2/4], Step [1/3844], Loss: 0.1405\n",
      "Epoch [2/4], Step [2/3844], Loss: 0.1104\n",
      "Epoch [2/4], Step [3/3844], Loss: 0.1462\n",
      "Epoch [2/4], Step [4/3844], Loss: 0.1495\n",
      "Epoch [2/4], Step [5/3844], Loss: 0.1558\n",
      "Epoch [2/4], Step [6/3844], Loss: 0.2134\n",
      "Epoch [2/4], Step [7/3844], Loss: 0.1660\n",
      "Epoch [2/4], Step [8/3844], Loss: 0.1617\n",
      "Epoch [2/4], Step [9/3844], Loss: 0.1345\n",
      "Epoch [2/4], Step [10/3844], Loss: 0.1497\n",
      "Epoch [2/4], Step [11/3844], Loss: 0.1361\n",
      "Epoch [2/4], Step [12/3844], Loss: 0.2226\n",
      "Epoch [2/4], Step [13/3844], Loss: 0.1238\n",
      "Epoch [2/4], Step [14/3844], Loss: 0.1171\n",
      "Epoch [2/4], Step [15/3844], Loss: 0.2333\n",
      "Epoch [2/4], Step [16/3844], Loss: 0.2251\n",
      "Epoch [2/4], Step [17/3844], Loss: 0.1687\n",
      "Epoch [2/4], Step [18/3844], Loss: 0.1381\n",
      "Epoch [2/4], Step [19/3844], Loss: 0.1651\n",
      "Epoch [2/4], Step [20/3844], Loss: 0.1299\n",
      "Epoch [2/4], Step [21/3844], Loss: 0.1509\n",
      "Epoch [2/4], Step [22/3844], Loss: 0.1508\n",
      "Epoch [2/4], Step [23/3844], Loss: 0.2471\n",
      "Epoch [2/4], Step [24/3844], Loss: 0.1354\n",
      "Epoch [2/4], Step [25/3844], Loss: 0.1082\n",
      "Epoch [2/4], Step [26/3844], Loss: 0.1581\n",
      "Epoch [2/4], Step [27/3844], Loss: 0.1400\n",
      "Epoch [2/4], Step [28/3844], Loss: 0.1158\n",
      "Epoch [2/4], Step [29/3844], Loss: 0.1819\n",
      "Epoch [2/4], Step [30/3844], Loss: 0.1293\n",
      "Epoch [2/4], Step [31/3844], Loss: 0.1012\n",
      "Epoch [2/4], Step [32/3844], Loss: 0.1880\n",
      "Epoch [2/4], Step [33/3844], Loss: 0.1187\n",
      "Epoch [2/4], Step [34/3844], Loss: 0.1365\n",
      "Epoch [2/4], Step [35/3844], Loss: 0.1410\n",
      "Epoch [2/4], Step [36/3844], Loss: 0.1474\n",
      "Epoch [2/4], Step [37/3844], Loss: 0.1479\n",
      "Epoch [2/4], Step [38/3844], Loss: 0.1197\n",
      "Epoch [2/4], Step [39/3844], Loss: 0.1448\n",
      "Epoch [2/4], Step [40/3844], Loss: 0.1386\n",
      "Epoch [2/4], Step [41/3844], Loss: 0.1416\n",
      "Epoch [2/4], Step [42/3844], Loss: 0.1440\n",
      "Epoch [2/4], Step [43/3844], Loss: 0.1373\n",
      "Epoch [2/4], Step [44/3844], Loss: 0.1721\n",
      "Epoch [2/4], Step [45/3844], Loss: 0.1179\n",
      "Epoch [2/4], Step [46/3844], Loss: 0.1476\n",
      "Epoch [2/4], Step [47/3844], Loss: 0.1349\n",
      "Epoch [2/4], Step [48/3844], Loss: 0.1266\n",
      "Epoch [2/4], Step [49/3844], Loss: 0.1195\n",
      "Epoch [2/4], Step [50/3844], Loss: 0.2056\n",
      "Epoch [2/4], Step [51/3844], Loss: 0.1272\n",
      "Epoch [2/4], Step [52/3844], Loss: 0.1489\n",
      "Epoch [2/4], Step [53/3844], Loss: 0.2059\n",
      "Epoch [2/4], Step [54/3844], Loss: 0.2270\n",
      "Epoch [2/4], Step [55/3844], Loss: 0.1579\n",
      "Epoch [2/4], Step [56/3844], Loss: 0.1432\n",
      "Epoch [2/4], Step [57/3844], Loss: 0.1629\n",
      "Epoch [2/4], Step [58/3844], Loss: 0.0912\n",
      "Epoch [2/4], Step [59/3844], Loss: 0.1315\n",
      "Epoch [2/4], Step [60/3844], Loss: 0.1297\n",
      "Epoch [2/4], Step [61/3844], Loss: 0.1329\n",
      "Epoch [2/4], Step [62/3844], Loss: 0.1256\n",
      "Epoch [2/4], Step [63/3844], Loss: 0.2289\n",
      "Epoch [2/4], Step [64/3844], Loss: 0.1319\n",
      "Epoch [2/4], Step [65/3844], Loss: 0.1709\n",
      "Epoch [2/4], Step [66/3844], Loss: 0.1153\n",
      "Epoch [2/4], Step [67/3844], Loss: 0.2251\n",
      "Epoch [2/4], Step [68/3844], Loss: 0.2092\n",
      "Epoch [2/4], Step [69/3844], Loss: 0.1173\n",
      "Epoch [2/4], Step [70/3844], Loss: 0.1232\n",
      "Epoch [2/4], Step [71/3844], Loss: 0.1276\n",
      "Epoch [2/4], Step [72/3844], Loss: 0.1292\n",
      "Epoch [2/4], Step [73/3844], Loss: 0.1413\n",
      "Epoch [2/4], Step [74/3844], Loss: 0.1052\n",
      "Epoch [2/4], Step [75/3844], Loss: 0.1297\n",
      "Epoch [2/4], Step [76/3844], Loss: 0.1105\n",
      "Epoch [2/4], Step [77/3844], Loss: 0.1148\n",
      "Epoch [2/4], Step [78/3844], Loss: 0.1402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/4], Step [79/3844], Loss: 0.1697\n",
      "Epoch [2/4], Step [80/3844], Loss: 0.1241\n",
      "Epoch [2/4], Step [81/3844], Loss: 0.1685\n",
      "Epoch [2/4], Step [82/3844], Loss: 0.1238\n",
      "Epoch [2/4], Step [83/3844], Loss: 0.1809\n",
      "Epoch [2/4], Step [84/3844], Loss: 0.1218\n",
      "Epoch [2/4], Step [85/3844], Loss: 0.2324\n",
      "Epoch [2/4], Step [86/3844], Loss: 0.1259\n",
      "Epoch [2/4], Step [87/3844], Loss: 0.2347\n",
      "Epoch [2/4], Step [88/3844], Loss: 0.1195\n",
      "Epoch [2/4], Step [89/3844], Loss: 0.1538\n",
      "Epoch [2/4], Step [90/3844], Loss: 0.1484\n",
      "Epoch [2/4], Step [91/3844], Loss: 0.1564\n",
      "Epoch [2/4], Step [92/3844], Loss: 0.1112\n",
      "Epoch [2/4], Step [93/3844], Loss: 0.1267\n",
      "Epoch [2/4], Step [94/3844], Loss: 0.2318\n",
      "Epoch [2/4], Step [95/3844], Loss: 0.1451\n",
      "Epoch [2/4], Step [96/3844], Loss: 0.1223\n",
      "Epoch [2/4], Step [97/3844], Loss: 0.1220\n",
      "Epoch [2/4], Step [98/3844], Loss: 0.1284\n",
      "Epoch [2/4], Step [99/3844], Loss: 0.2220\n",
      "Epoch [2/4], Step [100/3844], Loss: 0.1262\n",
      "Epoch [2/4], Step [101/3844], Loss: 0.1154\n",
      "Epoch [2/4], Step [102/3844], Loss: 0.1053\n",
      "Epoch [2/4], Step [103/3844], Loss: 0.1350\n",
      "Epoch [2/4], Step [104/3844], Loss: 0.1306\n",
      "Epoch [2/4], Step [105/3844], Loss: 0.0797\n",
      "Epoch [2/4], Step [106/3844], Loss: 0.1011\n",
      "Epoch [2/4], Step [107/3844], Loss: 0.1014\n",
      "Epoch [2/4], Step [108/3844], Loss: 0.1086\n",
      "Epoch [2/4], Step [109/3844], Loss: 0.1639\n",
      "Epoch [2/4], Step [110/3844], Loss: 0.1417\n",
      "Epoch [2/4], Step [111/3844], Loss: 0.1203\n",
      "Epoch [2/4], Step [112/3844], Loss: 0.1346\n",
      "Epoch [2/4], Step [113/3844], Loss: 0.1246\n",
      "Epoch [2/4], Step [114/3844], Loss: 0.1114\n",
      "Epoch [2/4], Step [115/3844], Loss: 0.2072\n",
      "Epoch [2/4], Step [116/3844], Loss: 0.1607\n",
      "Epoch [2/4], Step [117/3844], Loss: 0.1175\n",
      "Epoch [2/4], Step [118/3844], Loss: 0.1397\n",
      "Epoch [2/4], Step [119/3844], Loss: 0.1962\n",
      "Epoch [2/4], Step [120/3844], Loss: 0.1377\n",
      "Epoch [2/4], Step [121/3844], Loss: 0.1677\n",
      "Epoch [2/4], Step [122/3844], Loss: 0.1403\n",
      "Epoch [2/4], Step [123/3844], Loss: 0.2233\n",
      "Epoch [2/4], Step [124/3844], Loss: 0.2075\n",
      "Epoch [2/4], Step [125/3844], Loss: 0.1518\n",
      "Epoch [2/4], Step [126/3844], Loss: 0.1491\n",
      "Epoch [2/4], Step [127/3844], Loss: 0.1593\n",
      "Epoch [2/4], Step [128/3844], Loss: 0.1314\n",
      "Epoch [2/4], Step [129/3844], Loss: 0.1179\n",
      "Epoch [2/4], Step [130/3844], Loss: 0.0997\n",
      "Epoch [2/4], Step [131/3844], Loss: 0.0844\n",
      "Epoch [2/4], Step [132/3844], Loss: 0.1907\n",
      "Epoch [2/4], Step [133/3844], Loss: 0.1094\n",
      "Epoch [2/4], Step [134/3844], Loss: 0.1025\n",
      "Epoch [2/4], Step [135/3844], Loss: 0.1127\n",
      "Epoch [2/4], Step [136/3844], Loss: 0.1093\n",
      "Epoch [2/4], Step [137/3844], Loss: 0.1482\n",
      "Epoch [2/4], Step [138/3844], Loss: 0.1090\n",
      "Epoch [2/4], Step [139/3844], Loss: 0.0927\n",
      "Epoch [2/4], Step [140/3844], Loss: 0.1310\n",
      "Epoch [2/4], Step [141/3844], Loss: 0.1078\n",
      "Epoch [2/4], Step [142/3844], Loss: 0.1762\n",
      "Epoch [2/4], Step [143/3844], Loss: 0.0833\n",
      "Epoch [2/4], Step [144/3844], Loss: 0.1465\n",
      "Epoch [2/4], Step [145/3844], Loss: 0.0851\n",
      "Epoch [2/4], Step [146/3844], Loss: 0.1108\n",
      "Epoch [2/4], Step [147/3844], Loss: 0.1574\n",
      "Epoch [2/4], Step [148/3844], Loss: 0.1336\n",
      "Epoch [2/4], Step [149/3844], Loss: 0.2323\n",
      "Epoch [2/4], Step [150/3844], Loss: 0.1975\n",
      "Epoch [2/4], Step [151/3844], Loss: 0.1306\n",
      "Epoch [2/4], Step [152/3844], Loss: 0.1023\n",
      "Epoch [2/4], Step [153/3844], Loss: 0.1333\n",
      "Epoch [2/4], Step [154/3844], Loss: 0.1998\n",
      "Epoch [2/4], Step [155/3844], Loss: 0.0795\n",
      "Epoch [2/4], Step [156/3844], Loss: 0.1598\n",
      "Epoch [2/4], Step [157/3844], Loss: 0.1131\n",
      "Epoch [2/4], Step [158/3844], Loss: 0.1153\n",
      "Epoch [2/4], Step [159/3844], Loss: 0.1024\n",
      "Epoch [2/4], Step [160/3844], Loss: 0.1045\n",
      "Epoch [2/4], Step [161/3844], Loss: 0.1246\n",
      "Epoch [2/4], Step [162/3844], Loss: 0.2315\n",
      "Epoch [2/4], Step [163/3844], Loss: 0.2125\n",
      "Epoch [2/4], Step [164/3844], Loss: 0.0716\n",
      "Epoch [2/4], Step [165/3844], Loss: 0.1779\n",
      "Epoch [2/4], Step [166/3844], Loss: 0.0950\n",
      "Epoch [2/4], Step [167/3844], Loss: 0.1484\n",
      "Epoch [2/4], Step [168/3844], Loss: 0.1477\n",
      "Epoch [2/4], Step [169/3844], Loss: 0.1090\n",
      "Epoch [2/4], Step [170/3844], Loss: 0.1030\n",
      "Epoch [2/4], Step [171/3844], Loss: 0.0984\n",
      "Epoch [2/4], Step [172/3844], Loss: 0.1450\n",
      "Epoch [2/4], Step [173/3844], Loss: 0.2004\n",
      "Epoch [2/4], Step [174/3844], Loss: 0.2183\n",
      "Epoch [2/4], Step [175/3844], Loss: 0.0819\n",
      "Epoch [2/4], Step [176/3844], Loss: 0.1017\n",
      "Epoch [2/4], Step [177/3844], Loss: 0.1291\n",
      "Epoch [2/4], Step [178/3844], Loss: 0.1358\n",
      "Epoch [2/4], Step [179/3844], Loss: 0.1899\n",
      "Epoch [2/4], Step [180/3844], Loss: 0.0972\n",
      "Epoch [2/4], Step [181/3844], Loss: 0.1010\n",
      "Epoch [2/4], Step [182/3844], Loss: 0.0924\n",
      "Epoch [2/4], Step [183/3844], Loss: 0.1237\n",
      "Epoch [2/4], Step [184/3844], Loss: 0.0849\n",
      "Epoch [2/4], Step [185/3844], Loss: 0.1459\n",
      "Epoch [2/4], Step [186/3844], Loss: 0.1424\n",
      "Epoch [2/4], Step [187/3844], Loss: 0.0698\n",
      "Epoch [2/4], Step [188/3844], Loss: 0.0858\n",
      "Epoch [2/4], Step [189/3844], Loss: 0.1431\n",
      "Epoch [2/4], Step [190/3844], Loss: 0.0784\n",
      "Epoch [2/4], Step [191/3844], Loss: 0.1048\n",
      "Epoch [2/4], Step [192/3844], Loss: 0.0928\n",
      "Epoch [2/4], Step [193/3844], Loss: 0.0780\n",
      "Epoch [2/4], Step [194/3844], Loss: 0.1111\n",
      "Epoch [2/4], Step [195/3844], Loss: 0.0799\n",
      "Epoch [2/4], Step [196/3844], Loss: 0.1030\n",
      "Epoch [2/4], Step [197/3844], Loss: 0.1623\n",
      "Epoch [2/4], Step [198/3844], Loss: 0.0795\n",
      "Epoch [2/4], Step [199/3844], Loss: 0.1440\n",
      "Epoch [2/4], Step [200/3844], Loss: 0.1511\n",
      "Epoch [2/4], Step [201/3844], Loss: 0.2212\n",
      "Epoch [2/4], Step [202/3844], Loss: 0.1380\n",
      "Epoch [2/4], Step [203/3844], Loss: 0.0809\n",
      "Epoch [2/4], Step [204/3844], Loss: 0.0987\n",
      "Epoch [2/4], Step [205/3844], Loss: 0.1407\n",
      "Epoch [2/4], Step [206/3844], Loss: 0.1134\n",
      "Epoch [2/4], Step [207/3844], Loss: 0.1521\n",
      "Epoch [2/4], Step [208/3844], Loss: 0.0598\n",
      "Epoch [2/4], Step [209/3844], Loss: 0.1527\n",
      "Epoch [2/4], Step [210/3844], Loss: 0.0912\n",
      "Epoch [2/4], Step [211/3844], Loss: 0.1237\n",
      "Epoch [2/4], Step [212/3844], Loss: 0.0823\n",
      "Epoch [2/4], Step [213/3844], Loss: 0.1100\n",
      "Epoch [2/4], Step [214/3844], Loss: 0.0947\n",
      "Epoch [2/4], Step [215/3844], Loss: 0.1106\n",
      "Epoch [2/4], Step [216/3844], Loss: 0.0873\n",
      "Epoch [2/4], Step [217/3844], Loss: 0.1371\n",
      "Epoch [2/4], Step [218/3844], Loss: 0.1956\n",
      "Epoch [2/4], Step [219/3844], Loss: 0.0954\n",
      "Epoch [2/4], Step [220/3844], Loss: 0.1904\n",
      "Epoch [2/4], Step [221/3844], Loss: 0.0858\n",
      "Epoch [2/4], Step [222/3844], Loss: 0.2174\n",
      "Epoch [2/4], Step [223/3844], Loss: 0.1275\n",
      "Epoch [2/4], Step [224/3844], Loss: 0.1198\n",
      "Epoch [2/4], Step [225/3844], Loss: 0.2275\n",
      "Epoch [2/4], Step [226/3844], Loss: 0.2052\n",
      "Epoch [2/4], Step [227/3844], Loss: 0.1600\n",
      "Epoch [2/4], Step [228/3844], Loss: 0.1767\n",
      "Epoch [2/4], Step [229/3844], Loss: 0.2023\n",
      "Epoch [2/4], Step [230/3844], Loss: 0.1442\n",
      "Epoch [2/4], Step [231/3844], Loss: 0.0992\n",
      "Epoch [2/4], Step [232/3844], Loss: 0.0771\n",
      "Epoch [2/4], Step [233/3844], Loss: 0.0749\n",
      "Epoch [2/4], Step [234/3844], Loss: 0.2120\n",
      "Epoch [2/4], Step [235/3844], Loss: 0.1535\n",
      "Epoch [2/4], Step [236/3844], Loss: 0.0998\n",
      "Epoch [2/4], Step [237/3844], Loss: 0.1415\n",
      "Epoch [2/4], Step [238/3844], Loss: 0.1220\n",
      "Epoch [2/4], Step [239/3844], Loss: 0.1637\n",
      "Epoch [2/4], Step [240/3844], Loss: 0.1059\n",
      "Epoch [2/4], Step [241/3844], Loss: 0.1446\n",
      "Epoch [2/4], Step [242/3844], Loss: 0.0769\n",
      "Epoch [2/4], Step [243/3844], Loss: 0.1008\n",
      "Epoch [2/4], Step [244/3844], Loss: 0.1917\n",
      "Epoch [2/4], Step [245/3844], Loss: 0.0794\n",
      "Epoch [2/4], Step [246/3844], Loss: 0.2079\n",
      "Epoch [2/4], Step [247/3844], Loss: 0.1377\n",
      "Epoch [2/4], Step [248/3844], Loss: 0.1161\n",
      "Epoch [2/4], Step [249/3844], Loss: 0.1661\n",
      "Epoch [2/4], Step [250/3844], Loss: 0.1682\n",
      "Epoch [2/4], Step [251/3844], Loss: 0.0777\n",
      "Epoch [2/4], Step [252/3844], Loss: 0.1086\n",
      "Epoch [2/4], Step [253/3844], Loss: 0.0837\n",
      "Epoch [2/4], Step [254/3844], Loss: 0.1217\n",
      "Epoch [2/4], Step [255/3844], Loss: 0.1748\n",
      "Epoch [2/4], Step [256/3844], Loss: 0.2172\n",
      "Epoch [2/4], Step [257/3844], Loss: 0.1653\n",
      "Epoch [2/4], Step [258/3844], Loss: 0.2449\n",
      "Epoch [2/4], Step [259/3844], Loss: 0.1642\n",
      "Epoch [2/4], Step [260/3844], Loss: 0.0604\n",
      "Epoch [2/4], Step [261/3844], Loss: 0.1563\n",
      "Epoch [2/4], Step [262/3844], Loss: 0.1363\n",
      "Epoch [2/4], Step [263/3844], Loss: 0.1063\n",
      "Epoch [2/4], Step [264/3844], Loss: 0.1434\n",
      "Epoch [2/4], Step [265/3844], Loss: 0.0698\n",
      "Epoch [2/4], Step [266/3844], Loss: 0.0899\n",
      "Epoch [2/4], Step [267/3844], Loss: 0.1236\n",
      "Epoch [2/4], Step [268/3844], Loss: 0.1211\n",
      "Epoch [2/4], Step [269/3844], Loss: 0.1017\n",
      "Epoch [2/4], Step [270/3844], Loss: 0.0663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/4], Step [271/3844], Loss: 0.1695\n",
      "Epoch [2/4], Step [272/3844], Loss: 0.1052\n",
      "Epoch [2/4], Step [273/3844], Loss: 0.0926\n",
      "Epoch [2/4], Step [274/3844], Loss: 0.2151\n",
      "Epoch [2/4], Step [275/3844], Loss: 0.1250\n",
      "Epoch [2/4], Step [276/3844], Loss: 0.1622\n",
      "Epoch [2/4], Step [277/3844], Loss: 0.0920\n",
      "Epoch [2/4], Step [278/3844], Loss: 0.1141\n",
      "Epoch [2/4], Step [279/3844], Loss: 0.1410\n",
      "Epoch [2/4], Step [280/3844], Loss: 0.1329\n",
      "Epoch [2/4], Step [281/3844], Loss: 0.2314\n",
      "Epoch [2/4], Step [282/3844], Loss: 0.0938\n",
      "Epoch [2/4], Step [283/3844], Loss: 0.1717\n",
      "Epoch [2/4], Step [284/3844], Loss: 0.1224\n",
      "Epoch [2/4], Step [285/3844], Loss: 0.0774\n",
      "Epoch [2/4], Step [286/3844], Loss: 0.0791\n",
      "Epoch [2/4], Step [287/3844], Loss: 0.1043\n",
      "Epoch [2/4], Step [288/3844], Loss: 0.1847\n",
      "Epoch [2/4], Step [289/3844], Loss: 0.0970\n",
      "Epoch [2/4], Step [290/3844], Loss: 0.1615\n",
      "Epoch [2/4], Step [291/3844], Loss: 0.1637\n",
      "Epoch [2/4], Step [292/3844], Loss: 0.1110\n",
      "Epoch [2/4], Step [293/3844], Loss: 0.0870\n",
      "Epoch [2/4], Step [294/3844], Loss: 0.0976\n",
      "Epoch [2/4], Step [295/3844], Loss: 0.0821\n",
      "Epoch [2/4], Step [296/3844], Loss: 0.0711\n",
      "Epoch [2/4], Step [297/3844], Loss: 0.0949\n",
      "Epoch [2/4], Step [298/3844], Loss: 0.1114\n",
      "Epoch [2/4], Step [299/3844], Loss: 0.1293\n",
      "Epoch [2/4], Step [300/3844], Loss: 0.2188\n",
      "Epoch [2/4], Step [301/3844], Loss: 0.1050\n",
      "Epoch [2/4], Step [302/3844], Loss: 0.1473\n",
      "Epoch [2/4], Step [303/3844], Loss: 0.0786\n",
      "Epoch [2/4], Step [304/3844], Loss: 0.1285\n",
      "Epoch [2/4], Step [305/3844], Loss: 0.1834\n",
      "Epoch [2/4], Step [306/3844], Loss: 0.1635\n",
      "Epoch [2/4], Step [307/3844], Loss: 0.1178\n",
      "Epoch [2/4], Step [308/3844], Loss: 0.2335\n",
      "Epoch [2/4], Step [309/3844], Loss: 0.0697\n",
      "Epoch [2/4], Step [310/3844], Loss: 0.1040\n",
      "Epoch [2/4], Step [311/3844], Loss: 0.0962\n",
      "Epoch [2/4], Step [312/3844], Loss: 0.0972\n",
      "Epoch [2/4], Step [313/3844], Loss: 0.0875\n",
      "Epoch [2/4], Step [314/3844], Loss: 0.1056\n",
      "Epoch [2/4], Step [315/3844], Loss: 0.2213\n",
      "Epoch [2/4], Step [316/3844], Loss: 0.0870\n",
      "Epoch [2/4], Step [317/3844], Loss: 0.1086\n",
      "Epoch [2/4], Step [318/3844], Loss: 0.1443\n",
      "Epoch [2/4], Step [319/3844], Loss: 0.0928\n",
      "Epoch [2/4], Step [320/3844], Loss: 0.1223\n",
      "Epoch [2/4], Step [321/3844], Loss: 0.0778\n",
      "Epoch [2/4], Step [322/3844], Loss: 0.0936\n",
      "Epoch [2/4], Step [323/3844], Loss: 0.2143\n",
      "Epoch [2/4], Step [324/3844], Loss: 0.1163\n",
      "Epoch [2/4], Step [325/3844], Loss: 0.2429\n",
      "Epoch [2/4], Step [326/3844], Loss: 0.0787\n",
      "Epoch [2/4], Step [327/3844], Loss: 0.0536\n",
      "Epoch [2/4], Step [328/3844], Loss: 0.1354\n",
      "Epoch [2/4], Step [329/3844], Loss: 0.2267\n",
      "Epoch [2/4], Step [330/3844], Loss: 0.2414\n",
      "Epoch [2/4], Step [331/3844], Loss: 0.1004\n",
      "Epoch [2/4], Step [332/3844], Loss: 0.0975\n",
      "Epoch [2/4], Step [333/3844], Loss: 0.0990\n",
      "Epoch [2/4], Step [334/3844], Loss: 0.1008\n",
      "Epoch [2/4], Step [335/3844], Loss: 0.0922\n",
      "Epoch [2/4], Step [336/3844], Loss: 0.0952\n",
      "Epoch [2/4], Step [337/3844], Loss: 0.1030\n",
      "Epoch [2/4], Step [338/3844], Loss: 0.0925\n",
      "Epoch [2/4], Step [339/3844], Loss: 0.1313\n",
      "Epoch [2/4], Step [340/3844], Loss: 0.0874\n",
      "Epoch [2/4], Step [341/3844], Loss: 0.1363\n",
      "Epoch [2/4], Step [342/3844], Loss: 0.2067\n",
      "Epoch [2/4], Step [343/3844], Loss: 0.0715\n",
      "Epoch [2/4], Step [344/3844], Loss: 0.0854\n",
      "Epoch [2/4], Step [345/3844], Loss: 0.1632\n",
      "Epoch [2/4], Step [346/3844], Loss: 0.1847\n",
      "Epoch [2/4], Step [347/3844], Loss: 0.1196\n",
      "Epoch [2/4], Step [348/3844], Loss: 0.0749\n",
      "Epoch [2/4], Step [349/3844], Loss: 0.0616\n",
      "Epoch [2/4], Step [350/3844], Loss: 0.2300\n",
      "Epoch [2/4], Step [351/3844], Loss: 0.0667\n",
      "Epoch [2/4], Step [352/3844], Loss: 0.1248\n",
      "Epoch [2/4], Step [353/3844], Loss: 0.0847\n",
      "Epoch [2/4], Step [354/3844], Loss: 0.1506\n",
      "Epoch [2/4], Step [355/3844], Loss: 0.0806\n",
      "Epoch [2/4], Step [356/3844], Loss: 0.1399\n",
      "Epoch [2/4], Step [357/3844], Loss: 0.2096\n",
      "Epoch [2/4], Step [358/3844], Loss: 0.2331\n",
      "Epoch [2/4], Step [359/3844], Loss: 0.2288\n",
      "Epoch [2/4], Step [360/3844], Loss: 0.0873\n",
      "Epoch [2/4], Step [361/3844], Loss: 0.0831\n",
      "Epoch [2/4], Step [362/3844], Loss: 0.1351\n",
      "Epoch [2/4], Step [363/3844], Loss: 0.0830\n",
      "Epoch [2/4], Step [364/3844], Loss: 0.2102\n",
      "Epoch [2/4], Step [365/3844], Loss: 0.1048\n",
      "Epoch [2/4], Step [366/3844], Loss: 0.0834\n",
      "Epoch [2/4], Step [367/3844], Loss: 0.1033\n",
      "Epoch [2/4], Step [368/3844], Loss: 0.2328\n",
      "Epoch [2/4], Step [369/3844], Loss: 0.0962\n",
      "Epoch [2/4], Step [370/3844], Loss: 0.1043\n",
      "Epoch [2/4], Step [371/3844], Loss: 0.1868\n",
      "Epoch [2/4], Step [372/3844], Loss: 0.0885\n",
      "Epoch [2/4], Step [373/3844], Loss: 0.0845\n",
      "Epoch [2/4], Step [374/3844], Loss: 0.1391\n",
      "Epoch [2/4], Step [375/3844], Loss: 0.1647\n",
      "Epoch [2/4], Step [376/3844], Loss: 0.1164\n",
      "Epoch [2/4], Step [377/3844], Loss: 0.1569\n",
      "Epoch [2/4], Step [378/3844], Loss: 0.1368\n",
      "Epoch [2/4], Step [379/3844], Loss: 0.2255\n",
      "Epoch [2/4], Step [380/3844], Loss: 0.1424\n",
      "Epoch [2/4], Step [381/3844], Loss: 0.0857\n",
      "Epoch [2/4], Step [382/3844], Loss: 0.2131\n",
      "Epoch [2/4], Step [383/3844], Loss: 0.1957\n",
      "Epoch [2/4], Step [384/3844], Loss: 0.1432\n",
      "Epoch [2/4], Step [385/3844], Loss: 0.0864\n",
      "Epoch [2/4], Step [386/3844], Loss: 0.1050\n",
      "Epoch [2/4], Step [387/3844], Loss: 0.1022\n",
      "Epoch [2/4], Step [388/3844], Loss: 0.0680\n",
      "Epoch [2/4], Step [389/3844], Loss: 0.2135\n",
      "Epoch [2/4], Step [390/3844], Loss: 0.0967\n",
      "Epoch [2/4], Step [391/3844], Loss: 0.1000\n",
      "Epoch [2/4], Step [392/3844], Loss: 0.1015\n",
      "Epoch [2/4], Step [393/3844], Loss: 0.1326\n",
      "Epoch [2/4], Step [394/3844], Loss: 0.1093\n",
      "Epoch [2/4], Step [395/3844], Loss: 0.1743\n",
      "Epoch [2/4], Step [396/3844], Loss: 0.1085\n",
      "Epoch [2/4], Step [397/3844], Loss: 0.1797\n",
      "Epoch [2/4], Step [398/3844], Loss: 0.1631\n",
      "Epoch [2/4], Step [399/3844], Loss: 0.1002\n",
      "Epoch [2/4], Step [400/3844], Loss: 0.0670\n",
      "Epoch [2/4], Step [401/3844], Loss: 0.1139\n",
      "Epoch [2/4], Step [402/3844], Loss: 0.0935\n",
      "Epoch [2/4], Step [403/3844], Loss: 0.1243\n",
      "Epoch [2/4], Step [404/3844], Loss: 0.0928\n",
      "Epoch [2/4], Step [405/3844], Loss: 0.1775\n",
      "Epoch [2/4], Step [406/3844], Loss: 0.1454\n",
      "Epoch [2/4], Step [407/3844], Loss: 0.0819\n",
      "Epoch [2/4], Step [408/3844], Loss: 0.1169\n",
      "Epoch [2/4], Step [409/3844], Loss: 0.1592\n",
      "Epoch [2/4], Step [410/3844], Loss: 0.0827\n",
      "Epoch [2/4], Step [411/3844], Loss: 0.0977\n",
      "Epoch [2/4], Step [412/3844], Loss: 0.1475\n",
      "Epoch [2/4], Step [413/3844], Loss: 0.1492\n",
      "Epoch [2/4], Step [414/3844], Loss: 0.2377\n",
      "Epoch [2/4], Step [415/3844], Loss: 0.1354\n",
      "Epoch [2/4], Step [416/3844], Loss: 0.0967\n",
      "Epoch [2/4], Step [417/3844], Loss: 0.2155\n",
      "Epoch [2/4], Step [418/3844], Loss: 0.1134\n",
      "Epoch [2/4], Step [419/3844], Loss: 0.0805\n",
      "Epoch [2/4], Step [420/3844], Loss: 0.0840\n",
      "Epoch [2/4], Step [421/3844], Loss: 0.1468\n",
      "Epoch [2/4], Step [422/3844], Loss: 0.1024\n",
      "Epoch [2/4], Step [423/3844], Loss: 0.1293\n",
      "Epoch [2/4], Step [424/3844], Loss: 0.1523\n",
      "Epoch [2/4], Step [425/3844], Loss: 0.0640\n",
      "Epoch [2/4], Step [426/3844], Loss: 0.1076\n",
      "Epoch [2/4], Step [427/3844], Loss: 0.2108\n",
      "Epoch [2/4], Step [428/3844], Loss: 0.0928\n",
      "Epoch [2/4], Step [429/3844], Loss: 0.0967\n",
      "Epoch [2/4], Step [430/3844], Loss: 0.1750\n",
      "Epoch [2/4], Step [431/3844], Loss: 0.1063\n",
      "Epoch [2/4], Step [432/3844], Loss: 0.0882\n",
      "Epoch [2/4], Step [433/3844], Loss: 0.0806\n",
      "Epoch [2/4], Step [434/3844], Loss: 0.1468\n",
      "Epoch [2/4], Step [435/3844], Loss: 0.0641\n",
      "Epoch [2/4], Step [436/3844], Loss: 0.1816\n",
      "Epoch [2/4], Step [437/3844], Loss: 0.0613\n",
      "Epoch [2/4], Step [438/3844], Loss: 0.0891\n",
      "Epoch [2/4], Step [439/3844], Loss: 0.0669\n",
      "Epoch [2/4], Step [440/3844], Loss: 0.1183\n",
      "Epoch [2/4], Step [441/3844], Loss: 0.1305\n",
      "Epoch [2/4], Step [442/3844], Loss: 0.2407\n",
      "Epoch [2/4], Step [443/3844], Loss: 0.1328\n",
      "Epoch [2/4], Step [444/3844], Loss: 0.1442\n",
      "Epoch [2/4], Step [445/3844], Loss: 0.1335\n",
      "Epoch [2/4], Step [446/3844], Loss: 0.2193\n",
      "Epoch [2/4], Step [447/3844], Loss: 0.2279\n",
      "Epoch [2/4], Step [448/3844], Loss: 0.2235\n",
      "Epoch [2/4], Step [449/3844], Loss: 0.1052\n",
      "Epoch [2/4], Step [450/3844], Loss: 0.0866\n",
      "Epoch [2/4], Step [451/3844], Loss: 0.0933\n",
      "Epoch [2/4], Step [452/3844], Loss: 0.0805\n",
      "Epoch [2/4], Step [453/3844], Loss: 0.1467\n",
      "Epoch [2/4], Step [454/3844], Loss: 0.1360\n",
      "Epoch [2/4], Step [455/3844], Loss: 0.1047\n",
      "Epoch [2/4], Step [456/3844], Loss: 0.1067\n",
      "Epoch [2/4], Step [457/3844], Loss: 0.1578\n",
      "Epoch [2/4], Step [458/3844], Loss: 0.1138\n",
      "Epoch [2/4], Step [459/3844], Loss: 0.1128\n",
      "Epoch [2/4], Step [460/3844], Loss: 0.0905\n",
      "Epoch [2/4], Step [461/3844], Loss: 0.1140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/4], Step [462/3844], Loss: 0.2160\n",
      "Epoch [2/4], Step [463/3844], Loss: 0.1047\n",
      "Epoch [2/4], Step [464/3844], Loss: 0.0991\n",
      "Epoch [2/4], Step [465/3844], Loss: 0.2546\n",
      "Epoch [2/4], Step [466/3844], Loss: 0.0979\n",
      "Epoch [2/4], Step [467/3844], Loss: 0.2451\n",
      "Epoch [2/4], Step [468/3844], Loss: 0.1522\n",
      "Epoch [2/4], Step [469/3844], Loss: 0.0940\n",
      "Epoch [2/4], Step [470/3844], Loss: 0.0708\n",
      "Epoch [2/4], Step [471/3844], Loss: 0.1402\n",
      "Epoch [2/4], Step [472/3844], Loss: 0.1179\n",
      "Epoch [2/4], Step [473/3844], Loss: 0.0834\n",
      "Epoch [2/4], Step [474/3844], Loss: 0.1028\n",
      "Epoch [2/4], Step [475/3844], Loss: 0.1537\n",
      "Epoch [2/4], Step [476/3844], Loss: 0.0752\n",
      "Epoch [2/4], Step [477/3844], Loss: 0.2204\n",
      "Epoch [2/4], Step [478/3844], Loss: 0.1124\n",
      "Epoch [2/4], Step [479/3844], Loss: 0.1451\n",
      "Epoch [2/4], Step [480/3844], Loss: 0.1832\n",
      "Epoch [2/4], Step [481/3844], Loss: 0.0772\n",
      "Epoch [2/4], Step [482/3844], Loss: 0.0998\n",
      "Epoch [2/4], Step [483/3844], Loss: 0.1424\n",
      "Epoch [2/4], Step [484/3844], Loss: 0.0879\n",
      "Epoch [2/4], Step [485/3844], Loss: 0.1378\n",
      "Epoch [2/4], Step [486/3844], Loss: 0.1506\n",
      "Epoch [2/4], Step [487/3844], Loss: 0.0992\n",
      "Epoch [2/4], Step [488/3844], Loss: 0.0942\n",
      "Epoch [2/4], Step [489/3844], Loss: 0.0931\n",
      "Epoch [2/4], Step [490/3844], Loss: 0.0801\n",
      "Epoch [2/4], Step [491/3844], Loss: 0.0479\n",
      "Epoch [2/4], Step [492/3844], Loss: 0.0900\n",
      "Epoch [2/4], Step [493/3844], Loss: 0.0780\n",
      "Epoch [2/4], Step [494/3844], Loss: 0.1631\n",
      "Epoch [2/4], Step [495/3844], Loss: 0.0957\n",
      "Epoch [2/4], Step [496/3844], Loss: 0.1092\n",
      "Epoch [2/4], Step [497/3844], Loss: 0.1564\n",
      "Epoch [2/4], Step [498/3844], Loss: 0.1060\n",
      "Epoch [2/4], Step [499/3844], Loss: 0.0816\n",
      "Epoch [2/4], Step [500/3844], Loss: 0.1567\n",
      "Epoch [2/4], Step [501/3844], Loss: 0.0852\n",
      "Epoch [2/4], Step [502/3844], Loss: 0.1185\n",
      "Epoch [2/4], Step [503/3844], Loss: 0.0866\n",
      "Epoch [2/4], Step [504/3844], Loss: 0.1089\n",
      "Epoch [2/4], Step [505/3844], Loss: 0.0601\n",
      "Epoch [2/4], Step [506/3844], Loss: 0.1082\n",
      "Epoch [2/4], Step [507/3844], Loss: 0.2313\n",
      "Epoch [2/4], Step [508/3844], Loss: 0.2250\n",
      "Epoch [2/4], Step [509/3844], Loss: 0.1464\n",
      "Epoch [2/4], Step [510/3844], Loss: 0.1190\n",
      "Epoch [2/4], Step [511/3844], Loss: 0.1150\n",
      "Epoch [2/4], Step [512/3844], Loss: 0.0663\n",
      "Epoch [2/4], Step [513/3844], Loss: 0.1665\n",
      "Epoch [2/4], Step [514/3844], Loss: 0.0978\n",
      "Epoch [2/4], Step [515/3844], Loss: 0.1519\n",
      "Epoch [2/4], Step [516/3844], Loss: 0.0862\n",
      "Epoch [2/4], Step [517/3844], Loss: 0.1756\n",
      "Epoch [2/4], Step [518/3844], Loss: 0.1700\n",
      "Epoch [2/4], Step [519/3844], Loss: 0.1398\n",
      "Epoch [2/4], Step [520/3844], Loss: 0.1241\n",
      "Epoch [2/4], Step [521/3844], Loss: 0.1101\n",
      "Epoch [2/4], Step [522/3844], Loss: 0.1363\n",
      "Epoch [2/4], Step [523/3844], Loss: 0.1624\n",
      "Epoch [2/4], Step [524/3844], Loss: 0.1037\n",
      "Epoch [2/4], Step [525/3844], Loss: 0.0996\n",
      "Epoch [2/4], Step [526/3844], Loss: 0.0905\n",
      "Epoch [2/4], Step [527/3844], Loss: 0.1116\n",
      "Epoch [2/4], Step [528/3844], Loss: 0.0972\n",
      "Epoch [2/4], Step [529/3844], Loss: 0.1068\n",
      "Epoch [2/4], Step [530/3844], Loss: 0.0866\n",
      "Epoch [2/4], Step [531/3844], Loss: 0.0823\n",
      "Epoch [2/4], Step [532/3844], Loss: 0.0817\n",
      "Epoch [2/4], Step [533/3844], Loss: 0.1256\n",
      "Epoch [2/4], Step [534/3844], Loss: 0.1238\n",
      "Epoch [2/4], Step [535/3844], Loss: 0.0948\n",
      "Epoch [2/4], Step [536/3844], Loss: 0.0938\n",
      "Epoch [2/4], Step [537/3844], Loss: 0.2412\n",
      "Epoch [2/4], Step [538/3844], Loss: 0.1248\n",
      "Epoch [2/4], Step [539/3844], Loss: 0.0730\n",
      "Epoch [2/4], Step [540/3844], Loss: 0.1882\n",
      "Epoch [2/4], Step [541/3844], Loss: 0.1258\n",
      "Epoch [2/4], Step [542/3844], Loss: 0.0742\n",
      "Epoch [2/4], Step [543/3844], Loss: 0.0785\n",
      "Epoch [2/4], Step [544/3844], Loss: 0.1227\n",
      "Epoch [2/4], Step [545/3844], Loss: 0.1313\n",
      "Epoch [2/4], Step [546/3844], Loss: 0.1268\n",
      "Epoch [2/4], Step [547/3844], Loss: 0.1358\n",
      "Epoch [2/4], Step [548/3844], Loss: 0.1722\n",
      "Epoch [2/4], Step [549/3844], Loss: 0.1574\n",
      "Epoch [2/4], Step [550/3844], Loss: 0.0878\n",
      "Epoch [2/4], Step [551/3844], Loss: 0.0791\n",
      "Epoch [2/4], Step [552/3844], Loss: 0.0804\n",
      "Epoch [2/4], Step [553/3844], Loss: 0.1826\n",
      "Epoch [2/4], Step [554/3844], Loss: 0.1015\n",
      "Epoch [2/4], Step [555/3844], Loss: 0.1147\n",
      "Epoch [2/4], Step [556/3844], Loss: 0.0684\n",
      "Epoch [2/4], Step [557/3844], Loss: 0.0775\n",
      "Epoch [2/4], Step [558/3844], Loss: 0.1658\n",
      "Epoch [2/4], Step [559/3844], Loss: 0.1698\n",
      "Epoch [2/4], Step [560/3844], Loss: 0.1672\n",
      "Epoch [2/4], Step [561/3844], Loss: 0.1591\n",
      "Epoch [2/4], Step [562/3844], Loss: 0.1645\n",
      "Epoch [2/4], Step [563/3844], Loss: 0.1107\n",
      "Epoch [2/4], Step [564/3844], Loss: 0.1096\n",
      "Epoch [2/4], Step [565/3844], Loss: 0.1707\n",
      "Epoch [2/4], Step [566/3844], Loss: 0.0983\n",
      "Epoch [2/4], Step [567/3844], Loss: 0.0943\n",
      "Epoch [2/4], Step [568/3844], Loss: 0.1390\n",
      "Epoch [2/4], Step [569/3844], Loss: 0.1618\n",
      "Epoch [2/4], Step [570/3844], Loss: 0.1128\n",
      "Epoch [2/4], Step [571/3844], Loss: 0.1247\n",
      "Epoch [2/4], Step [572/3844], Loss: 0.1185\n",
      "Epoch [2/4], Step [573/3844], Loss: 0.1819\n",
      "Epoch [2/4], Step [574/3844], Loss: 0.1039\n",
      "Epoch [2/4], Step [575/3844], Loss: 0.1110\n",
      "Epoch [2/4], Step [576/3844], Loss: 0.1054\n",
      "Epoch [2/4], Step [577/3844], Loss: 0.0812\n",
      "Epoch [2/4], Step [578/3844], Loss: 0.0951\n",
      "Epoch [2/4], Step [579/3844], Loss: 0.1277\n",
      "Epoch [2/4], Step [580/3844], Loss: 0.2125\n",
      "Epoch [2/4], Step [581/3844], Loss: 0.0835\n",
      "Epoch [2/4], Step [582/3844], Loss: 0.1475\n",
      "Epoch [2/4], Step [583/3844], Loss: 0.1498\n",
      "Epoch [2/4], Step [584/3844], Loss: 0.1422\n",
      "Epoch [2/4], Step [585/3844], Loss: 0.1128\n",
      "Epoch [2/4], Step [586/3844], Loss: 0.0792\n",
      "Epoch [2/4], Step [587/3844], Loss: 0.0990\n",
      "Epoch [2/4], Step [588/3844], Loss: 0.1665\n",
      "Epoch [2/4], Step [589/3844], Loss: 0.2199\n",
      "Epoch [2/4], Step [590/3844], Loss: 0.1561\n",
      "Epoch [2/4], Step [591/3844], Loss: 0.0757\n",
      "Epoch [2/4], Step [592/3844], Loss: 0.1347\n",
      "Epoch [2/4], Step [593/3844], Loss: 0.1134\n",
      "Epoch [2/4], Step [594/3844], Loss: 0.1596\n",
      "Epoch [2/4], Step [595/3844], Loss: 0.0898\n",
      "Epoch [2/4], Step [596/3844], Loss: 0.1095\n",
      "Epoch [2/4], Step [597/3844], Loss: 0.1033\n",
      "Epoch [2/4], Step [598/3844], Loss: 0.0847\n",
      "Epoch [2/4], Step [599/3844], Loss: 0.0892\n",
      "Epoch [2/4], Step [600/3844], Loss: 0.1470\n",
      "Epoch [2/4], Step [601/3844], Loss: 0.1372\n",
      "Epoch [2/4], Step [602/3844], Loss: 0.1852\n",
      "Epoch [2/4], Step [603/3844], Loss: 0.1157\n",
      "Epoch [2/4], Step [604/3844], Loss: 0.1052\n",
      "Epoch [2/4], Step [605/3844], Loss: 0.0839\n",
      "Epoch [2/4], Step [606/3844], Loss: 0.1410\n",
      "Epoch [2/4], Step [607/3844], Loss: 0.1317\n",
      "Epoch [2/4], Step [608/3844], Loss: 0.0808\n",
      "Epoch [2/4], Step [609/3844], Loss: 0.1043\n",
      "Epoch [2/4], Step [610/3844], Loss: 0.1128\n",
      "Epoch [2/4], Step [611/3844], Loss: 0.0791\n",
      "Epoch [2/4], Step [612/3844], Loss: 0.0963\n",
      "Epoch [2/4], Step [613/3844], Loss: 0.1068\n",
      "Epoch [2/4], Step [614/3844], Loss: 0.0990\n",
      "Epoch [2/4], Step [615/3844], Loss: 0.0782\n",
      "Epoch [2/4], Step [616/3844], Loss: 0.0934\n",
      "Epoch [2/4], Step [617/3844], Loss: 0.1054\n",
      "Epoch [2/4], Step [618/3844], Loss: 0.1582\n",
      "Epoch [2/4], Step [619/3844], Loss: 0.1585\n",
      "Epoch [2/4], Step [620/3844], Loss: 0.0910\n",
      "Epoch [2/4], Step [621/3844], Loss: 0.0830\n",
      "Epoch [2/4], Step [622/3844], Loss: 0.0643\n",
      "Epoch [2/4], Step [623/3844], Loss: 0.0966\n",
      "Epoch [2/4], Step [624/3844], Loss: 0.1294\n",
      "Epoch [2/4], Step [625/3844], Loss: 0.0918\n",
      "Epoch [2/4], Step [626/3844], Loss: 0.0683\n",
      "Epoch [2/4], Step [627/3844], Loss: 0.1855\n",
      "Epoch [2/4], Step [628/3844], Loss: 0.0783\n",
      "Epoch [2/4], Step [629/3844], Loss: 0.0707\n",
      "Epoch [2/4], Step [630/3844], Loss: 0.1509\n",
      "Epoch [2/4], Step [631/3844], Loss: 0.2213\n",
      "Epoch [2/4], Step [632/3844], Loss: 0.0968\n",
      "Epoch [2/4], Step [633/3844], Loss: 0.2039\n",
      "Epoch [2/4], Step [634/3844], Loss: 0.0994\n",
      "Epoch [2/4], Step [635/3844], Loss: 0.2301\n",
      "Epoch [2/4], Step [636/3844], Loss: 0.1265\n",
      "Epoch [2/4], Step [637/3844], Loss: 0.1579\n",
      "Epoch [2/4], Step [638/3844], Loss: 0.2275\n",
      "Epoch [2/4], Step [639/3844], Loss: 0.0919\n",
      "Epoch [2/4], Step [640/3844], Loss: 0.0784\n",
      "Epoch [2/4], Step [641/3844], Loss: 0.1747\n",
      "Epoch [2/4], Step [642/3844], Loss: 0.1852\n",
      "Epoch [2/4], Step [643/3844], Loss: 0.1473\n",
      "Epoch [2/4], Step [644/3844], Loss: 0.1442\n",
      "Epoch [2/4], Step [645/3844], Loss: 0.0953\n",
      "Epoch [2/4], Step [646/3844], Loss: 0.0909\n",
      "Epoch [2/4], Step [647/3844], Loss: 0.0696\n",
      "Epoch [2/4], Step [648/3844], Loss: 0.1017\n",
      "Epoch [2/4], Step [649/3844], Loss: 0.1070\n",
      "Epoch [2/4], Step [650/3844], Loss: 0.0794\n",
      "Epoch [2/4], Step [651/3844], Loss: 0.0849\n",
      "Epoch [2/4], Step [652/3844], Loss: 0.0809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/4], Step [653/3844], Loss: 0.1000\n",
      "Epoch [2/4], Step [654/3844], Loss: 0.0880\n",
      "Epoch [2/4], Step [655/3844], Loss: 0.0968\n",
      "Epoch [2/4], Step [656/3844], Loss: 0.1039\n",
      "Epoch [2/4], Step [657/3844], Loss: 0.1053\n",
      "Epoch [2/4], Step [658/3844], Loss: 0.0839\n",
      "Epoch [2/4], Step [659/3844], Loss: 0.1558\n",
      "Epoch [2/4], Step [660/3844], Loss: 0.1213\n",
      "Epoch [2/4], Step [661/3844], Loss: 0.0948\n",
      "Epoch [2/4], Step [662/3844], Loss: 0.1353\n",
      "Epoch [2/4], Step [663/3844], Loss: 0.0853\n",
      "Epoch [2/4], Step [664/3844], Loss: 0.1594\n",
      "Epoch [2/4], Step [665/3844], Loss: 0.0911\n",
      "Epoch [2/4], Step [666/3844], Loss: 0.1474\n",
      "Epoch [2/4], Step [667/3844], Loss: 0.0977\n",
      "Epoch [2/4], Step [668/3844], Loss: 0.0715\n",
      "Epoch [2/4], Step [669/3844], Loss: 0.0978\n",
      "Epoch [2/4], Step [670/3844], Loss: 0.1438\n",
      "Epoch [2/4], Step [671/3844], Loss: 0.1687\n",
      "Epoch [2/4], Step [672/3844], Loss: 0.1770\n",
      "Epoch [2/4], Step [673/3844], Loss: 0.1264\n",
      "Epoch [2/4], Step [674/3844], Loss: 0.0812\n",
      "Epoch [2/4], Step [675/3844], Loss: 0.1377\n",
      "Epoch [2/4], Step [676/3844], Loss: 0.2615\n",
      "Epoch [2/4], Step [677/3844], Loss: 0.1442\n",
      "Epoch [2/4], Step [678/3844], Loss: 0.2514\n",
      "Epoch [2/4], Step [679/3844], Loss: 0.1496\n",
      "Epoch [2/4], Step [680/3844], Loss: 0.1069\n",
      "Epoch [2/4], Step [681/3844], Loss: 0.2231\n",
      "Epoch [2/4], Step [682/3844], Loss: 0.1682\n",
      "Epoch [2/4], Step [683/3844], Loss: 0.2160\n",
      "Epoch [2/4], Step [684/3844], Loss: 0.2198\n",
      "Epoch [2/4], Step [685/3844], Loss: 0.1796\n",
      "Epoch [2/4], Step [686/3844], Loss: 0.0934\n",
      "Epoch [2/4], Step [687/3844], Loss: 0.1427\n",
      "Epoch [2/4], Step [688/3844], Loss: 0.1328\n",
      "Epoch [2/4], Step [689/3844], Loss: 0.0637\n",
      "Epoch [2/4], Step [690/3844], Loss: 0.0842\n",
      "Epoch [2/4], Step [691/3844], Loss: 0.1029\n",
      "Epoch [2/4], Step [692/3844], Loss: 0.0555\n",
      "Epoch [2/4], Step [693/3844], Loss: 0.0883\n",
      "Epoch [2/4], Step [694/3844], Loss: 0.0860\n",
      "Epoch [2/4], Step [695/3844], Loss: 0.2254\n",
      "Epoch [2/4], Step [696/3844], Loss: 0.0979\n",
      "Epoch [2/4], Step [697/3844], Loss: 0.1726\n",
      "Epoch [2/4], Step [698/3844], Loss: 0.0958\n",
      "Epoch [2/4], Step [699/3844], Loss: 0.2433\n",
      "Epoch [2/4], Step [700/3844], Loss: 0.1000\n",
      "Epoch [2/4], Step [701/3844], Loss: 0.0764\n",
      "Epoch [2/4], Step [702/3844], Loss: 0.0872\n",
      "Epoch [2/4], Step [703/3844], Loss: 0.0730\n",
      "Epoch [2/4], Step [704/3844], Loss: 0.1023\n",
      "Epoch [2/4], Step [705/3844], Loss: 0.1536\n",
      "Epoch [2/4], Step [706/3844], Loss: 0.0975\n",
      "Epoch [2/4], Step [707/3844], Loss: 0.1618\n",
      "Epoch [2/4], Step [708/3844], Loss: 0.0928\n",
      "Epoch [2/4], Step [709/3844], Loss: 0.1536\n",
      "Epoch [2/4], Step [710/3844], Loss: 0.1197\n",
      "Epoch [2/4], Step [711/3844], Loss: 0.0941\n",
      "Epoch [2/4], Step [712/3844], Loss: 0.1438\n",
      "Epoch [2/4], Step [713/3844], Loss: 0.0786\n",
      "Epoch [2/4], Step [714/3844], Loss: 0.2361\n",
      "Epoch [2/4], Step [715/3844], Loss: 0.1503\n",
      "Epoch [2/4], Step [716/3844], Loss: 0.1055\n",
      "Epoch [2/4], Step [717/3844], Loss: 0.0886\n",
      "Epoch [2/4], Step [718/3844], Loss: 0.0754\n",
      "Epoch [2/4], Step [719/3844], Loss: 0.1173\n",
      "Epoch [2/4], Step [720/3844], Loss: 0.1679\n",
      "Epoch [2/4], Step [721/3844], Loss: 0.0853\n",
      "Epoch [2/4], Step [722/3844], Loss: 0.1602\n",
      "Epoch [2/4], Step [723/3844], Loss: 0.1438\n",
      "Epoch [2/4], Step [724/3844], Loss: 0.0798\n",
      "Epoch [2/4], Step [725/3844], Loss: 0.1258\n",
      "Epoch [2/4], Step [726/3844], Loss: 0.2062\n",
      "Epoch [2/4], Step [727/3844], Loss: 0.1140\n",
      "Epoch [2/4], Step [728/3844], Loss: 0.0859\n",
      "Epoch [2/4], Step [729/3844], Loss: 0.0944\n",
      "Epoch [2/4], Step [730/3844], Loss: 0.0939\n",
      "Epoch [2/4], Step [731/3844], Loss: 0.1604\n",
      "Epoch [2/4], Step [732/3844], Loss: 0.1696\n",
      "Epoch [2/4], Step [733/3844], Loss: 0.0972\n",
      "Epoch [2/4], Step [734/3844], Loss: 0.1227\n",
      "Epoch [2/4], Step [735/3844], Loss: 0.1473\n",
      "Epoch [2/4], Step [736/3844], Loss: 0.1863\n",
      "Epoch [2/4], Step [737/3844], Loss: 0.1066\n",
      "Epoch [2/4], Step [738/3844], Loss: 0.0891\n",
      "Epoch [2/4], Step [739/3844], Loss: 0.1802\n",
      "Epoch [2/4], Step [740/3844], Loss: 0.0799\n",
      "Epoch [2/4], Step [741/3844], Loss: 0.1558\n",
      "Epoch [2/4], Step [742/3844], Loss: 0.0966\n",
      "Epoch [2/4], Step [743/3844], Loss: 0.0706\n",
      "Epoch [2/4], Step [744/3844], Loss: 0.1183\n",
      "Epoch [2/4], Step [745/3844], Loss: 0.1511\n",
      "Epoch [2/4], Step [746/3844], Loss: 0.0965\n",
      "Epoch [2/4], Step [747/3844], Loss: 0.1200\n",
      "Epoch [2/4], Step [748/3844], Loss: 0.2189\n",
      "Epoch [2/4], Step [749/3844], Loss: 0.1031\n",
      "Epoch [2/4], Step [750/3844], Loss: 0.0690\n",
      "Epoch [2/4], Step [751/3844], Loss: 0.1894\n",
      "Epoch [2/4], Step [752/3844], Loss: 0.0881\n",
      "Epoch [2/4], Step [753/3844], Loss: 0.1704\n",
      "Epoch [2/4], Step [754/3844], Loss: 0.0855\n",
      "Epoch [2/4], Step [755/3844], Loss: 0.0889\n",
      "Epoch [2/4], Step [756/3844], Loss: 0.1710\n",
      "Epoch [2/4], Step [757/3844], Loss: 0.1426\n",
      "Epoch [2/4], Step [758/3844], Loss: 0.0959\n",
      "Epoch [2/4], Step [759/3844], Loss: 0.0927\n",
      "Epoch [2/4], Step [760/3844], Loss: 0.1419\n",
      "Epoch [2/4], Step [761/3844], Loss: 0.0986\n",
      "Epoch [2/4], Step [762/3844], Loss: 0.2338\n",
      "Epoch [2/4], Step [763/3844], Loss: 0.1085\n",
      "Epoch [2/4], Step [764/3844], Loss: 0.1687\n",
      "Epoch [2/4], Step [765/3844], Loss: 0.1222\n",
      "Epoch [2/4], Step [766/3844], Loss: 0.0768\n",
      "Epoch [2/4], Step [767/3844], Loss: 0.2197\n",
      "Epoch [2/4], Step [768/3844], Loss: 0.1281\n",
      "Epoch [2/4], Step [769/3844], Loss: 0.1840\n",
      "Epoch [2/4], Step [770/3844], Loss: 0.0808\n",
      "Epoch [2/4], Step [771/3844], Loss: 0.0711\n",
      "Epoch [2/4], Step [772/3844], Loss: 0.1376\n",
      "Epoch [2/4], Step [773/3844], Loss: 0.0983\n",
      "Epoch [2/4], Step [774/3844], Loss: 0.1670\n",
      "Epoch [2/4], Step [775/3844], Loss: 0.0849\n",
      "Epoch [2/4], Step [776/3844], Loss: 0.0857\n",
      "Epoch [2/4], Step [777/3844], Loss: 0.2027\n",
      "Epoch [2/4], Step [778/3844], Loss: 0.0930\n",
      "Epoch [2/4], Step [779/3844], Loss: 0.0981\n",
      "Epoch [2/4], Step [780/3844], Loss: 0.1012\n",
      "Epoch [2/4], Step [781/3844], Loss: 0.2368\n",
      "Epoch [2/4], Step [782/3844], Loss: 0.2182\n",
      "Epoch [2/4], Step [783/3844], Loss: 0.1565\n",
      "Epoch [2/4], Step [784/3844], Loss: 0.0896\n",
      "Epoch [2/4], Step [785/3844], Loss: 0.1885\n",
      "Epoch [2/4], Step [786/3844], Loss: 0.0975\n",
      "Epoch [2/4], Step [787/3844], Loss: 0.1172\n",
      "Epoch [2/4], Step [788/3844], Loss: 0.0943\n",
      "Epoch [2/4], Step [789/3844], Loss: 0.0689\n",
      "Epoch [2/4], Step [790/3844], Loss: 0.0874\n",
      "Epoch [2/4], Step [791/3844], Loss: 0.2249\n",
      "Epoch [2/4], Step [792/3844], Loss: 0.1061\n",
      "Epoch [2/4], Step [793/3844], Loss: 0.1047\n",
      "Epoch [2/4], Step [794/3844], Loss: 0.0906\n",
      "Epoch [2/4], Step [795/3844], Loss: 0.2158\n",
      "Epoch [2/4], Step [796/3844], Loss: 0.1438\n",
      "Epoch [2/4], Step [797/3844], Loss: 0.1123\n",
      "Epoch [2/4], Step [798/3844], Loss: 0.0813\n",
      "Epoch [2/4], Step [799/3844], Loss: 0.0821\n",
      "Epoch [2/4], Step [800/3844], Loss: 0.1079\n",
      "Epoch [2/4], Step [801/3844], Loss: 0.0897\n",
      "Epoch [2/4], Step [802/3844], Loss: 0.1058\n",
      "Epoch [2/4], Step [803/3844], Loss: 0.1051\n",
      "Epoch [2/4], Step [804/3844], Loss: 0.0979\n",
      "Epoch [2/4], Step [805/3844], Loss: 0.1271\n",
      "Epoch [2/4], Step [806/3844], Loss: 0.1326\n",
      "Epoch [2/4], Step [807/3844], Loss: 0.0757\n",
      "Epoch [2/4], Step [808/3844], Loss: 0.2223\n",
      "Epoch [2/4], Step [809/3844], Loss: 0.0899\n",
      "Epoch [2/4], Step [810/3844], Loss: 0.1542\n",
      "Epoch [2/4], Step [811/3844], Loss: 0.1527\n",
      "Epoch [2/4], Step [812/3844], Loss: 0.1904\n",
      "Epoch [2/4], Step [813/3844], Loss: 0.1302\n",
      "Epoch [2/4], Step [814/3844], Loss: 0.0586\n",
      "Epoch [2/4], Step [815/3844], Loss: 0.1551\n",
      "Epoch [2/4], Step [816/3844], Loss: 0.1047\n",
      "Epoch [2/4], Step [817/3844], Loss: 0.1506\n",
      "Epoch [2/4], Step [818/3844], Loss: 0.0917\n",
      "Epoch [2/4], Step [819/3844], Loss: 0.1758\n",
      "Epoch [2/4], Step [820/3844], Loss: 0.1559\n",
      "Epoch [2/4], Step [821/3844], Loss: 0.1071\n",
      "Epoch [2/4], Step [822/3844], Loss: 0.1102\n",
      "Epoch [2/4], Step [823/3844], Loss: 0.1034\n",
      "Epoch [2/4], Step [824/3844], Loss: 0.1019\n",
      "Epoch [2/4], Step [825/3844], Loss: 0.0863\n",
      "Epoch [2/4], Step [826/3844], Loss: 0.2483\n",
      "Epoch [2/4], Step [827/3844], Loss: 0.1490\n",
      "Epoch [2/4], Step [828/3844], Loss: 0.2387\n",
      "Epoch [2/4], Step [829/3844], Loss: 0.1255\n",
      "Epoch [2/4], Step [830/3844], Loss: 0.2115\n",
      "Epoch [2/4], Step [831/3844], Loss: 0.0751\n",
      "Epoch [2/4], Step [832/3844], Loss: 0.1089\n",
      "Epoch [2/4], Step [833/3844], Loss: 0.0897\n",
      "Epoch [2/4], Step [834/3844], Loss: 0.0715\n",
      "Epoch [2/4], Step [835/3844], Loss: 0.1953\n",
      "Epoch [2/4], Step [836/3844], Loss: 0.0996\n",
      "Epoch [2/4], Step [837/3844], Loss: 0.0622\n",
      "Epoch [2/4], Step [838/3844], Loss: 0.0806\n",
      "Epoch [2/4], Step [839/3844], Loss: 0.0990\n",
      "Epoch [2/4], Step [840/3844], Loss: 0.0790\n",
      "Epoch [2/4], Step [841/3844], Loss: 0.0731\n",
      "Epoch [2/4], Step [842/3844], Loss: 0.1732\n",
      "Epoch [2/4], Step [843/3844], Loss: 0.1127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/4], Step [844/3844], Loss: 0.1672\n",
      "Epoch [2/4], Step [845/3844], Loss: 0.1389\n",
      "Epoch [2/4], Step [846/3844], Loss: 0.2133\n",
      "Epoch [2/4], Step [847/3844], Loss: 0.1605\n",
      "Epoch [2/4], Step [848/3844], Loss: 0.0945\n",
      "Epoch [2/4], Step [849/3844], Loss: 0.1005\n",
      "Epoch [2/4], Step [850/3844], Loss: 0.0936\n",
      "Epoch [2/4], Step [851/3844], Loss: 0.1200\n",
      "Epoch [2/4], Step [852/3844], Loss: 0.1970\n",
      "Epoch [2/4], Step [853/3844], Loss: 0.0952\n",
      "Epoch [2/4], Step [854/3844], Loss: 0.1142\n",
      "Epoch [2/4], Step [855/3844], Loss: 0.2344\n",
      "Epoch [2/4], Step [856/3844], Loss: 0.1571\n",
      "Epoch [2/4], Step [857/3844], Loss: 0.1169\n",
      "Epoch [2/4], Step [858/3844], Loss: 0.0931\n",
      "Epoch [2/4], Step [859/3844], Loss: 0.1452\n",
      "Epoch [2/4], Step [860/3844], Loss: 0.1001\n",
      "Epoch [2/4], Step [861/3844], Loss: 0.1241\n",
      "Epoch [2/4], Step [862/3844], Loss: 0.1025\n",
      "Epoch [2/4], Step [863/3844], Loss: 0.1017\n",
      "Epoch [2/4], Step [864/3844], Loss: 0.1726\n",
      "Epoch [2/4], Step [865/3844], Loss: 0.1114\n",
      "Epoch [2/4], Step [866/3844], Loss: 0.2156\n",
      "Epoch [2/4], Step [867/3844], Loss: 0.2418\n",
      "Epoch [2/4], Step [868/3844], Loss: 0.0820\n",
      "Epoch [2/4], Step [869/3844], Loss: 0.1432\n",
      "Epoch [2/4], Step [870/3844], Loss: 0.1092\n",
      "Epoch [2/4], Step [871/3844], Loss: 0.1072\n",
      "Epoch [2/4], Step [872/3844], Loss: 0.2129\n",
      "Epoch [2/4], Step [873/3844], Loss: 0.1290\n",
      "Epoch [2/4], Step [874/3844], Loss: 0.1067\n",
      "Epoch [2/4], Step [875/3844], Loss: 0.2088\n",
      "Epoch [2/4], Step [876/3844], Loss: 0.0760\n",
      "Epoch [2/4], Step [877/3844], Loss: 0.1039\n",
      "Epoch [2/4], Step [878/3844], Loss: 0.1951\n",
      "Epoch [2/4], Step [879/3844], Loss: 0.0959\n",
      "Epoch [2/4], Step [880/3844], Loss: 0.1021\n",
      "Epoch [2/4], Step [881/3844], Loss: 0.0854\n",
      "Epoch [2/4], Step [882/3844], Loss: 0.1359\n",
      "Epoch [2/4], Step [883/3844], Loss: 0.1158\n",
      "Epoch [2/4], Step [884/3844], Loss: 0.1158\n",
      "Epoch [2/4], Step [885/3844], Loss: 0.0964\n",
      "Epoch [2/4], Step [886/3844], Loss: 0.1652\n",
      "Epoch [2/4], Step [887/3844], Loss: 0.0611\n",
      "Epoch [2/4], Step [888/3844], Loss: 0.0994\n",
      "Epoch [2/4], Step [889/3844], Loss: 0.0908\n",
      "Epoch [2/4], Step [890/3844], Loss: 0.1332\n",
      "Epoch [2/4], Step [891/3844], Loss: 0.0681\n",
      "Epoch [2/4], Step [892/3844], Loss: 0.0879\n",
      "Epoch [2/4], Step [893/3844], Loss: 0.1150\n",
      "Epoch [2/4], Step [894/3844], Loss: 0.1700\n",
      "Epoch [2/4], Step [895/3844], Loss: 0.1285\n",
      "Epoch [2/4], Step [896/3844], Loss: 0.1395\n",
      "Epoch [2/4], Step [897/3844], Loss: 0.0818\n",
      "Epoch [2/4], Step [898/3844], Loss: 0.2000\n",
      "Epoch [2/4], Step [899/3844], Loss: 0.1551\n",
      "Epoch [2/4], Step [900/3844], Loss: 0.1184\n",
      "Epoch [2/4], Step [901/3844], Loss: 0.0985\n",
      "Epoch [2/4], Step [902/3844], Loss: 0.0944\n",
      "Epoch [2/4], Step [903/3844], Loss: 0.0785\n",
      "Epoch [2/4], Step [904/3844], Loss: 0.1247\n",
      "Epoch [2/4], Step [905/3844], Loss: 0.2011\n",
      "Epoch [2/4], Step [906/3844], Loss: 0.1708\n",
      "Epoch [2/4], Step [907/3844], Loss: 0.1034\n",
      "Epoch [2/4], Step [908/3844], Loss: 0.1066\n",
      "Epoch [2/4], Step [909/3844], Loss: 0.0708\n",
      "Epoch [2/4], Step [910/3844], Loss: 0.0920\n",
      "Epoch [2/4], Step [911/3844], Loss: 0.0978\n",
      "Epoch [2/4], Step [912/3844], Loss: 0.1650\n",
      "Epoch [2/4], Step [913/3844], Loss: 0.0642\n",
      "Epoch [2/4], Step [914/3844], Loss: 0.0745\n",
      "Epoch [2/4], Step [915/3844], Loss: 0.1509\n",
      "Epoch [2/4], Step [916/3844], Loss: 0.0995\n",
      "Epoch [2/4], Step [917/3844], Loss: 0.0898\n",
      "Epoch [2/4], Step [918/3844], Loss: 0.0612\n",
      "Epoch [2/4], Step [919/3844], Loss: 0.0948\n",
      "Epoch [2/4], Step [920/3844], Loss: 0.1285\n",
      "Epoch [2/4], Step [921/3844], Loss: 0.1103\n",
      "Epoch [2/4], Step [922/3844], Loss: 0.0782\n",
      "Epoch [2/4], Step [923/3844], Loss: 0.1059\n",
      "Epoch [2/4], Step [924/3844], Loss: 0.0824\n",
      "Epoch [2/4], Step [925/3844], Loss: 0.1081\n",
      "Epoch [2/4], Step [926/3844], Loss: 0.1469\n",
      "Epoch [2/4], Step [927/3844], Loss: 0.1124\n",
      "Epoch [2/4], Step [928/3844], Loss: 0.1223\n",
      "Epoch [2/4], Step [929/3844], Loss: 0.1027\n",
      "Epoch [2/4], Step [930/3844], Loss: 0.1032\n",
      "Epoch [2/4], Step [931/3844], Loss: 0.2102\n",
      "Epoch [2/4], Step [932/3844], Loss: 0.1427\n",
      "Epoch [2/4], Step [933/3844], Loss: 0.1576\n",
      "Epoch [2/4], Step [934/3844], Loss: 0.1137\n",
      "Epoch [2/4], Step [935/3844], Loss: 0.0984\n",
      "Epoch [2/4], Step [936/3844], Loss: 0.1696\n",
      "Epoch [2/4], Step [937/3844], Loss: 0.1049\n",
      "Epoch [2/4], Step [938/3844], Loss: 0.0997\n",
      "Epoch [2/4], Step [939/3844], Loss: 0.2063\n",
      "Epoch [2/4], Step [940/3844], Loss: 0.0915\n",
      "Epoch [2/4], Step [941/3844], Loss: 0.0665\n",
      "Epoch [2/4], Step [942/3844], Loss: 0.1348\n",
      "Epoch [2/4], Step [943/3844], Loss: 0.2156\n",
      "Epoch [2/4], Step [944/3844], Loss: 0.0998\n",
      "Epoch [2/4], Step [945/3844], Loss: 0.1111\n",
      "Epoch [2/4], Step [946/3844], Loss: 0.1021\n",
      "Epoch [2/4], Step [947/3844], Loss: 0.0970\n",
      "Epoch [2/4], Step [948/3844], Loss: 0.2306\n",
      "Epoch [2/4], Step [949/3844], Loss: 0.0929\n",
      "Epoch [2/4], Step [950/3844], Loss: 0.1324\n",
      "Epoch [2/4], Step [951/3844], Loss: 0.0946\n",
      "Epoch [2/4], Step [952/3844], Loss: 0.1282\n",
      "Epoch [2/4], Step [953/3844], Loss: 0.1946\n",
      "Epoch [2/4], Step [954/3844], Loss: 0.0927\n",
      "Epoch [2/4], Step [955/3844], Loss: 0.1061\n",
      "Epoch [2/4], Step [956/3844], Loss: 0.0826\n",
      "Epoch [2/4], Step [957/3844], Loss: 0.0562\n",
      "Epoch [2/4], Step [958/3844], Loss: 0.0782\n",
      "Epoch [2/4], Step [959/3844], Loss: 0.2000\n",
      "Epoch [2/4], Step [960/3844], Loss: 0.0802\n",
      "Epoch [2/4], Step [961/3844], Loss: 0.1004\n",
      "Epoch [2/4], Step [962/3844], Loss: 0.1560\n",
      "Epoch [2/4], Step [963/3844], Loss: 0.1323\n",
      "Epoch [2/4], Step [964/3844], Loss: 0.1623\n",
      "Epoch [2/4], Step [965/3844], Loss: 0.1485\n",
      "Epoch [2/4], Step [966/3844], Loss: 0.0979\n",
      "Epoch [2/4], Step [967/3844], Loss: 0.1052\n",
      "Epoch [2/4], Step [968/3844], Loss: 0.1224\n",
      "Epoch [2/4], Step [969/3844], Loss: 0.0706\n",
      "Epoch [2/4], Step [970/3844], Loss: 0.1641\n",
      "Epoch [2/4], Step [971/3844], Loss: 0.0930\n",
      "Epoch [2/4], Step [972/3844], Loss: 0.1317\n",
      "Epoch [2/4], Step [973/3844], Loss: 0.1746\n",
      "Epoch [2/4], Step [974/3844], Loss: 0.2091\n",
      "Epoch [2/4], Step [975/3844], Loss: 0.1027\n",
      "Epoch [2/4], Step [976/3844], Loss: 0.2192\n",
      "Epoch [2/4], Step [977/3844], Loss: 0.0960\n",
      "Epoch [2/4], Step [978/3844], Loss: 0.1635\n",
      "Epoch [2/4], Step [979/3844], Loss: 0.0879\n",
      "Epoch [2/4], Step [980/3844], Loss: 0.0786\n",
      "Epoch [2/4], Step [981/3844], Loss: 0.0837\n",
      "Epoch [2/4], Step [982/3844], Loss: 0.1857\n",
      "Epoch [2/4], Step [983/3844], Loss: 0.0681\n",
      "Epoch [2/4], Step [984/3844], Loss: 0.1675\n",
      "Epoch [2/4], Step [985/3844], Loss: 0.1545\n",
      "Epoch [2/4], Step [986/3844], Loss: 0.1139\n",
      "Epoch [2/4], Step [987/3844], Loss: 0.2260\n",
      "Epoch [2/4], Step [988/3844], Loss: 0.1714\n",
      "Epoch [2/4], Step [989/3844], Loss: 0.0830\n",
      "Epoch [2/4], Step [990/3844], Loss: 0.1252\n",
      "Epoch [2/4], Step [991/3844], Loss: 0.0906\n",
      "Epoch [2/4], Step [992/3844], Loss: 0.2263\n",
      "Epoch [2/4], Step [993/3844], Loss: 0.2102\n",
      "Epoch [2/4], Step [994/3844], Loss: 0.1877\n",
      "Epoch [2/4], Step [995/3844], Loss: 0.2275\n",
      "Epoch [2/4], Step [996/3844], Loss: 0.1090\n",
      "Epoch [2/4], Step [997/3844], Loss: 0.0894\n",
      "Epoch [2/4], Step [998/3844], Loss: 0.0796\n",
      "Epoch [2/4], Step [999/3844], Loss: 0.0594\n",
      "Epoch [2/4], Step [1000/3844], Loss: 0.0848\n",
      "Epoch [2/4], Step [1001/3844], Loss: 0.1126\n",
      "Epoch [2/4], Step [1002/3844], Loss: 0.0745\n",
      "Epoch [2/4], Step [1003/3844], Loss: 0.0806\n",
      "Epoch [2/4], Step [1004/3844], Loss: 0.0485\n",
      "Epoch [2/4], Step [1005/3844], Loss: 0.0874\n",
      "Epoch [2/4], Step [1006/3844], Loss: 0.1705\n",
      "Epoch [2/4], Step [1007/3844], Loss: 0.2228\n",
      "Epoch [2/4], Step [1008/3844], Loss: 0.1126\n",
      "Epoch [2/4], Step [1009/3844], Loss: 0.1063\n",
      "Epoch [2/4], Step [1010/3844], Loss: 0.1486\n",
      "Epoch [2/4], Step [1011/3844], Loss: 0.1673\n",
      "Epoch [2/4], Step [1012/3844], Loss: 0.1904\n",
      "Epoch [2/4], Step [1013/3844], Loss: 0.0781\n",
      "Epoch [2/4], Step [1014/3844], Loss: 0.1602\n",
      "Epoch [2/4], Step [1015/3844], Loss: 0.1005\n",
      "Epoch [2/4], Step [1016/3844], Loss: 0.0921\n",
      "Epoch [2/4], Step [1017/3844], Loss: 0.0771\n",
      "Epoch [2/4], Step [1018/3844], Loss: 0.1493\n",
      "Epoch [2/4], Step [1019/3844], Loss: 0.1473\n",
      "Epoch [2/4], Step [1020/3844], Loss: 0.0989\n",
      "Epoch [2/4], Step [1021/3844], Loss: 0.1719\n",
      "Epoch [2/4], Step [1022/3844], Loss: 0.2071\n",
      "Epoch [2/4], Step [1023/3844], Loss: 0.1470\n",
      "Epoch [2/4], Step [1024/3844], Loss: 0.1254\n",
      "Epoch [2/4], Step [1025/3844], Loss: 0.1406\n",
      "Epoch [2/4], Step [1026/3844], Loss: 0.0918\n",
      "Epoch [2/4], Step [1027/3844], Loss: 0.1253\n",
      "Epoch [2/4], Step [1028/3844], Loss: 0.1448\n",
      "Epoch [2/4], Step [1029/3844], Loss: 0.1125\n",
      "Epoch [2/4], Step [1030/3844], Loss: 0.1127\n",
      "Epoch [2/4], Step [1031/3844], Loss: 0.1549\n",
      "Epoch [2/4], Step [1032/3844], Loss: 0.1843\n",
      "Epoch [2/4], Step [1033/3844], Loss: 0.1546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/4], Step [1034/3844], Loss: 0.0740\n",
      "Epoch [2/4], Step [1035/3844], Loss: 0.1149\n",
      "Epoch [2/4], Step [1036/3844], Loss: 0.1398\n",
      "Epoch [2/4], Step [1037/3844], Loss: 0.1246\n",
      "Epoch [2/4], Step [1038/3844], Loss: 0.1056\n",
      "Epoch [2/4], Step [1039/3844], Loss: 0.1388\n",
      "Epoch [2/4], Step [1040/3844], Loss: 0.1545\n",
      "Epoch [2/4], Step [1041/3844], Loss: 0.1058\n",
      "Epoch [2/4], Step [1042/3844], Loss: 0.0990\n",
      "Epoch [2/4], Step [1043/3844], Loss: 0.2255\n",
      "Epoch [2/4], Step [1044/3844], Loss: 0.1256\n",
      "Epoch [2/4], Step [1045/3844], Loss: 0.0747\n",
      "Epoch [2/4], Step [1046/3844], Loss: 0.2131\n",
      "Epoch [2/4], Step [1047/3844], Loss: 0.1504\n",
      "Epoch [2/4], Step [1048/3844], Loss: 0.0983\n",
      "Epoch [2/4], Step [1049/3844], Loss: 0.1236\n",
      "Epoch [2/4], Step [1050/3844], Loss: 0.0900\n",
      "Epoch [2/4], Step [1051/3844], Loss: 0.1081\n",
      "Epoch [2/4], Step [1052/3844], Loss: 0.0913\n",
      "Epoch [2/4], Step [1053/3844], Loss: 0.0860\n",
      "Epoch [2/4], Step [1054/3844], Loss: 0.1196\n",
      "Epoch [2/4], Step [1055/3844], Loss: 0.1472\n",
      "Epoch [2/4], Step [1056/3844], Loss: 0.1878\n",
      "Epoch [2/4], Step [1057/3844], Loss: 0.0632\n",
      "Epoch [2/4], Step [1058/3844], Loss: 0.1531\n",
      "Epoch [2/4], Step [1059/3844], Loss: 0.0990\n",
      "Epoch [2/4], Step [1060/3844], Loss: 0.0974\n",
      "Epoch [2/4], Step [1061/3844], Loss: 0.2176\n",
      "Epoch [2/4], Step [1062/3844], Loss: 0.1576\n",
      "Epoch [2/4], Step [1063/3844], Loss: 0.1234\n",
      "Epoch [2/4], Step [1064/3844], Loss: 0.1394\n",
      "Epoch [2/4], Step [1065/3844], Loss: 0.0873\n",
      "Epoch [2/4], Step [1066/3844], Loss: 0.0939\n",
      "Epoch [2/4], Step [1067/3844], Loss: 0.1102\n",
      "Epoch [2/4], Step [1068/3844], Loss: 0.0908\n",
      "Epoch [2/4], Step [1069/3844], Loss: 0.2283\n",
      "Epoch [2/4], Step [1070/3844], Loss: 0.0651\n",
      "Epoch [2/4], Step [1071/3844], Loss: 0.1638\n",
      "Epoch [2/4], Step [1072/3844], Loss: 0.1151\n",
      "Epoch [2/4], Step [1073/3844], Loss: 0.2310\n",
      "Epoch [2/4], Step [1074/3844], Loss: 0.1509\n",
      "Epoch [2/4], Step [1075/3844], Loss: 0.0836\n",
      "Epoch [2/4], Step [1076/3844], Loss: 0.0809\n",
      "Epoch [2/4], Step [1077/3844], Loss: 0.1030\n",
      "Epoch [2/4], Step [1078/3844], Loss: 0.0824\n",
      "Epoch [2/4], Step [1079/3844], Loss: 0.0925\n",
      "Epoch [2/4], Step [1080/3844], Loss: 0.1659\n",
      "Epoch [2/4], Step [1081/3844], Loss: 0.0955\n",
      "Epoch [2/4], Step [1082/3844], Loss: 0.1070\n",
      "Epoch [2/4], Step [1083/3844], Loss: 0.1396\n",
      "Epoch [2/4], Step [1084/3844], Loss: 0.1085\n",
      "Epoch [2/4], Step [1085/3844], Loss: 0.0629\n",
      "Epoch [2/4], Step [1086/3844], Loss: 0.2237\n",
      "Epoch [2/4], Step [1087/3844], Loss: 0.0830\n",
      "Epoch [2/4], Step [1088/3844], Loss: 0.1237\n",
      "Epoch [2/4], Step [1089/3844], Loss: 0.1294\n",
      "Epoch [2/4], Step [1090/3844], Loss: 0.1312\n",
      "Epoch [2/4], Step [1091/3844], Loss: 0.1049\n",
      "Epoch [2/4], Step [1092/3844], Loss: 0.2350\n",
      "Epoch [2/4], Step [1093/3844], Loss: 0.1388\n",
      "Epoch [2/4], Step [1094/3844], Loss: 0.1008\n",
      "Epoch [2/4], Step [1095/3844], Loss: 0.0957\n",
      "Epoch [2/4], Step [1096/3844], Loss: 0.1325\n",
      "Epoch [2/4], Step [1097/3844], Loss: 0.1956\n",
      "Epoch [2/4], Step [1098/3844], Loss: 0.1320\n",
      "Epoch [2/4], Step [1099/3844], Loss: 0.1136\n",
      "Epoch [2/4], Step [1100/3844], Loss: 0.2398\n",
      "Epoch [2/4], Step [1101/3844], Loss: 0.1092\n",
      "Epoch [2/4], Step [1102/3844], Loss: 0.0955\n",
      "Epoch [2/4], Step [1103/3844], Loss: 0.0804\n",
      "Epoch [2/4], Step [1104/3844], Loss: 0.1390\n",
      "Epoch [2/4], Step [1105/3844], Loss: 0.0841\n",
      "Epoch [2/4], Step [1106/3844], Loss: 0.1262\n",
      "Epoch [2/4], Step [1107/3844], Loss: 0.1279\n",
      "Epoch [2/4], Step [1108/3844], Loss: 0.0849\n",
      "Epoch [2/4], Step [1109/3844], Loss: 0.1669\n",
      "Epoch [2/4], Step [1110/3844], Loss: 0.0789\n",
      "Epoch [2/4], Step [1111/3844], Loss: 0.0654\n",
      "Epoch [2/4], Step [1112/3844], Loss: 0.0788\n",
      "Epoch [2/4], Step [1113/3844], Loss: 0.1430\n",
      "Epoch [2/4], Step [1114/3844], Loss: 0.0662\n",
      "Epoch [2/4], Step [1115/3844], Loss: 0.1168\n",
      "Epoch [2/4], Step [1116/3844], Loss: 0.0787\n",
      "Epoch [2/4], Step [1117/3844], Loss: 0.0670\n",
      "Epoch [2/4], Step [1118/3844], Loss: 0.0927\n",
      "Epoch [2/4], Step [1119/3844], Loss: 0.1016\n",
      "Epoch [2/4], Step [1120/3844], Loss: 0.2385\n",
      "Epoch [2/4], Step [1121/3844], Loss: 0.0824\n",
      "Epoch [2/4], Step [1122/3844], Loss: 0.1625\n",
      "Epoch [2/4], Step [1123/3844], Loss: 0.1556\n",
      "Epoch [2/4], Step [1124/3844], Loss: 0.0900\n",
      "Epoch [2/4], Step [1125/3844], Loss: 0.0723\n",
      "Epoch [2/4], Step [1126/3844], Loss: 0.1411\n",
      "Epoch [2/4], Step [1127/3844], Loss: 0.0751\n",
      "Epoch [2/4], Step [1128/3844], Loss: 0.0899\n",
      "Epoch [2/4], Step [1129/3844], Loss: 0.2199\n",
      "Epoch [2/4], Step [1130/3844], Loss: 0.1501\n",
      "Epoch [2/4], Step [1131/3844], Loss: 0.2283\n",
      "Epoch [2/4], Step [1132/3844], Loss: 0.1289\n",
      "Epoch [2/4], Step [1133/3844], Loss: 0.1131\n",
      "Epoch [2/4], Step [1134/3844], Loss: 0.0764\n",
      "Epoch [2/4], Step [1135/3844], Loss: 0.0597\n",
      "Epoch [2/4], Step [1136/3844], Loss: 0.1508\n",
      "Epoch [2/4], Step [1137/3844], Loss: 0.1527\n",
      "Epoch [2/4], Step [1138/3844], Loss: 0.1663\n",
      "Epoch [2/4], Step [1139/3844], Loss: 0.1136\n",
      "Epoch [2/4], Step [1140/3844], Loss: 0.1152\n",
      "Epoch [2/4], Step [1141/3844], Loss: 0.1717\n",
      "Epoch [2/4], Step [1142/3844], Loss: 0.2240\n",
      "Epoch [2/4], Step [1143/3844], Loss: 0.1430\n",
      "Epoch [2/4], Step [1144/3844], Loss: 0.1283\n",
      "Epoch [2/4], Step [1145/3844], Loss: 0.0822\n",
      "Epoch [2/4], Step [1146/3844], Loss: 0.1441\n",
      "Epoch [2/4], Step [1147/3844], Loss: 0.1727\n",
      "Epoch [2/4], Step [1148/3844], Loss: 0.0729\n",
      "Epoch [2/4], Step [1149/3844], Loss: 0.0880\n",
      "Epoch [2/4], Step [1150/3844], Loss: 0.1688\n",
      "Epoch [2/4], Step [1151/3844], Loss: 0.0758\n",
      "Epoch [2/4], Step [1152/3844], Loss: 0.0662\n",
      "Epoch [2/4], Step [1153/3844], Loss: 0.1914\n",
      "Epoch [2/4], Step [1154/3844], Loss: 0.1601\n",
      "Epoch [2/4], Step [1155/3844], Loss: 0.2227\n",
      "Epoch [2/4], Step [1156/3844], Loss: 0.1140\n",
      "Epoch [2/4], Step [1157/3844], Loss: 0.1936\n",
      "Epoch [2/4], Step [1158/3844], Loss: 0.0772\n",
      "Epoch [2/4], Step [1159/3844], Loss: 0.0851\n",
      "Epoch [2/4], Step [1160/3844], Loss: 0.2294\n",
      "Epoch [2/4], Step [1161/3844], Loss: 0.1068\n",
      "Epoch [2/4], Step [1162/3844], Loss: 0.1705\n",
      "Epoch [2/4], Step [1163/3844], Loss: 0.1036\n",
      "Epoch [2/4], Step [1164/3844], Loss: 0.1502\n",
      "Epoch [2/4], Step [1165/3844], Loss: 0.2101\n",
      "Epoch [2/4], Step [1166/3844], Loss: 0.2048\n",
      "Epoch [2/4], Step [1167/3844], Loss: 0.1411\n",
      "Epoch [2/4], Step [1168/3844], Loss: 0.1085\n",
      "Epoch [2/4], Step [1169/3844], Loss: 0.2297\n",
      "Epoch [2/4], Step [1170/3844], Loss: 0.1454\n",
      "Epoch [2/4], Step [1171/3844], Loss: 0.0970\n",
      "Epoch [2/4], Step [1172/3844], Loss: 0.1255\n",
      "Epoch [2/4], Step [1173/3844], Loss: 0.1797\n",
      "Epoch [2/4], Step [1174/3844], Loss: 0.1122\n",
      "Epoch [2/4], Step [1175/3844], Loss: 0.1239\n",
      "Epoch [2/4], Step [1176/3844], Loss: 0.0833\n",
      "Epoch [2/4], Step [1177/3844], Loss: 0.1048\n",
      "Epoch [2/4], Step [1178/3844], Loss: 0.1189\n",
      "Epoch [2/4], Step [1179/3844], Loss: 0.1785\n",
      "Epoch [2/4], Step [1180/3844], Loss: 0.1022\n",
      "Epoch [2/4], Step [1181/3844], Loss: 0.2150\n",
      "Epoch [2/4], Step [1182/3844], Loss: 0.1441\n",
      "Epoch [2/4], Step [1183/3844], Loss: 0.2627\n",
      "Epoch [2/4], Step [1184/3844], Loss: 0.1499\n",
      "Epoch [2/4], Step [1185/3844], Loss: 0.1039\n",
      "Epoch [2/4], Step [1186/3844], Loss: 0.2423\n",
      "Epoch [2/4], Step [1187/3844], Loss: 0.1634\n",
      "Epoch [2/4], Step [1188/3844], Loss: 0.1060\n",
      "Epoch [2/4], Step [1189/3844], Loss: 0.0740\n",
      "Epoch [2/4], Step [1190/3844], Loss: 0.0958\n",
      "Epoch [2/4], Step [1191/3844], Loss: 0.0787\n",
      "Epoch [2/4], Step [1192/3844], Loss: 0.0910\n",
      "Epoch [2/4], Step [1193/3844], Loss: 0.1038\n",
      "Epoch [2/4], Step [1194/3844], Loss: 0.1462\n",
      "Epoch [2/4], Step [1195/3844], Loss: 0.1376\n",
      "Epoch [2/4], Step [1196/3844], Loss: 0.0996\n",
      "Epoch [2/4], Step [1197/3844], Loss: 0.0792\n",
      "Epoch [2/4], Step [1198/3844], Loss: 0.1681\n",
      "Epoch [2/4], Step [1199/3844], Loss: 0.1368\n",
      "Epoch [2/4], Step [1200/3844], Loss: 0.1065\n",
      "Epoch [2/4], Step [1201/3844], Loss: 0.0830\n",
      "Epoch [2/4], Step [1202/3844], Loss: 0.2244\n",
      "Epoch [2/4], Step [1203/3844], Loss: 0.0859\n",
      "Epoch [2/4], Step [1204/3844], Loss: 0.0932\n",
      "Epoch [2/4], Step [1205/3844], Loss: 0.0899\n",
      "Epoch [2/4], Step [1206/3844], Loss: 0.0786\n",
      "Epoch [2/4], Step [1207/3844], Loss: 0.1329\n",
      "Epoch [2/4], Step [1208/3844], Loss: 0.0961\n",
      "Epoch [2/4], Step [1209/3844], Loss: 0.0888\n",
      "Epoch [2/4], Step [1210/3844], Loss: 0.1264\n",
      "Epoch [2/4], Step [1211/3844], Loss: 0.0860\n",
      "Epoch [2/4], Step [1212/3844], Loss: 0.0838\n",
      "Epoch [2/4], Step [1213/3844], Loss: 0.1029\n",
      "Epoch [2/4], Step [1214/3844], Loss: 0.1299\n",
      "Epoch [2/4], Step [1215/3844], Loss: 0.1653\n",
      "Epoch [2/4], Step [1216/3844], Loss: 0.0973\n",
      "Epoch [2/4], Step [1217/3844], Loss: 0.1042\n",
      "Epoch [2/4], Step [1218/3844], Loss: 0.0951\n",
      "Epoch [2/4], Step [1219/3844], Loss: 0.1035\n",
      "Epoch [2/4], Step [1220/3844], Loss: 0.1378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/4], Step [1221/3844], Loss: 0.1130\n",
      "Epoch [2/4], Step [1222/3844], Loss: 0.1499\n",
      "Epoch [2/4], Step [1223/3844], Loss: 0.1524\n",
      "Epoch [2/4], Step [1224/3844], Loss: 0.2232\n",
      "Epoch [2/4], Step [1225/3844], Loss: 0.1218\n",
      "Epoch [2/4], Step [1226/3844], Loss: 0.0802\n",
      "Epoch [2/4], Step [1227/3844], Loss: 0.0990\n",
      "Epoch [2/4], Step [1228/3844], Loss: 0.1251\n",
      "Epoch [2/4], Step [1229/3844], Loss: 0.0969\n",
      "Epoch [2/4], Step [1230/3844], Loss: 0.1104\n",
      "Epoch [2/4], Step [1231/3844], Loss: 0.0952\n",
      "Epoch [2/4], Step [1232/3844], Loss: 0.1057\n",
      "Epoch [2/4], Step [1233/3844], Loss: 0.1173\n",
      "Epoch [2/4], Step [1234/3844], Loss: 0.1722\n",
      "Epoch [2/4], Step [1235/3844], Loss: 0.0847\n",
      "Epoch [2/4], Step [1236/3844], Loss: 0.0796\n",
      "Epoch [2/4], Step [1237/3844], Loss: 0.1654\n",
      "Epoch [2/4], Step [1238/3844], Loss: 0.0893\n",
      "Epoch [2/4], Step [1239/3844], Loss: 0.1594\n",
      "Epoch [2/4], Step [1240/3844], Loss: 0.1287\n",
      "Epoch [2/4], Step [1241/3844], Loss: 0.1623\n",
      "Epoch [2/4], Step [1242/3844], Loss: 0.1009\n",
      "Epoch [2/4], Step [1243/3844], Loss: 0.0906\n",
      "Epoch [2/4], Step [1244/3844], Loss: 0.1189\n",
      "Epoch [2/4], Step [1245/3844], Loss: 0.0686\n",
      "Epoch [2/4], Step [1246/3844], Loss: 0.1055\n",
      "Epoch [2/4], Step [1247/3844], Loss: 0.2312\n",
      "Epoch [2/4], Step [1248/3844], Loss: 0.0673\n",
      "Epoch [2/4], Step [1249/3844], Loss: 0.1034\n",
      "Epoch [2/4], Step [1250/3844], Loss: 0.0847\n",
      "Epoch [2/4], Step [1251/3844], Loss: 0.1935\n",
      "Epoch [2/4], Step [1252/3844], Loss: 0.0743\n",
      "Epoch [2/4], Step [1253/3844], Loss: 0.1853\n",
      "Epoch [2/4], Step [1254/3844], Loss: 0.0933\n",
      "Epoch [2/4], Step [1255/3844], Loss: 0.1259\n",
      "Epoch [2/4], Step [1256/3844], Loss: 0.1415\n",
      "Epoch [2/4], Step [1257/3844], Loss: 0.0933\n",
      "Epoch [2/4], Step [1258/3844], Loss: 0.0826\n",
      "Epoch [2/4], Step [1259/3844], Loss: 0.1399\n",
      "Epoch [2/4], Step [1260/3844], Loss: 0.1186\n",
      "Epoch [2/4], Step [1261/3844], Loss: 0.1053\n",
      "Epoch [2/4], Step [1262/3844], Loss: 0.0851\n",
      "Epoch [2/4], Step [1263/3844], Loss: 0.1654\n",
      "Epoch [2/4], Step [1264/3844], Loss: 0.1485\n",
      "Epoch [2/4], Step [1265/3844], Loss: 0.1025\n",
      "Epoch [2/4], Step [1266/3844], Loss: 0.1093\n",
      "Epoch [2/4], Step [1267/3844], Loss: 0.1475\n",
      "Epoch [2/4], Step [1268/3844], Loss: 0.1178\n",
      "Epoch [2/4], Step [1269/3844], Loss: 0.0870\n",
      "Epoch [2/4], Step [1270/3844], Loss: 0.1293\n",
      "Epoch [2/4], Step [1271/3844], Loss: 0.1225\n",
      "Epoch [2/4], Step [1272/3844], Loss: 0.2223\n",
      "Epoch [2/4], Step [1273/3844], Loss: 0.1267\n",
      "Epoch [2/4], Step [1274/3844], Loss: 0.0867\n",
      "Epoch [2/4], Step [1275/3844], Loss: 0.0887\n",
      "Epoch [2/4], Step [1276/3844], Loss: 0.1152\n",
      "Epoch [2/4], Step [1277/3844], Loss: 0.1525\n",
      "Epoch [2/4], Step [1278/3844], Loss: 0.0955\n",
      "Epoch [2/4], Step [1279/3844], Loss: 0.0486\n",
      "Epoch [2/4], Step [1280/3844], Loss: 0.0992\n",
      "Epoch [2/4], Step [1281/3844], Loss: 0.0828\n",
      "Epoch [2/4], Step [1282/3844], Loss: 0.1537\n",
      "Epoch [2/4], Step [1283/3844], Loss: 0.0842\n",
      "Epoch [2/4], Step [1284/3844], Loss: 0.1085\n",
      "Epoch [2/4], Step [1285/3844], Loss: 0.1329\n",
      "Epoch [2/4], Step [1286/3844], Loss: 0.1220\n",
      "Epoch [2/4], Step [1287/3844], Loss: 0.1488\n",
      "Epoch [2/4], Step [1288/3844], Loss: 0.0889\n",
      "Epoch [2/4], Step [1289/3844], Loss: 0.1795\n",
      "Epoch [2/4], Step [1290/3844], Loss: 0.0669\n",
      "Epoch [2/4], Step [1291/3844], Loss: 0.1159\n",
      "Epoch [2/4], Step [1292/3844], Loss: 0.0886\n",
      "Epoch [2/4], Step [1293/3844], Loss: 0.1962\n",
      "Epoch [2/4], Step [1294/3844], Loss: 0.1073\n",
      "Epoch [2/4], Step [1295/3844], Loss: 0.1601\n",
      "Epoch [2/4], Step [1296/3844], Loss: 0.0983\n",
      "Epoch [2/4], Step [1297/3844], Loss: 0.0711\n",
      "Epoch [2/4], Step [1298/3844], Loss: 0.0832\n",
      "Epoch [2/4], Step [1299/3844], Loss: 0.2406\n",
      "Epoch [2/4], Step [1300/3844], Loss: 0.0780\n",
      "Epoch [2/4], Step [1301/3844], Loss: 0.0909\n",
      "Epoch [2/4], Step [1302/3844], Loss: 0.0798\n",
      "Epoch [2/4], Step [1303/3844], Loss: 0.0935\n",
      "Epoch [2/4], Step [1304/3844], Loss: 0.0713\n",
      "Epoch [2/4], Step [1305/3844], Loss: 0.0666\n",
      "Epoch [2/4], Step [1306/3844], Loss: 0.0809\n",
      "Epoch [2/4], Step [1307/3844], Loss: 0.1498\n",
      "Epoch [2/4], Step [1308/3844], Loss: 0.2212\n",
      "Epoch [2/4], Step [1309/3844], Loss: 0.0836\n",
      "Epoch [2/4], Step [1310/3844], Loss: 0.0493\n",
      "Epoch [2/4], Step [1311/3844], Loss: 0.0991\n",
      "Epoch [2/4], Step [1312/3844], Loss: 0.0865\n",
      "Epoch [2/4], Step [1313/3844], Loss: 0.1236\n",
      "Epoch [2/4], Step [1314/3844], Loss: 0.0984\n",
      "Epoch [2/4], Step [1315/3844], Loss: 0.0861\n",
      "Epoch [2/4], Step [1316/3844], Loss: 0.1018\n",
      "Epoch [2/4], Step [1317/3844], Loss: 0.0790\n",
      "Epoch [2/4], Step [1318/3844], Loss: 0.1437\n",
      "Epoch [2/4], Step [1319/3844], Loss: 0.1244\n",
      "Epoch [2/4], Step [1320/3844], Loss: 0.0656\n",
      "Epoch [2/4], Step [1321/3844], Loss: 0.0946\n",
      "Epoch [2/4], Step [1322/3844], Loss: 0.1176\n",
      "Epoch [2/4], Step [1323/3844], Loss: 0.0975\n",
      "Epoch [2/4], Step [1324/3844], Loss: 0.0755\n",
      "Epoch [2/4], Step [1325/3844], Loss: 0.1461\n",
      "Epoch [2/4], Step [1326/3844], Loss: 0.0813\n",
      "Epoch [2/4], Step [1327/3844], Loss: 0.1197\n",
      "Epoch [2/4], Step [1328/3844], Loss: 0.1327\n",
      "Epoch [2/4], Step [1329/3844], Loss: 0.1402\n",
      "Epoch [2/4], Step [1330/3844], Loss: 0.0764\n",
      "Epoch [2/4], Step [1331/3844], Loss: 0.1359\n",
      "Epoch [2/4], Step [1332/3844], Loss: 0.1728\n",
      "Epoch [2/4], Step [1333/3844], Loss: 0.1739\n",
      "Epoch [2/4], Step [1334/3844], Loss: 0.0884\n",
      "Epoch [2/4], Step [1335/3844], Loss: 0.1541\n",
      "Epoch [2/4], Step [1336/3844], Loss: 0.0838\n",
      "Epoch [2/4], Step [1337/3844], Loss: 0.1021\n",
      "Epoch [2/4], Step [1338/3844], Loss: 0.1043\n",
      "Epoch [2/4], Step [1339/3844], Loss: 0.1007\n",
      "Epoch [2/4], Step [1340/3844], Loss: 0.1089\n",
      "Epoch [2/4], Step [1341/3844], Loss: 0.0864\n",
      "Epoch [2/4], Step [1342/3844], Loss: 0.0952\n",
      "Epoch [2/4], Step [1343/3844], Loss: 0.1797\n",
      "Epoch [2/4], Step [1344/3844], Loss: 0.1376\n",
      "Epoch [2/4], Step [1345/3844], Loss: 0.0963\n",
      "Epoch [2/4], Step [1346/3844], Loss: 0.0928\n",
      "Epoch [2/4], Step [1347/3844], Loss: 0.1173\n",
      "Epoch [2/4], Step [1348/3844], Loss: 0.1209\n",
      "Epoch [2/4], Step [1349/3844], Loss: 0.1494\n",
      "Epoch [2/4], Step [1350/3844], Loss: 0.1479\n",
      "Epoch [2/4], Step [1351/3844], Loss: 0.0972\n",
      "Epoch [2/4], Step [1352/3844], Loss: 0.1305\n",
      "Epoch [2/4], Step [1353/3844], Loss: 0.1382\n",
      "Epoch [2/4], Step [1354/3844], Loss: 0.2485\n",
      "Epoch [2/4], Step [1355/3844], Loss: 0.0986\n",
      "Epoch [2/4], Step [1356/3844], Loss: 0.0614\n",
      "Epoch [2/4], Step [1357/3844], Loss: 0.1411\n",
      "Epoch [2/4], Step [1358/3844], Loss: 0.0985\n",
      "Epoch [2/4], Step [1359/3844], Loss: 0.1129\n",
      "Epoch [2/4], Step [1360/3844], Loss: 0.1501\n",
      "Epoch [2/4], Step [1361/3844], Loss: 0.0914\n",
      "Epoch [2/4], Step [1362/3844], Loss: 0.0816\n",
      "Epoch [2/4], Step [1363/3844], Loss: 0.1033\n",
      "Epoch [2/4], Step [1364/3844], Loss: 0.1555\n",
      "Epoch [2/4], Step [1365/3844], Loss: 0.1239\n",
      "Epoch [2/4], Step [1366/3844], Loss: 0.1313\n",
      "Epoch [2/4], Step [1367/3844], Loss: 0.0931\n",
      "Epoch [2/4], Step [1368/3844], Loss: 0.1035\n",
      "Epoch [2/4], Step [1369/3844], Loss: 0.1170\n",
      "Epoch [2/4], Step [1370/3844], Loss: 0.1029\n",
      "Epoch [2/4], Step [1371/3844], Loss: 0.2426\n",
      "Epoch [2/4], Step [1372/3844], Loss: 0.1157\n",
      "Epoch [2/4], Step [1373/3844], Loss: 0.1068\n",
      "Epoch [2/4], Step [1374/3844], Loss: 0.1774\n",
      "Epoch [2/4], Step [1375/3844], Loss: 0.1379\n",
      "Epoch [2/4], Step [1376/3844], Loss: 0.0978\n",
      "Epoch [2/4], Step [1377/3844], Loss: 0.0431\n",
      "Epoch [2/4], Step [1378/3844], Loss: 0.1350\n",
      "Epoch [2/4], Step [1379/3844], Loss: 0.1047\n",
      "Epoch [2/4], Step [1380/3844], Loss: 0.0851\n",
      "Epoch [2/4], Step [1381/3844], Loss: 0.1079\n",
      "Epoch [2/4], Step [1382/3844], Loss: 0.1222\n",
      "Epoch [2/4], Step [1383/3844], Loss: 0.1449\n",
      "Epoch [2/4], Step [1384/3844], Loss: 0.2123\n",
      "Epoch [2/4], Step [1385/3844], Loss: 0.0925\n",
      "Epoch [2/4], Step [1386/3844], Loss: 0.0603\n",
      "Epoch [2/4], Step [1387/3844], Loss: 0.1054\n",
      "Epoch [2/4], Step [1388/3844], Loss: 0.1066\n",
      "Epoch [2/4], Step [1389/3844], Loss: 0.2270\n",
      "Epoch [2/4], Step [1390/3844], Loss: 0.2164\n",
      "Epoch [2/4], Step [1391/3844], Loss: 0.0706\n",
      "Epoch [2/4], Step [1392/3844], Loss: 0.1023\n",
      "Epoch [2/4], Step [1393/3844], Loss: 0.0859\n",
      "Epoch [2/4], Step [1394/3844], Loss: 0.0964\n",
      "Epoch [2/4], Step [1395/3844], Loss: 0.1460\n",
      "Epoch [2/4], Step [1396/3844], Loss: 0.1001\n",
      "Epoch [2/4], Step [1397/3844], Loss: 0.1884\n",
      "Epoch [2/4], Step [1398/3844], Loss: 0.1254\n",
      "Epoch [2/4], Step [1399/3844], Loss: 0.1731\n",
      "Epoch [2/4], Step [1400/3844], Loss: 0.0943\n",
      "Epoch [2/4], Step [1401/3844], Loss: 0.0972\n",
      "Epoch [2/4], Step [1402/3844], Loss: 0.0856\n",
      "Epoch [2/4], Step [1403/3844], Loss: 0.1339\n",
      "Epoch [2/4], Step [1404/3844], Loss: 0.1374\n",
      "Epoch [2/4], Step [1405/3844], Loss: 0.0865\n",
      "Epoch [2/4], Step [1406/3844], Loss: 0.1053\n",
      "Epoch [2/4], Step [1407/3844], Loss: 0.0874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/4], Step [1408/3844], Loss: 0.1023\n",
      "Epoch [2/4], Step [1409/3844], Loss: 0.1865\n",
      "Epoch [2/4], Step [1410/3844], Loss: 0.0815\n",
      "Epoch [2/4], Step [1411/3844], Loss: 0.1297\n",
      "Epoch [2/4], Step [1412/3844], Loss: 0.0859\n",
      "Epoch [2/4], Step [1413/3844], Loss: 0.1567\n",
      "Epoch [2/4], Step [1414/3844], Loss: 0.1151\n",
      "Epoch [2/4], Step [1415/3844], Loss: 0.1419\n",
      "Epoch [2/4], Step [1416/3844], Loss: 0.1563\n",
      "Epoch [2/4], Step [1417/3844], Loss: 0.1526\n",
      "Epoch [2/4], Step [1418/3844], Loss: 0.1073\n",
      "Epoch [2/4], Step [1419/3844], Loss: 0.2394\n",
      "Epoch [2/4], Step [1420/3844], Loss: 0.0940\n",
      "Epoch [2/4], Step [1421/3844], Loss: 0.2416\n",
      "Epoch [2/4], Step [1422/3844], Loss: 0.0834\n",
      "Epoch [2/4], Step [1423/3844], Loss: 0.1176\n",
      "Epoch [2/4], Step [1424/3844], Loss: 0.0823\n",
      "Epoch [2/4], Step [1425/3844], Loss: 0.1496\n",
      "Epoch [2/4], Step [1426/3844], Loss: 0.1283\n",
      "Epoch [2/4], Step [1427/3844], Loss: 0.2099\n",
      "Epoch [2/4], Step [1428/3844], Loss: 0.0758\n",
      "Epoch [2/4], Step [1429/3844], Loss: 0.1620\n",
      "Epoch [2/4], Step [1430/3844], Loss: 0.0634\n",
      "Epoch [2/4], Step [1431/3844], Loss: 0.1426\n",
      "Epoch [2/4], Step [1432/3844], Loss: 0.2208\n",
      "Epoch [2/4], Step [1433/3844], Loss: 0.1601\n",
      "Epoch [2/4], Step [1434/3844], Loss: 0.1419\n",
      "Epoch [2/4], Step [1435/3844], Loss: 0.1042\n",
      "Epoch [2/4], Step [1436/3844], Loss: 0.1442\n",
      "Epoch [2/4], Step [1437/3844], Loss: 0.0843\n",
      "Epoch [2/4], Step [1438/3844], Loss: 0.1114\n",
      "Epoch [2/4], Step [1439/3844], Loss: 0.0718\n",
      "Epoch [2/4], Step [1440/3844], Loss: 0.1140\n",
      "Epoch [2/4], Step [1441/3844], Loss: 0.0858\n",
      "Epoch [2/4], Step [1442/3844], Loss: 0.1534\n",
      "Epoch [2/4], Step [1443/3844], Loss: 0.0792\n",
      "Epoch [2/4], Step [1444/3844], Loss: 0.2316\n",
      "Epoch [2/4], Step [1445/3844], Loss: 0.0701\n",
      "Epoch [2/4], Step [1446/3844], Loss: 0.1265\n",
      "Epoch [2/4], Step [1447/3844], Loss: 0.0813\n",
      "Epoch [2/4], Step [1448/3844], Loss: 0.1448\n",
      "Epoch [2/4], Step [1449/3844], Loss: 0.0873\n",
      "Epoch [2/4], Step [1450/3844], Loss: 0.0807\n",
      "Epoch [2/4], Step [1451/3844], Loss: 0.1212\n",
      "Epoch [2/4], Step [1452/3844], Loss: 0.0892\n",
      "Epoch [2/4], Step [1453/3844], Loss: 0.1653\n",
      "Epoch [2/4], Step [1454/3844], Loss: 0.1620\n",
      "Epoch [2/4], Step [1455/3844], Loss: 0.1479\n",
      "Epoch [2/4], Step [1456/3844], Loss: 0.0943\n",
      "Epoch [2/4], Step [1457/3844], Loss: 0.1440\n",
      "Epoch [2/4], Step [1458/3844], Loss: 0.1520\n",
      "Epoch [2/4], Step [1459/3844], Loss: 0.2281\n",
      "Epoch [2/4], Step [1460/3844], Loss: 0.0964\n",
      "Epoch [2/4], Step [1461/3844], Loss: 0.0888\n",
      "Epoch [2/4], Step [1462/3844], Loss: 0.1569\n",
      "Epoch [2/4], Step [1463/3844], Loss: 0.0782\n",
      "Epoch [2/4], Step [1464/3844], Loss: 0.1376\n",
      "Epoch [2/4], Step [1465/3844], Loss: 0.0768\n",
      "Epoch [2/4], Step [1466/3844], Loss: 0.0927\n",
      "Epoch [2/4], Step [1467/3844], Loss: 0.1331\n",
      "Epoch [2/4], Step [1468/3844], Loss: 0.0844\n",
      "Epoch [2/4], Step [1469/3844], Loss: 0.0956\n",
      "Epoch [2/4], Step [1470/3844], Loss: 0.1568\n",
      "Epoch [2/4], Step [1471/3844], Loss: 0.0815\n",
      "Epoch [2/4], Step [1472/3844], Loss: 0.0781\n",
      "Epoch [2/4], Step [1473/3844], Loss: 0.0607\n",
      "Epoch [2/4], Step [1474/3844], Loss: 0.0953\n",
      "Epoch [2/4], Step [1475/3844], Loss: 0.1047\n",
      "Epoch [2/4], Step [1476/3844], Loss: 0.1643\n",
      "Epoch [2/4], Step [1477/3844], Loss: 0.0897\n",
      "Epoch [2/4], Step [1478/3844], Loss: 0.1795\n",
      "Epoch [2/4], Step [1479/3844], Loss: 0.1451\n",
      "Epoch [2/4], Step [1480/3844], Loss: 0.1274\n",
      "Epoch [2/4], Step [1481/3844], Loss: 0.2186\n",
      "Epoch [2/4], Step [1482/3844], Loss: 0.1587\n",
      "Epoch [2/4], Step [1483/3844], Loss: 0.1382\n",
      "Epoch [2/4], Step [1484/3844], Loss: 0.0919\n",
      "Epoch [2/4], Step [1485/3844], Loss: 0.1618\n",
      "Epoch [2/4], Step [1486/3844], Loss: 0.0939\n",
      "Epoch [2/4], Step [1487/3844], Loss: 0.1597\n",
      "Epoch [2/4], Step [1488/3844], Loss: 0.1648\n",
      "Epoch [2/4], Step [1489/3844], Loss: 0.0922\n",
      "Epoch [2/4], Step [1490/3844], Loss: 0.1583\n",
      "Epoch [2/4], Step [1491/3844], Loss: 0.0832\n",
      "Epoch [2/4], Step [1492/3844], Loss: 0.1745\n",
      "Epoch [2/4], Step [1493/3844], Loss: 0.1070\n",
      "Epoch [2/4], Step [1494/3844], Loss: 0.0968\n",
      "Epoch [2/4], Step [1495/3844], Loss: 0.1346\n",
      "Epoch [2/4], Step [1496/3844], Loss: 0.1602\n",
      "Epoch [2/4], Step [1497/3844], Loss: 0.0853\n",
      "Epoch [2/4], Step [1498/3844], Loss: 0.1410\n",
      "Epoch [2/4], Step [1499/3844], Loss: 0.0960\n",
      "Epoch [2/4], Step [1500/3844], Loss: 0.1571\n",
      "Epoch [2/4], Step [1501/3844], Loss: 0.2177\n",
      "Epoch [2/4], Step [1502/3844], Loss: 0.1027\n",
      "Epoch [2/4], Step [1503/3844], Loss: 0.0829\n",
      "Epoch [2/4], Step [1504/3844], Loss: 0.1367\n",
      "Epoch [2/4], Step [1505/3844], Loss: 0.0723\n",
      "Epoch [2/4], Step [1506/3844], Loss: 0.1352\n",
      "Epoch [2/4], Step [1507/3844], Loss: 0.0706\n",
      "Epoch [2/4], Step [1508/3844], Loss: 0.1370\n",
      "Epoch [2/4], Step [1509/3844], Loss: 0.0671\n",
      "Epoch [2/4], Step [1510/3844], Loss: 0.0621\n",
      "Epoch [2/4], Step [1511/3844], Loss: 0.0860\n",
      "Epoch [2/4], Step [1512/3844], Loss: 0.0846\n",
      "Epoch [2/4], Step [1513/3844], Loss: 0.2000\n",
      "Epoch [2/4], Step [1514/3844], Loss: 0.1126\n",
      "Epoch [2/4], Step [1515/3844], Loss: 0.1021\n",
      "Epoch [2/4], Step [1516/3844], Loss: 0.0861\n",
      "Epoch [2/4], Step [1517/3844], Loss: 0.2113\n",
      "Epoch [2/4], Step [1518/3844], Loss: 0.1818\n",
      "Epoch [2/4], Step [1519/3844], Loss: 0.2079\n",
      "Epoch [2/4], Step [1520/3844], Loss: 0.0983\n",
      "Epoch [2/4], Step [1521/3844], Loss: 0.1517\n",
      "Epoch [2/4], Step [1522/3844], Loss: 0.1348\n",
      "Epoch [2/4], Step [1523/3844], Loss: 0.1107\n",
      "Epoch [2/4], Step [1524/3844], Loss: 0.0913\n",
      "Epoch [2/4], Step [1525/3844], Loss: 0.0935\n",
      "Epoch [2/4], Step [1526/3844], Loss: 0.2426\n",
      "Epoch [2/4], Step [1527/3844], Loss: 0.1250\n",
      "Epoch [2/4], Step [1528/3844], Loss: 0.1395\n",
      "Epoch [2/4], Step [1529/3844], Loss: 0.0666\n",
      "Epoch [2/4], Step [1530/3844], Loss: 0.1686\n",
      "Epoch [2/4], Step [1531/3844], Loss: 0.1367\n",
      "Epoch [2/4], Step [1532/3844], Loss: 0.0712\n",
      "Epoch [2/4], Step [1533/3844], Loss: 0.0663\n",
      "Epoch [2/4], Step [1534/3844], Loss: 0.0639\n",
      "Epoch [2/4], Step [1535/3844], Loss: 0.1631\n",
      "Epoch [2/4], Step [1536/3844], Loss: 0.0582\n",
      "Epoch [2/4], Step [1537/3844], Loss: 0.1391\n",
      "Epoch [2/4], Step [1538/3844], Loss: 0.2536\n",
      "Epoch [2/4], Step [1539/3844], Loss: 0.2193\n",
      "Epoch [2/4], Step [1540/3844], Loss: 0.0902\n",
      "Epoch [2/4], Step [1541/3844], Loss: 0.1019\n",
      "Epoch [2/4], Step [1542/3844], Loss: 0.0922\n",
      "Epoch [2/4], Step [1543/3844], Loss: 0.0972\n",
      "Epoch [2/4], Step [1544/3844], Loss: 0.1579\n",
      "Epoch [2/4], Step [1545/3844], Loss: 0.0696\n",
      "Epoch [2/4], Step [1546/3844], Loss: 0.1514\n",
      "Epoch [2/4], Step [1547/3844], Loss: 0.2125\n",
      "Epoch [2/4], Step [1548/3844], Loss: 0.1425\n",
      "Epoch [2/4], Step [1549/3844], Loss: 0.0931\n",
      "Epoch [2/4], Step [1550/3844], Loss: 0.0815\n",
      "Epoch [2/4], Step [1551/3844], Loss: 0.0901\n",
      "Epoch [2/4], Step [1552/3844], Loss: 0.1696\n",
      "Epoch [2/4], Step [1553/3844], Loss: 0.2179\n",
      "Epoch [2/4], Step [1554/3844], Loss: 0.0999\n",
      "Epoch [2/4], Step [1555/3844], Loss: 0.0790\n",
      "Epoch [2/4], Step [1556/3844], Loss: 0.0862\n",
      "Epoch [2/4], Step [1557/3844], Loss: 0.1885\n",
      "Epoch [2/4], Step [1558/3844], Loss: 0.1566\n",
      "Epoch [2/4], Step [1559/3844], Loss: 0.1088\n",
      "Epoch [2/4], Step [1560/3844], Loss: 0.0878\n",
      "Epoch [2/4], Step [1561/3844], Loss: 0.0998\n",
      "Epoch [2/4], Step [1562/3844], Loss: 0.1319\n",
      "Epoch [2/4], Step [1563/3844], Loss: 0.0782\n",
      "Epoch [2/4], Step [1564/3844], Loss: 0.1749\n",
      "Epoch [2/4], Step [1565/3844], Loss: 0.0528\n",
      "Epoch [2/4], Step [1566/3844], Loss: 0.2142\n",
      "Epoch [2/4], Step [1567/3844], Loss: 0.0730\n",
      "Epoch [2/4], Step [1568/3844], Loss: 0.0911\n",
      "Epoch [2/4], Step [1569/3844], Loss: 0.0884\n",
      "Epoch [2/4], Step [1570/3844], Loss: 0.0824\n",
      "Epoch [2/4], Step [1571/3844], Loss: 0.1393\n",
      "Epoch [2/4], Step [1572/3844], Loss: 0.1096\n",
      "Epoch [2/4], Step [1573/3844], Loss: 0.0617\n",
      "Epoch [2/4], Step [1574/3844], Loss: 0.1734\n",
      "Epoch [2/4], Step [1575/3844], Loss: 0.1664\n",
      "Epoch [2/4], Step [1576/3844], Loss: 0.0903\n",
      "Epoch [2/4], Step [1577/3844], Loss: 0.1395\n",
      "Epoch [2/4], Step [1578/3844], Loss: 0.1017\n",
      "Epoch [2/4], Step [1579/3844], Loss: 0.1444\n",
      "Epoch [2/4], Step [1580/3844], Loss: 0.1562\n",
      "Epoch [2/4], Step [1581/3844], Loss: 0.1035\n",
      "Epoch [2/4], Step [1582/3844], Loss: 0.1194\n",
      "Epoch [2/4], Step [1583/3844], Loss: 0.2280\n",
      "Epoch [2/4], Step [1584/3844], Loss: 0.0852\n",
      "Epoch [2/4], Step [1585/3844], Loss: 0.2470\n",
      "Epoch [2/4], Step [1586/3844], Loss: 0.0864\n",
      "Epoch [2/4], Step [1587/3844], Loss: 0.1700\n",
      "Epoch [2/4], Step [1588/3844], Loss: 0.1607\n",
      "Epoch [2/4], Step [1589/3844], Loss: 0.1093\n",
      "Epoch [2/4], Step [1590/3844], Loss: 0.0733\n",
      "Epoch [2/4], Step [1591/3844], Loss: 0.1522\n",
      "Epoch [2/4], Step [1592/3844], Loss: 0.0881\n",
      "Epoch [2/4], Step [1593/3844], Loss: 0.1477\n",
      "Epoch [2/4], Step [1594/3844], Loss: 0.1247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/4], Step [1595/3844], Loss: 0.1554\n",
      "Epoch [2/4], Step [1596/3844], Loss: 0.0589\n",
      "Epoch [2/4], Step [1597/3844], Loss: 0.1704\n",
      "Epoch [2/4], Step [1598/3844], Loss: 0.0948\n",
      "Epoch [2/4], Step [1599/3844], Loss: 0.1716\n",
      "Epoch [2/4], Step [1600/3844], Loss: 0.1529\n",
      "Epoch [2/4], Step [1601/3844], Loss: 0.1127\n",
      "Epoch [2/4], Step [1602/3844], Loss: 0.0786\n",
      "Epoch [2/4], Step [1603/3844], Loss: 0.1476\n",
      "Epoch [2/4], Step [1604/3844], Loss: 0.2114\n",
      "Epoch [2/4], Step [1605/3844], Loss: 0.0779\n",
      "Epoch [2/4], Step [1606/3844], Loss: 0.0902\n",
      "Epoch [2/4], Step [1607/3844], Loss: 0.1409\n",
      "Epoch [2/4], Step [1608/3844], Loss: 0.1545\n",
      "Epoch [2/4], Step [1609/3844], Loss: 0.1091\n",
      "Epoch [2/4], Step [1610/3844], Loss: 0.2115\n",
      "Epoch [2/4], Step [1611/3844], Loss: 0.1903\n",
      "Epoch [2/4], Step [1612/3844], Loss: 0.2165\n",
      "Epoch [2/4], Step [1613/3844], Loss: 0.0817\n",
      "Epoch [2/4], Step [1614/3844], Loss: 0.0817\n",
      "Epoch [2/4], Step [1615/3844], Loss: 0.0862\n",
      "Epoch [2/4], Step [1616/3844], Loss: 0.0844\n",
      "Epoch [2/4], Step [1617/3844], Loss: 0.1044\n",
      "Epoch [2/4], Step [1618/3844], Loss: 0.1532\n",
      "Epoch [2/4], Step [1619/3844], Loss: 0.1024\n",
      "Epoch [2/4], Step [1620/3844], Loss: 0.2132\n",
      "Epoch [2/4], Step [1621/3844], Loss: 0.1528\n",
      "Epoch [2/4], Step [1622/3844], Loss: 0.1152\n",
      "Epoch [2/4], Step [1623/3844], Loss: 0.1738\n",
      "Epoch [2/4], Step [1624/3844], Loss: 0.0841\n",
      "Epoch [2/4], Step [1625/3844], Loss: 0.0841\n",
      "Epoch [2/4], Step [1626/3844], Loss: 0.0802\n",
      "Epoch [2/4], Step [1627/3844], Loss: 0.1493\n",
      "Epoch [2/4], Step [1628/3844], Loss: 0.2031\n",
      "Epoch [2/4], Step [1629/3844], Loss: 0.1150\n",
      "Epoch [2/4], Step [1630/3844], Loss: 0.0821\n",
      "Epoch [2/4], Step [1631/3844], Loss: 0.1086\n",
      "Epoch [2/4], Step [1632/3844], Loss: 0.1795\n",
      "Epoch [2/4], Step [1633/3844], Loss: 0.0683\n",
      "Epoch [2/4], Step [1634/3844], Loss: 0.1097\n",
      "Epoch [2/4], Step [1635/3844], Loss: 0.2101\n",
      "Epoch [2/4], Step [1636/3844], Loss: 0.1616\n",
      "Epoch [2/4], Step [1637/3844], Loss: 0.0996\n",
      "Epoch [2/4], Step [1638/3844], Loss: 0.1136\n",
      "Epoch [2/4], Step [1639/3844], Loss: 0.0872\n",
      "Epoch [2/4], Step [1640/3844], Loss: 0.0916\n",
      "Epoch [2/4], Step [1641/3844], Loss: 0.1188\n",
      "Epoch [2/4], Step [1642/3844], Loss: 0.0970\n",
      "Epoch [2/4], Step [1643/3844], Loss: 0.1454\n",
      "Epoch [2/4], Step [1644/3844], Loss: 0.1549\n",
      "Epoch [2/4], Step [1645/3844], Loss: 0.0811\n",
      "Epoch [2/4], Step [1646/3844], Loss: 0.1114\n",
      "Epoch [2/4], Step [1647/3844], Loss: 0.1113\n",
      "Epoch [2/4], Step [1648/3844], Loss: 0.1087\n",
      "Epoch [2/4], Step [1649/3844], Loss: 0.0985\n",
      "Epoch [2/4], Step [1650/3844], Loss: 0.1200\n",
      "Epoch [2/4], Step [1651/3844], Loss: 0.0878\n",
      "Epoch [2/4], Step [1652/3844], Loss: 0.1222\n",
      "Epoch [2/4], Step [1653/3844], Loss: 0.1089\n",
      "Epoch [2/4], Step [1654/3844], Loss: 0.0868\n",
      "Epoch [2/4], Step [1655/3844], Loss: 0.1379\n",
      "Epoch [2/4], Step [1656/3844], Loss: 0.0857\n",
      "Epoch [2/4], Step [1657/3844], Loss: 0.1185\n",
      "Epoch [2/4], Step [1658/3844], Loss: 0.0815\n",
      "Epoch [2/4], Step [1659/3844], Loss: 0.1246\n",
      "Epoch [2/4], Step [1660/3844], Loss: 0.0935\n",
      "Epoch [2/4], Step [1661/3844], Loss: 0.1449\n",
      "Epoch [2/4], Step [1662/3844], Loss: 0.1017\n",
      "Epoch [2/4], Step [1663/3844], Loss: 0.0846\n",
      "Epoch [2/4], Step [1664/3844], Loss: 0.0984\n",
      "Epoch [2/4], Step [1665/3844], Loss: 0.1852\n",
      "Epoch [2/4], Step [1666/3844], Loss: 0.0598\n",
      "Epoch [2/4], Step [1667/3844], Loss: 0.1468\n",
      "Epoch [2/4], Step [1668/3844], Loss: 0.1765\n",
      "Epoch [2/4], Step [1669/3844], Loss: 0.1027\n",
      "Epoch [2/4], Step [1670/3844], Loss: 0.1520\n",
      "Epoch [2/4], Step [1671/3844], Loss: 0.1416\n",
      "Epoch [2/4], Step [1672/3844], Loss: 0.1019\n",
      "Epoch [2/4], Step [1673/3844], Loss: 0.0624\n",
      "Epoch [2/4], Step [1674/3844], Loss: 0.0696\n",
      "Epoch [2/4], Step [1675/3844], Loss: 0.0746\n",
      "Epoch [2/4], Step [1676/3844], Loss: 0.1052\n",
      "Epoch [2/4], Step [1677/3844], Loss: 0.0646\n",
      "Epoch [2/4], Step [1678/3844], Loss: 0.0898\n",
      "Epoch [2/4], Step [1679/3844], Loss: 0.1605\n",
      "Epoch [2/4], Step [1680/3844], Loss: 0.0970\n",
      "Epoch [2/4], Step [1681/3844], Loss: 0.0797\n",
      "Epoch [2/4], Step [1682/3844], Loss: 0.0699\n",
      "Epoch [2/4], Step [1683/3844], Loss: 0.1629\n",
      "Epoch [2/4], Step [1684/3844], Loss: 0.0983\n",
      "Epoch [2/4], Step [1685/3844], Loss: 0.1265\n",
      "Epoch [2/4], Step [1686/3844], Loss: 0.0981\n",
      "Epoch [2/4], Step [1687/3844], Loss: 0.1395\n",
      "Epoch [2/4], Step [1688/3844], Loss: 0.0840\n",
      "Epoch [2/4], Step [1689/3844], Loss: 0.0599\n",
      "Epoch [2/4], Step [1690/3844], Loss: 0.0793\n",
      "Epoch [2/4], Step [1691/3844], Loss: 0.1466\n",
      "Epoch [2/4], Step [1692/3844], Loss: 0.1872\n",
      "Epoch [2/4], Step [1693/3844], Loss: 0.1440\n",
      "Epoch [2/4], Step [1694/3844], Loss: 0.1299\n",
      "Epoch [2/4], Step [1695/3844], Loss: 0.0923\n",
      "Epoch [2/4], Step [1696/3844], Loss: 0.1720\n",
      "Epoch [2/4], Step [1697/3844], Loss: 0.0949\n",
      "Epoch [2/4], Step [1698/3844], Loss: 0.1142\n",
      "Epoch [2/4], Step [1699/3844], Loss: 0.1264\n",
      "Epoch [2/4], Step [1700/3844], Loss: 0.1542\n",
      "Epoch [2/4], Step [1701/3844], Loss: 0.1977\n",
      "Epoch [2/4], Step [1702/3844], Loss: 0.1137\n",
      "Epoch [2/4], Step [1703/3844], Loss: 0.1351\n",
      "Epoch [2/4], Step [1704/3844], Loss: 0.1521\n",
      "Epoch [2/4], Step [1705/3844], Loss: 0.1108\n",
      "Epoch [2/4], Step [1706/3844], Loss: 0.1116\n",
      "Epoch [2/4], Step [1707/3844], Loss: 0.1428\n",
      "Epoch [2/4], Step [1708/3844], Loss: 0.1385\n",
      "Epoch [2/4], Step [1709/3844], Loss: 0.1382\n",
      "Epoch [2/4], Step [1710/3844], Loss: 0.1649\n",
      "Epoch [2/4], Step [1711/3844], Loss: 0.2099\n",
      "Epoch [2/4], Step [1712/3844], Loss: 0.0840\n",
      "Epoch [2/4], Step [1713/3844], Loss: 0.0903\n",
      "Epoch [2/4], Step [1714/3844], Loss: 0.0875\n",
      "Epoch [2/4], Step [1715/3844], Loss: 0.0996\n",
      "Epoch [2/4], Step [1716/3844], Loss: 0.1179\n",
      "Epoch [2/4], Step [1717/3844], Loss: 0.1730\n",
      "Epoch [2/4], Step [1718/3844], Loss: 0.1308\n",
      "Epoch [2/4], Step [1719/3844], Loss: 0.1055\n",
      "Epoch [2/4], Step [1720/3844], Loss: 0.0853\n",
      "Epoch [2/4], Step [1721/3844], Loss: 0.0949\n",
      "Epoch [2/4], Step [1722/3844], Loss: 0.1199\n",
      "Epoch [2/4], Step [1723/3844], Loss: 0.0889\n",
      "Epoch [2/4], Step [1724/3844], Loss: 0.1609\n",
      "Epoch [2/4], Step [1725/3844], Loss: 0.1526\n",
      "Epoch [2/4], Step [1726/3844], Loss: 0.1017\n",
      "Epoch [2/4], Step [1727/3844], Loss: 0.0821\n",
      "Epoch [2/4], Step [1728/3844], Loss: 0.1087\n",
      "Epoch [2/4], Step [1729/3844], Loss: 0.1494\n",
      "Epoch [2/4], Step [1730/3844], Loss: 0.1393\n",
      "Epoch [2/4], Step [1731/3844], Loss: 0.0944\n",
      "Epoch [2/4], Step [1732/3844], Loss: 0.1327\n",
      "Epoch [2/4], Step [1733/3844], Loss: 0.1126\n",
      "Epoch [2/4], Step [1734/3844], Loss: 0.0843\n",
      "Epoch [2/4], Step [1735/3844], Loss: 0.0950\n",
      "Epoch [2/4], Step [1736/3844], Loss: 0.1046\n",
      "Epoch [2/4], Step [1737/3844], Loss: 0.1730\n",
      "Epoch [2/4], Step [1738/3844], Loss: 0.0837\n",
      "Epoch [2/4], Step [1739/3844], Loss: 0.2161\n",
      "Epoch [2/4], Step [1740/3844], Loss: 0.0948\n",
      "Epoch [2/4], Step [1741/3844], Loss: 0.1514\n",
      "Epoch [2/4], Step [1742/3844], Loss: 0.1549\n",
      "Epoch [2/4], Step [1743/3844], Loss: 0.0583\n",
      "Epoch [2/4], Step [1744/3844], Loss: 0.1074\n",
      "Epoch [2/4], Step [1745/3844], Loss: 0.0839\n",
      "Epoch [2/4], Step [1746/3844], Loss: 0.1454\n",
      "Epoch [2/4], Step [1747/3844], Loss: 0.0785\n",
      "Epoch [2/4], Step [1748/3844], Loss: 0.2234\n",
      "Epoch [2/4], Step [1749/3844], Loss: 0.1077\n",
      "Epoch [2/4], Step [1750/3844], Loss: 0.1958\n",
      "Epoch [2/4], Step [1751/3844], Loss: 0.0808\n",
      "Epoch [2/4], Step [1752/3844], Loss: 0.0807\n",
      "Epoch [2/4], Step [1753/3844], Loss: 0.0685\n",
      "Epoch [2/4], Step [1754/3844], Loss: 0.1508\n",
      "Epoch [2/4], Step [1755/3844], Loss: 0.0620\n",
      "Epoch [2/4], Step [1756/3844], Loss: 0.0612\n",
      "Epoch [2/4], Step [1757/3844], Loss: 0.1352\n",
      "Epoch [2/4], Step [1758/3844], Loss: 0.1656\n",
      "Epoch [2/4], Step [1759/3844], Loss: 0.1256\n",
      "Epoch [2/4], Step [1760/3844], Loss: 0.0772\n",
      "Epoch [2/4], Step [1761/3844], Loss: 0.1374\n",
      "Epoch [2/4], Step [1762/3844], Loss: 0.0762\n",
      "Epoch [2/4], Step [1763/3844], Loss: 0.0957\n",
      "Epoch [2/4], Step [1764/3844], Loss: 0.0881\n",
      "Epoch [2/4], Step [1765/3844], Loss: 0.2103\n",
      "Epoch [2/4], Step [1766/3844], Loss: 0.1409\n",
      "Epoch [2/4], Step [1767/3844], Loss: 0.2014\n",
      "Epoch [2/4], Step [1768/3844], Loss: 0.1372\n",
      "Epoch [2/4], Step [1769/3844], Loss: 0.0875\n",
      "Epoch [2/4], Step [1770/3844], Loss: 0.1650\n",
      "Epoch [2/4], Step [1771/3844], Loss: 0.1515\n",
      "Epoch [2/4], Step [1772/3844], Loss: 0.0787\n",
      "Epoch [2/4], Step [1773/3844], Loss: 0.1484\n",
      "Epoch [2/4], Step [1774/3844], Loss: 0.0747\n",
      "Epoch [2/4], Step [1775/3844], Loss: 0.0880\n",
      "Epoch [2/4], Step [1776/3844], Loss: 0.2037\n",
      "Epoch [2/4], Step [1777/3844], Loss: 0.0546\n",
      "Epoch [2/4], Step [1778/3844], Loss: 0.2147\n",
      "Epoch [2/4], Step [1779/3844], Loss: 0.1066\n",
      "Epoch [2/4], Step [1780/3844], Loss: 0.1124\n",
      "Epoch [2/4], Step [1781/3844], Loss: 0.1690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/4], Step [1782/3844], Loss: 0.2222\n",
      "Epoch [2/4], Step [1783/3844], Loss: 0.0886\n",
      "Epoch [2/4], Step [1784/3844], Loss: 0.0960\n",
      "Epoch [2/4], Step [1785/3844], Loss: 0.1370\n",
      "Epoch [2/4], Step [1786/3844], Loss: 0.0788\n",
      "Epoch [2/4], Step [1787/3844], Loss: 0.0569\n",
      "Epoch [2/4], Step [1788/3844], Loss: 0.0961\n",
      "Epoch [2/4], Step [1789/3844], Loss: 0.0842\n",
      "Epoch [2/4], Step [1790/3844], Loss: 0.1717\n",
      "Epoch [2/4], Step [1791/3844], Loss: 0.1833\n",
      "Epoch [2/4], Step [1792/3844], Loss: 0.1109\n",
      "Epoch [2/4], Step [1793/3844], Loss: 0.1654\n",
      "Epoch [2/4], Step [1794/3844], Loss: 0.1581\n",
      "Epoch [2/4], Step [1795/3844], Loss: 0.1650\n",
      "Epoch [2/4], Step [1796/3844], Loss: 0.1491\n",
      "Epoch [2/4], Step [1797/3844], Loss: 0.1600\n",
      "Epoch [2/4], Step [1798/3844], Loss: 0.0822\n",
      "Epoch [2/4], Step [1799/3844], Loss: 0.2207\n",
      "Epoch [2/4], Step [1800/3844], Loss: 0.2146\n",
      "Epoch [2/4], Step [1801/3844], Loss: 0.0875\n",
      "Epoch [2/4], Step [1802/3844], Loss: 0.1424\n",
      "Epoch [2/4], Step [1803/3844], Loss: 0.1272\n",
      "Epoch [2/4], Step [1804/3844], Loss: 0.0921\n",
      "Epoch [2/4], Step [1805/3844], Loss: 0.0942\n",
      "Epoch [2/4], Step [1806/3844], Loss: 0.1077\n",
      "Epoch [2/4], Step [1807/3844], Loss: 0.0866\n",
      "Epoch [2/4], Step [1808/3844], Loss: 0.1563\n",
      "Epoch [2/4], Step [1809/3844], Loss: 0.1429\n",
      "Epoch [2/4], Step [1810/3844], Loss: 0.1443\n",
      "Epoch [2/4], Step [1811/3844], Loss: 0.1455\n",
      "Epoch [2/4], Step [1812/3844], Loss: 0.1790\n",
      "Epoch [2/4], Step [1813/3844], Loss: 0.2081\n",
      "Epoch [2/4], Step [1814/3844], Loss: 0.0926\n",
      "Epoch [2/4], Step [1815/3844], Loss: 0.0928\n",
      "Epoch [2/4], Step [1816/3844], Loss: 0.1483\n",
      "Epoch [2/4], Step [1817/3844], Loss: 0.2493\n",
      "Epoch [2/4], Step [1818/3844], Loss: 0.0820\n",
      "Epoch [2/4], Step [1819/3844], Loss: 0.2343\n",
      "Epoch [2/4], Step [1820/3844], Loss: 0.1006\n",
      "Epoch [2/4], Step [1821/3844], Loss: 0.1820\n",
      "Epoch [2/4], Step [1822/3844], Loss: 0.1086\n",
      "Epoch [2/4], Step [1823/3844], Loss: 0.0712\n",
      "Epoch [2/4], Step [1824/3844], Loss: 0.1286\n",
      "Epoch [2/4], Step [1825/3844], Loss: 0.0652\n",
      "Epoch [2/4], Step [1826/3844], Loss: 0.1769\n",
      "Epoch [2/4], Step [1827/3844], Loss: 0.1022\n",
      "Epoch [2/4], Step [1828/3844], Loss: 0.0976\n",
      "Epoch [2/4], Step [1829/3844], Loss: 0.0977\n",
      "Epoch [2/4], Step [1830/3844], Loss: 0.2025\n",
      "Epoch [2/4], Step [1831/3844], Loss: 0.0948\n",
      "Epoch [2/4], Step [1832/3844], Loss: 0.0981\n",
      "Epoch [2/4], Step [1833/3844], Loss: 0.1500\n",
      "Epoch [2/4], Step [1834/3844], Loss: 0.1102\n",
      "Epoch [2/4], Step [1835/3844], Loss: 0.1077\n",
      "Epoch [2/4], Step [1836/3844], Loss: 0.1030\n",
      "Epoch [2/4], Step [1837/3844], Loss: 0.1288\n",
      "Epoch [2/4], Step [1838/3844], Loss: 0.1322\n",
      "Epoch [2/4], Step [1839/3844], Loss: 0.0774\n",
      "Epoch [2/4], Step [1840/3844], Loss: 0.2109\n",
      "Epoch [2/4], Step [1841/3844], Loss: 0.0973\n",
      "Epoch [2/4], Step [1842/3844], Loss: 0.0863\n",
      "Epoch [2/4], Step [1843/3844], Loss: 0.0638\n",
      "Epoch [2/4], Step [1844/3844], Loss: 0.2088\n",
      "Epoch [2/4], Step [1845/3844], Loss: 0.1096\n",
      "Epoch [2/4], Step [1846/3844], Loss: 0.1652\n",
      "Epoch [2/4], Step [1847/3844], Loss: 0.0830\n",
      "Epoch [2/4], Step [1848/3844], Loss: 0.0892\n",
      "Epoch [2/4], Step [1849/3844], Loss: 0.1726\n",
      "Epoch [2/4], Step [1850/3844], Loss: 0.2091\n",
      "Epoch [2/4], Step [1851/3844], Loss: 0.1475\n",
      "Epoch [2/4], Step [1852/3844], Loss: 0.0835\n",
      "Epoch [2/4], Step [1853/3844], Loss: 0.1046\n",
      "Epoch [2/4], Step [1854/3844], Loss: 0.0864\n",
      "Epoch [2/4], Step [1855/3844], Loss: 0.0702\n",
      "Epoch [2/4], Step [1856/3844], Loss: 0.1030\n",
      "Epoch [2/4], Step [1857/3844], Loss: 0.2261\n",
      "Epoch [2/4], Step [1858/3844], Loss: 0.0908\n",
      "Epoch [2/4], Step [1859/3844], Loss: 0.1247\n",
      "Epoch [2/4], Step [1860/3844], Loss: 0.0928\n",
      "Epoch [2/4], Step [1861/3844], Loss: 0.0980\n",
      "Epoch [2/4], Step [1862/3844], Loss: 0.1226\n",
      "Epoch [2/4], Step [1863/3844], Loss: 0.0860\n",
      "Epoch [2/4], Step [1864/3844], Loss: 0.0772\n",
      "Epoch [2/4], Step [1865/3844], Loss: 0.1327\n",
      "Epoch [2/4], Step [1866/3844], Loss: 0.1636\n",
      "Epoch [2/4], Step [1867/3844], Loss: 0.1299\n",
      "Epoch [2/4], Step [1868/3844], Loss: 0.1143\n",
      "Epoch [2/4], Step [1869/3844], Loss: 0.1409\n",
      "Epoch [2/4], Step [1870/3844], Loss: 0.1435\n",
      "Epoch [2/4], Step [1871/3844], Loss: 0.0785\n",
      "Epoch [2/4], Step [1872/3844], Loss: 0.1230\n",
      "Epoch [2/4], Step [1873/3844], Loss: 0.1364\n",
      "Epoch [2/4], Step [1874/3844], Loss: 0.1729\n",
      "Epoch [2/4], Step [1875/3844], Loss: 0.1277\n",
      "Epoch [2/4], Step [1876/3844], Loss: 0.1657\n",
      "Epoch [2/4], Step [1877/3844], Loss: 0.1397\n",
      "Epoch [2/4], Step [1878/3844], Loss: 0.1229\n",
      "Epoch [2/4], Step [1879/3844], Loss: 0.0880\n",
      "Epoch [2/4], Step [1880/3844], Loss: 0.1329\n",
      "Epoch [2/4], Step [1881/3844], Loss: 0.0906\n",
      "Epoch [2/4], Step [1882/3844], Loss: 0.0844\n",
      "Epoch [2/4], Step [1883/3844], Loss: 0.0807\n",
      "Epoch [2/4], Step [1884/3844], Loss: 0.0681\n",
      "Epoch [2/4], Step [1885/3844], Loss: 0.1570\n",
      "Epoch [2/4], Step [1886/3844], Loss: 0.1620\n",
      "Epoch [2/4], Step [1887/3844], Loss: 0.0946\n",
      "Epoch [2/4], Step [1888/3844], Loss: 0.1213\n",
      "Epoch [2/4], Step [1889/3844], Loss: 0.1262\n",
      "Epoch [2/4], Step [1890/3844], Loss: 0.2367\n",
      "Epoch [2/4], Step [1891/3844], Loss: 0.0786\n",
      "Epoch [2/4], Step [1892/3844], Loss: 0.0880\n",
      "Epoch [2/4], Step [1893/3844], Loss: 0.1359\n",
      "Epoch [2/4], Step [1894/3844], Loss: 0.1050\n",
      "Epoch [2/4], Step [1895/3844], Loss: 0.1042\n",
      "Epoch [2/4], Step [1896/3844], Loss: 0.1386\n",
      "Epoch [2/4], Step [1897/3844], Loss: 0.1389\n",
      "Epoch [2/4], Step [1898/3844], Loss: 0.1472\n",
      "Epoch [2/4], Step [1899/3844], Loss: 0.0904\n",
      "Epoch [2/4], Step [1900/3844], Loss: 0.2150\n",
      "Epoch [2/4], Step [1901/3844], Loss: 0.1579\n",
      "Epoch [2/4], Step [1902/3844], Loss: 0.1137\n",
      "Epoch [2/4], Step [1903/3844], Loss: 0.0883\n",
      "Epoch [2/4], Step [1904/3844], Loss: 0.2007\n",
      "Epoch [2/4], Step [1905/3844], Loss: 0.2011\n",
      "Epoch [2/4], Step [1906/3844], Loss: 0.0703\n",
      "Epoch [2/4], Step [1907/3844], Loss: 0.1578\n",
      "Epoch [2/4], Step [1908/3844], Loss: 0.0918\n",
      "Epoch [2/4], Step [1909/3844], Loss: 0.1638\n",
      "Epoch [2/4], Step [1910/3844], Loss: 0.1068\n",
      "Epoch [2/4], Step [1911/3844], Loss: 0.0613\n",
      "Epoch [2/4], Step [1912/3844], Loss: 0.0939\n",
      "Epoch [2/4], Step [1913/3844], Loss: 0.1518\n",
      "Epoch [2/4], Step [1914/3844], Loss: 0.0643\n",
      "Epoch [2/4], Step [1915/3844], Loss: 0.1209\n",
      "Epoch [2/4], Step [1916/3844], Loss: 0.1199\n",
      "Epoch [2/4], Step [1917/3844], Loss: 0.1167\n",
      "Epoch [2/4], Step [1918/3844], Loss: 0.0920\n",
      "Epoch [2/4], Step [1919/3844], Loss: 0.0957\n",
      "Epoch [2/4], Step [1920/3844], Loss: 0.1827\n",
      "Epoch [2/4], Step [1921/3844], Loss: 0.0971\n",
      "Epoch [2/4], Step [1922/3844], Loss: 0.1955\n",
      "Epoch [2/4], Step [1923/3844], Loss: 0.0765\n",
      "Epoch [2/4], Step [1924/3844], Loss: 0.0861\n",
      "Epoch [2/4], Step [1925/3844], Loss: 0.1471\n",
      "Epoch [2/4], Step [1926/3844], Loss: 0.2045\n",
      "Epoch [2/4], Step [1927/3844], Loss: 0.0952\n",
      "Epoch [2/4], Step [1928/3844], Loss: 0.0757\n",
      "Epoch [2/4], Step [1929/3844], Loss: 0.1597\n",
      "Epoch [2/4], Step [1930/3844], Loss: 0.1928\n",
      "Epoch [2/4], Step [1931/3844], Loss: 0.1495\n",
      "Epoch [2/4], Step [1932/3844], Loss: 0.1411\n",
      "Epoch [2/4], Step [1933/3844], Loss: 0.0974\n",
      "Epoch [2/4], Step [1934/3844], Loss: 0.0934\n",
      "Epoch [2/4], Step [1935/3844], Loss: 0.1095\n",
      "Epoch [2/4], Step [1936/3844], Loss: 0.1124\n",
      "Epoch [2/4], Step [1937/3844], Loss: 0.1295\n",
      "Epoch [2/4], Step [1938/3844], Loss: 0.1646\n",
      "Epoch [2/4], Step [1939/3844], Loss: 0.0984\n",
      "Epoch [2/4], Step [1940/3844], Loss: 0.0695\n",
      "Epoch [2/4], Step [1941/3844], Loss: 0.0871\n",
      "Epoch [2/4], Step [1942/3844], Loss: 0.0836\n",
      "Epoch [2/4], Step [1943/3844], Loss: 0.1001\n",
      "Epoch [2/4], Step [1944/3844], Loss: 0.1033\n",
      "Epoch [2/4], Step [1945/3844], Loss: 0.1038\n",
      "Epoch [2/4], Step [1946/3844], Loss: 0.0815\n",
      "Epoch [2/4], Step [1947/3844], Loss: 0.1147\n",
      "Epoch [2/4], Step [1948/3844], Loss: 0.0629\n",
      "Epoch [2/4], Step [1949/3844], Loss: 0.1374\n",
      "Epoch [2/4], Step [1950/3844], Loss: 0.0903\n",
      "Epoch [2/4], Step [1951/3844], Loss: 0.1052\n",
      "Epoch [2/4], Step [1952/3844], Loss: 0.0804\n",
      "Epoch [2/4], Step [1953/3844], Loss: 0.0692\n",
      "Epoch [2/4], Step [1954/3844], Loss: 0.0645\n",
      "Epoch [2/4], Step [1955/3844], Loss: 0.1125\n",
      "Epoch [2/4], Step [1956/3844], Loss: 0.1565\n",
      "Epoch [2/4], Step [1957/3844], Loss: 0.1537\n",
      "Epoch [2/4], Step [1958/3844], Loss: 0.1024\n",
      "Epoch [2/4], Step [1959/3844], Loss: 0.0959\n",
      "Epoch [2/4], Step [1960/3844], Loss: 0.1430\n",
      "Epoch [2/4], Step [1961/3844], Loss: 0.1104\n",
      "Epoch [2/4], Step [1962/3844], Loss: 0.1553\n",
      "Epoch [2/4], Step [1963/3844], Loss: 0.1388\n",
      "Epoch [2/4], Step [1964/3844], Loss: 0.1672\n",
      "Epoch [2/4], Step [1965/3844], Loss: 0.0885\n",
      "Epoch [2/4], Step [1966/3844], Loss: 0.0867\n",
      "Epoch [2/4], Step [1967/3844], Loss: 0.0598\n",
      "Epoch [2/4], Step [1968/3844], Loss: 0.1398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/4], Step [1969/3844], Loss: 0.1187\n",
      "Epoch [2/4], Step [1970/3844], Loss: 0.0931\n",
      "Epoch [2/4], Step [1971/3844], Loss: 0.0805\n",
      "Epoch [2/4], Step [1972/3844], Loss: 0.1341\n",
      "Epoch [2/4], Step [1973/3844], Loss: 0.1478\n",
      "Epoch [2/4], Step [1974/3844], Loss: 0.1391\n",
      "Epoch [2/4], Step [1975/3844], Loss: 0.0988\n",
      "Epoch [2/4], Step [1976/3844], Loss: 0.1214\n",
      "Epoch [2/4], Step [1977/3844], Loss: 0.1810\n",
      "Epoch [2/4], Step [1978/3844], Loss: 0.1014\n",
      "Epoch [2/4], Step [1979/3844], Loss: 0.0860\n",
      "Epoch [2/4], Step [1980/3844], Loss: 0.1748\n",
      "Epoch [2/4], Step [1981/3844], Loss: 0.1536\n",
      "Epoch [2/4], Step [1982/3844], Loss: 0.0911\n",
      "Epoch [2/4], Step [1983/3844], Loss: 0.1231\n",
      "Epoch [2/4], Step [1984/3844], Loss: 0.1506\n",
      "Epoch [2/4], Step [1985/3844], Loss: 0.1154\n",
      "Epoch [2/4], Step [1986/3844], Loss: 0.0676\n",
      "Epoch [2/4], Step [1987/3844], Loss: 0.2441\n",
      "Epoch [2/4], Step [1988/3844], Loss: 0.1434\n",
      "Epoch [2/4], Step [1989/3844], Loss: 0.1071\n",
      "Epoch [2/4], Step [1990/3844], Loss: 0.0956\n",
      "Epoch [2/4], Step [1991/3844], Loss: 0.1263\n",
      "Epoch [2/4], Step [1992/3844], Loss: 0.1066\n",
      "Epoch [2/4], Step [1993/3844], Loss: 0.1043\n",
      "Epoch [2/4], Step [1994/3844], Loss: 0.1436\n",
      "Epoch [2/4], Step [1995/3844], Loss: 0.0701\n",
      "Epoch [2/4], Step [1996/3844], Loss: 0.0805\n",
      "Epoch [2/4], Step [1997/3844], Loss: 0.0846\n",
      "Epoch [2/4], Step [1998/3844], Loss: 0.1946\n",
      "Epoch [2/4], Step [1999/3844], Loss: 0.0905\n",
      "Epoch [2/4], Step [2000/3844], Loss: 0.1058\n",
      "Epoch [2/4], Step [2001/3844], Loss: 0.1459\n",
      "Epoch [2/4], Step [2002/3844], Loss: 0.0958\n",
      "Epoch [2/4], Step [2003/3844], Loss: 0.1883\n",
      "Epoch [2/4], Step [2004/3844], Loss: 0.0932\n",
      "Epoch [2/4], Step [2005/3844], Loss: 0.1234\n",
      "Epoch [2/4], Step [2006/3844], Loss: 0.1832\n",
      "Epoch [2/4], Step [2007/3844], Loss: 0.1530\n",
      "Epoch [2/4], Step [2008/3844], Loss: 0.0721\n",
      "Epoch [2/4], Step [2009/3844], Loss: 0.2174\n",
      "Epoch [2/4], Step [2010/3844], Loss: 0.0876\n",
      "Epoch [2/4], Step [2011/3844], Loss: 0.0736\n",
      "Epoch [2/4], Step [2012/3844], Loss: 0.0718\n",
      "Epoch [2/4], Step [2013/3844], Loss: 0.1497\n",
      "Epoch [2/4], Step [2014/3844], Loss: 0.1672\n",
      "Epoch [2/4], Step [2015/3844], Loss: 0.1599\n",
      "Epoch [2/4], Step [2016/3844], Loss: 0.1269\n",
      "Epoch [2/4], Step [2017/3844], Loss: 0.0857\n",
      "Epoch [2/4], Step [2018/3844], Loss: 0.2395\n",
      "Epoch [2/4], Step [2019/3844], Loss: 0.0830\n",
      "Epoch [2/4], Step [2020/3844], Loss: 0.0807\n",
      "Epoch [2/4], Step [2021/3844], Loss: 0.1274\n",
      "Epoch [2/4], Step [2022/3844], Loss: 0.0780\n",
      "Epoch [2/4], Step [2023/3844], Loss: 0.1756\n",
      "Epoch [2/4], Step [2024/3844], Loss: 0.0629\n",
      "Epoch [2/4], Step [2025/3844], Loss: 0.2111\n",
      "Epoch [2/4], Step [2026/3844], Loss: 0.2022\n",
      "Epoch [2/4], Step [2027/3844], Loss: 0.1482\n",
      "Epoch [2/4], Step [2028/3844], Loss: 0.0923\n",
      "Epoch [2/4], Step [2029/3844], Loss: 0.1137\n",
      "Epoch [2/4], Step [2030/3844], Loss: 0.0786\n",
      "Epoch [2/4], Step [2031/3844], Loss: 0.1134\n",
      "Epoch [2/4], Step [2032/3844], Loss: 0.1541\n",
      "Epoch [2/4], Step [2033/3844], Loss: 0.0984\n",
      "Epoch [2/4], Step [2034/3844], Loss: 0.0822\n",
      "Epoch [2/4], Step [2035/3844], Loss: 0.0959\n",
      "Epoch [2/4], Step [2036/3844], Loss: 0.1432\n",
      "Epoch [2/4], Step [2037/3844], Loss: 0.0862\n",
      "Epoch [2/4], Step [2038/3844], Loss: 0.0877\n",
      "Epoch [2/4], Step [2039/3844], Loss: 0.1123\n",
      "Epoch [2/4], Step [2040/3844], Loss: 0.0886\n",
      "Epoch [2/4], Step [2041/3844], Loss: 0.1366\n",
      "Epoch [2/4], Step [2042/3844], Loss: 0.1339\n",
      "Epoch [2/4], Step [2043/3844], Loss: 0.2055\n",
      "Epoch [2/4], Step [2044/3844], Loss: 0.2314\n",
      "Epoch [2/4], Step [2045/3844], Loss: 0.2226\n",
      "Epoch [2/4], Step [2046/3844], Loss: 0.2089\n",
      "Epoch [2/4], Step [2047/3844], Loss: 0.0638\n",
      "Epoch [2/4], Step [2048/3844], Loss: 0.1427\n",
      "Epoch [2/4], Step [2049/3844], Loss: 0.2011\n",
      "Epoch [2/4], Step [2050/3844], Loss: 0.0820\n",
      "Epoch [2/4], Step [2051/3844], Loss: 0.0997\n",
      "Epoch [2/4], Step [2052/3844], Loss: 0.0761\n",
      "Epoch [2/4], Step [2053/3844], Loss: 0.0860\n",
      "Epoch [2/4], Step [2054/3844], Loss: 0.0565\n",
      "Epoch [2/4], Step [2055/3844], Loss: 0.1715\n",
      "Epoch [2/4], Step [2056/3844], Loss: 0.1103\n",
      "Epoch [2/4], Step [2057/3844], Loss: 0.0882\n",
      "Epoch [2/4], Step [2058/3844], Loss: 0.1317\n",
      "Epoch [2/4], Step [2059/3844], Loss: 0.1562\n",
      "Epoch [2/4], Step [2060/3844], Loss: 0.0612\n",
      "Epoch [2/4], Step [2061/3844], Loss: 0.1026\n",
      "Epoch [2/4], Step [2062/3844], Loss: 0.2031\n",
      "Epoch [2/4], Step [2063/3844], Loss: 0.1574\n",
      "Epoch [2/4], Step [2064/3844], Loss: 0.0910\n",
      "Epoch [2/4], Step [2065/3844], Loss: 0.1562\n",
      "Epoch [2/4], Step [2066/3844], Loss: 0.1305\n",
      "Epoch [2/4], Step [2067/3844], Loss: 0.0977\n",
      "Epoch [2/4], Step [2068/3844], Loss: 0.1398\n",
      "Epoch [2/4], Step [2069/3844], Loss: 0.0787\n",
      "Epoch [2/4], Step [2070/3844], Loss: 0.1142\n",
      "Epoch [2/4], Step [2071/3844], Loss: 0.1197\n",
      "Epoch [2/4], Step [2072/3844], Loss: 0.1299\n",
      "Epoch [2/4], Step [2073/3844], Loss: 0.1777\n",
      "Epoch [2/4], Step [2074/3844], Loss: 0.0938\n",
      "Epoch [2/4], Step [2075/3844], Loss: 0.1021\n",
      "Epoch [2/4], Step [2076/3844], Loss: 0.0994\n",
      "Epoch [2/4], Step [2077/3844], Loss: 0.1008\n",
      "Epoch [2/4], Step [2078/3844], Loss: 0.1111\n",
      "Epoch [2/4], Step [2079/3844], Loss: 0.1047\n",
      "Epoch [2/4], Step [2080/3844], Loss: 0.0952\n",
      "Epoch [2/4], Step [2081/3844], Loss: 0.0761\n",
      "Epoch [2/4], Step [2082/3844], Loss: 0.0871\n",
      "Epoch [2/4], Step [2083/3844], Loss: 0.1550\n",
      "Epoch [2/4], Step [2084/3844], Loss: 0.0681\n",
      "Epoch [2/4], Step [2085/3844], Loss: 0.1567\n",
      "Epoch [2/4], Step [2086/3844], Loss: 0.0726\n",
      "Epoch [2/4], Step [2087/3844], Loss: 0.0973\n",
      "Epoch [2/4], Step [2088/3844], Loss: 0.1435\n",
      "Epoch [2/4], Step [2089/3844], Loss: 0.0784\n",
      "Epoch [2/4], Step [2090/3844], Loss: 0.0938\n",
      "Epoch [2/4], Step [2091/3844], Loss: 0.1414\n",
      "Epoch [2/4], Step [2092/3844], Loss: 0.1470\n",
      "Epoch [2/4], Step [2093/3844], Loss: 0.0806\n",
      "Epoch [2/4], Step [2094/3844], Loss: 0.1198\n",
      "Epoch [2/4], Step [2095/3844], Loss: 0.1390\n",
      "Epoch [2/4], Step [2096/3844], Loss: 0.1338\n",
      "Epoch [2/4], Step [2097/3844], Loss: 0.0986\n",
      "Epoch [2/4], Step [2098/3844], Loss: 0.1132\n",
      "Epoch [2/4], Step [2099/3844], Loss: 0.1917\n",
      "Epoch [2/4], Step [2100/3844], Loss: 0.1447\n",
      "Epoch [2/4], Step [2101/3844], Loss: 0.2184\n",
      "Epoch [2/4], Step [2102/3844], Loss: 0.0808\n",
      "Epoch [2/4], Step [2103/3844], Loss: 0.0915\n",
      "Epoch [2/4], Step [2104/3844], Loss: 0.0673\n",
      "Epoch [2/4], Step [2105/3844], Loss: 0.1378\n",
      "Epoch [2/4], Step [2106/3844], Loss: 0.0773\n",
      "Epoch [2/4], Step [2107/3844], Loss: 0.1044\n",
      "Epoch [2/4], Step [2108/3844], Loss: 0.1142\n",
      "Epoch [2/4], Step [2109/3844], Loss: 0.0661\n",
      "Epoch [2/4], Step [2110/3844], Loss: 0.0717\n",
      "Epoch [2/4], Step [2111/3844], Loss: 0.0780\n",
      "Epoch [2/4], Step [2112/3844], Loss: 0.1060\n",
      "Epoch [2/4], Step [2113/3844], Loss: 0.0663\n",
      "Epoch [2/4], Step [2114/3844], Loss: 0.1004\n",
      "Epoch [2/4], Step [2115/3844], Loss: 0.2092\n",
      "Epoch [2/4], Step [2116/3844], Loss: 0.1532\n",
      "Epoch [2/4], Step [2117/3844], Loss: 0.1344\n",
      "Epoch [2/4], Step [2118/3844], Loss: 0.1448\n",
      "Epoch [2/4], Step [2119/3844], Loss: 0.1397\n",
      "Epoch [2/4], Step [2120/3844], Loss: 0.0914\n",
      "Epoch [2/4], Step [2121/3844], Loss: 0.1465\n",
      "Epoch [2/4], Step [2122/3844], Loss: 0.1650\n",
      "Epoch [2/4], Step [2123/3844], Loss: 0.1120\n",
      "Epoch [2/4], Step [2124/3844], Loss: 0.1035\n",
      "Epoch [2/4], Step [2125/3844], Loss: 0.1488\n",
      "Epoch [2/4], Step [2126/3844], Loss: 0.1666\n",
      "Epoch [2/4], Step [2127/3844], Loss: 0.0764\n",
      "Epoch [2/4], Step [2128/3844], Loss: 0.1321\n",
      "Epoch [2/4], Step [2129/3844], Loss: 0.1156\n",
      "Epoch [2/4], Step [2130/3844], Loss: 0.0918\n",
      "Epoch [2/4], Step [2131/3844], Loss: 0.1400\n",
      "Epoch [2/4], Step [2132/3844], Loss: 0.0737\n",
      "Epoch [2/4], Step [2133/3844], Loss: 0.0686\n",
      "Epoch [2/4], Step [2134/3844], Loss: 0.0688\n",
      "Epoch [2/4], Step [2135/3844], Loss: 0.0707\n",
      "Epoch [2/4], Step [2136/3844], Loss: 0.1255\n",
      "Epoch [2/4], Step [2137/3844], Loss: 0.0915\n",
      "Epoch [2/4], Step [2138/3844], Loss: 0.0748\n",
      "Epoch [2/4], Step [2139/3844], Loss: 0.1270\n",
      "Epoch [2/4], Step [2140/3844], Loss: 0.0738\n",
      "Epoch [2/4], Step [2141/3844], Loss: 0.1423\n",
      "Epoch [2/4], Step [2142/3844], Loss: 0.0986\n",
      "Epoch [2/4], Step [2143/3844], Loss: 0.0706\n",
      "Epoch [2/4], Step [2144/3844], Loss: 0.2215\n",
      "Epoch [2/4], Step [2145/3844], Loss: 0.0882\n",
      "Epoch [2/4], Step [2146/3844], Loss: 0.0747\n",
      "Epoch [2/4], Step [2147/3844], Loss: 0.1098\n",
      "Epoch [2/4], Step [2148/3844], Loss: 0.0749\n",
      "Epoch [2/4], Step [2149/3844], Loss: 0.1974\n",
      "Epoch [2/4], Step [2150/3844], Loss: 0.1629\n",
      "Epoch [2/4], Step [2151/3844], Loss: 0.2278\n",
      "Epoch [2/4], Step [2152/3844], Loss: 0.1071\n",
      "Epoch [2/4], Step [2153/3844], Loss: 0.1625\n",
      "Epoch [2/4], Step [2154/3844], Loss: 0.1547\n",
      "Epoch [2/4], Step [2155/3844], Loss: 0.1029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/4], Step [2156/3844], Loss: 0.1622\n",
      "Epoch [2/4], Step [2157/3844], Loss: 0.1320\n",
      "Epoch [2/4], Step [2158/3844], Loss: 0.1295\n",
      "Epoch [2/4], Step [2159/3844], Loss: 0.0874\n",
      "Epoch [2/4], Step [2160/3844], Loss: 0.1204\n",
      "Epoch [2/4], Step [2161/3844], Loss: 0.1060\n",
      "Epoch [2/4], Step [2162/3844], Loss: 0.1452\n",
      "Epoch [2/4], Step [2163/3844], Loss: 0.0904\n",
      "Epoch [2/4], Step [2164/3844], Loss: 0.0838\n",
      "Epoch [2/4], Step [2165/3844], Loss: 0.1482\n",
      "Epoch [2/4], Step [2166/3844], Loss: 0.0946\n",
      "Epoch [2/4], Step [2167/3844], Loss: 0.0868\n",
      "Epoch [2/4], Step [2168/3844], Loss: 0.2360\n",
      "Epoch [2/4], Step [2169/3844], Loss: 0.1567\n",
      "Epoch [2/4], Step [2170/3844], Loss: 0.0920\n",
      "Epoch [2/4], Step [2171/3844], Loss: 0.1719\n",
      "Epoch [2/4], Step [2172/3844], Loss: 0.2231\n",
      "Epoch [2/4], Step [2173/3844], Loss: 0.1388\n",
      "Epoch [2/4], Step [2174/3844], Loss: 0.1252\n",
      "Epoch [2/4], Step [2175/3844], Loss: 0.0626\n",
      "Epoch [2/4], Step [2176/3844], Loss: 0.0989\n",
      "Epoch [2/4], Step [2177/3844], Loss: 0.0896\n",
      "Epoch [2/4], Step [2178/3844], Loss: 0.1029\n",
      "Epoch [2/4], Step [2179/3844], Loss: 0.1518\n",
      "Epoch [2/4], Step [2180/3844], Loss: 0.0807\n",
      "Epoch [2/4], Step [2181/3844], Loss: 0.1167\n",
      "Epoch [2/4], Step [2182/3844], Loss: 0.1269\n",
      "Epoch [2/4], Step [2183/3844], Loss: 0.2027\n",
      "Epoch [2/4], Step [2184/3844], Loss: 0.1092\n",
      "Epoch [2/4], Step [2185/3844], Loss: 0.1050\n",
      "Epoch [2/4], Step [2186/3844], Loss: 0.1059\n",
      "Epoch [2/4], Step [2187/3844], Loss: 0.1721\n",
      "Epoch [2/4], Step [2188/3844], Loss: 0.2115\n",
      "Epoch [2/4], Step [2189/3844], Loss: 0.0764\n",
      "Epoch [2/4], Step [2190/3844], Loss: 0.1050\n",
      "Epoch [2/4], Step [2191/3844], Loss: 0.2088\n",
      "Epoch [2/4], Step [2192/3844], Loss: 0.1607\n",
      "Epoch [2/4], Step [2193/3844], Loss: 0.1543\n",
      "Epoch [2/4], Step [2194/3844], Loss: 0.0675\n",
      "Epoch [2/4], Step [2195/3844], Loss: 0.0892\n",
      "Epoch [2/4], Step [2196/3844], Loss: 0.0820\n",
      "Epoch [2/4], Step [2197/3844], Loss: 0.0967\n",
      "Epoch [2/4], Step [2198/3844], Loss: 0.2132\n",
      "Epoch [2/4], Step [2199/3844], Loss: 0.0686\n",
      "Epoch [2/4], Step [2200/3844], Loss: 0.0872\n",
      "Epoch [2/4], Step [2201/3844], Loss: 0.1524\n",
      "Epoch [2/4], Step [2202/3844], Loss: 0.0832\n",
      "Epoch [2/4], Step [2203/3844], Loss: 0.0765\n",
      "Epoch [2/4], Step [2204/3844], Loss: 0.0811\n",
      "Epoch [2/4], Step [2205/3844], Loss: 0.0749\n",
      "Epoch [2/4], Step [2206/3844], Loss: 0.0852\n",
      "Epoch [2/4], Step [2207/3844], Loss: 0.1243\n",
      "Epoch [2/4], Step [2208/3844], Loss: 0.0941\n",
      "Epoch [2/4], Step [2209/3844], Loss: 0.1094\n",
      "Epoch [2/4], Step [2210/3844], Loss: 0.1382\n",
      "Epoch [2/4], Step [2211/3844], Loss: 0.2265\n",
      "Epoch [2/4], Step [2212/3844], Loss: 0.1472\n",
      "Epoch [2/4], Step [2213/3844], Loss: 0.1327\n",
      "Epoch [2/4], Step [2214/3844], Loss: 0.1278\n",
      "Epoch [2/4], Step [2215/3844], Loss: 0.0908\n",
      "Epoch [2/4], Step [2216/3844], Loss: 0.1099\n",
      "Epoch [2/4], Step [2217/3844], Loss: 0.1081\n",
      "Epoch [2/4], Step [2218/3844], Loss: 0.2101\n",
      "Epoch [2/4], Step [2219/3844], Loss: 0.1257\n",
      "Epoch [2/4], Step [2220/3844], Loss: 0.0718\n",
      "Epoch [2/4], Step [2221/3844], Loss: 0.1085\n",
      "Epoch [2/4], Step [2222/3844], Loss: 0.0899\n",
      "Epoch [2/4], Step [2223/3844], Loss: 0.0796\n",
      "Epoch [2/4], Step [2224/3844], Loss: 0.0581\n",
      "Epoch [2/4], Step [2225/3844], Loss: 0.0802\n",
      "Epoch [2/4], Step [2226/3844], Loss: 0.1268\n",
      "Epoch [2/4], Step [2227/3844], Loss: 0.2034\n",
      "Epoch [2/4], Step [2228/3844], Loss: 0.1319\n",
      "Epoch [2/4], Step [2229/3844], Loss: 0.1091\n",
      "Epoch [2/4], Step [2230/3844], Loss: 0.1729\n",
      "Epoch [2/4], Step [2231/3844], Loss: 0.1012\n",
      "Epoch [2/4], Step [2232/3844], Loss: 0.0711\n",
      "Epoch [2/4], Step [2233/3844], Loss: 0.1117\n",
      "Epoch [2/4], Step [2234/3844], Loss: 0.1535\n",
      "Epoch [2/4], Step [2235/3844], Loss: 0.1558\n",
      "Epoch [2/4], Step [2236/3844], Loss: 0.2040\n",
      "Epoch [2/4], Step [2237/3844], Loss: 0.0939\n",
      "Epoch [2/4], Step [2238/3844], Loss: 0.0882\n",
      "Epoch [2/4], Step [2239/3844], Loss: 0.1446\n",
      "Epoch [2/4], Step [2240/3844], Loss: 0.1182\n",
      "Epoch [2/4], Step [2241/3844], Loss: 0.1265\n",
      "Epoch [2/4], Step [2242/3844], Loss: 0.0919\n",
      "Epoch [2/4], Step [2243/3844], Loss: 0.1078\n",
      "Epoch [2/4], Step [2244/3844], Loss: 0.1616\n",
      "Epoch [2/4], Step [2245/3844], Loss: 0.1005\n",
      "Epoch [2/4], Step [2246/3844], Loss: 0.2101\n",
      "Epoch [2/4], Step [2247/3844], Loss: 0.0815\n",
      "Epoch [2/4], Step [2248/3844], Loss: 0.0837\n",
      "Epoch [2/4], Step [2249/3844], Loss: 0.1757\n",
      "Epoch [2/4], Step [2250/3844], Loss: 0.2292\n",
      "Epoch [2/4], Step [2251/3844], Loss: 0.1019\n",
      "Epoch [2/4], Step [2252/3844], Loss: 0.0774\n",
      "Epoch [2/4], Step [2253/3844], Loss: 0.0750\n",
      "Epoch [2/4], Step [2254/3844], Loss: 0.1950\n",
      "Epoch [2/4], Step [2255/3844], Loss: 0.1347\n",
      "Epoch [2/4], Step [2256/3844], Loss: 0.1182\n",
      "Epoch [2/4], Step [2257/3844], Loss: 0.0837\n",
      "Epoch [2/4], Step [2258/3844], Loss: 0.0998\n",
      "Epoch [2/4], Step [2259/3844], Loss: 0.1102\n",
      "Epoch [2/4], Step [2260/3844], Loss: 0.1537\n",
      "Epoch [2/4], Step [2261/3844], Loss: 0.1226\n",
      "Epoch [2/4], Step [2262/3844], Loss: 0.1981\n",
      "Epoch [2/4], Step [2263/3844], Loss: 0.1085\n",
      "Epoch [2/4], Step [2264/3844], Loss: 0.1176\n",
      "Epoch [2/4], Step [2265/3844], Loss: 0.0799\n",
      "Epoch [2/4], Step [2266/3844], Loss: 0.0721\n",
      "Epoch [2/4], Step [2267/3844], Loss: 0.0809\n",
      "Epoch [2/4], Step [2268/3844], Loss: 0.1381\n",
      "Epoch [2/4], Step [2269/3844], Loss: 0.0735\n",
      "Epoch [2/4], Step [2270/3844], Loss: 0.0736\n",
      "Epoch [2/4], Step [2271/3844], Loss: 0.0926\n",
      "Epoch [2/4], Step [2272/3844], Loss: 0.1025\n",
      "Epoch [2/4], Step [2273/3844], Loss: 0.1652\n",
      "Epoch [2/4], Step [2274/3844], Loss: 0.1227\n",
      "Epoch [2/4], Step [2275/3844], Loss: 0.1147\n",
      "Epoch [2/4], Step [2276/3844], Loss: 0.1557\n",
      "Epoch [2/4], Step [2277/3844], Loss: 0.1303\n",
      "Epoch [2/4], Step [2278/3844], Loss: 0.1626\n",
      "Epoch [2/4], Step [2279/3844], Loss: 0.1019\n",
      "Epoch [2/4], Step [2280/3844], Loss: 0.1548\n",
      "Epoch [2/4], Step [2281/3844], Loss: 0.0814\n",
      "Epoch [2/4], Step [2282/3844], Loss: 0.0602\n",
      "Epoch [2/4], Step [2283/3844], Loss: 0.1449\n",
      "Epoch [2/4], Step [2284/3844], Loss: 0.0649\n",
      "Epoch [2/4], Step [2285/3844], Loss: 0.0800\n",
      "Epoch [2/4], Step [2286/3844], Loss: 0.1091\n",
      "Epoch [2/4], Step [2287/3844], Loss: 0.1616\n",
      "Epoch [2/4], Step [2288/3844], Loss: 0.0966\n",
      "Epoch [2/4], Step [2289/3844], Loss: 0.0935\n",
      "Epoch [2/4], Step [2290/3844], Loss: 0.1675\n",
      "Epoch [2/4], Step [2291/3844], Loss: 0.0759\n",
      "Epoch [2/4], Step [2292/3844], Loss: 0.0746\n",
      "Epoch [2/4], Step [2293/3844], Loss: 0.2022\n",
      "Epoch [2/4], Step [2294/3844], Loss: 0.2071\n",
      "Epoch [2/4], Step [2295/3844], Loss: 0.1427\n",
      "Epoch [2/4], Step [2296/3844], Loss: 0.0956\n",
      "Epoch [2/4], Step [2297/3844], Loss: 0.1461\n",
      "Epoch [2/4], Step [2298/3844], Loss: 0.0912\n",
      "Epoch [2/4], Step [2299/3844], Loss: 0.1585\n",
      "Epoch [2/4], Step [2300/3844], Loss: 0.1487\n",
      "Epoch [2/4], Step [2301/3844], Loss: 0.1046\n",
      "Epoch [2/4], Step [2302/3844], Loss: 0.1589\n",
      "Epoch [2/4], Step [2303/3844], Loss: 0.1323\n",
      "Epoch [2/4], Step [2304/3844], Loss: 0.1910\n",
      "Epoch [2/4], Step [2305/3844], Loss: 0.0978\n",
      "Epoch [2/4], Step [2306/3844], Loss: 0.1497\n",
      "Epoch [2/4], Step [2307/3844], Loss: 0.1514\n",
      "Epoch [2/4], Step [2308/3844], Loss: 0.0652\n",
      "Epoch [2/4], Step [2309/3844], Loss: 0.1511\n",
      "Epoch [2/4], Step [2310/3844], Loss: 0.1413\n",
      "Epoch [2/4], Step [2311/3844], Loss: 0.2228\n",
      "Epoch [2/4], Step [2312/3844], Loss: 0.1162\n",
      "Epoch [2/4], Step [2313/3844], Loss: 0.1314\n",
      "Epoch [2/4], Step [2314/3844], Loss: 0.0896\n",
      "Epoch [2/4], Step [2315/3844], Loss: 0.1103\n",
      "Epoch [2/4], Step [2316/3844], Loss: 0.0805\n",
      "Epoch [2/4], Step [2317/3844], Loss: 0.0816\n",
      "Epoch [2/4], Step [2318/3844], Loss: 0.1028\n",
      "Epoch [2/4], Step [2319/3844], Loss: 0.2058\n",
      "Epoch [2/4], Step [2320/3844], Loss: 0.2232\n",
      "Epoch [2/4], Step [2321/3844], Loss: 0.0754\n",
      "Epoch [2/4], Step [2322/3844], Loss: 0.1418\n",
      "Epoch [2/4], Step [2323/3844], Loss: 0.1264\n",
      "Epoch [2/4], Step [2324/3844], Loss: 0.1179\n",
      "Epoch [2/4], Step [2325/3844], Loss: 0.0748\n",
      "Epoch [2/4], Step [2326/3844], Loss: 0.0749\n",
      "Epoch [2/4], Step [2327/3844], Loss: 0.1320\n",
      "Epoch [2/4], Step [2328/3844], Loss: 0.1258\n",
      "Epoch [2/4], Step [2329/3844], Loss: 0.1091\n",
      "Epoch [2/4], Step [2330/3844], Loss: 0.1302\n",
      "Epoch [2/4], Step [2331/3844], Loss: 0.0711\n",
      "Epoch [2/4], Step [2332/3844], Loss: 0.0820\n",
      "Epoch [2/4], Step [2333/3844], Loss: 0.0807\n",
      "Epoch [2/4], Step [2334/3844], Loss: 0.0906\n",
      "Epoch [2/4], Step [2335/3844], Loss: 0.1648\n",
      "Epoch [2/4], Step [2336/3844], Loss: 0.0799\n",
      "Epoch [2/4], Step [2337/3844], Loss: 0.0880\n",
      "Epoch [2/4], Step [2338/3844], Loss: 0.1199\n",
      "Epoch [2/4], Step [2339/3844], Loss: 0.0915\n",
      "Epoch [2/4], Step [2340/3844], Loss: 0.1029\n",
      "Epoch [2/4], Step [2341/3844], Loss: 0.0685\n",
      "Epoch [2/4], Step [2342/3844], Loss: 0.1103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/4], Step [2343/3844], Loss: 0.2030\n",
      "Epoch [2/4], Step [2344/3844], Loss: 0.2018\n",
      "Epoch [2/4], Step [2345/3844], Loss: 0.0717\n",
      "Epoch [2/4], Step [2346/3844], Loss: 0.1643\n",
      "Epoch [2/4], Step [2347/3844], Loss: 0.1339\n",
      "Epoch [2/4], Step [2348/3844], Loss: 0.0710\n",
      "Epoch [2/4], Step [2349/3844], Loss: 0.1540\n",
      "Epoch [2/4], Step [2350/3844], Loss: 0.1566\n",
      "Epoch [2/4], Step [2351/3844], Loss: 0.0916\n",
      "Epoch [2/4], Step [2352/3844], Loss: 0.1556\n",
      "Epoch [2/4], Step [2353/3844], Loss: 0.1093\n",
      "Epoch [2/4], Step [2354/3844], Loss: 0.1050\n",
      "Epoch [2/4], Step [2355/3844], Loss: 0.1203\n",
      "Epoch [2/4], Step [2356/3844], Loss: 0.0937\n",
      "Epoch [2/4], Step [2357/3844], Loss: 0.1602\n",
      "Epoch [2/4], Step [2358/3844], Loss: 0.1283\n",
      "Epoch [2/4], Step [2359/3844], Loss: 0.1559\n",
      "Epoch [2/4], Step [2360/3844], Loss: 0.0869\n",
      "Epoch [2/4], Step [2361/3844], Loss: 0.2290\n",
      "Epoch [2/4], Step [2362/3844], Loss: 0.0802\n",
      "Epoch [2/4], Step [2363/3844], Loss: 0.1256\n",
      "Epoch [2/4], Step [2364/3844], Loss: 0.1284\n",
      "Epoch [2/4], Step [2365/3844], Loss: 0.1369\n",
      "Epoch [2/4], Step [2366/3844], Loss: 0.0886\n",
      "Epoch [2/4], Step [2367/3844], Loss: 0.1325\n",
      "Epoch [2/4], Step [2368/3844], Loss: 0.2458\n",
      "Epoch [2/4], Step [2369/3844], Loss: 0.1746\n",
      "Epoch [2/4], Step [2370/3844], Loss: 0.0803\n",
      "Epoch [2/4], Step [2371/3844], Loss: 0.0900\n",
      "Epoch [2/4], Step [2372/3844], Loss: 0.1239\n",
      "Epoch [2/4], Step [2373/3844], Loss: 0.0874\n",
      "Epoch [2/4], Step [2374/3844], Loss: 0.1189\n",
      "Epoch [2/4], Step [2375/3844], Loss: 0.1460\n",
      "Epoch [2/4], Step [2376/3844], Loss: 0.0758\n",
      "Epoch [2/4], Step [2377/3844], Loss: 0.1019\n",
      "Epoch [2/4], Step [2378/3844], Loss: 0.1172\n",
      "Epoch [2/4], Step [2379/3844], Loss: 0.1521\n",
      "Epoch [2/4], Step [2380/3844], Loss: 0.0786\n",
      "Epoch [2/4], Step [2381/3844], Loss: 0.0484\n",
      "Epoch [2/4], Step [2382/3844], Loss: 0.0890\n",
      "Epoch [2/4], Step [2383/3844], Loss: 0.2103\n",
      "Epoch [2/4], Step [2384/3844], Loss: 0.1048\n",
      "Epoch [2/4], Step [2385/3844], Loss: 0.1285\n",
      "Epoch [2/4], Step [2386/3844], Loss: 0.1666\n",
      "Epoch [2/4], Step [2387/3844], Loss: 0.0882\n",
      "Epoch [2/4], Step [2388/3844], Loss: 0.1212\n",
      "Epoch [2/4], Step [2389/3844], Loss: 0.1300\n",
      "Epoch [2/4], Step [2390/3844], Loss: 0.0822\n",
      "Epoch [2/4], Step [2391/3844], Loss: 0.1583\n",
      "Epoch [2/4], Step [2392/3844], Loss: 0.0776\n",
      "Epoch [2/4], Step [2393/3844], Loss: 0.1216\n",
      "Epoch [2/4], Step [2394/3844], Loss: 0.0925\n",
      "Epoch [2/4], Step [2395/3844], Loss: 0.1072\n",
      "Epoch [2/4], Step [2396/3844], Loss: 0.0814\n",
      "Epoch [2/4], Step [2397/3844], Loss: 0.1642\n",
      "Epoch [2/4], Step [2398/3844], Loss: 0.1029\n",
      "Epoch [2/4], Step [2399/3844], Loss: 0.1855\n",
      "Epoch [2/4], Step [2400/3844], Loss: 0.0877\n",
      "Epoch [2/4], Step [2401/3844], Loss: 0.1397\n",
      "Epoch [2/4], Step [2402/3844], Loss: 0.1451\n",
      "Epoch [2/4], Step [2403/3844], Loss: 0.1541\n",
      "Epoch [2/4], Step [2404/3844], Loss: 0.0812\n",
      "Epoch [2/4], Step [2405/3844], Loss: 0.1623\n",
      "Epoch [2/4], Step [2406/3844], Loss: 0.1586\n",
      "Epoch [2/4], Step [2407/3844], Loss: 0.0832\n",
      "Epoch [2/4], Step [2408/3844], Loss: 0.0724\n",
      "Epoch [2/4], Step [2409/3844], Loss: 0.0984\n",
      "Epoch [2/4], Step [2410/3844], Loss: 0.0827\n",
      "Epoch [2/4], Step [2411/3844], Loss: 0.1524\n",
      "Epoch [2/4], Step [2412/3844], Loss: 0.1750\n",
      "Epoch [2/4], Step [2413/3844], Loss: 0.0704\n",
      "Epoch [2/4], Step [2414/3844], Loss: 0.0748\n",
      "Epoch [2/4], Step [2415/3844], Loss: 0.1437\n",
      "Epoch [2/4], Step [2416/3844], Loss: 0.1533\n",
      "Epoch [2/4], Step [2417/3844], Loss: 0.0737\n",
      "Epoch [2/4], Step [2418/3844], Loss: 0.0772\n",
      "Epoch [2/4], Step [2419/3844], Loss: 0.1186\n",
      "Epoch [2/4], Step [2420/3844], Loss: 0.1011\n",
      "Epoch [2/4], Step [2421/3844], Loss: 0.0976\n",
      "Epoch [2/4], Step [2422/3844], Loss: 0.0807\n",
      "Epoch [2/4], Step [2423/3844], Loss: 0.0752\n",
      "Epoch [2/4], Step [2424/3844], Loss: 0.1233\n",
      "Epoch [2/4], Step [2425/3844], Loss: 0.1164\n",
      "Epoch [2/4], Step [2426/3844], Loss: 0.0861\n",
      "Epoch [2/4], Step [2427/3844], Loss: 0.0763\n",
      "Epoch [2/4], Step [2428/3844], Loss: 0.1085\n",
      "Epoch [2/4], Step [2429/3844], Loss: 0.0590\n",
      "Epoch [2/4], Step [2430/3844], Loss: 0.1025\n",
      "Epoch [2/4], Step [2431/3844], Loss: 0.0839\n",
      "Epoch [2/4], Step [2432/3844], Loss: 0.0643\n",
      "Epoch [2/4], Step [2433/3844], Loss: 0.0924\n",
      "Epoch [2/4], Step [2434/3844], Loss: 0.1398\n",
      "Epoch [2/4], Step [2435/3844], Loss: 0.1154\n",
      "Epoch [2/4], Step [2436/3844], Loss: 0.2531\n",
      "Epoch [2/4], Step [2437/3844], Loss: 0.2398\n",
      "Epoch [2/4], Step [2438/3844], Loss: 0.2135\n",
      "Epoch [2/4], Step [2439/3844], Loss: 0.0612\n",
      "Epoch [2/4], Step [2440/3844], Loss: 0.1227\n",
      "Epoch [2/4], Step [2441/3844], Loss: 0.1849\n",
      "Epoch [2/4], Step [2442/3844], Loss: 0.1627\n",
      "Epoch [2/4], Step [2443/3844], Loss: 0.0752\n",
      "Epoch [2/4], Step [2444/3844], Loss: 0.0748\n",
      "Epoch [2/4], Step [2445/3844], Loss: 0.1028\n",
      "Epoch [2/4], Step [2446/3844], Loss: 0.1435\n",
      "Epoch [2/4], Step [2447/3844], Loss: 0.0679\n",
      "Epoch [2/4], Step [2448/3844], Loss: 0.1586\n",
      "Epoch [2/4], Step [2449/3844], Loss: 0.0561\n",
      "Epoch [2/4], Step [2450/3844], Loss: 0.1091\n",
      "Epoch [2/4], Step [2451/3844], Loss: 0.0627\n",
      "Epoch [2/4], Step [2452/3844], Loss: 0.1205\n",
      "Epoch [2/4], Step [2453/3844], Loss: 0.1187\n",
      "Epoch [2/4], Step [2454/3844], Loss: 0.1650\n",
      "Epoch [2/4], Step [2455/3844], Loss: 0.0775\n",
      "Epoch [2/4], Step [2456/3844], Loss: 0.1761\n",
      "Epoch [2/4], Step [2457/3844], Loss: 0.0392\n",
      "Epoch [2/4], Step [2458/3844], Loss: 0.0530\n",
      "Epoch [2/4], Step [2459/3844], Loss: 0.1721\n",
      "Epoch [2/4], Step [2460/3844], Loss: 0.1557\n",
      "Epoch [2/4], Step [2461/3844], Loss: 0.2118\n",
      "Epoch [2/4], Step [2462/3844], Loss: 0.0534\n",
      "Epoch [2/4], Step [2463/3844], Loss: 0.1434\n",
      "Epoch [2/4], Step [2464/3844], Loss: 0.2657\n",
      "Epoch [2/4], Step [2465/3844], Loss: 0.0777\n",
      "Epoch [2/4], Step [2466/3844], Loss: 0.2777\n",
      "Epoch [2/4], Step [2467/3844], Loss: 0.1788\n",
      "Epoch [2/4], Step [2468/3844], Loss: 0.0851\n",
      "Epoch [2/4], Step [2469/3844], Loss: 0.1259\n",
      "Epoch [2/4], Step [2470/3844], Loss: 0.0877\n",
      "Epoch [2/4], Step [2471/3844], Loss: 0.1904\n",
      "Epoch [2/4], Step [2472/3844], Loss: 0.0864\n",
      "Epoch [2/4], Step [2473/3844], Loss: 0.1183\n",
      "Epoch [2/4], Step [2474/3844], Loss: 0.1811\n",
      "Epoch [2/4], Step [2475/3844], Loss: 0.0751\n",
      "Epoch [2/4], Step [2476/3844], Loss: 0.1111\n",
      "Epoch [2/4], Step [2477/3844], Loss: 0.0894\n",
      "Epoch [2/4], Step [2478/3844], Loss: 0.0822\n",
      "Epoch [2/4], Step [2479/3844], Loss: 0.0854\n",
      "Epoch [2/4], Step [2480/3844], Loss: 0.0932\n",
      "Epoch [2/4], Step [2481/3844], Loss: 0.2408\n",
      "Epoch [2/4], Step [2482/3844], Loss: 0.0960\n",
      "Epoch [2/4], Step [2483/3844], Loss: 0.1331\n",
      "Epoch [2/4], Step [2484/3844], Loss: 0.1017\n",
      "Epoch [2/4], Step [2485/3844], Loss: 0.2101\n",
      "Epoch [2/4], Step [2486/3844], Loss: 0.1404\n",
      "Epoch [2/4], Step [2487/3844], Loss: 0.2118\n",
      "Epoch [2/4], Step [2488/3844], Loss: 0.0951\n",
      "Epoch [2/4], Step [2489/3844], Loss: 0.1073\n",
      "Epoch [2/4], Step [2490/3844], Loss: 0.0877\n",
      "Epoch [2/4], Step [2491/3844], Loss: 0.0739\n",
      "Epoch [2/4], Step [2492/3844], Loss: 0.1008\n",
      "Epoch [2/4], Step [2493/3844], Loss: 0.1353\n",
      "Epoch [2/4], Step [2494/3844], Loss: 0.0916\n",
      "Epoch [2/4], Step [2495/3844], Loss: 0.0979\n",
      "Epoch [2/4], Step [2496/3844], Loss: 0.1715\n",
      "Epoch [2/4], Step [2497/3844], Loss: 0.0759\n",
      "Epoch [2/4], Step [2498/3844], Loss: 0.0811\n",
      "Epoch [2/4], Step [2499/3844], Loss: 0.1058\n",
      "Epoch [2/4], Step [2500/3844], Loss: 0.0904\n",
      "Epoch [2/4], Step [2501/3844], Loss: 0.1099\n",
      "Epoch [2/4], Step [2502/3844], Loss: 0.0868\n",
      "Epoch [2/4], Step [2503/3844], Loss: 0.1429\n",
      "Epoch [2/4], Step [2504/3844], Loss: 0.0789\n",
      "Epoch [2/4], Step [2505/3844], Loss: 0.1021\n",
      "Epoch [2/4], Step [2506/3844], Loss: 0.1080\n",
      "Epoch [2/4], Step [2507/3844], Loss: 0.1995\n",
      "Epoch [2/4], Step [2508/3844], Loss: 0.0805\n",
      "Epoch [2/4], Step [2509/3844], Loss: 0.2216\n",
      "Epoch [2/4], Step [2510/3844], Loss: 0.0822\n",
      "Epoch [2/4], Step [2511/3844], Loss: 0.1158\n",
      "Epoch [2/4], Step [2512/3844], Loss: 0.0963\n",
      "Epoch [2/4], Step [2513/3844], Loss: 0.0897\n",
      "Epoch [2/4], Step [2514/3844], Loss: 0.2118\n",
      "Epoch [2/4], Step [2515/3844], Loss: 0.1037\n",
      "Epoch [2/4], Step [2516/3844], Loss: 0.1111\n",
      "Epoch [2/4], Step [2517/3844], Loss: 0.1451\n",
      "Epoch [2/4], Step [2518/3844], Loss: 0.1128\n",
      "Epoch [2/4], Step [2519/3844], Loss: 0.0982\n",
      "Epoch [2/4], Step [2520/3844], Loss: 0.1016\n",
      "Epoch [2/4], Step [2521/3844], Loss: 0.1503\n",
      "Epoch [2/4], Step [2522/3844], Loss: 0.0961\n",
      "Epoch [2/4], Step [2523/3844], Loss: 0.0846\n",
      "Epoch [2/4], Step [2524/3844], Loss: 0.1588\n",
      "Epoch [2/4], Step [2525/3844], Loss: 0.1075\n",
      "Epoch [2/4], Step [2526/3844], Loss: 0.1329\n",
      "Epoch [2/4], Step [2527/3844], Loss: 0.0798\n",
      "Epoch [2/4], Step [2528/3844], Loss: 0.1134\n",
      "Epoch [2/4], Step [2529/3844], Loss: 0.1369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/4], Step [2530/3844], Loss: 0.0921\n",
      "Epoch [2/4], Step [2531/3844], Loss: 0.1549\n",
      "Epoch [2/4], Step [2532/3844], Loss: 0.0781\n",
      "Epoch [2/4], Step [2533/3844], Loss: 0.1110\n",
      "Epoch [2/4], Step [2534/3844], Loss: 0.1283\n",
      "Epoch [2/4], Step [2535/3844], Loss: 0.1839\n",
      "Epoch [2/4], Step [2536/3844], Loss: 0.2001\n",
      "Epoch [2/4], Step [2537/3844], Loss: 0.1006\n",
      "Epoch [2/4], Step [2538/3844], Loss: 0.0862\n",
      "Epoch [2/4], Step [2539/3844], Loss: 0.1098\n",
      "Epoch [2/4], Step [2540/3844], Loss: 0.1281\n",
      "Epoch [2/4], Step [2541/3844], Loss: 0.1561\n",
      "Epoch [2/4], Step [2542/3844], Loss: 0.1483\n",
      "Epoch [2/4], Step [2543/3844], Loss: 0.1057\n",
      "Epoch [2/4], Step [2544/3844], Loss: 0.1287\n",
      "Epoch [2/4], Step [2545/3844], Loss: 0.1321\n",
      "Epoch [2/4], Step [2546/3844], Loss: 0.0753\n",
      "Epoch [2/4], Step [2547/3844], Loss: 0.0929\n",
      "Epoch [2/4], Step [2548/3844], Loss: 0.0988\n",
      "Epoch [2/4], Step [2549/3844], Loss: 0.0840\n",
      "Epoch [2/4], Step [2550/3844], Loss: 0.1091\n",
      "Epoch [2/4], Step [2551/3844], Loss: 0.1017\n",
      "Epoch [2/4], Step [2552/3844], Loss: 0.0605\n",
      "Epoch [2/4], Step [2553/3844], Loss: 0.0988\n",
      "Epoch [2/4], Step [2554/3844], Loss: 0.0528\n",
      "Epoch [2/4], Step [2555/3844], Loss: 0.1302\n",
      "Epoch [2/4], Step [2556/3844], Loss: 0.1545\n",
      "Epoch [2/4], Step [2557/3844], Loss: 0.1056\n",
      "Epoch [2/4], Step [2558/3844], Loss: 0.2134\n",
      "Epoch [2/4], Step [2559/3844], Loss: 0.0668\n",
      "Epoch [2/4], Step [2560/3844], Loss: 0.1426\n",
      "Epoch [2/4], Step [2561/3844], Loss: 0.1635\n",
      "Epoch [2/4], Step [2562/3844], Loss: 0.1034\n",
      "Epoch [2/4], Step [2563/3844], Loss: 0.0598\n",
      "Epoch [2/4], Step [2564/3844], Loss: 0.1756\n",
      "Epoch [2/4], Step [2565/3844], Loss: 0.0960\n",
      "Epoch [2/4], Step [2566/3844], Loss: 0.0953\n",
      "Epoch [2/4], Step [2567/3844], Loss: 0.0972\n",
      "Epoch [2/4], Step [2568/3844], Loss: 0.1162\n",
      "Epoch [2/4], Step [2569/3844], Loss: 0.1216\n",
      "Epoch [2/4], Step [2570/3844], Loss: 0.0944\n",
      "Epoch [2/4], Step [2571/3844], Loss: 0.1028\n",
      "Epoch [2/4], Step [2572/3844], Loss: 0.1109\n",
      "Epoch [2/4], Step [2573/3844], Loss: 0.0695\n",
      "Epoch [2/4], Step [2574/3844], Loss: 0.0863\n",
      "Epoch [2/4], Step [2575/3844], Loss: 0.0856\n",
      "Epoch [2/4], Step [2576/3844], Loss: 0.1389\n",
      "Epoch [2/4], Step [2577/3844], Loss: 0.0711\n",
      "Epoch [2/4], Step [2578/3844], Loss: 0.1640\n",
      "Epoch [2/4], Step [2579/3844], Loss: 0.0755\n",
      "Epoch [2/4], Step [2580/3844], Loss: 0.0849\n",
      "Epoch [2/4], Step [2581/3844], Loss: 0.1670\n",
      "Epoch [2/4], Step [2582/3844], Loss: 0.1523\n",
      "Epoch [2/4], Step [2583/3844], Loss: 0.1631\n",
      "Epoch [2/4], Step [2584/3844], Loss: 0.1308\n",
      "Epoch [2/4], Step [2585/3844], Loss: 0.1981\n",
      "Epoch [2/4], Step [2586/3844], Loss: 0.0863\n",
      "Epoch [2/4], Step [2587/3844], Loss: 0.2382\n",
      "Epoch [2/4], Step [2588/3844], Loss: 0.0977\n",
      "Epoch [2/4], Step [2589/3844], Loss: 0.1202\n",
      "Epoch [2/4], Step [2590/3844], Loss: 0.1650\n",
      "Epoch [2/4], Step [2591/3844], Loss: 0.2305\n",
      "Epoch [2/4], Step [2592/3844], Loss: 0.2266\n",
      "Epoch [2/4], Step [2593/3844], Loss: 0.0854\n",
      "Epoch [2/4], Step [2594/3844], Loss: 0.1055\n",
      "Epoch [2/4], Step [2595/3844], Loss: 0.1258\n",
      "Epoch [2/4], Step [2596/3844], Loss: 0.1848\n",
      "Epoch [2/4], Step [2597/3844], Loss: 0.1979\n",
      "Epoch [2/4], Step [2598/3844], Loss: 0.1581\n",
      "Epoch [2/4], Step [2599/3844], Loss: 0.1215\n",
      "Epoch [2/4], Step [2600/3844], Loss: 0.0991\n",
      "Epoch [2/4], Step [2601/3844], Loss: 0.0890\n",
      "Epoch [2/4], Step [2602/3844], Loss: 0.0885\n",
      "Epoch [2/4], Step [2603/3844], Loss: 0.0987\n",
      "Epoch [2/4], Step [2604/3844], Loss: 0.0705\n",
      "Epoch [2/4], Step [2605/3844], Loss: 0.0936\n",
      "Epoch [2/4], Step [2606/3844], Loss: 0.0995\n",
      "Epoch [2/4], Step [2607/3844], Loss: 0.0825\n",
      "Epoch [2/4], Step [2608/3844], Loss: 0.1642\n",
      "Epoch [2/4], Step [2609/3844], Loss: 0.1389\n",
      "Epoch [2/4], Step [2610/3844], Loss: 0.0727\n",
      "Epoch [2/4], Step [2611/3844], Loss: 0.1281\n",
      "Epoch [2/4], Step [2612/3844], Loss: 0.0919\n",
      "Epoch [2/4], Step [2613/3844], Loss: 0.0783\n",
      "Epoch [2/4], Step [2614/3844], Loss: 0.1188\n",
      "Epoch [2/4], Step [2615/3844], Loss: 0.1361\n",
      "Epoch [2/4], Step [2616/3844], Loss: 0.1282\n",
      "Epoch [2/4], Step [2617/3844], Loss: 0.0968\n",
      "Epoch [2/4], Step [2618/3844], Loss: 0.1206\n",
      "Epoch [2/4], Step [2619/3844], Loss: 0.1058\n",
      "Epoch [2/4], Step [2620/3844], Loss: 0.2176\n",
      "Epoch [2/4], Step [2621/3844], Loss: 0.1635\n",
      "Epoch [2/4], Step [2622/3844], Loss: 0.1127\n",
      "Epoch [2/4], Step [2623/3844], Loss: 0.0968\n",
      "Epoch [2/4], Step [2624/3844], Loss: 0.0936\n",
      "Epoch [2/4], Step [2625/3844], Loss: 0.0722\n",
      "Epoch [2/4], Step [2626/3844], Loss: 0.0993\n",
      "Epoch [2/4], Step [2627/3844], Loss: 0.0529\n",
      "Epoch [2/4], Step [2628/3844], Loss: 0.1120\n",
      "Epoch [2/4], Step [2629/3844], Loss: 0.1876\n",
      "Epoch [2/4], Step [2630/3844], Loss: 0.1234\n",
      "Epoch [2/4], Step [2631/3844], Loss: 0.0860\n",
      "Epoch [2/4], Step [2632/3844], Loss: 0.1712\n",
      "Epoch [2/4], Step [2633/3844], Loss: 0.1623\n",
      "Epoch [2/4], Step [2634/3844], Loss: 0.1334\n",
      "Epoch [2/4], Step [2635/3844], Loss: 0.0931\n",
      "Epoch [2/4], Step [2636/3844], Loss: 0.1069\n",
      "Epoch [2/4], Step [2637/3844], Loss: 0.1364\n",
      "Epoch [2/4], Step [2638/3844], Loss: 0.1174\n",
      "Epoch [2/4], Step [2639/3844], Loss: 0.1486\n",
      "Epoch [2/4], Step [2640/3844], Loss: 0.1641\n",
      "Epoch [2/4], Step [2641/3844], Loss: 0.2454\n",
      "Epoch [2/4], Step [2642/3844], Loss: 0.1029\n",
      "Epoch [2/4], Step [2643/3844], Loss: 0.0994\n",
      "Epoch [2/4], Step [2644/3844], Loss: 0.1417\n",
      "Epoch [2/4], Step [2645/3844], Loss: 0.1540\n",
      "Epoch [2/4], Step [2646/3844], Loss: 0.0966\n",
      "Epoch [2/4], Step [2647/3844], Loss: 0.1050\n",
      "Epoch [2/4], Step [2648/3844], Loss: 0.1136\n",
      "Epoch [2/4], Step [2649/3844], Loss: 0.1193\n",
      "Epoch [2/4], Step [2650/3844], Loss: 0.1710\n",
      "Epoch [2/4], Step [2651/3844], Loss: 0.1045\n",
      "Epoch [2/4], Step [2652/3844], Loss: 0.1568\n",
      "Epoch [2/4], Step [2653/3844], Loss: 0.1480\n",
      "Epoch [2/4], Step [2654/3844], Loss: 0.0647\n",
      "Epoch [2/4], Step [2655/3844], Loss: 0.0962\n",
      "Epoch [2/4], Step [2656/3844], Loss: 0.2082\n",
      "Epoch [2/4], Step [2657/3844], Loss: 0.1803\n",
      "Epoch [2/4], Step [2658/3844], Loss: 0.1484\n",
      "Epoch [2/4], Step [2659/3844], Loss: 0.1549\n",
      "Epoch [2/4], Step [2660/3844], Loss: 0.1094\n",
      "Epoch [2/4], Step [2661/3844], Loss: 0.1285\n",
      "Epoch [2/4], Step [2662/3844], Loss: 0.1308\n",
      "Epoch [2/4], Step [2663/3844], Loss: 0.0818\n",
      "Epoch [2/4], Step [2664/3844], Loss: 0.1656\n",
      "Epoch [2/4], Step [2665/3844], Loss: 0.1661\n",
      "Epoch [2/4], Step [2666/3844], Loss: 0.0625\n",
      "Epoch [2/4], Step [2667/3844], Loss: 0.1534\n",
      "Epoch [2/4], Step [2668/3844], Loss: 0.1256\n",
      "Epoch [2/4], Step [2669/3844], Loss: 0.0756\n",
      "Epoch [2/4], Step [2670/3844], Loss: 0.1520\n",
      "Epoch [2/4], Step [2671/3844], Loss: 0.1265\n",
      "Epoch [2/4], Step [2672/3844], Loss: 0.1642\n",
      "Epoch [2/4], Step [2673/3844], Loss: 0.1795\n",
      "Epoch [2/4], Step [2674/3844], Loss: 0.1498\n",
      "Epoch [2/4], Step [2675/3844], Loss: 0.1222\n",
      "Epoch [2/4], Step [2676/3844], Loss: 0.0707\n",
      "Epoch [2/4], Step [2677/3844], Loss: 0.0813\n",
      "Epoch [2/4], Step [2678/3844], Loss: 0.2019\n",
      "Epoch [2/4], Step [2679/3844], Loss: 0.0873\n",
      "Epoch [2/4], Step [2680/3844], Loss: 0.1259\n",
      "Epoch [2/4], Step [2681/3844], Loss: 0.1388\n",
      "Epoch [2/4], Step [2682/3844], Loss: 0.0953\n",
      "Epoch [2/4], Step [2683/3844], Loss: 0.0784\n",
      "Epoch [2/4], Step [2684/3844], Loss: 0.1409\n",
      "Epoch [2/4], Step [2685/3844], Loss: 0.1029\n",
      "Epoch [2/4], Step [2686/3844], Loss: 0.0881\n",
      "Epoch [2/4], Step [2687/3844], Loss: 0.2133\n",
      "Epoch [2/4], Step [2688/3844], Loss: 0.1226\n",
      "Epoch [2/4], Step [2689/3844], Loss: 0.1479\n",
      "Epoch [2/4], Step [2690/3844], Loss: 0.1091\n",
      "Epoch [2/4], Step [2691/3844], Loss: 0.2249\n",
      "Epoch [2/4], Step [2692/3844], Loss: 0.1072\n",
      "Epoch [2/4], Step [2693/3844], Loss: 0.0915\n",
      "Epoch [2/4], Step [2694/3844], Loss: 0.1001\n",
      "Epoch [2/4], Step [2695/3844], Loss: 0.0911\n",
      "Epoch [2/4], Step [2696/3844], Loss: 0.0860\n",
      "Epoch [2/4], Step [2697/3844], Loss: 0.1206\n",
      "Epoch [2/4], Step [2698/3844], Loss: 0.1069\n",
      "Epoch [2/4], Step [2699/3844], Loss: 0.0626\n",
      "Epoch [2/4], Step [2700/3844], Loss: 0.1683\n",
      "Epoch [2/4], Step [2701/3844], Loss: 0.1649\n",
      "Epoch [2/4], Step [2702/3844], Loss: 0.0826\n",
      "Epoch [2/4], Step [2703/3844], Loss: 0.0849\n",
      "Epoch [2/4], Step [2704/3844], Loss: 0.1047\n",
      "Epoch [2/4], Step [2705/3844], Loss: 0.0771\n",
      "Epoch [2/4], Step [2706/3844], Loss: 0.0676\n",
      "Epoch [2/4], Step [2707/3844], Loss: 0.0770\n",
      "Epoch [2/4], Step [2708/3844], Loss: 0.1740\n",
      "Epoch [2/4], Step [2709/3844], Loss: 0.1487\n",
      "Epoch [2/4], Step [2710/3844], Loss: 0.0870\n",
      "Epoch [2/4], Step [2711/3844], Loss: 0.0949\n",
      "Epoch [2/4], Step [2712/3844], Loss: 0.0834\n",
      "Epoch [2/4], Step [2713/3844], Loss: 0.2136\n",
      "Epoch [2/4], Step [2714/3844], Loss: 0.1457\n",
      "Epoch [2/4], Step [2715/3844], Loss: 0.1330\n",
      "Epoch [2/4], Step [2716/3844], Loss: 0.1296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/4], Step [2717/3844], Loss: 0.1075\n",
      "Epoch [2/4], Step [2718/3844], Loss: 0.0988\n",
      "Epoch [2/4], Step [2719/3844], Loss: 0.1063\n",
      "Epoch [2/4], Step [2720/3844], Loss: 0.1601\n",
      "Epoch [2/4], Step [2721/3844], Loss: 0.1687\n",
      "Epoch [2/4], Step [2722/3844], Loss: 0.1269\n",
      "Epoch [2/4], Step [2723/3844], Loss: 0.1009\n",
      "Epoch [2/4], Step [2724/3844], Loss: 0.1998\n",
      "Epoch [2/4], Step [2725/3844], Loss: 0.0936\n",
      "Epoch [2/4], Step [2726/3844], Loss: 0.0963\n",
      "Epoch [2/4], Step [2727/3844], Loss: 0.1739\n",
      "Epoch [2/4], Step [2728/3844], Loss: 0.0820\n",
      "Epoch [2/4], Step [2729/3844], Loss: 0.1577\n",
      "Epoch [2/4], Step [2730/3844], Loss: 0.1221\n",
      "Epoch [2/4], Step [2731/3844], Loss: 0.1195\n",
      "Epoch [2/4], Step [2732/3844], Loss: 0.1192\n",
      "Epoch [2/4], Step [2733/3844], Loss: 0.1530\n",
      "Epoch [2/4], Step [2734/3844], Loss: 0.0843\n",
      "Epoch [2/4], Step [2735/3844], Loss: 0.1507\n",
      "Epoch [2/4], Step [2736/3844], Loss: 0.1338\n",
      "Epoch [2/4], Step [2737/3844], Loss: 0.1683\n",
      "Epoch [2/4], Step [2738/3844], Loss: 0.0932\n",
      "Epoch [2/4], Step [2739/3844], Loss: 0.1048\n",
      "Epoch [2/4], Step [2740/3844], Loss: 0.1745\n",
      "Epoch [2/4], Step [2741/3844], Loss: 0.0895\n",
      "Epoch [2/4], Step [2742/3844], Loss: 0.0853\n",
      "Epoch [2/4], Step [2743/3844], Loss: 0.1780\n",
      "Epoch [2/4], Step [2744/3844], Loss: 0.1469\n",
      "Epoch [2/4], Step [2745/3844], Loss: 0.0997\n",
      "Epoch [2/4], Step [2746/3844], Loss: 0.1264\n",
      "Epoch [2/4], Step [2747/3844], Loss: 0.2007\n",
      "Epoch [2/4], Step [2748/3844], Loss: 0.1308\n",
      "Epoch [2/4], Step [2749/3844], Loss: 0.0740\n",
      "Epoch [2/4], Step [2750/3844], Loss: 0.0958\n",
      "Epoch [2/4], Step [2751/3844], Loss: 0.0881\n",
      "Epoch [2/4], Step [2752/3844], Loss: 0.0820\n",
      "Epoch [2/4], Step [2753/3844], Loss: 0.1208\n",
      "Epoch [2/4], Step [2754/3844], Loss: 0.1499\n",
      "Epoch [2/4], Step [2755/3844], Loss: 0.1525\n",
      "Epoch [2/4], Step [2756/3844], Loss: 0.0711\n",
      "Epoch [2/4], Step [2757/3844], Loss: 0.0784\n",
      "Epoch [2/4], Step [2758/3844], Loss: 0.1531\n",
      "Epoch [2/4], Step [2759/3844], Loss: 0.0989\n",
      "Epoch [2/4], Step [2760/3844], Loss: 0.0597\n",
      "Epoch [2/4], Step [2761/3844], Loss: 0.0736\n",
      "Epoch [2/4], Step [2762/3844], Loss: 0.0999\n",
      "Epoch [2/4], Step [2763/3844], Loss: 0.1604\n",
      "Epoch [2/4], Step [2764/3844], Loss: 0.0707\n",
      "Epoch [2/4], Step [2765/3844], Loss: 0.0631\n",
      "Epoch [2/4], Step [2766/3844], Loss: 0.0745\n",
      "Epoch [2/4], Step [2767/3844], Loss: 0.0733\n",
      "Epoch [2/4], Step [2768/3844], Loss: 0.1529\n",
      "Epoch [2/4], Step [2769/3844], Loss: 0.0764\n",
      "Epoch [2/4], Step [2770/3844], Loss: 0.0890\n",
      "Epoch [2/4], Step [2771/3844], Loss: 0.0746\n",
      "Epoch [2/4], Step [2772/3844], Loss: 0.1146\n",
      "Epoch [2/4], Step [2773/3844], Loss: 0.1453\n",
      "Epoch [2/4], Step [2774/3844], Loss: 0.0652\n",
      "Epoch [2/4], Step [2775/3844], Loss: 0.2223\n",
      "Epoch [2/4], Step [2776/3844], Loss: 0.1067\n",
      "Epoch [2/4], Step [2777/3844], Loss: 0.2221\n",
      "Epoch [2/4], Step [2778/3844], Loss: 0.1023\n",
      "Epoch [2/4], Step [2779/3844], Loss: 0.2114\n",
      "Epoch [2/4], Step [2780/3844], Loss: 0.1035\n",
      "Epoch [2/4], Step [2781/3844], Loss: 0.0967\n",
      "Epoch [2/4], Step [2782/3844], Loss: 0.0956\n",
      "Epoch [2/4], Step [2783/3844], Loss: 0.0814\n",
      "Epoch [2/4], Step [2784/3844], Loss: 0.0625\n",
      "Epoch [2/4], Step [2785/3844], Loss: 0.1068\n",
      "Epoch [2/4], Step [2786/3844], Loss: 0.1659\n",
      "Epoch [2/4], Step [2787/3844], Loss: 0.0726\n",
      "Epoch [2/4], Step [2788/3844], Loss: 0.0643\n",
      "Epoch [2/4], Step [2789/3844], Loss: 0.1651\n",
      "Epoch [2/4], Step [2790/3844], Loss: 0.1457\n",
      "Epoch [2/4], Step [2791/3844], Loss: 0.0625\n",
      "Epoch [2/4], Step [2792/3844], Loss: 0.1153\n",
      "Epoch [2/4], Step [2793/3844], Loss: 0.0785\n",
      "Epoch [2/4], Step [2794/3844], Loss: 0.1976\n",
      "Epoch [2/4], Step [2795/3844], Loss: 0.0631\n",
      "Epoch [2/4], Step [2796/3844], Loss: 0.1912\n",
      "Epoch [2/4], Step [2797/3844], Loss: 0.0702\n",
      "Epoch [2/4], Step [2798/3844], Loss: 0.0637\n",
      "Epoch [2/4], Step [2799/3844], Loss: 0.1408\n",
      "Epoch [2/4], Step [2800/3844], Loss: 0.0881\n",
      "Epoch [2/4], Step [2801/3844], Loss: 0.1638\n",
      "Epoch [2/4], Step [2802/3844], Loss: 0.0811\n",
      "Epoch [2/4], Step [2803/3844], Loss: 0.0708\n",
      "Epoch [2/4], Step [2804/3844], Loss: 0.1965\n",
      "Epoch [2/4], Step [2805/3844], Loss: 0.0774\n",
      "Epoch [2/4], Step [2806/3844], Loss: 0.0738\n",
      "Epoch [2/4], Step [2807/3844], Loss: 0.0825\n",
      "Epoch [2/4], Step [2808/3844], Loss: 0.1553\n",
      "Epoch [2/4], Step [2809/3844], Loss: 0.0886\n",
      "Epoch [2/4], Step [2810/3844], Loss: 0.1093\n",
      "Epoch [2/4], Step [2811/3844], Loss: 0.0896\n",
      "Epoch [2/4], Step [2812/3844], Loss: 0.1305\n",
      "Epoch [2/4], Step [2813/3844], Loss: 0.1355\n",
      "Epoch [2/4], Step [2814/3844], Loss: 0.0598\n",
      "Epoch [2/4], Step [2815/3844], Loss: 0.1507\n",
      "Epoch [2/4], Step [2816/3844], Loss: 0.0896\n",
      "Epoch [2/4], Step [2817/3844], Loss: 0.1715\n",
      "Epoch [2/4], Step [2818/3844], Loss: 0.1333\n",
      "Epoch [2/4], Step [2819/3844], Loss: 0.1058\n",
      "Epoch [2/4], Step [2820/3844], Loss: 0.1008\n",
      "Epoch [2/4], Step [2821/3844], Loss: 0.1483\n",
      "Epoch [2/4], Step [2822/3844], Loss: 0.0787\n",
      "Epoch [2/4], Step [2823/3844], Loss: 0.0889\n",
      "Epoch [2/4], Step [2824/3844], Loss: 0.0836\n",
      "Epoch [2/4], Step [2825/3844], Loss: 0.0912\n",
      "Epoch [2/4], Step [2826/3844], Loss: 0.0833\n",
      "Epoch [2/4], Step [2827/3844], Loss: 0.0969\n",
      "Epoch [2/4], Step [2828/3844], Loss: 0.0788\n",
      "Epoch [2/4], Step [2829/3844], Loss: 0.0814\n",
      "Epoch [2/4], Step [2830/3844], Loss: 0.1012\n",
      "Epoch [2/4], Step [2831/3844], Loss: 0.1136\n",
      "Epoch [2/4], Step [2832/3844], Loss: 0.0647\n",
      "Epoch [2/4], Step [2833/3844], Loss: 0.0994\n",
      "Epoch [2/4], Step [2834/3844], Loss: 0.1344\n",
      "Epoch [2/4], Step [2835/3844], Loss: 0.0718\n",
      "Epoch [2/4], Step [2836/3844], Loss: 0.1511\n",
      "Epoch [2/4], Step [2837/3844], Loss: 0.1385\n",
      "Epoch [2/4], Step [2838/3844], Loss: 0.0814\n",
      "Epoch [2/4], Step [2839/3844], Loss: 0.1476\n",
      "Epoch [2/4], Step [2840/3844], Loss: 0.0821\n",
      "Epoch [2/4], Step [2841/3844], Loss: 0.1236\n",
      "Epoch [2/4], Step [2842/3844], Loss: 0.0852\n",
      "Epoch [2/4], Step [2843/3844], Loss: 0.0767\n",
      "Epoch [2/4], Step [2844/3844], Loss: 0.2161\n",
      "Epoch [2/4], Step [2845/3844], Loss: 0.1093\n",
      "Epoch [2/4], Step [2846/3844], Loss: 0.0917\n",
      "Epoch [2/4], Step [2847/3844], Loss: 0.1099\n",
      "Epoch [2/4], Step [2848/3844], Loss: 0.1740\n",
      "Epoch [2/4], Step [2849/3844], Loss: 0.1772\n",
      "Epoch [2/4], Step [2850/3844], Loss: 0.1476\n",
      "Epoch [2/4], Step [2851/3844], Loss: 0.1456\n",
      "Epoch [2/4], Step [2852/3844], Loss: 0.0665\n",
      "Epoch [2/4], Step [2853/3844], Loss: 0.1376\n",
      "Epoch [2/4], Step [2854/3844], Loss: 0.0784\n",
      "Epoch [2/4], Step [2855/3844], Loss: 0.0996\n",
      "Epoch [2/4], Step [2856/3844], Loss: 0.1350\n",
      "Epoch [2/4], Step [2857/3844], Loss: 0.0785\n",
      "Epoch [2/4], Step [2858/3844], Loss: 0.0808\n",
      "Epoch [2/4], Step [2859/3844], Loss: 0.0803\n",
      "Epoch [2/4], Step [2860/3844], Loss: 0.2583\n",
      "Epoch [2/4], Step [2861/3844], Loss: 0.1088\n",
      "Epoch [2/4], Step [2862/3844], Loss: 0.0743\n",
      "Epoch [2/4], Step [2863/3844], Loss: 0.1687\n",
      "Epoch [2/4], Step [2864/3844], Loss: 0.1181\n",
      "Epoch [2/4], Step [2865/3844], Loss: 0.2349\n",
      "Epoch [2/4], Step [2866/3844], Loss: 0.0819\n",
      "Epoch [2/4], Step [2867/3844], Loss: 0.0847\n",
      "Epoch [2/4], Step [2868/3844], Loss: 0.1180\n",
      "Epoch [2/4], Step [2869/3844], Loss: 0.0911\n",
      "Epoch [2/4], Step [2870/3844], Loss: 0.0830\n",
      "Epoch [2/4], Step [2871/3844], Loss: 0.0974\n",
      "Epoch [2/4], Step [2872/3844], Loss: 0.1036\n",
      "Epoch [2/4], Step [2873/3844], Loss: 0.0603\n",
      "Epoch [2/4], Step [2874/3844], Loss: 0.1104\n",
      "Epoch [2/4], Step [2875/3844], Loss: 0.1301\n",
      "Epoch [2/4], Step [2876/3844], Loss: 0.0773\n",
      "Epoch [2/4], Step [2877/3844], Loss: 0.1616\n",
      "Epoch [2/4], Step [2878/3844], Loss: 0.0753\n",
      "Epoch [2/4], Step [2879/3844], Loss: 0.1218\n",
      "Epoch [2/4], Step [2880/3844], Loss: 0.1849\n",
      "Epoch [2/4], Step [2881/3844], Loss: 0.0782\n",
      "Epoch [2/4], Step [2882/3844], Loss: 0.0600\n",
      "Epoch [2/4], Step [2883/3844], Loss: 0.1459\n",
      "Epoch [2/4], Step [2884/3844], Loss: 0.1496\n",
      "Epoch [2/4], Step [2885/3844], Loss: 0.1151\n",
      "Epoch [2/4], Step [2886/3844], Loss: 0.0867\n",
      "Epoch [2/4], Step [2887/3844], Loss: 0.1076\n",
      "Epoch [2/4], Step [2888/3844], Loss: 0.1535\n",
      "Epoch [2/4], Step [2889/3844], Loss: 0.1029\n",
      "Epoch [2/4], Step [2890/3844], Loss: 0.0718\n",
      "Epoch [2/4], Step [2891/3844], Loss: 0.1008\n",
      "Epoch [2/4], Step [2892/3844], Loss: 0.0713\n",
      "Epoch [2/4], Step [2893/3844], Loss: 0.0870\n",
      "Epoch [2/4], Step [2894/3844], Loss: 0.0872\n",
      "Epoch [2/4], Step [2895/3844], Loss: 0.1190\n",
      "Epoch [2/4], Step [2896/3844], Loss: 0.0803\n",
      "Epoch [2/4], Step [2897/3844], Loss: 0.0948\n",
      "Epoch [2/4], Step [2898/3844], Loss: 0.1211\n",
      "Epoch [2/4], Step [2899/3844], Loss: 0.1875\n",
      "Epoch [2/4], Step [2900/3844], Loss: 0.1376\n",
      "Epoch [2/4], Step [2901/3844], Loss: 0.1345\n",
      "Epoch [2/4], Step [2902/3844], Loss: 0.1621\n",
      "Epoch [2/4], Step [2903/3844], Loss: 0.0989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/4], Step [2904/3844], Loss: 0.0842\n",
      "Epoch [2/4], Step [2905/3844], Loss: 0.1604\n",
      "Epoch [2/4], Step [2906/3844], Loss: 0.0926\n",
      "Epoch [2/4], Step [2907/3844], Loss: 0.1517\n",
      "Epoch [2/4], Step [2908/3844], Loss: 0.1016\n",
      "Epoch [2/4], Step [2909/3844], Loss: 0.0733\n",
      "Epoch [2/4], Step [2910/3844], Loss: 0.0634\n",
      "Epoch [2/4], Step [2911/3844], Loss: 0.1422\n",
      "Epoch [2/4], Step [2912/3844], Loss: 0.0988\n",
      "Epoch [2/4], Step [2913/3844], Loss: 0.1288\n",
      "Epoch [2/4], Step [2914/3844], Loss: 0.0838\n",
      "Epoch [2/4], Step [2915/3844], Loss: 0.0856\n",
      "Epoch [2/4], Step [2916/3844], Loss: 0.1086\n",
      "Epoch [2/4], Step [2917/3844], Loss: 0.0551\n",
      "Epoch [2/4], Step [2918/3844], Loss: 0.0772\n",
      "Epoch [2/4], Step [2919/3844], Loss: 0.1834\n",
      "Epoch [2/4], Step [2920/3844], Loss: 0.0934\n",
      "Epoch [2/4], Step [2921/3844], Loss: 0.0851\n",
      "Epoch [2/4], Step [2922/3844], Loss: 0.1219\n",
      "Epoch [2/4], Step [2923/3844], Loss: 0.1014\n",
      "Epoch [2/4], Step [2924/3844], Loss: 0.1921\n",
      "Epoch [2/4], Step [2925/3844], Loss: 0.0790\n",
      "Epoch [2/4], Step [2926/3844], Loss: 0.0984\n",
      "Epoch [2/4], Step [2927/3844], Loss: 0.1623\n",
      "Epoch [2/4], Step [2928/3844], Loss: 0.0838\n",
      "Epoch [2/4], Step [2929/3844], Loss: 0.1679\n",
      "Epoch [2/4], Step [2930/3844], Loss: 0.0928\n",
      "Epoch [2/4], Step [2931/3844], Loss: 0.1414\n",
      "Epoch [2/4], Step [2932/3844], Loss: 0.1659\n",
      "Epoch [2/4], Step [2933/3844], Loss: 0.1833\n",
      "Epoch [2/4], Step [2934/3844], Loss: 0.2194\n",
      "Epoch [2/4], Step [2935/3844], Loss: 0.0785\n",
      "Epoch [2/4], Step [2936/3844], Loss: 0.0741\n",
      "Epoch [2/4], Step [2937/3844], Loss: 0.1968\n",
      "Epoch [2/4], Step [2938/3844], Loss: 0.1212\n",
      "Epoch [2/4], Step [2939/3844], Loss: 0.1389\n",
      "Epoch [2/4], Step [2940/3844], Loss: 0.0807\n",
      "Epoch [2/4], Step [2941/3844], Loss: 0.1648\n",
      "Epoch [2/4], Step [2942/3844], Loss: 0.1266\n",
      "Epoch [2/4], Step [2943/3844], Loss: 0.0918\n",
      "Epoch [2/4], Step [2944/3844], Loss: 0.0928\n",
      "Epoch [2/4], Step [2945/3844], Loss: 0.0892\n",
      "Epoch [2/4], Step [2946/3844], Loss: 0.0849\n",
      "Epoch [2/4], Step [2947/3844], Loss: 0.1478\n",
      "Epoch [2/4], Step [2948/3844], Loss: 0.1793\n",
      "Epoch [2/4], Step [2949/3844], Loss: 0.0687\n",
      "Epoch [2/4], Step [2950/3844], Loss: 0.1106\n",
      "Epoch [2/4], Step [2951/3844], Loss: 0.1523\n",
      "Epoch [2/4], Step [2952/3844], Loss: 0.1180\n",
      "Epoch [2/4], Step [2953/3844], Loss: 0.0781\n",
      "Epoch [2/4], Step [2954/3844], Loss: 0.0961\n",
      "Epoch [2/4], Step [2955/3844], Loss: 0.0647\n",
      "Epoch [2/4], Step [2956/3844], Loss: 0.1073\n",
      "Epoch [2/4], Step [2957/3844], Loss: 0.1555\n",
      "Epoch [2/4], Step [2958/3844], Loss: 0.0906\n",
      "Epoch [2/4], Step [2959/3844], Loss: 0.1221\n",
      "Epoch [2/4], Step [2960/3844], Loss: 0.0871\n",
      "Epoch [2/4], Step [2961/3844], Loss: 0.1342\n",
      "Epoch [2/4], Step [2962/3844], Loss: 0.1432\n",
      "Epoch [2/4], Step [2963/3844], Loss: 0.0764\n",
      "Epoch [2/4], Step [2964/3844], Loss: 0.0601\n",
      "Epoch [2/4], Step [2965/3844], Loss: 0.1030\n",
      "Epoch [2/4], Step [2966/3844], Loss: 0.1678\n",
      "Epoch [2/4], Step [2967/3844], Loss: 0.1018\n",
      "Epoch [2/4], Step [2968/3844], Loss: 0.0757\n",
      "Epoch [2/4], Step [2969/3844], Loss: 0.1196\n",
      "Epoch [2/4], Step [2970/3844], Loss: 0.1088\n",
      "Epoch [2/4], Step [2971/3844], Loss: 0.0857\n",
      "Epoch [2/4], Step [2972/3844], Loss: 0.0952\n",
      "Epoch [2/4], Step [2973/3844], Loss: 0.1119\n",
      "Epoch [2/4], Step [2974/3844], Loss: 0.1591\n",
      "Epoch [2/4], Step [2975/3844], Loss: 0.1120\n",
      "Epoch [2/4], Step [2976/3844], Loss: 0.1375\n",
      "Epoch [2/4], Step [2977/3844], Loss: 0.0814\n",
      "Epoch [2/4], Step [2978/3844], Loss: 0.1880\n",
      "Epoch [2/4], Step [2979/3844], Loss: 0.1872\n",
      "Epoch [2/4], Step [2980/3844], Loss: 0.0698\n",
      "Epoch [2/4], Step [2981/3844], Loss: 0.1457\n",
      "Epoch [2/4], Step [2982/3844], Loss: 0.0713\n",
      "Epoch [2/4], Step [2983/3844], Loss: 0.1675\n",
      "Epoch [2/4], Step [2984/3844], Loss: 0.0594\n",
      "Epoch [2/4], Step [2985/3844], Loss: 0.1194\n",
      "Epoch [2/4], Step [2986/3844], Loss: 0.1497\n",
      "Epoch [2/4], Step [2987/3844], Loss: 0.1127\n",
      "Epoch [2/4], Step [2988/3844], Loss: 0.1046\n",
      "Epoch [2/4], Step [2989/3844], Loss: 0.0806\n",
      "Epoch [2/4], Step [2990/3844], Loss: 0.1116\n",
      "Epoch [2/4], Step [2991/3844], Loss: 0.1107\n",
      "Epoch [2/4], Step [2992/3844], Loss: 0.1498\n",
      "Epoch [2/4], Step [2993/3844], Loss: 0.1461\n",
      "Epoch [2/4], Step [2994/3844], Loss: 0.1348\n",
      "Epoch [2/4], Step [2995/3844], Loss: 0.1505\n",
      "Epoch [2/4], Step [2996/3844], Loss: 0.0918\n",
      "Epoch [2/4], Step [2997/3844], Loss: 0.1464\n",
      "Epoch [2/4], Step [2998/3844], Loss: 0.0675\n",
      "Epoch [2/4], Step [2999/3844], Loss: 0.0806\n",
      "Epoch [2/4], Step [3000/3844], Loss: 0.1363\n",
      "Epoch [2/4], Step [3001/3844], Loss: 0.0747\n",
      "Epoch [2/4], Step [3002/3844], Loss: 0.0884\n",
      "Epoch [2/4], Step [3003/3844], Loss: 0.0807\n",
      "Epoch [2/4], Step [3004/3844], Loss: 0.1272\n",
      "Epoch [2/4], Step [3005/3844], Loss: 0.0875\n",
      "Epoch [2/4], Step [3006/3844], Loss: 0.1103\n",
      "Epoch [2/4], Step [3007/3844], Loss: 0.1275\n",
      "Epoch [2/4], Step [3008/3844], Loss: 0.0831\n",
      "Epoch [2/4], Step [3009/3844], Loss: 0.1001\n",
      "Epoch [2/4], Step [3010/3844], Loss: 0.0921\n",
      "Epoch [2/4], Step [3011/3844], Loss: 0.1186\n",
      "Epoch [2/4], Step [3012/3844], Loss: 0.1584\n",
      "Epoch [2/4], Step [3013/3844], Loss: 0.1003\n",
      "Epoch [2/4], Step [3014/3844], Loss: 0.0656\n",
      "Epoch [2/4], Step [3015/3844], Loss: 0.1354\n",
      "Epoch [2/4], Step [3016/3844], Loss: 0.0839\n",
      "Epoch [2/4], Step [3017/3844], Loss: 0.0670\n",
      "Epoch [2/4], Step [3018/3844], Loss: 0.0859\n",
      "Epoch [2/4], Step [3019/3844], Loss: 0.0549\n",
      "Epoch [2/4], Step [3020/3844], Loss: 0.1133\n",
      "Epoch [2/4], Step [3021/3844], Loss: 0.2087\n",
      "Epoch [2/4], Step [3022/3844], Loss: 0.1600\n",
      "Epoch [2/4], Step [3023/3844], Loss: 0.1581\n",
      "Epoch [2/4], Step [3024/3844], Loss: 0.0778\n",
      "Epoch [2/4], Step [3025/3844], Loss: 0.0951\n",
      "Epoch [2/4], Step [3026/3844], Loss: 0.0711\n",
      "Epoch [2/4], Step [3027/3844], Loss: 0.1268\n",
      "Epoch [2/4], Step [3028/3844], Loss: 0.0826\n",
      "Epoch [2/4], Step [3029/3844], Loss: 0.1510\n",
      "Epoch [2/4], Step [3030/3844], Loss: 0.1008\n",
      "Epoch [2/4], Step [3031/3844], Loss: 0.0823\n",
      "Epoch [2/4], Step [3032/3844], Loss: 0.1407\n",
      "Epoch [2/4], Step [3033/3844], Loss: 0.0743\n",
      "Epoch [2/4], Step [3034/3844], Loss: 0.1215\n",
      "Epoch [2/4], Step [3035/3844], Loss: 0.1413\n",
      "Epoch [2/4], Step [3036/3844], Loss: 0.0739\n",
      "Epoch [2/4], Step [3037/3844], Loss: 0.1364\n",
      "Epoch [2/4], Step [3038/3844], Loss: 0.0881\n",
      "Epoch [2/4], Step [3039/3844], Loss: 0.0637\n",
      "Epoch [2/4], Step [3040/3844], Loss: 0.0823\n",
      "Epoch [2/4], Step [3041/3844], Loss: 0.0775\n",
      "Epoch [2/4], Step [3042/3844], Loss: 0.0958\n",
      "Epoch [2/4], Step [3043/3844], Loss: 0.0810\n",
      "Epoch [2/4], Step [3044/3844], Loss: 0.1004\n",
      "Epoch [2/4], Step [3045/3844], Loss: 0.1264\n",
      "Epoch [2/4], Step [3046/3844], Loss: 0.1336\n",
      "Epoch [2/4], Step [3047/3844], Loss: 0.2119\n",
      "Epoch [2/4], Step [3048/3844], Loss: 0.0938\n",
      "Epoch [2/4], Step [3049/3844], Loss: 0.1568\n",
      "Epoch [2/4], Step [3050/3844], Loss: 0.0934\n",
      "Epoch [2/4], Step [3051/3844], Loss: 0.1566\n",
      "Epoch [2/4], Step [3052/3844], Loss: 0.1219\n",
      "Epoch [2/4], Step [3053/3844], Loss: 0.1406\n",
      "Epoch [2/4], Step [3054/3844], Loss: 0.1553\n",
      "Epoch [2/4], Step [3055/3844], Loss: 0.1217\n",
      "Epoch [2/4], Step [3056/3844], Loss: 0.0893\n",
      "Epoch [2/4], Step [3057/3844], Loss: 0.1132\n",
      "Epoch [2/4], Step [3058/3844], Loss: 0.1323\n",
      "Epoch [2/4], Step [3059/3844], Loss: 0.1238\n",
      "Epoch [2/4], Step [3060/3844], Loss: 0.1226\n",
      "Epoch [2/4], Step [3061/3844], Loss: 0.1516\n",
      "Epoch [2/4], Step [3062/3844], Loss: 0.1410\n",
      "Epoch [2/4], Step [3063/3844], Loss: 0.1463\n",
      "Epoch [2/4], Step [3064/3844], Loss: 0.1190\n",
      "Epoch [2/4], Step [3065/3844], Loss: 0.0981\n",
      "Epoch [2/4], Step [3066/3844], Loss: 0.1589\n",
      "Epoch [2/4], Step [3067/3844], Loss: 0.1217\n",
      "Epoch [2/4], Step [3068/3844], Loss: 0.1580\n",
      "Epoch [2/4], Step [3069/3844], Loss: 0.1587\n",
      "Epoch [2/4], Step [3070/3844], Loss: 0.1274\n",
      "Epoch [2/4], Step [3071/3844], Loss: 0.1042\n",
      "Epoch [2/4], Step [3072/3844], Loss: 0.0885\n",
      "Epoch [2/4], Step [3073/3844], Loss: 0.0875\n",
      "Epoch [2/4], Step [3074/3844], Loss: 0.1063\n",
      "Epoch [2/4], Step [3075/3844], Loss: 0.1124\n",
      "Epoch [2/4], Step [3076/3844], Loss: 0.0991\n",
      "Epoch [2/4], Step [3077/3844], Loss: 0.1554\n",
      "Epoch [2/4], Step [3078/3844], Loss: 0.1119\n",
      "Epoch [2/4], Step [3079/3844], Loss: 0.2136\n",
      "Epoch [2/4], Step [3080/3844], Loss: 0.1635\n",
      "Epoch [2/4], Step [3081/3844], Loss: 0.2333\n",
      "Epoch [2/4], Step [3082/3844], Loss: 0.0796\n",
      "Epoch [2/4], Step [3083/3844], Loss: 0.1046\n",
      "Epoch [2/4], Step [3084/3844], Loss: 0.1424\n",
      "Epoch [2/4], Step [3085/3844], Loss: 0.0839\n",
      "Epoch [2/4], Step [3086/3844], Loss: 0.1259\n",
      "Epoch [2/4], Step [3087/3844], Loss: 0.1510\n",
      "Epoch [2/4], Step [3088/3844], Loss: 0.0743\n",
      "Epoch [2/4], Step [3089/3844], Loss: 0.1280\n",
      "Epoch [2/4], Step [3090/3844], Loss: 0.2006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/4], Step [3091/3844], Loss: 0.1534\n",
      "Epoch [2/4], Step [3092/3844], Loss: 0.1669\n",
      "Epoch [2/4], Step [3093/3844], Loss: 0.0768\n",
      "Epoch [2/4], Step [3094/3844], Loss: 0.1295\n",
      "Epoch [2/4], Step [3095/3844], Loss: 0.1091\n",
      "Epoch [2/4], Step [3096/3844], Loss: 0.1489\n",
      "Epoch [2/4], Step [3097/3844], Loss: 0.0750\n",
      "Epoch [2/4], Step [3098/3844], Loss: 0.0702\n",
      "Epoch [2/4], Step [3099/3844], Loss: 0.1019\n",
      "Epoch [2/4], Step [3100/3844], Loss: 0.2287\n",
      "Epoch [2/4], Step [3101/3844], Loss: 0.1788\n",
      "Epoch [2/4], Step [3102/3844], Loss: 0.1139\n",
      "Epoch [2/4], Step [3103/3844], Loss: 0.2211\n",
      "Epoch [2/4], Step [3104/3844], Loss: 0.0690\n",
      "Epoch [2/4], Step [3105/3844], Loss: 0.1285\n",
      "Epoch [2/4], Step [3106/3844], Loss: 0.1006\n",
      "Epoch [2/4], Step [3107/3844], Loss: 0.1646\n",
      "Epoch [2/4], Step [3108/3844], Loss: 0.1314\n",
      "Epoch [2/4], Step [3109/3844], Loss: 0.0827\n",
      "Epoch [2/4], Step [3110/3844], Loss: 0.1318\n",
      "Epoch [2/4], Step [3111/3844], Loss: 0.1618\n",
      "Epoch [2/4], Step [3112/3844], Loss: 0.0579\n",
      "Epoch [2/4], Step [3113/3844], Loss: 0.0853\n",
      "Epoch [2/4], Step [3114/3844], Loss: 0.1117\n",
      "Epoch [2/4], Step [3115/3844], Loss: 0.0961\n",
      "Epoch [2/4], Step [3116/3844], Loss: 0.0645\n",
      "Epoch [2/4], Step [3117/3844], Loss: 0.1509\n",
      "Epoch [2/4], Step [3118/3844], Loss: 0.1109\n",
      "Epoch [2/4], Step [3119/3844], Loss: 0.1876\n",
      "Epoch [2/4], Step [3120/3844], Loss: 0.1472\n",
      "Epoch [2/4], Step [3121/3844], Loss: 0.1676\n",
      "Epoch [2/4], Step [3122/3844], Loss: 0.1423\n",
      "Epoch [2/4], Step [3123/3844], Loss: 0.1199\n",
      "Epoch [2/4], Step [3124/3844], Loss: 0.0798\n",
      "Epoch [2/4], Step [3125/3844], Loss: 0.1641\n",
      "Epoch [2/4], Step [3126/3844], Loss: 0.0910\n",
      "Epoch [2/4], Step [3127/3844], Loss: 0.1039\n",
      "Epoch [2/4], Step [3128/3844], Loss: 0.1347\n",
      "Epoch [2/4], Step [3129/3844], Loss: 0.1196\n",
      "Epoch [2/4], Step [3130/3844], Loss: 0.1606\n",
      "Epoch [2/4], Step [3131/3844], Loss: 0.1047\n",
      "Epoch [2/4], Step [3132/3844], Loss: 0.0826\n",
      "Epoch [2/4], Step [3133/3844], Loss: 0.0868\n",
      "Epoch [2/4], Step [3134/3844], Loss: 0.0847\n",
      "Epoch [2/4], Step [3135/3844], Loss: 0.0927\n",
      "Epoch [2/4], Step [3136/3844], Loss: 0.1267\n",
      "Epoch [2/4], Step [3137/3844], Loss: 0.0794\n",
      "Epoch [2/4], Step [3138/3844], Loss: 0.0755\n",
      "Epoch [2/4], Step [3139/3844], Loss: 0.0761\n",
      "Epoch [2/4], Step [3140/3844], Loss: 0.0723\n",
      "Epoch [2/4], Step [3141/3844], Loss: 0.1461\n",
      "Epoch [2/4], Step [3142/3844], Loss: 0.1618\n",
      "Epoch [2/4], Step [3143/3844], Loss: 0.0666\n",
      "Epoch [2/4], Step [3144/3844], Loss: 0.1371\n",
      "Epoch [2/4], Step [3145/3844], Loss: 0.0838\n",
      "Epoch [2/4], Step [3146/3844], Loss: 0.0746\n",
      "Epoch [2/4], Step [3147/3844], Loss: 0.1115\n",
      "Epoch [2/4], Step [3148/3844], Loss: 0.1571\n",
      "Epoch [2/4], Step [3149/3844], Loss: 0.1527\n",
      "Epoch [2/4], Step [3150/3844], Loss: 0.1193\n",
      "Epoch [2/4], Step [3151/3844], Loss: 0.1781\n",
      "Epoch [2/4], Step [3152/3844], Loss: 0.0929\n",
      "Epoch [2/4], Step [3153/3844], Loss: 0.1491\n",
      "Epoch [2/4], Step [3154/3844], Loss: 0.0932\n",
      "Epoch [2/4], Step [3155/3844], Loss: 0.1549\n",
      "Epoch [2/4], Step [3156/3844], Loss: 0.1404\n",
      "Epoch [2/4], Step [3157/3844], Loss: 0.1262\n",
      "Epoch [2/4], Step [3158/3844], Loss: 0.1086\n",
      "Epoch [2/4], Step [3159/3844], Loss: 0.1104\n",
      "Epoch [2/4], Step [3160/3844], Loss: 0.0946\n",
      "Epoch [2/4], Step [3161/3844], Loss: 0.0934\n",
      "Epoch [2/4], Step [3162/3844], Loss: 0.0906\n",
      "Epoch [2/4], Step [3163/3844], Loss: 0.1608\n",
      "Epoch [2/4], Step [3164/3844], Loss: 0.1670\n",
      "Epoch [2/4], Step [3165/3844], Loss: 0.0926\n",
      "Epoch [2/4], Step [3166/3844], Loss: 0.0717\n",
      "Epoch [2/4], Step [3167/3844], Loss: 0.2198\n",
      "Epoch [2/4], Step [3168/3844], Loss: 0.1028\n",
      "Epoch [2/4], Step [3169/3844], Loss: 0.0964\n",
      "Epoch [2/4], Step [3170/3844], Loss: 0.0938\n",
      "Epoch [2/4], Step [3171/3844], Loss: 0.1054\n",
      "Epoch [2/4], Step [3172/3844], Loss: 0.1188\n",
      "Epoch [2/4], Step [3173/3844], Loss: 0.0809\n",
      "Epoch [2/4], Step [3174/3844], Loss: 0.0889\n",
      "Epoch [2/4], Step [3175/3844], Loss: 0.0969\n",
      "Epoch [2/4], Step [3176/3844], Loss: 0.1245\n",
      "Epoch [2/4], Step [3177/3844], Loss: 0.0769\n",
      "Epoch [2/4], Step [3178/3844], Loss: 0.0815\n",
      "Epoch [2/4], Step [3179/3844], Loss: 0.1193\n",
      "Epoch [2/4], Step [3180/3844], Loss: 0.1359\n",
      "Epoch [2/4], Step [3181/3844], Loss: 0.1106\n",
      "Epoch [2/4], Step [3182/3844], Loss: 0.1091\n",
      "Epoch [2/4], Step [3183/3844], Loss: 0.1454\n",
      "Epoch [2/4], Step [3184/3844], Loss: 0.0923\n",
      "Epoch [2/4], Step [3185/3844], Loss: 0.1125\n",
      "Epoch [2/4], Step [3186/3844], Loss: 0.1048\n",
      "Epoch [2/4], Step [3187/3844], Loss: 0.0431\n",
      "Epoch [2/4], Step [3188/3844], Loss: 0.0781\n",
      "Epoch [2/4], Step [3189/3844], Loss: 0.1300\n",
      "Epoch [2/4], Step [3190/3844], Loss: 0.1277\n",
      "Epoch [2/4], Step [3191/3844], Loss: 0.1489\n",
      "Epoch [2/4], Step [3192/3844], Loss: 0.0913\n",
      "Epoch [2/4], Step [3193/3844], Loss: 0.1286\n",
      "Epoch [2/4], Step [3194/3844], Loss: 0.1422\n",
      "Epoch [2/4], Step [3195/3844], Loss: 0.1060\n",
      "Epoch [2/4], Step [3196/3844], Loss: 0.1472\n",
      "Epoch [2/4], Step [3197/3844], Loss: 0.0709\n",
      "Epoch [2/4], Step [3198/3844], Loss: 0.1507\n",
      "Epoch [2/4], Step [3199/3844], Loss: 0.0982\n",
      "Epoch [2/4], Step [3200/3844], Loss: 0.2098\n",
      "Epoch [2/4], Step [3201/3844], Loss: 0.1041\n",
      "Epoch [2/4], Step [3202/3844], Loss: 0.1069\n",
      "Epoch [2/4], Step [3203/3844], Loss: 0.0975\n",
      "Epoch [2/4], Step [3204/3844], Loss: 0.0838\n",
      "Epoch [2/4], Step [3205/3844], Loss: 0.1076\n",
      "Epoch [2/4], Step [3206/3844], Loss: 0.2162\n",
      "Epoch [2/4], Step [3207/3844], Loss: 0.0961\n",
      "Epoch [2/4], Step [3208/3844], Loss: 0.1284\n",
      "Epoch [2/4], Step [3209/3844], Loss: 0.0813\n",
      "Epoch [2/4], Step [3210/3844], Loss: 0.1354\n",
      "Epoch [2/4], Step [3211/3844], Loss: 0.0845\n",
      "Epoch [2/4], Step [3212/3844], Loss: 0.0817\n",
      "Epoch [2/4], Step [3213/3844], Loss: 0.0926\n",
      "Epoch [2/4], Step [3214/3844], Loss: 0.1680\n",
      "Epoch [2/4], Step [3215/3844], Loss: 0.2090\n",
      "Epoch [2/4], Step [3216/3844], Loss: 0.1512\n",
      "Epoch [2/4], Step [3217/3844], Loss: 0.1210\n",
      "Epoch [2/4], Step [3218/3844], Loss: 0.1110\n",
      "Epoch [2/4], Step [3219/3844], Loss: 0.0713\n",
      "Epoch [2/4], Step [3220/3844], Loss: 0.0669\n",
      "Epoch [2/4], Step [3221/3844], Loss: 0.1070\n",
      "Epoch [2/4], Step [3222/3844], Loss: 0.0605\n",
      "Epoch [2/4], Step [3223/3844], Loss: 0.1385\n",
      "Epoch [2/4], Step [3224/3844], Loss: 0.1467\n",
      "Epoch [2/4], Step [3225/3844], Loss: 0.0939\n",
      "Epoch [2/4], Step [3226/3844], Loss: 0.1204\n",
      "Epoch [2/4], Step [3227/3844], Loss: 0.0997\n",
      "Epoch [2/4], Step [3228/3844], Loss: 0.2110\n",
      "Epoch [2/4], Step [3229/3844], Loss: 0.0844\n",
      "Epoch [2/4], Step [3230/3844], Loss: 0.1298\n",
      "Epoch [2/4], Step [3231/3844], Loss: 0.0986\n",
      "Epoch [2/4], Step [3232/3844], Loss: 0.1974\n",
      "Epoch [2/4], Step [3233/3844], Loss: 0.0737\n",
      "Epoch [2/4], Step [3234/3844], Loss: 0.0775\n",
      "Epoch [2/4], Step [3235/3844], Loss: 0.1769\n",
      "Epoch [2/4], Step [3236/3844], Loss: 0.0654\n",
      "Epoch [2/4], Step [3237/3844], Loss: 0.1390\n",
      "Epoch [2/4], Step [3238/3844], Loss: 0.1358\n",
      "Epoch [2/4], Step [3239/3844], Loss: 0.1040\n",
      "Epoch [2/4], Step [3240/3844], Loss: 0.1350\n",
      "Epoch [2/4], Step [3241/3844], Loss: 0.1332\n",
      "Epoch [2/4], Step [3242/3844], Loss: 0.1008\n",
      "Epoch [2/4], Step [3243/3844], Loss: 0.0836\n",
      "Epoch [2/4], Step [3244/3844], Loss: 0.0800\n",
      "Epoch [2/4], Step [3245/3844], Loss: 0.1630\n",
      "Epoch [2/4], Step [3246/3844], Loss: 0.1024\n",
      "Epoch [2/4], Step [3247/3844], Loss: 0.1271\n",
      "Epoch [2/4], Step [3248/3844], Loss: 0.0735\n",
      "Epoch [2/4], Step [3249/3844], Loss: 0.0868\n",
      "Epoch [2/4], Step [3250/3844], Loss: 0.0931\n",
      "Epoch [2/4], Step [3251/3844], Loss: 0.1987\n",
      "Epoch [2/4], Step [3252/3844], Loss: 0.1067\n",
      "Epoch [2/4], Step [3253/3844], Loss: 0.0608\n",
      "Epoch [2/4], Step [3254/3844], Loss: 0.0954\n",
      "Epoch [2/4], Step [3255/3844], Loss: 0.1244\n",
      "Epoch [2/4], Step [3256/3844], Loss: 0.0908\n",
      "Epoch [2/4], Step [3257/3844], Loss: 0.0781\n",
      "Epoch [2/4], Step [3258/3844], Loss: 0.1097\n",
      "Epoch [2/4], Step [3259/3844], Loss: 0.0748\n",
      "Epoch [2/4], Step [3260/3844], Loss: 0.1488\n",
      "Epoch [2/4], Step [3261/3844], Loss: 0.1344\n",
      "Epoch [2/4], Step [3262/3844], Loss: 0.0984\n",
      "Epoch [2/4], Step [3263/3844], Loss: 0.0806\n",
      "Epoch [2/4], Step [3264/3844], Loss: 0.0952\n",
      "Epoch [2/4], Step [3265/3844], Loss: 0.0936\n",
      "Epoch [2/4], Step [3266/3844], Loss: 0.1584\n",
      "Epoch [2/4], Step [3267/3844], Loss: 0.0924\n",
      "Epoch [2/4], Step [3268/3844], Loss: 0.1026\n",
      "Epoch [2/4], Step [3269/3844], Loss: 0.1439\n",
      "Epoch [2/4], Step [3270/3844], Loss: 0.1536\n",
      "Epoch [2/4], Step [3271/3844], Loss: 0.2358\n",
      "Epoch [2/4], Step [3272/3844], Loss: 0.1265\n",
      "Epoch [2/4], Step [3273/3844], Loss: 0.0805\n",
      "Epoch [2/4], Step [3274/3844], Loss: 0.1131\n",
      "Epoch [2/4], Step [3275/3844], Loss: 0.0819\n",
      "Epoch [2/4], Step [3276/3844], Loss: 0.1541\n",
      "Epoch [2/4], Step [3277/3844], Loss: 0.1387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/4], Step [3278/3844], Loss: 0.1647\n",
      "Epoch [2/4], Step [3279/3844], Loss: 0.0940\n",
      "Epoch [2/4], Step [3280/3844], Loss: 0.1155\n",
      "Epoch [2/4], Step [3281/3844], Loss: 0.1374\n",
      "Epoch [2/4], Step [3282/3844], Loss: 0.1072\n",
      "Epoch [2/4], Step [3283/3844], Loss: 0.1672\n",
      "Epoch [2/4], Step [3284/3844], Loss: 0.1702\n",
      "Epoch [2/4], Step [3285/3844], Loss: 0.1367\n",
      "Epoch [2/4], Step [3286/3844], Loss: 0.1010\n",
      "Epoch [2/4], Step [3287/3844], Loss: 0.1616\n",
      "Epoch [2/4], Step [3288/3844], Loss: 0.0728\n",
      "Epoch [2/4], Step [3289/3844], Loss: 0.0680\n",
      "Epoch [2/4], Step [3290/3844], Loss: 0.1678\n",
      "Epoch [2/4], Step [3291/3844], Loss: 0.1235\n",
      "Epoch [2/4], Step [3292/3844], Loss: 0.1042\n",
      "Epoch [2/4], Step [3293/3844], Loss: 0.0941\n",
      "Epoch [2/4], Step [3294/3844], Loss: 0.0746\n",
      "Epoch [2/4], Step [3295/3844], Loss: 0.1164\n",
      "Epoch [2/4], Step [3296/3844], Loss: 0.0997\n",
      "Epoch [2/4], Step [3297/3844], Loss: 0.1065\n",
      "Epoch [2/4], Step [3298/3844], Loss: 0.1356\n",
      "Epoch [2/4], Step [3299/3844], Loss: 0.1118\n",
      "Epoch [2/4], Step [3300/3844], Loss: 0.0857\n",
      "Epoch [2/4], Step [3301/3844], Loss: 0.1272\n",
      "Epoch [2/4], Step [3302/3844], Loss: 0.1346\n",
      "Epoch [2/4], Step [3303/3844], Loss: 0.0924\n",
      "Epoch [2/4], Step [3304/3844], Loss: 0.1511\n",
      "Epoch [2/4], Step [3305/3844], Loss: 0.1039\n",
      "Epoch [2/4], Step [3306/3844], Loss: 0.0812\n",
      "Epoch [2/4], Step [3307/3844], Loss: 0.1322\n",
      "Epoch [2/4], Step [3308/3844], Loss: 0.1077\n",
      "Epoch [2/4], Step [3309/3844], Loss: 0.0811\n",
      "Epoch [2/4], Step [3310/3844], Loss: 0.0969\n",
      "Epoch [2/4], Step [3311/3844], Loss: 0.1437\n",
      "Epoch [2/4], Step [3312/3844], Loss: 0.1142\n",
      "Epoch [2/4], Step [3313/3844], Loss: 0.1067\n",
      "Epoch [2/4], Step [3314/3844], Loss: 0.1573\n",
      "Epoch [2/4], Step [3315/3844], Loss: 0.0810\n",
      "Epoch [2/4], Step [3316/3844], Loss: 0.1196\n",
      "Epoch [2/4], Step [3317/3844], Loss: 0.2135\n",
      "Epoch [2/4], Step [3318/3844], Loss: 0.0993\n",
      "Epoch [2/4], Step [3319/3844], Loss: 0.2314\n",
      "Epoch [2/4], Step [3320/3844], Loss: 0.1447\n",
      "Epoch [2/4], Step [3321/3844], Loss: 0.0872\n",
      "Epoch [2/4], Step [3322/3844], Loss: 0.1392\n",
      "Epoch [2/4], Step [3323/3844], Loss: 0.1506\n",
      "Epoch [2/4], Step [3324/3844], Loss: 0.1001\n",
      "Epoch [2/4], Step [3325/3844], Loss: 0.0901\n",
      "Epoch [2/4], Step [3326/3844], Loss: 0.1118\n",
      "Epoch [2/4], Step [3327/3844], Loss: 0.1150\n",
      "Epoch [2/4], Step [3328/3844], Loss: 0.1083\n",
      "Epoch [2/4], Step [3329/3844], Loss: 0.1210\n",
      "Epoch [2/4], Step [3330/3844], Loss: 0.1340\n",
      "Epoch [2/4], Step [3331/3844], Loss: 0.1410\n",
      "Epoch [2/4], Step [3332/3844], Loss: 0.0757\n",
      "Epoch [2/4], Step [3333/3844], Loss: 0.2499\n",
      "Epoch [2/4], Step [3334/3844], Loss: 0.0712\n",
      "Epoch [2/4], Step [3335/3844], Loss: 0.0619\n",
      "Epoch [2/4], Step [3336/3844], Loss: 0.0544\n",
      "Epoch [2/4], Step [3337/3844], Loss: 0.1100\n",
      "Epoch [2/4], Step [3338/3844], Loss: 0.1349\n",
      "Epoch [2/4], Step [3339/3844], Loss: 0.0912\n",
      "Epoch [2/4], Step [3340/3844], Loss: 0.0731\n",
      "Epoch [2/4], Step [3341/3844], Loss: 0.1025\n",
      "Epoch [2/4], Step [3342/3844], Loss: 0.2573\n",
      "Epoch [2/4], Step [3343/3844], Loss: 0.1417\n",
      "Epoch [2/4], Step [3344/3844], Loss: 0.0959\n",
      "Epoch [2/4], Step [3345/3844], Loss: 0.0998\n",
      "Epoch [2/4], Step [3346/3844], Loss: 0.0920\n",
      "Epoch [2/4], Step [3347/3844], Loss: 0.0626\n",
      "Epoch [2/4], Step [3348/3844], Loss: 0.1008\n",
      "Epoch [2/4], Step [3349/3844], Loss: 0.0948\n",
      "Epoch [2/4], Step [3350/3844], Loss: 0.1577\n",
      "Epoch [2/4], Step [3351/3844], Loss: 0.2218\n",
      "Epoch [2/4], Step [3352/3844], Loss: 0.0912\n",
      "Epoch [2/4], Step [3353/3844], Loss: 0.1210\n",
      "Epoch [2/4], Step [3354/3844], Loss: 0.1718\n",
      "Epoch [2/4], Step [3355/3844], Loss: 0.0966\n",
      "Epoch [2/4], Step [3356/3844], Loss: 0.0820\n",
      "Epoch [2/4], Step [3357/3844], Loss: 0.0905\n",
      "Epoch [2/4], Step [3358/3844], Loss: 0.0803\n",
      "Epoch [2/4], Step [3359/3844], Loss: 0.1103\n",
      "Epoch [2/4], Step [3360/3844], Loss: 0.1003\n",
      "Epoch [2/4], Step [3361/3844], Loss: 0.1443\n",
      "Epoch [2/4], Step [3362/3844], Loss: 0.0949\n",
      "Epoch [2/4], Step [3363/3844], Loss: 0.1015\n",
      "Epoch [2/4], Step [3364/3844], Loss: 0.0903\n",
      "Epoch [2/4], Step [3365/3844], Loss: 0.1007\n",
      "Epoch [2/4], Step [3366/3844], Loss: 0.1264\n",
      "Epoch [2/4], Step [3367/3844], Loss: 0.0778\n",
      "Epoch [2/4], Step [3368/3844], Loss: 0.0617\n",
      "Epoch [2/4], Step [3369/3844], Loss: 0.1628\n",
      "Epoch [2/4], Step [3370/3844], Loss: 0.0624\n",
      "Epoch [2/4], Step [3371/3844], Loss: 0.1220\n",
      "Epoch [2/4], Step [3372/3844], Loss: 0.2300\n",
      "Epoch [2/4], Step [3373/3844], Loss: 0.1254\n",
      "Epoch [2/4], Step [3374/3844], Loss: 0.1110\n",
      "Epoch [2/4], Step [3375/3844], Loss: 0.1338\n",
      "Epoch [2/4], Step [3376/3844], Loss: 0.1342\n",
      "Epoch [2/4], Step [3377/3844], Loss: 0.0894\n",
      "Epoch [2/4], Step [3378/3844], Loss: 0.0967\n",
      "Epoch [2/4], Step [3379/3844], Loss: 0.0601\n",
      "Epoch [2/4], Step [3380/3844], Loss: 0.1107\n",
      "Epoch [2/4], Step [3381/3844], Loss: 0.0843\n",
      "Epoch [2/4], Step [3382/3844], Loss: 0.0638\n",
      "Epoch [2/4], Step [3383/3844], Loss: 0.0776\n",
      "Epoch [2/4], Step [3384/3844], Loss: 0.0967\n",
      "Epoch [2/4], Step [3385/3844], Loss: 0.0770\n",
      "Epoch [2/4], Step [3386/3844], Loss: 0.1771\n",
      "Epoch [2/4], Step [3387/3844], Loss: 0.1118\n",
      "Epoch [2/4], Step [3388/3844], Loss: 0.0740\n",
      "Epoch [2/4], Step [3389/3844], Loss: 0.1221\n",
      "Epoch [2/4], Step [3390/3844], Loss: 0.0869\n",
      "Epoch [2/4], Step [3391/3844], Loss: 0.0871\n",
      "Epoch [2/4], Step [3392/3844], Loss: 0.2440\n",
      "Epoch [2/4], Step [3393/3844], Loss: 0.1031\n",
      "Epoch [2/4], Step [3394/3844], Loss: 0.0808\n",
      "Epoch [2/4], Step [3395/3844], Loss: 0.0564\n",
      "Epoch [2/4], Step [3396/3844], Loss: 0.2099\n",
      "Epoch [2/4], Step [3397/3844], Loss: 0.0901\n",
      "Epoch [2/4], Step [3398/3844], Loss: 0.0848\n",
      "Epoch [2/4], Step [3399/3844], Loss: 0.1138\n",
      "Epoch [2/4], Step [3400/3844], Loss: 0.1235\n",
      "Epoch [2/4], Step [3401/3844], Loss: 0.1388\n",
      "Epoch [2/4], Step [3402/3844], Loss: 0.1838\n",
      "Epoch [2/4], Step [3403/3844], Loss: 0.0736\n",
      "Epoch [2/4], Step [3404/3844], Loss: 0.1106\n",
      "Epoch [2/4], Step [3405/3844], Loss: 0.1443\n",
      "Epoch [2/4], Step [3406/3844], Loss: 0.0782\n",
      "Epoch [2/4], Step [3407/3844], Loss: 0.1039\n",
      "Epoch [2/4], Step [3408/3844], Loss: 0.0828\n",
      "Epoch [2/4], Step [3409/3844], Loss: 0.0706\n",
      "Epoch [2/4], Step [3410/3844], Loss: 0.0932\n",
      "Epoch [2/4], Step [3411/3844], Loss: 0.1152\n",
      "Epoch [2/4], Step [3412/3844], Loss: 0.0948\n",
      "Epoch [2/4], Step [3413/3844], Loss: 0.1355\n",
      "Epoch [2/4], Step [3414/3844], Loss: 0.1061\n",
      "Epoch [2/4], Step [3415/3844], Loss: 0.1300\n",
      "Epoch [2/4], Step [3416/3844], Loss: 0.0923\n",
      "Epoch [2/4], Step [3417/3844], Loss: 0.1367\n",
      "Epoch [2/4], Step [3418/3844], Loss: 0.1038\n",
      "Epoch [2/4], Step [3419/3844], Loss: 0.0856\n",
      "Epoch [2/4], Step [3420/3844], Loss: 0.1243\n",
      "Epoch [2/4], Step [3421/3844], Loss: 0.0861\n",
      "Epoch [2/4], Step [3422/3844], Loss: 0.1281\n",
      "Epoch [2/4], Step [3423/3844], Loss: 0.0514\n",
      "Epoch [2/4], Step [3424/3844], Loss: 0.2227\n",
      "Epoch [2/4], Step [3425/3844], Loss: 0.1078\n",
      "Epoch [2/4], Step [3426/3844], Loss: 0.0919\n",
      "Epoch [2/4], Step [3427/3844], Loss: 0.1138\n",
      "Epoch [2/4], Step [3428/3844], Loss: 0.1694\n",
      "Epoch [2/4], Step [3429/3844], Loss: 0.0818\n",
      "Epoch [2/4], Step [3430/3844], Loss: 0.0939\n",
      "Epoch [2/4], Step [3431/3844], Loss: 0.0578\n",
      "Epoch [2/4], Step [3432/3844], Loss: 0.0641\n",
      "Epoch [2/4], Step [3433/3844], Loss: 0.1571\n",
      "Epoch [2/4], Step [3434/3844], Loss: 0.1322\n",
      "Epoch [2/4], Step [3435/3844], Loss: 0.1044\n",
      "Epoch [2/4], Step [3436/3844], Loss: 0.1373\n",
      "Epoch [2/4], Step [3437/3844], Loss: 0.2179\n",
      "Epoch [2/4], Step [3438/3844], Loss: 0.1080\n",
      "Epoch [2/4], Step [3439/3844], Loss: 0.1659\n",
      "Epoch [2/4], Step [3440/3844], Loss: 0.0991\n",
      "Epoch [2/4], Step [3441/3844], Loss: 0.1637\n",
      "Epoch [2/4], Step [3442/3844], Loss: 0.1398\n",
      "Epoch [2/4], Step [3443/3844], Loss: 0.1384\n",
      "Epoch [2/4], Step [3444/3844], Loss: 0.1066\n",
      "Epoch [2/4], Step [3445/3844], Loss: 0.0958\n",
      "Epoch [2/4], Step [3446/3844], Loss: 0.0631\n",
      "Epoch [2/4], Step [3447/3844], Loss: 0.1628\n",
      "Epoch [2/4], Step [3448/3844], Loss: 0.1835\n",
      "Epoch [2/4], Step [3449/3844], Loss: 0.1041\n",
      "Epoch [2/4], Step [3450/3844], Loss: 0.1765\n",
      "Epoch [2/4], Step [3451/3844], Loss: 0.1048\n",
      "Epoch [2/4], Step [3452/3844], Loss: 0.1308\n",
      "Epoch [2/4], Step [3453/3844], Loss: 0.0780\n",
      "Epoch [2/4], Step [3454/3844], Loss: 0.0841\n",
      "Epoch [2/4], Step [3455/3844], Loss: 0.1524\n",
      "Epoch [2/4], Step [3456/3844], Loss: 0.1287\n",
      "Epoch [2/4], Step [3457/3844], Loss: 0.0911\n",
      "Epoch [2/4], Step [3458/3844], Loss: 0.2109\n",
      "Epoch [2/4], Step [3459/3844], Loss: 0.0902\n",
      "Epoch [2/4], Step [3460/3844], Loss: 0.2058\n",
      "Epoch [2/4], Step [3461/3844], Loss: 0.1265\n",
      "Epoch [2/4], Step [3462/3844], Loss: 0.1158\n",
      "Epoch [2/4], Step [3463/3844], Loss: 0.1463\n",
      "Epoch [2/4], Step [3464/3844], Loss: 0.1003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/4], Step [3465/3844], Loss: 0.0777\n",
      "Epoch [2/4], Step [3466/3844], Loss: 0.0712\n",
      "Epoch [2/4], Step [3467/3844], Loss: 0.1393\n",
      "Epoch [2/4], Step [3468/3844], Loss: 0.2121\n",
      "Epoch [2/4], Step [3469/3844], Loss: 0.0741\n",
      "Epoch [2/4], Step [3470/3844], Loss: 0.1200\n",
      "Epoch [2/4], Step [3471/3844], Loss: 0.0979\n",
      "Epoch [2/4], Step [3472/3844], Loss: 0.1035\n",
      "Epoch [2/4], Step [3473/3844], Loss: 0.1100\n",
      "Epoch [2/4], Step [3474/3844], Loss: 0.0473\n",
      "Epoch [2/4], Step [3475/3844], Loss: 0.1028\n",
      "Epoch [2/4], Step [3476/3844], Loss: 0.0862\n",
      "Epoch [2/4], Step [3477/3844], Loss: 0.1277\n",
      "Epoch [2/4], Step [3478/3844], Loss: 0.0811\n",
      "Epoch [2/4], Step [3479/3844], Loss: 0.0725\n",
      "Epoch [2/4], Step [3480/3844], Loss: 0.1118\n",
      "Epoch [2/4], Step [3481/3844], Loss: 0.1674\n",
      "Epoch [2/4], Step [3482/3844], Loss: 0.1325\n",
      "Epoch [2/4], Step [3483/3844], Loss: 0.0581\n",
      "Epoch [2/4], Step [3484/3844], Loss: 0.0943\n",
      "Epoch [2/4], Step [3485/3844], Loss: 0.0877\n",
      "Epoch [2/4], Step [3486/3844], Loss: 0.1261\n",
      "Epoch [2/4], Step [3487/3844], Loss: 0.0600\n",
      "Epoch [2/4], Step [3488/3844], Loss: 0.1681\n",
      "Epoch [2/4], Step [3489/3844], Loss: 0.0831\n",
      "Epoch [2/4], Step [3490/3844], Loss: 0.0887\n",
      "Epoch [2/4], Step [3491/3844], Loss: 0.1078\n",
      "Epoch [2/4], Step [3492/3844], Loss: 0.1550\n",
      "Epoch [2/4], Step [3493/3844], Loss: 0.0916\n",
      "Epoch [2/4], Step [3494/3844], Loss: 0.0888\n",
      "Epoch [2/4], Step [3495/3844], Loss: 0.1449\n",
      "Epoch [2/4], Step [3496/3844], Loss: 0.1356\n",
      "Epoch [2/4], Step [3497/3844], Loss: 0.0802\n",
      "Epoch [2/4], Step [3498/3844], Loss: 0.1044\n",
      "Epoch [2/4], Step [3499/3844], Loss: 0.1440\n",
      "Epoch [2/4], Step [3500/3844], Loss: 0.1775\n",
      "Epoch [2/4], Step [3501/3844], Loss: 0.0837\n",
      "Epoch [2/4], Step [3502/3844], Loss: 0.0779\n",
      "Epoch [2/4], Step [3503/3844], Loss: 0.1196\n",
      "Epoch [2/4], Step [3504/3844], Loss: 0.0835\n",
      "Epoch [2/4], Step [3505/3844], Loss: 0.1965\n",
      "Epoch [2/4], Step [3506/3844], Loss: 0.1450\n",
      "Epoch [2/4], Step [3507/3844], Loss: 0.1618\n",
      "Epoch [2/4], Step [3508/3844], Loss: 0.0676\n",
      "Epoch [2/4], Step [3509/3844], Loss: 0.0727\n",
      "Epoch [2/4], Step [3510/3844], Loss: 0.2009\n",
      "Epoch [2/4], Step [3511/3844], Loss: 0.0853\n",
      "Epoch [2/4], Step [3512/3844], Loss: 0.2103\n",
      "Epoch [2/4], Step [3513/3844], Loss: 0.0895\n",
      "Epoch [2/4], Step [3514/3844], Loss: 0.1014\n",
      "Epoch [2/4], Step [3515/3844], Loss: 0.0570\n",
      "Epoch [2/4], Step [3516/3844], Loss: 0.0627\n",
      "Epoch [2/4], Step [3517/3844], Loss: 0.0914\n",
      "Epoch [2/4], Step [3518/3844], Loss: 0.0916\n",
      "Epoch [2/4], Step [3519/3844], Loss: 0.1117\n",
      "Epoch [2/4], Step [3520/3844], Loss: 0.0977\n",
      "Epoch [2/4], Step [3521/3844], Loss: 0.1960\n",
      "Epoch [2/4], Step [3522/3844], Loss: 0.1384\n",
      "Epoch [2/4], Step [3523/3844], Loss: 0.0774\n",
      "Epoch [2/4], Step [3524/3844], Loss: 0.0894\n",
      "Epoch [2/4], Step [3525/3844], Loss: 0.1404\n",
      "Epoch [2/4], Step [3526/3844], Loss: 0.1718\n",
      "Epoch [2/4], Step [3527/3844], Loss: 0.1032\n",
      "Epoch [2/4], Step [3528/3844], Loss: 0.1766\n",
      "Epoch [2/4], Step [3529/3844], Loss: 0.1104\n",
      "Epoch [2/4], Step [3530/3844], Loss: 0.1146\n",
      "Epoch [2/4], Step [3531/3844], Loss: 0.2279\n",
      "Epoch [2/4], Step [3532/3844], Loss: 0.0699\n",
      "Epoch [2/4], Step [3533/3844], Loss: 0.1609\n",
      "Epoch [2/4], Step [3534/3844], Loss: 0.2371\n",
      "Epoch [2/4], Step [3535/3844], Loss: 0.0659\n",
      "Epoch [2/4], Step [3536/3844], Loss: 0.0994\n",
      "Epoch [2/4], Step [3537/3844], Loss: 0.0666\n",
      "Epoch [2/4], Step [3538/3844], Loss: 0.0943\n",
      "Epoch [2/4], Step [3539/3844], Loss: 0.0812\n",
      "Epoch [2/4], Step [3540/3844], Loss: 0.0985\n",
      "Epoch [2/4], Step [3541/3844], Loss: 0.0944\n",
      "Epoch [2/4], Step [3542/3844], Loss: 0.1122\n",
      "Epoch [2/4], Step [3543/3844], Loss: 0.1776\n",
      "Epoch [2/4], Step [3544/3844], Loss: 0.2065\n",
      "Epoch [2/4], Step [3545/3844], Loss: 0.0765\n",
      "Epoch [2/4], Step [3546/3844], Loss: 0.1082\n",
      "Epoch [2/4], Step [3547/3844], Loss: 0.0967\n",
      "Epoch [2/4], Step [3548/3844], Loss: 0.0876\n",
      "Epoch [2/4], Step [3549/3844], Loss: 0.0751\n",
      "Epoch [2/4], Step [3550/3844], Loss: 0.1010\n",
      "Epoch [2/4], Step [3551/3844], Loss: 0.2201\n",
      "Epoch [2/4], Step [3552/3844], Loss: 0.1527\n",
      "Epoch [2/4], Step [3553/3844], Loss: 0.0766\n",
      "Epoch [2/4], Step [3554/3844], Loss: 0.1547\n",
      "Epoch [2/4], Step [3555/3844], Loss: 0.0689\n",
      "Epoch [2/4], Step [3556/3844], Loss: 0.0746\n",
      "Epoch [2/4], Step [3557/3844], Loss: 0.1284\n",
      "Epoch [2/4], Step [3558/3844], Loss: 0.1008\n",
      "Epoch [2/4], Step [3559/3844], Loss: 0.1973\n",
      "Epoch [2/4], Step [3560/3844], Loss: 0.0712\n",
      "Epoch [2/4], Step [3561/3844], Loss: 0.0902\n",
      "Epoch [2/4], Step [3562/3844], Loss: 0.1228\n",
      "Epoch [2/4], Step [3563/3844], Loss: 0.1564\n",
      "Epoch [2/4], Step [3564/3844], Loss: 0.1540\n",
      "Epoch [2/4], Step [3565/3844], Loss: 0.2031\n",
      "Epoch [2/4], Step [3566/3844], Loss: 0.1332\n",
      "Epoch [2/4], Step [3567/3844], Loss: 0.0799\n",
      "Epoch [2/4], Step [3568/3844], Loss: 0.0580\n",
      "Epoch [2/4], Step [3569/3844], Loss: 0.1636\n",
      "Epoch [2/4], Step [3570/3844], Loss: 0.1028\n",
      "Epoch [2/4], Step [3571/3844], Loss: 0.1729\n",
      "Epoch [2/4], Step [3572/3844], Loss: 0.1298\n",
      "Epoch [2/4], Step [3573/3844], Loss: 0.0769\n",
      "Epoch [2/4], Step [3574/3844], Loss: 0.0790\n",
      "Epoch [2/4], Step [3575/3844], Loss: 0.0629\n",
      "Epoch [2/4], Step [3576/3844], Loss: 0.1128\n",
      "Epoch [2/4], Step [3577/3844], Loss: 0.1437\n",
      "Epoch [2/4], Step [3578/3844], Loss: 0.1601\n",
      "Epoch [2/4], Step [3579/3844], Loss: 0.0999\n",
      "Epoch [2/4], Step [3580/3844], Loss: 0.0430\n",
      "Epoch [2/4], Step [3581/3844], Loss: 0.0580\n",
      "Epoch [2/4], Step [3582/3844], Loss: 0.0852\n",
      "Epoch [2/4], Step [3583/3844], Loss: 0.1681\n",
      "Epoch [2/4], Step [3584/3844], Loss: 0.1442\n",
      "Epoch [2/4], Step [3585/3844], Loss: 0.1474\n",
      "Epoch [2/4], Step [3586/3844], Loss: 0.1458\n",
      "Epoch [2/4], Step [3587/3844], Loss: 0.1537\n",
      "Epoch [2/4], Step [3588/3844], Loss: 0.1661\n",
      "Epoch [2/4], Step [3589/3844], Loss: 0.0799\n",
      "Epoch [2/4], Step [3590/3844], Loss: 0.0981\n",
      "Epoch [2/4], Step [3591/3844], Loss: 0.0789\n",
      "Epoch [2/4], Step [3592/3844], Loss: 0.0888\n",
      "Epoch [2/4], Step [3593/3844], Loss: 0.1205\n",
      "Epoch [2/4], Step [3594/3844], Loss: 0.0891\n",
      "Epoch [2/4], Step [3595/3844], Loss: 0.0604\n",
      "Epoch [2/4], Step [3596/3844], Loss: 0.2237\n",
      "Epoch [2/4], Step [3597/3844], Loss: 0.1094\n",
      "Epoch [2/4], Step [3598/3844], Loss: 0.1360\n",
      "Epoch [2/4], Step [3599/3844], Loss: 0.1437\n",
      "Epoch [2/4], Step [3600/3844], Loss: 0.1026\n",
      "Epoch [2/4], Step [3601/3844], Loss: 0.0833\n",
      "Epoch [2/4], Step [3602/3844], Loss: 0.0580\n",
      "Epoch [2/4], Step [3603/3844], Loss: 0.1502\n",
      "Epoch [2/4], Step [3604/3844], Loss: 0.1171\n",
      "Epoch [2/4], Step [3605/3844], Loss: 0.0708\n",
      "Epoch [2/4], Step [3606/3844], Loss: 0.0831\n",
      "Epoch [2/4], Step [3607/3844], Loss: 0.1470\n",
      "Epoch [2/4], Step [3608/3844], Loss: 0.1541\n",
      "Epoch [2/4], Step [3609/3844], Loss: 0.0972\n",
      "Epoch [2/4], Step [3610/3844], Loss: 0.1150\n",
      "Epoch [2/4], Step [3611/3844], Loss: 0.0835\n",
      "Epoch [2/4], Step [3612/3844], Loss: 0.1035\n",
      "Epoch [2/4], Step [3613/3844], Loss: 0.0934\n",
      "Epoch [2/4], Step [3614/3844], Loss: 0.0788\n",
      "Epoch [2/4], Step [3615/3844], Loss: 0.0954\n",
      "Epoch [2/4], Step [3616/3844], Loss: 0.1695\n",
      "Epoch [2/4], Step [3617/3844], Loss: 0.1659\n",
      "Epoch [2/4], Step [3618/3844], Loss: 0.0998\n",
      "Epoch [2/4], Step [3619/3844], Loss: 0.0770\n",
      "Epoch [2/4], Step [3620/3844], Loss: 0.1044\n",
      "Epoch [2/4], Step [3621/3844], Loss: 0.1279\n",
      "Epoch [2/4], Step [3622/3844], Loss: 0.0924\n",
      "Epoch [2/4], Step [3623/3844], Loss: 0.1476\n",
      "Epoch [2/4], Step [3624/3844], Loss: 0.1101\n",
      "Epoch [2/4], Step [3625/3844], Loss: 0.0871\n",
      "Epoch [2/4], Step [3626/3844], Loss: 0.1080\n",
      "Epoch [2/4], Step [3627/3844], Loss: 0.1555\n",
      "Epoch [2/4], Step [3628/3844], Loss: 0.1075\n",
      "Epoch [2/4], Step [3629/3844], Loss: 0.1040\n",
      "Epoch [2/4], Step [3630/3844], Loss: 0.1054\n",
      "Epoch [2/4], Step [3631/3844], Loss: 0.0859\n",
      "Epoch [2/4], Step [3632/3844], Loss: 0.0872\n",
      "Epoch [2/4], Step [3633/3844], Loss: 0.1006\n",
      "Epoch [2/4], Step [3634/3844], Loss: 0.0662\n",
      "Epoch [2/4], Step [3635/3844], Loss: 0.1209\n",
      "Epoch [2/4], Step [3636/3844], Loss: 0.1253\n",
      "Epoch [2/4], Step [3637/3844], Loss: 0.1590\n",
      "Epoch [2/4], Step [3638/3844], Loss: 0.1570\n",
      "Epoch [2/4], Step [3639/3844], Loss: 0.1339\n",
      "Epoch [2/4], Step [3640/3844], Loss: 0.1378\n",
      "Epoch [2/4], Step [3641/3844], Loss: 0.0919\n",
      "Epoch [2/4], Step [3642/3844], Loss: 0.0583\n",
      "Epoch [2/4], Step [3643/3844], Loss: 0.1481\n",
      "Epoch [2/4], Step [3644/3844], Loss: 0.1053\n",
      "Epoch [2/4], Step [3645/3844], Loss: 0.1363\n",
      "Epoch [2/4], Step [3646/3844], Loss: 0.1096\n",
      "Epoch [2/4], Step [3647/3844], Loss: 0.0846\n",
      "Epoch [2/4], Step [3648/3844], Loss: 0.1500\n",
      "Epoch [2/4], Step [3649/3844], Loss: 0.1386\n",
      "Epoch [2/4], Step [3650/3844], Loss: 0.0992\n",
      "Epoch [2/4], Step [3651/3844], Loss: 0.2064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/4], Step [3652/3844], Loss: 0.1630\n",
      "Epoch [2/4], Step [3653/3844], Loss: 0.0853\n",
      "Epoch [2/4], Step [3654/3844], Loss: 0.1685\n",
      "Epoch [2/4], Step [3655/3844], Loss: 0.0532\n",
      "Epoch [2/4], Step [3656/3844], Loss: 0.0728\n",
      "Epoch [2/4], Step [3657/3844], Loss: 0.0852\n",
      "Epoch [2/4], Step [3658/3844], Loss: 0.2096\n",
      "Epoch [2/4], Step [3659/3844], Loss: 0.2099\n",
      "Epoch [2/4], Step [3660/3844], Loss: 0.1037\n",
      "Epoch [2/4], Step [3661/3844], Loss: 0.0671\n",
      "Epoch [2/4], Step [3662/3844], Loss: 0.1333\n",
      "Epoch [2/4], Step [3663/3844], Loss: 0.1402\n",
      "Epoch [2/4], Step [3664/3844], Loss: 0.0906\n",
      "Epoch [2/4], Step [3665/3844], Loss: 0.0910\n",
      "Epoch [2/4], Step [3666/3844], Loss: 0.0859\n",
      "Epoch [2/4], Step [3667/3844], Loss: 0.1575\n",
      "Epoch [2/4], Step [3668/3844], Loss: 0.1221\n",
      "Epoch [2/4], Step [3669/3844], Loss: 0.1999\n",
      "Epoch [2/4], Step [3670/3844], Loss: 0.1443\n",
      "Epoch [2/4], Step [3671/3844], Loss: 0.0893\n",
      "Epoch [2/4], Step [3672/3844], Loss: 0.0959\n",
      "Epoch [2/4], Step [3673/3844], Loss: 0.0833\n",
      "Epoch [2/4], Step [3674/3844], Loss: 0.0994\n",
      "Epoch [2/4], Step [3675/3844], Loss: 0.1519\n",
      "Epoch [2/4], Step [3676/3844], Loss: 0.0928\n",
      "Epoch [2/4], Step [3677/3844], Loss: 0.1566\n",
      "Epoch [2/4], Step [3678/3844], Loss: 0.0911\n",
      "Epoch [2/4], Step [3679/3844], Loss: 0.1447\n",
      "Epoch [2/4], Step [3680/3844], Loss: 0.1115\n",
      "Epoch [2/4], Step [3681/3844], Loss: 0.1155\n",
      "Epoch [2/4], Step [3682/3844], Loss: 0.1124\n",
      "Epoch [2/4], Step [3683/3844], Loss: 0.1328\n",
      "Epoch [2/4], Step [3684/3844], Loss: 0.1444\n",
      "Epoch [2/4], Step [3685/3844], Loss: 0.1244\n",
      "Epoch [2/4], Step [3686/3844], Loss: 0.0949\n",
      "Epoch [2/4], Step [3687/3844], Loss: 0.1100\n",
      "Epoch [2/4], Step [3688/3844], Loss: 0.1030\n",
      "Epoch [2/4], Step [3689/3844], Loss: 0.1003\n",
      "Epoch [2/4], Step [3690/3844], Loss: 0.0641\n",
      "Epoch [2/4], Step [3691/3844], Loss: 0.1642\n",
      "Epoch [2/4], Step [3692/3844], Loss: 0.0953\n",
      "Epoch [2/4], Step [3693/3844], Loss: 0.1338\n",
      "Epoch [2/4], Step [3694/3844], Loss: 0.1052\n",
      "Epoch [2/4], Step [3695/3844], Loss: 0.0964\n",
      "Epoch [2/4], Step [3696/3844], Loss: 0.1698\n",
      "Epoch [2/4], Step [3697/3844], Loss: 0.1066\n",
      "Epoch [2/4], Step [3698/3844], Loss: 0.1253\n",
      "Epoch [2/4], Step [3699/3844], Loss: 0.0746\n",
      "Epoch [2/4], Step [3700/3844], Loss: 0.0791\n",
      "Epoch [2/4], Step [3701/3844], Loss: 0.0808\n",
      "Epoch [2/4], Step [3702/3844], Loss: 0.0556\n",
      "Epoch [2/4], Step [3703/3844], Loss: 0.0845\n",
      "Epoch [2/4], Step [3704/3844], Loss: 0.1027\n",
      "Epoch [2/4], Step [3705/3844], Loss: 0.1051\n",
      "Epoch [2/4], Step [3706/3844], Loss: 0.0870\n",
      "Epoch [2/4], Step [3707/3844], Loss: 0.0858\n",
      "Epoch [2/4], Step [3708/3844], Loss: 0.1376\n",
      "Epoch [2/4], Step [3709/3844], Loss: 0.1210\n",
      "Epoch [2/4], Step [3710/3844], Loss: 0.1059\n",
      "Epoch [2/4], Step [3711/3844], Loss: 0.1522\n",
      "Epoch [2/4], Step [3712/3844], Loss: 0.0642\n",
      "Epoch [2/4], Step [3713/3844], Loss: 0.1490\n",
      "Epoch [2/4], Step [3714/3844], Loss: 0.1272\n",
      "Epoch [2/4], Step [3715/3844], Loss: 0.1018\n",
      "Epoch [2/4], Step [3716/3844], Loss: 0.0922\n",
      "Epoch [2/4], Step [3717/3844], Loss: 0.0730\n",
      "Epoch [2/4], Step [3718/3844], Loss: 0.1310\n",
      "Epoch [2/4], Step [3719/3844], Loss: 0.0710\n",
      "Epoch [2/4], Step [3720/3844], Loss: 0.0888\n",
      "Epoch [2/4], Step [3721/3844], Loss: 0.1204\n",
      "Epoch [2/4], Step [3722/3844], Loss: 0.0689\n",
      "Epoch [2/4], Step [3723/3844], Loss: 0.0792\n",
      "Epoch [2/4], Step [3724/3844], Loss: 0.1031\n",
      "Epoch [2/4], Step [3725/3844], Loss: 0.0800\n",
      "Epoch [2/4], Step [3726/3844], Loss: 0.0719\n",
      "Epoch [2/4], Step [3727/3844], Loss: 0.1005\n",
      "Epoch [2/4], Step [3728/3844], Loss: 0.0878\n",
      "Epoch [2/4], Step [3729/3844], Loss: 0.0731\n",
      "Epoch [2/4], Step [3730/3844], Loss: 0.2066\n",
      "Epoch [2/4], Step [3731/3844], Loss: 0.1620\n",
      "Epoch [2/4], Step [3732/3844], Loss: 0.0930\n",
      "Epoch [2/4], Step [3733/3844], Loss: 0.0962\n",
      "Epoch [2/4], Step [3734/3844], Loss: 0.0904\n",
      "Epoch [2/4], Step [3735/3844], Loss: 0.1317\n",
      "Epoch [2/4], Step [3736/3844], Loss: 0.1339\n",
      "Epoch [2/4], Step [3737/3844], Loss: 0.1010\n",
      "Epoch [2/4], Step [3738/3844], Loss: 0.1270\n",
      "Epoch [2/4], Step [3739/3844], Loss: 0.1425\n",
      "Epoch [2/4], Step [3740/3844], Loss: 0.0959\n",
      "Epoch [2/4], Step [3741/3844], Loss: 0.0732\n",
      "Epoch [2/4], Step [3742/3844], Loss: 0.1131\n",
      "Epoch [2/4], Step [3743/3844], Loss: 0.0722\n",
      "Epoch [2/4], Step [3744/3844], Loss: 0.1288\n",
      "Epoch [2/4], Step [3745/3844], Loss: 0.1246\n",
      "Epoch [2/4], Step [3746/3844], Loss: 0.1759\n",
      "Epoch [2/4], Step [3747/3844], Loss: 0.0944\n",
      "Epoch [2/4], Step [3748/3844], Loss: 0.1393\n",
      "Epoch [2/4], Step [3749/3844], Loss: 0.1427\n",
      "Epoch [2/4], Step [3750/3844], Loss: 0.1161\n",
      "Epoch [2/4], Step [3751/3844], Loss: 0.1097\n",
      "Epoch [2/4], Step [3752/3844], Loss: 0.1960\n",
      "Epoch [2/4], Step [3753/3844], Loss: 0.0956\n",
      "Epoch [2/4], Step [3754/3844], Loss: 0.0810\n",
      "Epoch [2/4], Step [3755/3844], Loss: 0.0737\n",
      "Epoch [2/4], Step [3756/3844], Loss: 0.0798\n",
      "Epoch [2/4], Step [3757/3844], Loss: 0.1360\n",
      "Epoch [2/4], Step [3758/3844], Loss: 0.1611\n",
      "Epoch [2/4], Step [3759/3844], Loss: 0.0581\n",
      "Epoch [2/4], Step [3760/3844], Loss: 0.0911\n",
      "Epoch [2/4], Step [3761/3844], Loss: 0.1044\n",
      "Epoch [2/4], Step [3762/3844], Loss: 0.1193\n",
      "Epoch [2/4], Step [3763/3844], Loss: 0.0858\n",
      "Epoch [2/4], Step [3764/3844], Loss: 0.2135\n",
      "Epoch [2/4], Step [3765/3844], Loss: 0.1242\n",
      "Epoch [2/4], Step [3766/3844], Loss: 0.1062\n",
      "Epoch [2/4], Step [3767/3844], Loss: 0.1395\n",
      "Epoch [2/4], Step [3768/3844], Loss: 0.2042\n",
      "Epoch [2/4], Step [3769/3844], Loss: 0.0735\n",
      "Epoch [2/4], Step [3770/3844], Loss: 0.0745\n",
      "Epoch [2/4], Step [3771/3844], Loss: 0.1072\n",
      "Epoch [2/4], Step [3772/3844], Loss: 0.2048\n",
      "Epoch [2/4], Step [3773/3844], Loss: 0.1069\n",
      "Epoch [2/4], Step [3774/3844], Loss: 0.1459\n",
      "Epoch [2/4], Step [3775/3844], Loss: 0.0978\n",
      "Epoch [2/4], Step [3776/3844], Loss: 0.0956\n",
      "Epoch [2/4], Step [3777/3844], Loss: 0.1340\n",
      "Epoch [2/4], Step [3778/3844], Loss: 0.0730\n",
      "Epoch [2/4], Step [3779/3844], Loss: 0.1623\n",
      "Epoch [2/4], Step [3780/3844], Loss: 0.0903\n",
      "Epoch [2/4], Step [3781/3844], Loss: 0.0937\n",
      "Epoch [2/4], Step [3782/3844], Loss: 0.1374\n",
      "Epoch [2/4], Step [3783/3844], Loss: 0.0851\n",
      "Epoch [2/4], Step [3784/3844], Loss: 0.0900\n",
      "Epoch [2/4], Step [3785/3844], Loss: 0.1019\n",
      "Epoch [2/4], Step [3786/3844], Loss: 0.0939\n",
      "Epoch [2/4], Step [3787/3844], Loss: 0.0975\n",
      "Epoch [2/4], Step [3788/3844], Loss: 0.1269\n",
      "Epoch [2/4], Step [3789/3844], Loss: 0.1460\n",
      "Epoch [2/4], Step [3790/3844], Loss: 0.1095\n",
      "Epoch [2/4], Step [3791/3844], Loss: 0.0922\n",
      "Epoch [2/4], Step [3792/3844], Loss: 0.0810\n",
      "Epoch [2/4], Step [3793/3844], Loss: 0.0675\n",
      "Epoch [2/4], Step [3794/3844], Loss: 0.0841\n",
      "Epoch [2/4], Step [3795/3844], Loss: 0.1071\n",
      "Epoch [2/4], Step [3796/3844], Loss: 0.1617\n",
      "Epoch [2/4], Step [3797/3844], Loss: 0.1356\n",
      "Epoch [2/4], Step [3798/3844], Loss: 0.1130\n",
      "Epoch [2/4], Step [3799/3844], Loss: 0.1015\n",
      "Epoch [2/4], Step [3800/3844], Loss: 0.0829\n",
      "Epoch [2/4], Step [3801/3844], Loss: 0.0733\n",
      "Epoch [2/4], Step [3802/3844], Loss: 0.0860\n",
      "Epoch [2/4], Step [3803/3844], Loss: 0.0910\n",
      "Epoch [2/4], Step [3804/3844], Loss: 0.1609\n",
      "Epoch [2/4], Step [3805/3844], Loss: 0.1510\n",
      "Epoch [2/4], Step [3806/3844], Loss: 0.1537\n",
      "Epoch [2/4], Step [3807/3844], Loss: 0.0709\n",
      "Epoch [2/4], Step [3808/3844], Loss: 0.2184\n",
      "Epoch [2/4], Step [3809/3844], Loss: 0.0813\n",
      "Epoch [2/4], Step [3810/3844], Loss: 0.1735\n",
      "Epoch [2/4], Step [3811/3844], Loss: 0.1451\n",
      "Epoch [2/4], Step [3812/3844], Loss: 0.1079\n",
      "Epoch [2/4], Step [3813/3844], Loss: 0.0778\n",
      "Epoch [2/4], Step [3814/3844], Loss: 0.1430\n",
      "Epoch [2/4], Step [3815/3844], Loss: 0.1114\n",
      "Epoch [2/4], Step [3816/3844], Loss: 0.0647\n",
      "Epoch [2/4], Step [3817/3844], Loss: 0.1398\n",
      "Epoch [2/4], Step [3818/3844], Loss: 0.0804\n",
      "Epoch [2/4], Step [3819/3844], Loss: 0.1601\n",
      "Epoch [2/4], Step [3820/3844], Loss: 0.1030\n",
      "Epoch [2/4], Step [3821/3844], Loss: 0.0840\n",
      "Epoch [2/4], Step [3822/3844], Loss: 0.0712\n",
      "Epoch [2/4], Step [3823/3844], Loss: 0.1521\n",
      "Epoch [2/4], Step [3824/3844], Loss: 0.0867\n",
      "Epoch [2/4], Step [3825/3844], Loss: 0.0762\n",
      "Epoch [2/4], Step [3826/3844], Loss: 0.1574\n",
      "Epoch [2/4], Step [3827/3844], Loss: 0.1329\n",
      "Epoch [2/4], Step [3828/3844], Loss: 0.1012\n",
      "Epoch [2/4], Step [3829/3844], Loss: 0.2102\n",
      "Epoch [2/4], Step [3830/3844], Loss: 0.1064\n",
      "Epoch [2/4], Step [3831/3844], Loss: 0.0837\n",
      "Epoch [2/4], Step [3832/3844], Loss: 0.1101\n",
      "Epoch [2/4], Step [3833/3844], Loss: 0.1095\n",
      "Epoch [2/4], Step [3834/3844], Loss: 0.1739\n",
      "Epoch [2/4], Step [3835/3844], Loss: 0.0790\n",
      "Epoch [2/4], Step [3836/3844], Loss: 0.0870\n",
      "Epoch [2/4], Step [3837/3844], Loss: 0.0690\n",
      "Epoch [2/4], Step [3838/3844], Loss: 0.1540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/4], Step [3839/3844], Loss: 0.0714\n",
      "Epoch [2/4], Step [3840/3844], Loss: 0.2022\n",
      "Epoch [2/4], Step [3841/3844], Loss: 0.0859\n",
      "Epoch [2/4], Step [3842/3844], Loss: 0.0858\n",
      "Epoch [2/4], Step [3843/3844], Loss: 0.1281\n",
      "\n",
      "train-loss: 0.1546,\n",
      "Validation [2/4], Step [0/379], Loss: 0.0280\n",
      "Validation [2/4], Step [1/379], Loss: 0.0227\n",
      "Validation [2/4], Step [2/379], Loss: 0.0581\n",
      "Validation [2/4], Step [3/379], Loss: 0.0355\n",
      "Validation [2/4], Step [4/379], Loss: 0.0465\n",
      "Validation [2/4], Step [5/379], Loss: 0.0284\n",
      "Validation [2/4], Step [6/379], Loss: 0.0378\n",
      "Validation [2/4], Step [7/379], Loss: 0.0296\n",
      "Validation [2/4], Step [8/379], Loss: 0.0363\n",
      "Validation [2/4], Step [9/379], Loss: 0.0340\n",
      "Validation [2/4], Step [10/379], Loss: 0.0434\n",
      "Validation [2/4], Step [11/379], Loss: 0.0199\n",
      "Validation [2/4], Step [12/379], Loss: 0.0304\n",
      "Validation [2/4], Step [13/379], Loss: 0.0278\n",
      "Validation [2/4], Step [14/379], Loss: 0.0213\n",
      "Validation [2/4], Step [15/379], Loss: 0.0362\n",
      "Validation [2/4], Step [16/379], Loss: 0.0366\n",
      "Validation [2/4], Step [17/379], Loss: 0.0299\n",
      "Validation [2/4], Step [18/379], Loss: 0.0268\n",
      "Validation [2/4], Step [19/379], Loss: 0.0489\n",
      "Validation [2/4], Step [20/379], Loss: 0.0200\n",
      "Validation [2/4], Step [21/379], Loss: 0.0310\n",
      "Validation [2/4], Step [22/379], Loss: 0.0384\n",
      "Validation [2/4], Step [23/379], Loss: 0.0269\n",
      "Validation [2/4], Step [24/379], Loss: 0.0371\n",
      "Validation [2/4], Step [25/379], Loss: 0.0164\n",
      "Validation [2/4], Step [26/379], Loss: 0.0215\n",
      "Validation [2/4], Step [27/379], Loss: 0.0301\n",
      "Validation [2/4], Step [28/379], Loss: 0.0340\n",
      "Validation [2/4], Step [29/379], Loss: 0.0201\n",
      "Validation [2/4], Step [30/379], Loss: 0.0258\n",
      "Validation [2/4], Step [31/379], Loss: 0.0251\n",
      "Validation [2/4], Step [32/379], Loss: 0.0377\n",
      "Validation [2/4], Step [33/379], Loss: 0.0482\n",
      "Validation [2/4], Step [34/379], Loss: 0.0371\n",
      "Validation [2/4], Step [35/379], Loss: 0.0338\n",
      "Validation [2/4], Step [36/379], Loss: 0.0262\n",
      "Validation [2/4], Step [37/379], Loss: 0.0299\n",
      "Validation [2/4], Step [38/379], Loss: 0.0341\n",
      "Validation [2/4], Step [39/379], Loss: 0.0427\n",
      "Validation [2/4], Step [40/379], Loss: 0.0381\n",
      "Validation [2/4], Step [41/379], Loss: 0.0278\n",
      "Validation [2/4], Step [42/379], Loss: 0.0227\n",
      "Validation [2/4], Step [43/379], Loss: 0.0330\n",
      "Validation [2/4], Step [44/379], Loss: 0.0282\n",
      "Validation [2/4], Step [45/379], Loss: 0.0293\n",
      "Validation [2/4], Step [46/379], Loss: 0.0613\n",
      "Validation [2/4], Step [47/379], Loss: 0.0388\n",
      "Validation [2/4], Step [48/379], Loss: 0.0394\n",
      "Validation [2/4], Step [49/379], Loss: 0.0381\n",
      "Validation [2/4], Step [50/379], Loss: 0.0293\n",
      "Validation [2/4], Step [51/379], Loss: 0.0336\n",
      "Validation [2/4], Step [52/379], Loss: 0.0424\n",
      "Validation [2/4], Step [53/379], Loss: 0.0262\n",
      "Validation [2/4], Step [54/379], Loss: 0.0290\n",
      "Validation [2/4], Step [55/379], Loss: 0.0362\n",
      "Validation [2/4], Step [56/379], Loss: 0.0296\n",
      "Validation [2/4], Step [57/379], Loss: 0.0261\n",
      "Validation [2/4], Step [58/379], Loss: 0.0259\n",
      "Validation [2/4], Step [59/379], Loss: 0.0308\n",
      "Validation [2/4], Step [60/379], Loss: 0.0340\n",
      "Validation [2/4], Step [61/379], Loss: 0.0306\n",
      "Validation [2/4], Step [62/379], Loss: 0.0226\n",
      "Validation [2/4], Step [63/379], Loss: 0.0195\n",
      "Validation [2/4], Step [64/379], Loss: 0.0358\n",
      "Validation [2/4], Step [65/379], Loss: 0.0382\n",
      "Validation [2/4], Step [66/379], Loss: 0.0212\n",
      "Validation [2/4], Step [67/379], Loss: 0.0326\n",
      "Validation [2/4], Step [68/379], Loss: 0.0407\n",
      "Validation [2/4], Step [69/379], Loss: 0.0432\n",
      "Validation [2/4], Step [70/379], Loss: 0.0321\n",
      "Validation [2/4], Step [71/379], Loss: 0.0442\n",
      "Validation [2/4], Step [72/379], Loss: 0.0295\n",
      "Validation [2/4], Step [73/379], Loss: 0.0205\n",
      "Validation [2/4], Step [74/379], Loss: 0.0369\n",
      "Validation [2/4], Step [75/379], Loss: 0.0452\n",
      "Validation [2/4], Step [76/379], Loss: 0.0290\n",
      "Validation [2/4], Step [77/379], Loss: 0.0276\n",
      "Validation [2/4], Step [78/379], Loss: 0.0388\n",
      "Validation [2/4], Step [79/379], Loss: 0.0311\n",
      "Validation [2/4], Step [80/379], Loss: 0.0462\n",
      "Validation [2/4], Step [81/379], Loss: 0.0343\n",
      "Validation [2/4], Step [82/379], Loss: 0.0341\n",
      "Validation [2/4], Step [83/379], Loss: 0.0249\n",
      "Validation [2/4], Step [84/379], Loss: 0.0339\n",
      "Validation [2/4], Step [85/379], Loss: 0.0470\n",
      "Validation [2/4], Step [86/379], Loss: 0.0267\n",
      "Validation [2/4], Step [87/379], Loss: 0.0428\n",
      "Validation [2/4], Step [88/379], Loss: 0.0340\n",
      "Validation [2/4], Step [89/379], Loss: 0.0416\n",
      "Validation [2/4], Step [90/379], Loss: 0.0213\n",
      "Validation [2/4], Step [91/379], Loss: 0.0214\n",
      "Validation [2/4], Step [92/379], Loss: 0.0623\n",
      "Validation [2/4], Step [93/379], Loss: 0.0340\n",
      "Validation [2/4], Step [94/379], Loss: 0.0376\n",
      "Validation [2/4], Step [95/379], Loss: 0.0347\n",
      "Validation [2/4], Step [96/379], Loss: 0.0233\n",
      "Validation [2/4], Step [97/379], Loss: 0.0340\n",
      "Validation [2/4], Step [98/379], Loss: 0.0322\n",
      "Validation [2/4], Step [99/379], Loss: 0.0184\n",
      "Validation [2/4], Step [100/379], Loss: 0.0273\n",
      "Validation [2/4], Step [101/379], Loss: 0.0379\n",
      "Validation [2/4], Step [102/379], Loss: 0.0426\n",
      "Validation [2/4], Step [103/379], Loss: 0.0231\n",
      "Validation [2/4], Step [104/379], Loss: 0.0251\n",
      "Validation [2/4], Step [105/379], Loss: 0.0347\n",
      "Validation [2/4], Step [106/379], Loss: 0.0196\n",
      "Validation [2/4], Step [107/379], Loss: 0.0355\n",
      "Validation [2/4], Step [108/379], Loss: 0.0240\n",
      "Validation [2/4], Step [109/379], Loss: 0.0187\n",
      "Validation [2/4], Step [110/379], Loss: 0.0404\n",
      "Validation [2/4], Step [111/379], Loss: 0.0379\n",
      "Validation [2/4], Step [112/379], Loss: 0.0262\n",
      "Validation [2/4], Step [113/379], Loss: 0.0374\n",
      "Validation [2/4], Step [114/379], Loss: 0.0361\n",
      "Validation [2/4], Step [115/379], Loss: 0.0312\n",
      "Validation [2/4], Step [116/379], Loss: 0.0313\n",
      "Validation [2/4], Step [117/379], Loss: 0.0398\n",
      "Validation [2/4], Step [118/379], Loss: 0.0276\n",
      "Validation [2/4], Step [119/379], Loss: 0.0297\n",
      "Validation [2/4], Step [120/379], Loss: 0.0275\n",
      "Validation [2/4], Step [121/379], Loss: 0.0353\n",
      "Validation [2/4], Step [122/379], Loss: 0.0427\n",
      "Validation [2/4], Step [123/379], Loss: 0.0228\n",
      "Validation [2/4], Step [124/379], Loss: 0.0272\n",
      "Validation [2/4], Step [125/379], Loss: 0.0520\n",
      "Validation [2/4], Step [126/379], Loss: 0.0366\n",
      "Validation [2/4], Step [127/379], Loss: 0.0343\n",
      "Validation [2/4], Step [128/379], Loss: 0.0459\n",
      "Validation [2/4], Step [129/379], Loss: 0.0227\n",
      "Validation [2/4], Step [130/379], Loss: 0.0347\n",
      "Validation [2/4], Step [131/379], Loss: 0.0241\n",
      "Validation [2/4], Step [132/379], Loss: 0.0309\n",
      "Validation [2/4], Step [133/379], Loss: 0.0302\n",
      "Validation [2/4], Step [134/379], Loss: 0.0307\n",
      "Validation [2/4], Step [135/379], Loss: 0.0301\n",
      "Validation [2/4], Step [136/379], Loss: 0.0242\n",
      "Validation [2/4], Step [137/379], Loss: 0.0334\n",
      "Validation [2/4], Step [138/379], Loss: 0.0330\n",
      "Validation [2/4], Step [139/379], Loss: 0.0430\n",
      "Validation [2/4], Step [140/379], Loss: 0.0265\n",
      "Validation [2/4], Step [141/379], Loss: 0.0444\n",
      "Validation [2/4], Step [142/379], Loss: 0.0246\n",
      "Validation [2/4], Step [143/379], Loss: 0.0320\n",
      "Validation [2/4], Step [144/379], Loss: 0.0183\n",
      "Validation [2/4], Step [145/379], Loss: 0.0441\n",
      "Validation [2/4], Step [146/379], Loss: 0.0352\n",
      "Validation [2/4], Step [147/379], Loss: 0.0583\n",
      "Validation [2/4], Step [148/379], Loss: 0.0266\n",
      "Validation [2/4], Step [149/379], Loss: 0.0347\n",
      "Validation [2/4], Step [150/379], Loss: 0.0254\n",
      "Validation [2/4], Step [151/379], Loss: 0.0355\n",
      "Validation [2/4], Step [152/379], Loss: 0.0296\n",
      "Validation [2/4], Step [153/379], Loss: 0.0212\n",
      "Validation [2/4], Step [154/379], Loss: 0.0304\n",
      "Validation [2/4], Step [155/379], Loss: 0.0330\n",
      "Validation [2/4], Step [156/379], Loss: 0.0495\n",
      "Validation [2/4], Step [157/379], Loss: 0.0254\n",
      "Validation [2/4], Step [158/379], Loss: 0.0328\n",
      "Validation [2/4], Step [159/379], Loss: 0.0317\n",
      "Validation [2/4], Step [160/379], Loss: 0.0331\n",
      "Validation [2/4], Step [161/379], Loss: 0.0278\n",
      "Validation [2/4], Step [162/379], Loss: 0.0299\n",
      "Validation [2/4], Step [163/379], Loss: 0.0355\n",
      "Validation [2/4], Step [164/379], Loss: 0.0234\n",
      "Validation [2/4], Step [165/379], Loss: 0.0346\n",
      "Validation [2/4], Step [166/379], Loss: 0.0424\n",
      "Validation [2/4], Step [167/379], Loss: 0.0320\n",
      "Validation [2/4], Step [168/379], Loss: 0.0432\n",
      "Validation [2/4], Step [169/379], Loss: 0.0379\n",
      "Validation [2/4], Step [170/379], Loss: 0.0283\n",
      "Validation [2/4], Step [171/379], Loss: 0.0193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation [2/4], Step [172/379], Loss: 0.0365\n",
      "Validation [2/4], Step [173/379], Loss: 0.0390\n",
      "Validation [2/4], Step [174/379], Loss: 0.0324\n",
      "Validation [2/4], Step [175/379], Loss: 0.0264\n",
      "Validation [2/4], Step [176/379], Loss: 0.0328\n",
      "Validation [2/4], Step [177/379], Loss: 0.0391\n",
      "Validation [2/4], Step [178/379], Loss: 0.0304\n",
      "Validation [2/4], Step [179/379], Loss: 0.0208\n",
      "Validation [2/4], Step [180/379], Loss: 0.0355\n",
      "Validation [2/4], Step [181/379], Loss: 0.0232\n",
      "Validation [2/4], Step [182/379], Loss: 0.0308\n",
      "Validation [2/4], Step [183/379], Loss: 0.0235\n",
      "Validation [2/4], Step [184/379], Loss: 0.0396\n",
      "Validation [2/4], Step [185/379], Loss: 0.0367\n",
      "Validation [2/4], Step [186/379], Loss: 0.0201\n",
      "Validation [2/4], Step [187/379], Loss: 0.0293\n",
      "Validation [2/4], Step [188/379], Loss: 0.0449\n",
      "Validation [2/4], Step [189/379], Loss: 0.0359\n",
      "Validation [2/4], Step [190/379], Loss: 0.0343\n",
      "Validation [2/4], Step [191/379], Loss: 0.0316\n",
      "Validation [2/4], Step [192/379], Loss: 0.0249\n",
      "Validation [2/4], Step [193/379], Loss: 0.0456\n",
      "Validation [2/4], Step [194/379], Loss: 0.0376\n",
      "Validation [2/4], Step [195/379], Loss: 0.0496\n",
      "Validation [2/4], Step [196/379], Loss: 0.0383\n",
      "Validation [2/4], Step [197/379], Loss: 0.0238\n",
      "Validation [2/4], Step [198/379], Loss: 0.0521\n",
      "Validation [2/4], Step [199/379], Loss: 0.0171\n",
      "Validation [2/4], Step [200/379], Loss: 0.0392\n",
      "Validation [2/4], Step [201/379], Loss: 0.0372\n",
      "Validation [2/4], Step [202/379], Loss: 0.0294\n",
      "Validation [2/4], Step [203/379], Loss: 0.0257\n",
      "Validation [2/4], Step [204/379], Loss: 0.0413\n",
      "Validation [2/4], Step [205/379], Loss: 0.0465\n",
      "Validation [2/4], Step [206/379], Loss: 0.0242\n",
      "Validation [2/4], Step [207/379], Loss: 0.0342\n",
      "Validation [2/4], Step [208/379], Loss: 0.0231\n",
      "Validation [2/4], Step [209/379], Loss: 0.0350\n",
      "Validation [2/4], Step [210/379], Loss: 0.0363\n",
      "Validation [2/4], Step [211/379], Loss: 0.0353\n",
      "Validation [2/4], Step [212/379], Loss: 0.0236\n",
      "Validation [2/4], Step [213/379], Loss: 0.0405\n",
      "Validation [2/4], Step [214/379], Loss: 0.0415\n",
      "Validation [2/4], Step [215/379], Loss: 0.0353\n",
      "Validation [2/4], Step [216/379], Loss: 0.0346\n",
      "Validation [2/4], Step [217/379], Loss: 0.0314\n",
      "Validation [2/4], Step [218/379], Loss: 0.0394\n",
      "Validation [2/4], Step [219/379], Loss: 0.0320\n",
      "Validation [2/4], Step [220/379], Loss: 0.0325\n",
      "Validation [2/4], Step [221/379], Loss: 0.0313\n",
      "Validation [2/4], Step [222/379], Loss: 0.0331\n",
      "Validation [2/4], Step [223/379], Loss: 0.0399\n",
      "Validation [2/4], Step [224/379], Loss: 0.0279\n",
      "Validation [2/4], Step [225/379], Loss: 0.0312\n",
      "Validation [2/4], Step [226/379], Loss: 0.0276\n",
      "Validation [2/4], Step [227/379], Loss: 0.0204\n",
      "Validation [2/4], Step [228/379], Loss: 0.0440\n",
      "Validation [2/4], Step [229/379], Loss: 0.0403\n",
      "Validation [2/4], Step [230/379], Loss: 0.0327\n",
      "Validation [2/4], Step [231/379], Loss: 0.0264\n",
      "Validation [2/4], Step [232/379], Loss: 0.0318\n",
      "Validation [2/4], Step [233/379], Loss: 0.0508\n",
      "Validation [2/4], Step [234/379], Loss: 0.0266\n",
      "Validation [2/4], Step [235/379], Loss: 0.0361\n",
      "Validation [2/4], Step [236/379], Loss: 0.0507\n",
      "Validation [2/4], Step [237/379], Loss: 0.0370\n",
      "Validation [2/4], Step [238/379], Loss: 0.0484\n",
      "Validation [2/4], Step [239/379], Loss: 0.0479\n",
      "Validation [2/4], Step [240/379], Loss: 0.0250\n",
      "Validation [2/4], Step [241/379], Loss: 0.0204\n",
      "Validation [2/4], Step [242/379], Loss: 0.0422\n",
      "Validation [2/4], Step [243/379], Loss: 0.0348\n",
      "Validation [2/4], Step [244/379], Loss: 0.0235\n",
      "Validation [2/4], Step [245/379], Loss: 0.0302\n",
      "Validation [2/4], Step [246/379], Loss: 0.0330\n",
      "Validation [2/4], Step [247/379], Loss: 0.0277\n",
      "Validation [2/4], Step [248/379], Loss: 0.0346\n",
      "Validation [2/4], Step [249/379], Loss: 0.0393\n",
      "Validation [2/4], Step [250/379], Loss: 0.0404\n",
      "Validation [2/4], Step [251/379], Loss: 0.0544\n",
      "Validation [2/4], Step [252/379], Loss: 0.0443\n",
      "Validation [2/4], Step [253/379], Loss: 0.0365\n",
      "Validation [2/4], Step [254/379], Loss: 0.0310\n",
      "Validation [2/4], Step [255/379], Loss: 0.0468\n",
      "Validation [2/4], Step [256/379], Loss: 0.0213\n",
      "Validation [2/4], Step [257/379], Loss: 0.0346\n",
      "Validation [2/4], Step [258/379], Loss: 0.0338\n",
      "Validation [2/4], Step [259/379], Loss: 0.0240\n",
      "Validation [2/4], Step [260/379], Loss: 0.0332\n",
      "Validation [2/4], Step [261/379], Loss: 0.0256\n",
      "Validation [2/4], Step [262/379], Loss: 0.0329\n",
      "Validation [2/4], Step [263/379], Loss: 0.0337\n",
      "Validation [2/4], Step [264/379], Loss: 0.0216\n",
      "Validation [2/4], Step [265/379], Loss: 0.0361\n",
      "Validation [2/4], Step [266/379], Loss: 0.0376\n",
      "Validation [2/4], Step [267/379], Loss: 0.0365\n",
      "Validation [2/4], Step [268/379], Loss: 0.0271\n",
      "Validation [2/4], Step [269/379], Loss: 0.0373\n",
      "Validation [2/4], Step [270/379], Loss: 0.0333\n",
      "Validation [2/4], Step [271/379], Loss: 0.0255\n",
      "Validation [2/4], Step [272/379], Loss: 0.0432\n",
      "Validation [2/4], Step [273/379], Loss: 0.0264\n",
      "Validation [2/4], Step [274/379], Loss: 0.0469\n",
      "Validation [2/4], Step [275/379], Loss: 0.0328\n",
      "Validation [2/4], Step [276/379], Loss: 0.0176\n",
      "Validation [2/4], Step [277/379], Loss: 0.0276\n",
      "Validation [2/4], Step [278/379], Loss: 0.0258\n",
      "Validation [2/4], Step [279/379], Loss: 0.0212\n",
      "Validation [2/4], Step [280/379], Loss: 0.0353\n",
      "Validation [2/4], Step [281/379], Loss: 0.0430\n",
      "Validation [2/4], Step [282/379], Loss: 0.0191\n",
      "Validation [2/4], Step [283/379], Loss: 0.0292\n",
      "Validation [2/4], Step [284/379], Loss: 0.0342\n",
      "Validation [2/4], Step [285/379], Loss: 0.0270\n",
      "Validation [2/4], Step [286/379], Loss: 0.0311\n",
      "Validation [2/4], Step [287/379], Loss: 0.0265\n",
      "Validation [2/4], Step [288/379], Loss: 0.0361\n",
      "Validation [2/4], Step [289/379], Loss: 0.0400\n",
      "Validation [2/4], Step [290/379], Loss: 0.0280\n",
      "Validation [2/4], Step [291/379], Loss: 0.0328\n",
      "Validation [2/4], Step [292/379], Loss: 0.0334\n",
      "Validation [2/4], Step [293/379], Loss: 0.0389\n",
      "Validation [2/4], Step [294/379], Loss: 0.0333\n",
      "Validation [2/4], Step [295/379], Loss: 0.0259\n",
      "Validation [2/4], Step [296/379], Loss: 0.0370\n",
      "Validation [2/4], Step [297/379], Loss: 0.0241\n",
      "Validation [2/4], Step [298/379], Loss: 0.0341\n",
      "Validation [2/4], Step [299/379], Loss: 0.0391\n",
      "Validation [2/4], Step [300/379], Loss: 0.0291\n",
      "Validation [2/4], Step [301/379], Loss: 0.0369\n",
      "Validation [2/4], Step [302/379], Loss: 0.0356\n",
      "Validation [2/4], Step [303/379], Loss: 0.0195\n",
      "Validation [2/4], Step [304/379], Loss: 0.0241\n",
      "Validation [2/4], Step [305/379], Loss: 0.0276\n",
      "Validation [2/4], Step [306/379], Loss: 0.0365\n",
      "Validation [2/4], Step [307/379], Loss: 0.0283\n",
      "Validation [2/4], Step [308/379], Loss: 0.0241\n",
      "Validation [2/4], Step [309/379], Loss: 0.0210\n",
      "Validation [2/4], Step [310/379], Loss: 0.0226\n",
      "Validation [2/4], Step [311/379], Loss: 0.0292\n",
      "Validation [2/4], Step [312/379], Loss: 0.0409\n",
      "Validation [2/4], Step [313/379], Loss: 0.0445\n",
      "Validation [2/4], Step [314/379], Loss: 0.0183\n",
      "Validation [2/4], Step [315/379], Loss: 0.0254\n",
      "Validation [2/4], Step [316/379], Loss: 0.0276\n",
      "Validation [2/4], Step [317/379], Loss: 0.0277\n",
      "Validation [2/4], Step [318/379], Loss: 0.0402\n",
      "Validation [2/4], Step [319/379], Loss: 0.0313\n",
      "Validation [2/4], Step [320/379], Loss: 0.0171\n",
      "Validation [2/4], Step [321/379], Loss: 0.0290\n",
      "Validation [2/4], Step [322/379], Loss: 0.0277\n",
      "Validation [2/4], Step [323/379], Loss: 0.0372\n",
      "Validation [2/4], Step [324/379], Loss: 0.0237\n",
      "Validation [2/4], Step [325/379], Loss: 0.0394\n",
      "Validation [2/4], Step [326/379], Loss: 0.0392\n",
      "Validation [2/4], Step [327/379], Loss: 0.0258\n",
      "Validation [2/4], Step [328/379], Loss: 0.0331\n",
      "Validation [2/4], Step [329/379], Loss: 0.0340\n",
      "Validation [2/4], Step [330/379], Loss: 0.0297\n",
      "Validation [2/4], Step [331/379], Loss: 0.0365\n",
      "Validation [2/4], Step [332/379], Loss: 0.0418\n",
      "Validation [2/4], Step [333/379], Loss: 0.0296\n",
      "Validation [2/4], Step [334/379], Loss: 0.0345\n",
      "Validation [2/4], Step [335/379], Loss: 0.0385\n",
      "Validation [2/4], Step [336/379], Loss: 0.0485\n",
      "Validation [2/4], Step [337/379], Loss: 0.0231\n",
      "Validation [2/4], Step [338/379], Loss: 0.0289\n",
      "Validation [2/4], Step [339/379], Loss: 0.0352\n",
      "Validation [2/4], Step [340/379], Loss: 0.0197\n",
      "Validation [2/4], Step [341/379], Loss: 0.0285\n",
      "Validation [2/4], Step [342/379], Loss: 0.0252\n",
      "Validation [2/4], Step [343/379], Loss: 0.0244\n",
      "Validation [2/4], Step [344/379], Loss: 0.0247\n",
      "Validation [2/4], Step [345/379], Loss: 0.0360\n",
      "Validation [2/4], Step [346/379], Loss: 0.0247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation [2/4], Step [347/379], Loss: 0.0304\n",
      "Validation [2/4], Step [348/379], Loss: 0.0264\n",
      "Validation [2/4], Step [349/379], Loss: 0.0388\n",
      "Validation [2/4], Step [350/379], Loss: 0.0536\n",
      "Validation [2/4], Step [351/379], Loss: 0.0270\n",
      "Validation [2/4], Step [352/379], Loss: 0.0379\n",
      "Validation [2/4], Step [353/379], Loss: 0.0351\n",
      "Validation [2/4], Step [354/379], Loss: 0.0269\n",
      "Validation [2/4], Step [355/379], Loss: 0.0191\n",
      "Validation [2/4], Step [356/379], Loss: 0.0302\n",
      "Validation [2/4], Step [357/379], Loss: 0.0335\n",
      "Validation [2/4], Step [358/379], Loss: 0.0264\n",
      "Validation [2/4], Step [359/379], Loss: 0.0259\n",
      "Validation [2/4], Step [360/379], Loss: 0.0269\n",
      "Validation [2/4], Step [361/379], Loss: 0.0340\n",
      "Validation [2/4], Step [362/379], Loss: 0.0282\n",
      "Validation [2/4], Step [363/379], Loss: 0.0310\n",
      "Validation [2/4], Step [364/379], Loss: 0.0214\n",
      "Validation [2/4], Step [365/379], Loss: 0.0439\n",
      "Validation [2/4], Step [366/379], Loss: 0.0281\n",
      "Validation [2/4], Step [367/379], Loss: 0.0606\n",
      "Validation [2/4], Step [368/379], Loss: 0.0375\n",
      "Validation [2/4], Step [369/379], Loss: 0.0364\n",
      "Validation [2/4], Step [370/379], Loss: 0.0287\n",
      "Validation [2/4], Step [371/379], Loss: 0.0243\n",
      "Validation [2/4], Step [372/379], Loss: 0.0235\n",
      "Validation [2/4], Step [373/379], Loss: 0.0415\n",
      "Validation [2/4], Step [374/379], Loss: 0.0293\n",
      "Validation [2/4], Step [375/379], Loss: 0.0276\n",
      "Validation [2/4], Step [376/379], Loss: 0.0341\n",
      "Validation [2/4], Step [377/379], Loss: 0.0533\n",
      "Validation [2/4], Step [378/379], Loss: 0.0367\n",
      "validation loss: 0.0700, \n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 3\n",
      "\n",
      "Epoch [3/4], Step [0/3844], Loss: 0.0847\n",
      "Epoch [3/4], Step [1/3844], Loss: 0.0924\n",
      "Epoch [3/4], Step [2/3844], Loss: 0.0615\n",
      "Epoch [3/4], Step [3/3844], Loss: 0.1305\n",
      "Epoch [3/4], Step [4/3844], Loss: 0.1087\n",
      "Epoch [3/4], Step [5/3844], Loss: 0.1459\n",
      "Epoch [3/4], Step [6/3844], Loss: 0.1947\n",
      "Epoch [3/4], Step [7/3844], Loss: 0.1509\n",
      "Epoch [3/4], Step [8/3844], Loss: 0.1521\n",
      "Epoch [3/4], Step [9/3844], Loss: 0.0673\n",
      "Epoch [3/4], Step [10/3844], Loss: 0.1416\n",
      "Epoch [3/4], Step [11/3844], Loss: 0.0698\n",
      "Epoch [3/4], Step [12/3844], Loss: 0.1470\n",
      "Epoch [3/4], Step [13/3844], Loss: 0.0863\n",
      "Epoch [3/4], Step [14/3844], Loss: 0.0583\n",
      "Epoch [3/4], Step [15/3844], Loss: 0.1293\n",
      "Epoch [3/4], Step [16/3844], Loss: 0.2087\n",
      "Epoch [3/4], Step [17/3844], Loss: 0.1222\n",
      "Epoch [3/4], Step [18/3844], Loss: 0.1119\n",
      "Epoch [3/4], Step [19/3844], Loss: 0.1504\n",
      "Epoch [3/4], Step [20/3844], Loss: 0.0806\n",
      "Epoch [3/4], Step [21/3844], Loss: 0.0865\n",
      "Epoch [3/4], Step [22/3844], Loss: 0.1379\n",
      "Epoch [3/4], Step [23/3844], Loss: 0.1689\n",
      "Epoch [3/4], Step [24/3844], Loss: 0.0887\n",
      "Epoch [3/4], Step [25/3844], Loss: 0.0832\n",
      "Epoch [3/4], Step [26/3844], Loss: 0.1403\n",
      "Epoch [3/4], Step [27/3844], Loss: 0.0902\n",
      "Epoch [3/4], Step [28/3844], Loss: 0.0703\n",
      "Epoch [3/4], Step [29/3844], Loss: 0.1809\n",
      "Epoch [3/4], Step [30/3844], Loss: 0.0829\n",
      "Epoch [3/4], Step [31/3844], Loss: 0.0928\n",
      "Epoch [3/4], Step [32/3844], Loss: 0.1831\n",
      "Epoch [3/4], Step [33/3844], Loss: 0.0667\n",
      "Epoch [3/4], Step [34/3844], Loss: 0.1235\n",
      "Epoch [3/4], Step [35/3844], Loss: 0.0781\n",
      "Epoch [3/4], Step [36/3844], Loss: 0.1078\n",
      "Epoch [3/4], Step [37/3844], Loss: 0.1177\n",
      "Epoch [3/4], Step [38/3844], Loss: 0.0761\n",
      "Epoch [3/4], Step [39/3844], Loss: 0.1158\n",
      "Epoch [3/4], Step [40/3844], Loss: 0.1264\n",
      "Epoch [3/4], Step [41/3844], Loss: 0.0752\n",
      "Epoch [3/4], Step [42/3844], Loss: 0.1500\n",
      "Epoch [3/4], Step [43/3844], Loss: 0.0949\n",
      "Epoch [3/4], Step [44/3844], Loss: 0.1691\n",
      "Epoch [3/4], Step [45/3844], Loss: 0.0873\n",
      "Epoch [3/4], Step [46/3844], Loss: 0.1091\n",
      "Epoch [3/4], Step [47/3844], Loss: 0.0882\n",
      "Epoch [3/4], Step [48/3844], Loss: 0.0994\n",
      "Epoch [3/4], Step [49/3844], Loss: 0.0955\n",
      "Epoch [3/4], Step [50/3844], Loss: 0.1834\n",
      "Epoch [3/4], Step [51/3844], Loss: 0.0770\n",
      "Epoch [3/4], Step [52/3844], Loss: 0.1017\n",
      "Epoch [3/4], Step [53/3844], Loss: 0.1821\n",
      "Epoch [3/4], Step [54/3844], Loss: 0.1047\n",
      "Epoch [3/4], Step [55/3844], Loss: 0.1183\n",
      "Epoch [3/4], Step [56/3844], Loss: 0.1415\n",
      "Epoch [3/4], Step [57/3844], Loss: 0.1591\n",
      "Epoch [3/4], Step [58/3844], Loss: 0.0590\n",
      "Epoch [3/4], Step [59/3844], Loss: 0.0777\n",
      "Epoch [3/4], Step [60/3844], Loss: 0.1058\n",
      "Epoch [3/4], Step [61/3844], Loss: 0.1327\n",
      "Epoch [3/4], Step [62/3844], Loss: 0.0870\n",
      "Epoch [3/4], Step [63/3844], Loss: 0.1352\n",
      "Epoch [3/4], Step [64/3844], Loss: 0.1266\n",
      "Epoch [3/4], Step [65/3844], Loss: 0.1569\n",
      "Epoch [3/4], Step [66/3844], Loss: 0.1106\n",
      "Epoch [3/4], Step [67/3844], Loss: 0.2103\n",
      "Epoch [3/4], Step [68/3844], Loss: 0.1882\n",
      "Epoch [3/4], Step [69/3844], Loss: 0.1143\n",
      "Epoch [3/4], Step [70/3844], Loss: 0.0868\n",
      "Epoch [3/4], Step [71/3844], Loss: 0.0827\n",
      "Epoch [3/4], Step [72/3844], Loss: 0.0803\n",
      "Epoch [3/4], Step [73/3844], Loss: 0.1384\n",
      "Epoch [3/4], Step [74/3844], Loss: 0.0604\n",
      "Epoch [3/4], Step [75/3844], Loss: 0.0856\n",
      "Epoch [3/4], Step [76/3844], Loss: 0.0864\n",
      "Epoch [3/4], Step [77/3844], Loss: 0.1141\n",
      "Epoch [3/4], Step [78/3844], Loss: 0.1112\n",
      "Epoch [3/4], Step [79/3844], Loss: 0.1562\n",
      "Epoch [3/4], Step [80/3844], Loss: 0.1365\n",
      "Epoch [3/4], Step [81/3844], Loss: 0.0957\n",
      "Epoch [3/4], Step [82/3844], Loss: 0.0817\n",
      "Epoch [3/4], Step [83/3844], Loss: 0.1707\n",
      "Epoch [3/4], Step [84/3844], Loss: 0.0858\n",
      "Epoch [3/4], Step [85/3844], Loss: 0.2151\n",
      "Epoch [3/4], Step [86/3844], Loss: 0.0974\n",
      "Epoch [3/4], Step [87/3844], Loss: 0.1581\n",
      "Epoch [3/4], Step [88/3844], Loss: 0.1230\n",
      "Epoch [3/4], Step [89/3844], Loss: 0.1440\n",
      "Epoch [3/4], Step [90/3844], Loss: 0.1510\n",
      "Epoch [3/4], Step [91/3844], Loss: 0.1204\n",
      "Epoch [3/4], Step [92/3844], Loss: 0.0774\n",
      "Epoch [3/4], Step [93/3844], Loss: 0.0822\n",
      "Epoch [3/4], Step [94/3844], Loss: 0.2083\n",
      "Epoch [3/4], Step [95/3844], Loss: 0.1318\n",
      "Epoch [3/4], Step [96/3844], Loss: 0.1183\n",
      "Epoch [3/4], Step [97/3844], Loss: 0.0662\n",
      "Epoch [3/4], Step [98/3844], Loss: 0.1240\n",
      "Epoch [3/4], Step [99/3844], Loss: 0.1773\n",
      "Epoch [3/4], Step [100/3844], Loss: 0.0876\n",
      "Epoch [3/4], Step [101/3844], Loss: 0.0784\n",
      "Epoch [3/4], Step [102/3844], Loss: 0.0710\n",
      "Epoch [3/4], Step [103/3844], Loss: 0.1029\n",
      "Epoch [3/4], Step [104/3844], Loss: 0.1189\n",
      "Epoch [3/4], Step [105/3844], Loss: 0.0669\n",
      "Epoch [3/4], Step [106/3844], Loss: 0.0559\n",
      "Epoch [3/4], Step [107/3844], Loss: 0.0763\n",
      "Epoch [3/4], Step [108/3844], Loss: 0.0738\n",
      "Epoch [3/4], Step [109/3844], Loss: 0.1496\n",
      "Epoch [3/4], Step [110/3844], Loss: 0.1329\n",
      "Epoch [3/4], Step [111/3844], Loss: 0.0932\n",
      "Epoch [3/4], Step [112/3844], Loss: 0.0990\n",
      "Epoch [3/4], Step [113/3844], Loss: 0.1005\n",
      "Epoch [3/4], Step [114/3844], Loss: 0.0973\n",
      "Epoch [3/4], Step [115/3844], Loss: 0.1800\n",
      "Epoch [3/4], Step [116/3844], Loss: 0.1627\n",
      "Epoch [3/4], Step [117/3844], Loss: 0.0780\n",
      "Epoch [3/4], Step [118/3844], Loss: 0.1259\n",
      "Epoch [3/4], Step [119/3844], Loss: 0.1914\n",
      "Epoch [3/4], Step [120/3844], Loss: 0.1187\n",
      "Epoch [3/4], Step [121/3844], Loss: 0.1487\n",
      "Epoch [3/4], Step [122/3844], Loss: 0.1280\n",
      "Epoch [3/4], Step [123/3844], Loss: 0.1401\n",
      "Epoch [3/4], Step [124/3844], Loss: 0.1844\n",
      "Epoch [3/4], Step [125/3844], Loss: 0.1244\n",
      "Epoch [3/4], Step [126/3844], Loss: 0.1428\n",
      "Epoch [3/4], Step [127/3844], Loss: 0.1485\n",
      "Epoch [3/4], Step [128/3844], Loss: 0.1097\n",
      "Epoch [3/4], Step [129/3844], Loss: 0.1017\n",
      "Epoch [3/4], Step [130/3844], Loss: 0.0968\n",
      "Epoch [3/4], Step [131/3844], Loss: 0.0716\n",
      "Epoch [3/4], Step [132/3844], Loss: 0.1721\n",
      "Epoch [3/4], Step [133/3844], Loss: 0.0786\n",
      "Epoch [3/4], Step [134/3844], Loss: 0.0785\n",
      "Epoch [3/4], Step [135/3844], Loss: 0.1093\n",
      "Epoch [3/4], Step [136/3844], Loss: 0.0891\n",
      "Epoch [3/4], Step [137/3844], Loss: 0.1460\n",
      "Epoch [3/4], Step [138/3844], Loss: 0.0947\n",
      "Epoch [3/4], Step [139/3844], Loss: 0.0602\n",
      "Epoch [3/4], Step [140/3844], Loss: 0.1122\n",
      "Epoch [3/4], Step [141/3844], Loss: 0.0808\n",
      "Epoch [3/4], Step [142/3844], Loss: 0.1589\n",
      "Epoch [3/4], Step [143/3844], Loss: 0.0638\n",
      "Epoch [3/4], Step [144/3844], Loss: 0.1327\n",
      "Epoch [3/4], Step [145/3844], Loss: 0.0709\n",
      "Epoch [3/4], Step [146/3844], Loss: 0.1021\n",
      "Epoch [3/4], Step [147/3844], Loss: 0.1504\n",
      "Epoch [3/4], Step [148/3844], Loss: 0.1156\n",
      "Epoch [3/4], Step [149/3844], Loss: 0.2012\n",
      "Epoch [3/4], Step [150/3844], Loss: 0.1678\n",
      "Epoch [3/4], Step [151/3844], Loss: 0.1180\n",
      "Epoch [3/4], Step [152/3844], Loss: 0.0802\n",
      "Epoch [3/4], Step [153/3844], Loss: 0.1302\n",
      "Epoch [3/4], Step [154/3844], Loss: 0.1656\n",
      "Epoch [3/4], Step [155/3844], Loss: 0.0503\n",
      "Epoch [3/4], Step [156/3844], Loss: 0.1564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/4], Step [157/3844], Loss: 0.0949\n",
      "Epoch [3/4], Step [158/3844], Loss: 0.0955\n",
      "Epoch [3/4], Step [159/3844], Loss: 0.0813\n",
      "Epoch [3/4], Step [160/3844], Loss: 0.0866\n",
      "Epoch [3/4], Step [161/3844], Loss: 0.1062\n",
      "Epoch [3/4], Step [162/3844], Loss: 0.1883\n",
      "Epoch [3/4], Step [163/3844], Loss: 0.1756\n",
      "Epoch [3/4], Step [164/3844], Loss: 0.0599\n",
      "Epoch [3/4], Step [165/3844], Loss: 0.1536\n",
      "Epoch [3/4], Step [166/3844], Loss: 0.0826\n",
      "Epoch [3/4], Step [167/3844], Loss: 0.1385\n",
      "Epoch [3/4], Step [168/3844], Loss: 0.1408\n",
      "Epoch [3/4], Step [169/3844], Loss: 0.1008\n",
      "Epoch [3/4], Step [170/3844], Loss: 0.0937\n",
      "Epoch [3/4], Step [171/3844], Loss: 0.0799\n",
      "Epoch [3/4], Step [172/3844], Loss: 0.1402\n",
      "Epoch [3/4], Step [173/3844], Loss: 0.1828\n",
      "Epoch [3/4], Step [174/3844], Loss: 0.1346\n",
      "Epoch [3/4], Step [175/3844], Loss: 0.0795\n",
      "Epoch [3/4], Step [176/3844], Loss: 0.0719\n",
      "Epoch [3/4], Step [177/3844], Loss: 0.1210\n",
      "Epoch [3/4], Step [178/3844], Loss: 0.1309\n",
      "Epoch [3/4], Step [179/3844], Loss: 0.1690\n",
      "Epoch [3/4], Step [180/3844], Loss: 0.0781\n",
      "Epoch [3/4], Step [181/3844], Loss: 0.0796\n",
      "Epoch [3/4], Step [182/3844], Loss: 0.0770\n",
      "Epoch [3/4], Step [183/3844], Loss: 0.1251\n",
      "Epoch [3/4], Step [184/3844], Loss: 0.0794\n",
      "Epoch [3/4], Step [185/3844], Loss: 0.1262\n",
      "Epoch [3/4], Step [186/3844], Loss: 0.1310\n",
      "Epoch [3/4], Step [187/3844], Loss: 0.0527\n",
      "Epoch [3/4], Step [188/3844], Loss: 0.0886\n",
      "Epoch [3/4], Step [189/3844], Loss: 0.1298\n",
      "Epoch [3/4], Step [190/3844], Loss: 0.0664\n",
      "Epoch [3/4], Step [191/3844], Loss: 0.1053\n",
      "Epoch [3/4], Step [192/3844], Loss: 0.0816\n",
      "Epoch [3/4], Step [193/3844], Loss: 0.0537\n",
      "Epoch [3/4], Step [194/3844], Loss: 0.1094\n",
      "Epoch [3/4], Step [195/3844], Loss: 0.0779\n",
      "Epoch [3/4], Step [196/3844], Loss: 0.0928\n",
      "Epoch [3/4], Step [197/3844], Loss: 0.1453\n",
      "Epoch [3/4], Step [198/3844], Loss: 0.0656\n",
      "Epoch [3/4], Step [199/3844], Loss: 0.1166\n",
      "Epoch [3/4], Step [200/3844], Loss: 0.1340\n",
      "Epoch [3/4], Step [201/3844], Loss: 0.1637\n",
      "Epoch [3/4], Step [202/3844], Loss: 0.1312\n",
      "Epoch [3/4], Step [203/3844], Loss: 0.0837\n",
      "Epoch [3/4], Step [204/3844], Loss: 0.0935\n",
      "Epoch [3/4], Step [205/3844], Loss: 0.1363\n",
      "Epoch [3/4], Step [206/3844], Loss: 0.1045\n",
      "Epoch [3/4], Step [207/3844], Loss: 0.1601\n",
      "Epoch [3/4], Step [208/3844], Loss: 0.0471\n",
      "Epoch [3/4], Step [209/3844], Loss: 0.1381\n",
      "Epoch [3/4], Step [210/3844], Loss: 0.0805\n",
      "Epoch [3/4], Step [211/3844], Loss: 0.1150\n",
      "Epoch [3/4], Step [212/3844], Loss: 0.0694\n",
      "Epoch [3/4], Step [213/3844], Loss: 0.1123\n",
      "Epoch [3/4], Step [214/3844], Loss: 0.0986\n",
      "Epoch [3/4], Step [215/3844], Loss: 0.0973\n",
      "Epoch [3/4], Step [216/3844], Loss: 0.0744\n",
      "Epoch [3/4], Step [217/3844], Loss: 0.1316\n",
      "Epoch [3/4], Step [218/3844], Loss: 0.1724\n",
      "Epoch [3/4], Step [219/3844], Loss: 0.0907\n",
      "Epoch [3/4], Step [220/3844], Loss: 0.1816\n",
      "Epoch [3/4], Step [221/3844], Loss: 0.0689\n",
      "Epoch [3/4], Step [222/3844], Loss: 0.1218\n",
      "Epoch [3/4], Step [223/3844], Loss: 0.1388\n",
      "Epoch [3/4], Step [224/3844], Loss: 0.0886\n",
      "Epoch [3/4], Step [225/3844], Loss: 0.1315\n",
      "Epoch [3/4], Step [226/3844], Loss: 0.1587\n",
      "Epoch [3/4], Step [227/3844], Loss: 0.1564\n",
      "Epoch [3/4], Step [228/3844], Loss: 0.1740\n",
      "Epoch [3/4], Step [229/3844], Loss: 0.1718\n",
      "Epoch [3/4], Step [230/3844], Loss: 0.1334\n",
      "Epoch [3/4], Step [231/3844], Loss: 0.0879\n",
      "Epoch [3/4], Step [232/3844], Loss: 0.0526\n",
      "Epoch [3/4], Step [233/3844], Loss: 0.0653\n",
      "Epoch [3/4], Step [234/3844], Loss: 0.1246\n",
      "Epoch [3/4], Step [235/3844], Loss: 0.1434\n",
      "Epoch [3/4], Step [236/3844], Loss: 0.0806\n",
      "Epoch [3/4], Step [237/3844], Loss: 0.1389\n",
      "Epoch [3/4], Step [238/3844], Loss: 0.1048\n",
      "Epoch [3/4], Step [239/3844], Loss: 0.1661\n",
      "Epoch [3/4], Step [240/3844], Loss: 0.0977\n",
      "Epoch [3/4], Step [241/3844], Loss: 0.1365\n",
      "Epoch [3/4], Step [242/3844], Loss: 0.0708\n",
      "Epoch [3/4], Step [243/3844], Loss: 0.0872\n",
      "Epoch [3/4], Step [244/3844], Loss: 0.1752\n",
      "Epoch [3/4], Step [245/3844], Loss: 0.0673\n",
      "Epoch [3/4], Step [246/3844], Loss: 0.1646\n",
      "Epoch [3/4], Step [247/3844], Loss: 0.1351\n",
      "Epoch [3/4], Step [248/3844], Loss: 0.0911\n",
      "Epoch [3/4], Step [249/3844], Loss: 0.1558\n",
      "Epoch [3/4], Step [250/3844], Loss: 0.1611\n",
      "Epoch [3/4], Step [251/3844], Loss: 0.0704\n",
      "Epoch [3/4], Step [252/3844], Loss: 0.0972\n",
      "Epoch [3/4], Step [253/3844], Loss: 0.0652\n",
      "Epoch [3/4], Step [254/3844], Loss: 0.1124\n",
      "Epoch [3/4], Step [255/3844], Loss: 0.1714\n",
      "Epoch [3/4], Step [256/3844], Loss: 0.1845\n",
      "Epoch [3/4], Step [257/3844], Loss: 0.1434\n",
      "Epoch [3/4], Step [258/3844], Loss: 0.1425\n",
      "Epoch [3/4], Step [259/3844], Loss: 0.1521\n",
      "Epoch [3/4], Step [260/3844], Loss: 0.0561\n",
      "Epoch [3/4], Step [261/3844], Loss: 0.1491\n",
      "Epoch [3/4], Step [262/3844], Loss: 0.1355\n",
      "Epoch [3/4], Step [263/3844], Loss: 0.1000\n",
      "Epoch [3/4], Step [264/3844], Loss: 0.1339\n",
      "Epoch [3/4], Step [265/3844], Loss: 0.0672\n",
      "Epoch [3/4], Step [266/3844], Loss: 0.0862\n",
      "Epoch [3/4], Step [267/3844], Loss: 0.1180\n",
      "Epoch [3/4], Step [268/3844], Loss: 0.1189\n",
      "Epoch [3/4], Step [269/3844], Loss: 0.0931\n",
      "Epoch [3/4], Step [270/3844], Loss: 0.0703\n",
      "Epoch [3/4], Step [271/3844], Loss: 0.1618\n",
      "Epoch [3/4], Step [272/3844], Loss: 0.0943\n",
      "Epoch [3/4], Step [273/3844], Loss: 0.1030\n",
      "Epoch [3/4], Step [274/3844], Loss: 0.1300\n",
      "Epoch [3/4], Step [275/3844], Loss: 0.1178\n",
      "Epoch [3/4], Step [276/3844], Loss: 0.1579\n",
      "Epoch [3/4], Step [277/3844], Loss: 0.0810\n",
      "Epoch [3/4], Step [278/3844], Loss: 0.1000\n",
      "Epoch [3/4], Step [279/3844], Loss: 0.1317\n",
      "Epoch [3/4], Step [280/3844], Loss: 0.1187\n",
      "Epoch [3/4], Step [281/3844], Loss: 0.1828\n",
      "Epoch [3/4], Step [282/3844], Loss: 0.0904\n",
      "Epoch [3/4], Step [283/3844], Loss: 0.1521\n",
      "Epoch [3/4], Step [284/3844], Loss: 0.1308\n",
      "Epoch [3/4], Step [285/3844], Loss: 0.0723\n",
      "Epoch [3/4], Step [286/3844], Loss: 0.0855\n",
      "Epoch [3/4], Step [287/3844], Loss: 0.0952\n",
      "Epoch [3/4], Step [288/3844], Loss: 0.1718\n",
      "Epoch [3/4], Step [289/3844], Loss: 0.0723\n",
      "Epoch [3/4], Step [290/3844], Loss: 0.1521\n",
      "Epoch [3/4], Step [291/3844], Loss: 0.1751\n",
      "Epoch [3/4], Step [292/3844], Loss: 0.1002\n",
      "Epoch [3/4], Step [293/3844], Loss: 0.0746\n",
      "Epoch [3/4], Step [294/3844], Loss: 0.0912\n",
      "Epoch [3/4], Step [295/3844], Loss: 0.0682\n",
      "Epoch [3/4], Step [296/3844], Loss: 0.0647\n",
      "Epoch [3/4], Step [297/3844], Loss: 0.0871\n",
      "Epoch [3/4], Step [298/3844], Loss: 0.1048\n",
      "Epoch [3/4], Step [299/3844], Loss: 0.1341\n",
      "Epoch [3/4], Step [300/3844], Loss: 0.1236\n",
      "Epoch [3/4], Step [301/3844], Loss: 0.0953\n",
      "Epoch [3/4], Step [302/3844], Loss: 0.1620\n",
      "Epoch [3/4], Step [303/3844], Loss: 0.0672\n",
      "Epoch [3/4], Step [304/3844], Loss: 0.1330\n",
      "Epoch [3/4], Step [305/3844], Loss: 0.1754\n",
      "Epoch [3/4], Step [306/3844], Loss: 0.1658\n",
      "Epoch [3/4], Step [307/3844], Loss: 0.1121\n",
      "Epoch [3/4], Step [308/3844], Loss: 0.1291\n",
      "Epoch [3/4], Step [309/3844], Loss: 0.0617\n",
      "Epoch [3/4], Step [310/3844], Loss: 0.0923\n",
      "Epoch [3/4], Step [311/3844], Loss: 0.0915\n",
      "Epoch [3/4], Step [312/3844], Loss: 0.0788\n",
      "Epoch [3/4], Step [313/3844], Loss: 0.0766\n",
      "Epoch [3/4], Step [314/3844], Loss: 0.1084\n",
      "Epoch [3/4], Step [315/3844], Loss: 0.1106\n",
      "Epoch [3/4], Step [316/3844], Loss: 0.0805\n",
      "Epoch [3/4], Step [317/3844], Loss: 0.0889\n",
      "Epoch [3/4], Step [318/3844], Loss: 0.1290\n",
      "Epoch [3/4], Step [319/3844], Loss: 0.0839\n",
      "Epoch [3/4], Step [320/3844], Loss: 0.1048\n",
      "Epoch [3/4], Step [321/3844], Loss: 0.0677\n",
      "Epoch [3/4], Step [322/3844], Loss: 0.0826\n",
      "Epoch [3/4], Step [323/3844], Loss: 0.1948\n",
      "Epoch [3/4], Step [324/3844], Loss: 0.1109\n",
      "Epoch [3/4], Step [325/3844], Loss: 0.1957\n",
      "Epoch [3/4], Step [326/3844], Loss: 0.0737\n",
      "Epoch [3/4], Step [327/3844], Loss: 0.0541\n",
      "Epoch [3/4], Step [328/3844], Loss: 0.1223\n",
      "Epoch [3/4], Step [329/3844], Loss: 0.1233\n",
      "Epoch [3/4], Step [330/3844], Loss: 0.2094\n",
      "Epoch [3/4], Step [331/3844], Loss: 0.0858\n",
      "Epoch [3/4], Step [332/3844], Loss: 0.1020\n",
      "Epoch [3/4], Step [333/3844], Loss: 0.0977\n",
      "Epoch [3/4], Step [334/3844], Loss: 0.0941\n",
      "Epoch [3/4], Step [335/3844], Loss: 0.0791\n",
      "Epoch [3/4], Step [336/3844], Loss: 0.0914\n",
      "Epoch [3/4], Step [337/3844], Loss: 0.1063\n",
      "Epoch [3/4], Step [338/3844], Loss: 0.0795\n",
      "Epoch [3/4], Step [339/3844], Loss: 0.1329\n",
      "Epoch [3/4], Step [340/3844], Loss: 0.0792\n",
      "Epoch [3/4], Step [341/3844], Loss: 0.1332\n",
      "Epoch [3/4], Step [342/3844], Loss: 0.1043\n",
      "Epoch [3/4], Step [343/3844], Loss: 0.0801\n",
      "Epoch [3/4], Step [344/3844], Loss: 0.0742\n",
      "Epoch [3/4], Step [345/3844], Loss: 0.1399\n",
      "Epoch [3/4], Step [346/3844], Loss: 0.1671\n",
      "Epoch [3/4], Step [347/3844], Loss: 0.1093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/4], Step [348/3844], Loss: 0.0735\n",
      "Epoch [3/4], Step [349/3844], Loss: 0.0543\n",
      "Epoch [3/4], Step [350/3844], Loss: 0.1457\n",
      "Epoch [3/4], Step [351/3844], Loss: 0.0567\n",
      "Epoch [3/4], Step [352/3844], Loss: 0.1157\n",
      "Epoch [3/4], Step [353/3844], Loss: 0.0736\n",
      "Epoch [3/4], Step [354/3844], Loss: 0.1467\n",
      "Epoch [3/4], Step [355/3844], Loss: 0.0809\n",
      "Epoch [3/4], Step [356/3844], Loss: 0.1323\n",
      "Epoch [3/4], Step [357/3844], Loss: 0.0940\n",
      "Epoch [3/4], Step [358/3844], Loss: 0.1778\n",
      "Epoch [3/4], Step [359/3844], Loss: 0.1871\n",
      "Epoch [3/4], Step [360/3844], Loss: 0.0804\n",
      "Epoch [3/4], Step [361/3844], Loss: 0.0851\n",
      "Epoch [3/4], Step [362/3844], Loss: 0.1325\n",
      "Epoch [3/4], Step [363/3844], Loss: 0.0738\n",
      "Epoch [3/4], Step [364/3844], Loss: 0.1728\n",
      "Epoch [3/4], Step [365/3844], Loss: 0.0938\n",
      "Epoch [3/4], Step [366/3844], Loss: 0.0760\n",
      "Epoch [3/4], Step [367/3844], Loss: 0.0888\n",
      "Epoch [3/4], Step [368/3844], Loss: 0.1994\n",
      "Epoch [3/4], Step [369/3844], Loss: 0.0760\n",
      "Epoch [3/4], Step [370/3844], Loss: 0.0874\n",
      "Epoch [3/4], Step [371/3844], Loss: 0.1714\n",
      "Epoch [3/4], Step [372/3844], Loss: 0.0864\n",
      "Epoch [3/4], Step [373/3844], Loss: 0.0841\n",
      "Epoch [3/4], Step [374/3844], Loss: 0.1372\n",
      "Epoch [3/4], Step [375/3844], Loss: 0.1428\n",
      "Epoch [3/4], Step [376/3844], Loss: 0.0920\n",
      "Epoch [3/4], Step [377/3844], Loss: 0.1514\n",
      "Epoch [3/4], Step [378/3844], Loss: 0.1277\n",
      "Epoch [3/4], Step [379/3844], Loss: 0.1741\n",
      "Epoch [3/4], Step [380/3844], Loss: 0.1396\n",
      "Epoch [3/4], Step [381/3844], Loss: 0.1005\n",
      "Epoch [3/4], Step [382/3844], Loss: 0.1162\n",
      "Epoch [3/4], Step [383/3844], Loss: 0.1733\n",
      "Epoch [3/4], Step [384/3844], Loss: 0.1400\n",
      "Epoch [3/4], Step [385/3844], Loss: 0.0665\n",
      "Epoch [3/4], Step [386/3844], Loss: 0.0892\n",
      "Epoch [3/4], Step [387/3844], Loss: 0.1055\n",
      "Epoch [3/4], Step [388/3844], Loss: 0.0705\n",
      "Epoch [3/4], Step [389/3844], Loss: 0.1752\n",
      "Epoch [3/4], Step [390/3844], Loss: 0.0916\n",
      "Epoch [3/4], Step [391/3844], Loss: 0.0757\n",
      "Epoch [3/4], Step [392/3844], Loss: 0.0948\n",
      "Epoch [3/4], Step [393/3844], Loss: 0.1261\n",
      "Epoch [3/4], Step [394/3844], Loss: 0.0988\n",
      "Epoch [3/4], Step [395/3844], Loss: 0.1429\n",
      "Epoch [3/4], Step [396/3844], Loss: 0.0912\n",
      "Epoch [3/4], Step [397/3844], Loss: 0.1758\n",
      "Epoch [3/4], Step [398/3844], Loss: 0.1572\n",
      "Epoch [3/4], Step [399/3844], Loss: 0.0949\n",
      "Epoch [3/4], Step [400/3844], Loss: 0.0662\n",
      "Epoch [3/4], Step [401/3844], Loss: 0.1128\n",
      "Epoch [3/4], Step [402/3844], Loss: 0.0820\n",
      "Epoch [3/4], Step [403/3844], Loss: 0.1225\n",
      "Epoch [3/4], Step [404/3844], Loss: 0.0975\n",
      "Epoch [3/4], Step [405/3844], Loss: 0.1676\n",
      "Epoch [3/4], Step [406/3844], Loss: 0.1369\n",
      "Epoch [3/4], Step [407/3844], Loss: 0.0871\n",
      "Epoch [3/4], Step [408/3844], Loss: 0.1199\n",
      "Epoch [3/4], Step [409/3844], Loss: 0.1656\n",
      "Epoch [3/4], Step [410/3844], Loss: 0.0737\n",
      "Epoch [3/4], Step [411/3844], Loss: 0.0869\n",
      "Epoch [3/4], Step [412/3844], Loss: 0.1423\n",
      "Epoch [3/4], Step [413/3844], Loss: 0.1397\n",
      "Epoch [3/4], Step [414/3844], Loss: 0.1495\n",
      "Epoch [3/4], Step [415/3844], Loss: 0.1405\n",
      "Epoch [3/4], Step [416/3844], Loss: 0.0905\n",
      "Epoch [3/4], Step [417/3844], Loss: 0.1766\n",
      "Epoch [3/4], Step [418/3844], Loss: 0.1069\n",
      "Epoch [3/4], Step [419/3844], Loss: 0.0922\n",
      "Epoch [3/4], Step [420/3844], Loss: 0.0895\n",
      "Epoch [3/4], Step [421/3844], Loss: 0.1434\n",
      "Epoch [3/4], Step [422/3844], Loss: 0.0889\n",
      "Epoch [3/4], Step [423/3844], Loss: 0.1354\n",
      "Epoch [3/4], Step [424/3844], Loss: 0.1457\n",
      "Epoch [3/4], Step [425/3844], Loss: 0.0659\n",
      "Epoch [3/4], Step [426/3844], Loss: 0.1007\n",
      "Epoch [3/4], Step [427/3844], Loss: 0.1526\n",
      "Epoch [3/4], Step [428/3844], Loss: 0.0808\n",
      "Epoch [3/4], Step [429/3844], Loss: 0.0895\n",
      "Epoch [3/4], Step [430/3844], Loss: 0.1607\n",
      "Epoch [3/4], Step [431/3844], Loss: 0.0954\n",
      "Epoch [3/4], Step [432/3844], Loss: 0.0945\n",
      "Epoch [3/4], Step [433/3844], Loss: 0.0868\n",
      "Epoch [3/4], Step [434/3844], Loss: 0.1450\n",
      "Epoch [3/4], Step [435/3844], Loss: 0.0511\n",
      "Epoch [3/4], Step [436/3844], Loss: 0.1785\n",
      "Epoch [3/4], Step [437/3844], Loss: 0.0616\n",
      "Epoch [3/4], Step [438/3844], Loss: 0.0719\n",
      "Epoch [3/4], Step [439/3844], Loss: 0.0592\n",
      "Epoch [3/4], Step [440/3844], Loss: 0.1138\n",
      "Epoch [3/4], Step [441/3844], Loss: 0.1241\n",
      "Epoch [3/4], Step [442/3844], Loss: 0.1390\n",
      "Epoch [3/4], Step [443/3844], Loss: 0.1263\n",
      "Epoch [3/4], Step [444/3844], Loss: 0.1389\n",
      "Epoch [3/4], Step [445/3844], Loss: 0.1329\n",
      "Epoch [3/4], Step [446/3844], Loss: 0.1597\n",
      "Epoch [3/4], Step [447/3844], Loss: 0.1670\n",
      "Epoch [3/4], Step [448/3844], Loss: 0.1533\n",
      "Epoch [3/4], Step [449/3844], Loss: 0.1001\n",
      "Epoch [3/4], Step [450/3844], Loss: 0.0688\n",
      "Epoch [3/4], Step [451/3844], Loss: 0.0966\n",
      "Epoch [3/4], Step [452/3844], Loss: 0.0763\n",
      "Epoch [3/4], Step [453/3844], Loss: 0.1403\n",
      "Epoch [3/4], Step [454/3844], Loss: 0.1272\n",
      "Epoch [3/4], Step [455/3844], Loss: 0.0918\n",
      "Epoch [3/4], Step [456/3844], Loss: 0.0861\n",
      "Epoch [3/4], Step [457/3844], Loss: 0.1527\n",
      "Epoch [3/4], Step [458/3844], Loss: 0.1091\n",
      "Epoch [3/4], Step [459/3844], Loss: 0.1072\n",
      "Epoch [3/4], Step [460/3844], Loss: 0.0766\n",
      "Epoch [3/4], Step [461/3844], Loss: 0.1030\n",
      "Epoch [3/4], Step [462/3844], Loss: 0.1314\n",
      "Epoch [3/4], Step [463/3844], Loss: 0.0874\n",
      "Epoch [3/4], Step [464/3844], Loss: 0.0989\n",
      "Epoch [3/4], Step [465/3844], Loss: 0.2077\n",
      "Epoch [3/4], Step [466/3844], Loss: 0.0781\n",
      "Epoch [3/4], Step [467/3844], Loss: 0.1826\n",
      "Epoch [3/4], Step [468/3844], Loss: 0.1499\n",
      "Epoch [3/4], Step [469/3844], Loss: 0.0980\n",
      "Epoch [3/4], Step [470/3844], Loss: 0.0616\n",
      "Epoch [3/4], Step [471/3844], Loss: 0.1370\n",
      "Epoch [3/4], Step [472/3844], Loss: 0.1127\n",
      "Epoch [3/4], Step [473/3844], Loss: 0.0919\n",
      "Epoch [3/4], Step [474/3844], Loss: 0.0971\n",
      "Epoch [3/4], Step [475/3844], Loss: 0.1535\n",
      "Epoch [3/4], Step [476/3844], Loss: 0.0735\n",
      "Epoch [3/4], Step [477/3844], Loss: 0.1114\n",
      "Epoch [3/4], Step [478/3844], Loss: 0.1032\n",
      "Epoch [3/4], Step [479/3844], Loss: 0.1353\n",
      "Epoch [3/4], Step [480/3844], Loss: 0.1622\n",
      "Epoch [3/4], Step [481/3844], Loss: 0.0618\n",
      "Epoch [3/4], Step [482/3844], Loss: 0.0886\n",
      "Epoch [3/4], Step [483/3844], Loss: 0.1377\n",
      "Epoch [3/4], Step [484/3844], Loss: 0.0796\n",
      "Epoch [3/4], Step [485/3844], Loss: 0.1338\n",
      "Epoch [3/4], Step [486/3844], Loss: 0.1411\n",
      "Epoch [3/4], Step [487/3844], Loss: 0.0883\n",
      "Epoch [3/4], Step [488/3844], Loss: 0.0923\n",
      "Epoch [3/4], Step [489/3844], Loss: 0.0910\n",
      "Epoch [3/4], Step [490/3844], Loss: 0.0719\n",
      "Epoch [3/4], Step [491/3844], Loss: 0.0598\n",
      "Epoch [3/4], Step [492/3844], Loss: 0.0818\n",
      "Epoch [3/4], Step [493/3844], Loss: 0.0663\n",
      "Epoch [3/4], Step [494/3844], Loss: 0.1518\n",
      "Epoch [3/4], Step [495/3844], Loss: 0.0764\n",
      "Epoch [3/4], Step [496/3844], Loss: 0.0967\n",
      "Epoch [3/4], Step [497/3844], Loss: 0.1478\n",
      "Epoch [3/4], Step [498/3844], Loss: 0.1109\n",
      "Epoch [3/4], Step [499/3844], Loss: 0.0760\n",
      "Epoch [3/4], Step [500/3844], Loss: 0.1474\n",
      "Epoch [3/4], Step [501/3844], Loss: 0.0838\n",
      "Epoch [3/4], Step [502/3844], Loss: 0.1076\n",
      "Epoch [3/4], Step [503/3844], Loss: 0.0890\n",
      "Epoch [3/4], Step [504/3844], Loss: 0.0907\n",
      "Epoch [3/4], Step [505/3844], Loss: 0.0447\n",
      "Epoch [3/4], Step [506/3844], Loss: 0.1055\n",
      "Epoch [3/4], Step [507/3844], Loss: 0.1100\n",
      "Epoch [3/4], Step [508/3844], Loss: 0.1354\n",
      "Epoch [3/4], Step [509/3844], Loss: 0.1442\n",
      "Epoch [3/4], Step [510/3844], Loss: 0.1059\n",
      "Epoch [3/4], Step [511/3844], Loss: 0.0989\n",
      "Epoch [3/4], Step [512/3844], Loss: 0.0545\n",
      "Epoch [3/4], Step [513/3844], Loss: 0.1579\n",
      "Epoch [3/4], Step [514/3844], Loss: 0.0768\n",
      "Epoch [3/4], Step [515/3844], Loss: 0.1446\n",
      "Epoch [3/4], Step [516/3844], Loss: 0.0768\n",
      "Epoch [3/4], Step [517/3844], Loss: 0.1558\n",
      "Epoch [3/4], Step [518/3844], Loss: 0.1656\n",
      "Epoch [3/4], Step [519/3844], Loss: 0.1374\n",
      "Epoch [3/4], Step [520/3844], Loss: 0.1160\n",
      "Epoch [3/4], Step [521/3844], Loss: 0.1060\n",
      "Epoch [3/4], Step [522/3844], Loss: 0.1242\n",
      "Epoch [3/4], Step [523/3844], Loss: 0.1465\n",
      "Epoch [3/4], Step [524/3844], Loss: 0.0951\n",
      "Epoch [3/4], Step [525/3844], Loss: 0.0888\n",
      "Epoch [3/4], Step [526/3844], Loss: 0.0595\n",
      "Epoch [3/4], Step [527/3844], Loss: 0.1009\n",
      "Epoch [3/4], Step [528/3844], Loss: 0.0687\n",
      "Epoch [3/4], Step [529/3844], Loss: 0.0985\n",
      "Epoch [3/4], Step [530/3844], Loss: 0.0932\n",
      "Epoch [3/4], Step [531/3844], Loss: 0.0803\n",
      "Epoch [3/4], Step [532/3844], Loss: 0.0879\n",
      "Epoch [3/4], Step [533/3844], Loss: 0.1150\n",
      "Epoch [3/4], Step [534/3844], Loss: 0.1214\n",
      "Epoch [3/4], Step [535/3844], Loss: 0.0797\n",
      "Epoch [3/4], Step [536/3844], Loss: 0.0891\n",
      "Epoch [3/4], Step [537/3844], Loss: 0.1845\n",
      "Epoch [3/4], Step [538/3844], Loss: 0.1258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/4], Step [539/3844], Loss: 0.0785\n",
      "Epoch [3/4], Step [540/3844], Loss: 0.1827\n",
      "Epoch [3/4], Step [541/3844], Loss: 0.0932\n",
      "Epoch [3/4], Step [542/3844], Loss: 0.0709\n",
      "Epoch [3/4], Step [543/3844], Loss: 0.0611\n",
      "Epoch [3/4], Step [544/3844], Loss: 0.1161\n",
      "Epoch [3/4], Step [545/3844], Loss: 0.1237\n",
      "Epoch [3/4], Step [546/3844], Loss: 0.1163\n",
      "Epoch [3/4], Step [547/3844], Loss: 0.1318\n",
      "Epoch [3/4], Step [548/3844], Loss: 0.1621\n",
      "Epoch [3/4], Step [549/3844], Loss: 0.1480\n",
      "Epoch [3/4], Step [550/3844], Loss: 0.1009\n",
      "Epoch [3/4], Step [551/3844], Loss: 0.0850\n",
      "Epoch [3/4], Step [552/3844], Loss: 0.0688\n",
      "Epoch [3/4], Step [553/3844], Loss: 0.1702\n",
      "Epoch [3/4], Step [554/3844], Loss: 0.0950\n",
      "Epoch [3/4], Step [555/3844], Loss: 0.1116\n",
      "Epoch [3/4], Step [556/3844], Loss: 0.0636\n",
      "Epoch [3/4], Step [557/3844], Loss: 0.0701\n",
      "Epoch [3/4], Step [558/3844], Loss: 0.1452\n",
      "Epoch [3/4], Step [559/3844], Loss: 0.1587\n",
      "Epoch [3/4], Step [560/3844], Loss: 0.1483\n",
      "Epoch [3/4], Step [561/3844], Loss: 0.1593\n",
      "Epoch [3/4], Step [562/3844], Loss: 0.1573\n",
      "Epoch [3/4], Step [563/3844], Loss: 0.0837\n",
      "Epoch [3/4], Step [564/3844], Loss: 0.0807\n",
      "Epoch [3/4], Step [565/3844], Loss: 0.1566\n",
      "Epoch [3/4], Step [566/3844], Loss: 0.0933\n",
      "Epoch [3/4], Step [567/3844], Loss: 0.0934\n",
      "Epoch [3/4], Step [568/3844], Loss: 0.1247\n",
      "Epoch [3/4], Step [569/3844], Loss: 0.1558\n",
      "Epoch [3/4], Step [570/3844], Loss: 0.0967\n",
      "Epoch [3/4], Step [571/3844], Loss: 0.1092\n",
      "Epoch [3/4], Step [572/3844], Loss: 0.1117\n",
      "Epoch [3/4], Step [573/3844], Loss: 0.1615\n",
      "Epoch [3/4], Step [574/3844], Loss: 0.0931\n",
      "Epoch [3/4], Step [575/3844], Loss: 0.1087\n",
      "Epoch [3/4], Step [576/3844], Loss: 0.0835\n",
      "Epoch [3/4], Step [577/3844], Loss: 0.0961\n",
      "Epoch [3/4], Step [578/3844], Loss: 0.0829\n",
      "Epoch [3/4], Step [579/3844], Loss: 0.1277\n",
      "Epoch [3/4], Step [580/3844], Loss: 0.1651\n",
      "Epoch [3/4], Step [581/3844], Loss: 0.0780\n",
      "Epoch [3/4], Step [582/3844], Loss: 0.1426\n",
      "Epoch [3/4], Step [583/3844], Loss: 0.1364\n",
      "Epoch [3/4], Step [584/3844], Loss: 0.1219\n",
      "Epoch [3/4], Step [585/3844], Loss: 0.1110\n",
      "Epoch [3/4], Step [586/3844], Loss: 0.0756\n",
      "Epoch [3/4], Step [587/3844], Loss: 0.0949\n",
      "Epoch [3/4], Step [588/3844], Loss: 0.1588\n",
      "Epoch [3/4], Step [589/3844], Loss: 0.1558\n",
      "Epoch [3/4], Step [590/3844], Loss: 0.1571\n",
      "Epoch [3/4], Step [591/3844], Loss: 0.0944\n",
      "Epoch [3/4], Step [592/3844], Loss: 0.1365\n",
      "Epoch [3/4], Step [593/3844], Loss: 0.1129\n",
      "Epoch [3/4], Step [594/3844], Loss: 0.1663\n",
      "Epoch [3/4], Step [595/3844], Loss: 0.0874\n",
      "Epoch [3/4], Step [596/3844], Loss: 0.1121\n",
      "Epoch [3/4], Step [597/3844], Loss: 0.1063\n",
      "Epoch [3/4], Step [598/3844], Loss: 0.1016\n",
      "Epoch [3/4], Step [599/3844], Loss: 0.1003\n",
      "Epoch [3/4], Step [600/3844], Loss: 0.1558\n",
      "Epoch [3/4], Step [601/3844], Loss: 0.1387\n",
      "Epoch [3/4], Step [602/3844], Loss: 0.1964\n",
      "Epoch [3/4], Step [603/3844], Loss: 0.0946\n",
      "Epoch [3/4], Step [604/3844], Loss: 0.0952\n",
      "Epoch [3/4], Step [605/3844], Loss: 0.0770\n",
      "Epoch [3/4], Step [606/3844], Loss: 0.1628\n",
      "Epoch [3/4], Step [607/3844], Loss: 0.1493\n",
      "Epoch [3/4], Step [608/3844], Loss: 0.0940\n",
      "Epoch [3/4], Step [609/3844], Loss: 0.0991\n",
      "Epoch [3/4], Step [610/3844], Loss: 0.1183\n",
      "Epoch [3/4], Step [611/3844], Loss: 0.0664\n",
      "Epoch [3/4], Step [612/3844], Loss: 0.0933\n",
      "Epoch [3/4], Step [613/3844], Loss: 0.0988\n",
      "Epoch [3/4], Step [614/3844], Loss: 0.0994\n",
      "Epoch [3/4], Step [615/3844], Loss: 0.0651\n",
      "Epoch [3/4], Step [616/3844], Loss: 0.0754\n",
      "Epoch [3/4], Step [617/3844], Loss: 0.0919\n",
      "Epoch [3/4], Step [618/3844], Loss: 0.1481\n",
      "Epoch [3/4], Step [619/3844], Loss: 0.1744\n",
      "Epoch [3/4], Step [620/3844], Loss: 0.0811\n",
      "Epoch [3/4], Step [621/3844], Loss: 0.0643\n",
      "Epoch [3/4], Step [622/3844], Loss: 0.0653\n",
      "Epoch [3/4], Step [623/3844], Loss: 0.0872\n",
      "Epoch [3/4], Step [624/3844], Loss: 0.1091\n",
      "Epoch [3/4], Step [625/3844], Loss: 0.0855\n",
      "Epoch [3/4], Step [626/3844], Loss: 0.0698\n",
      "Epoch [3/4], Step [627/3844], Loss: 0.1733\n",
      "Epoch [3/4], Step [628/3844], Loss: 0.0701\n",
      "Epoch [3/4], Step [629/3844], Loss: 0.0872\n",
      "Epoch [3/4], Step [630/3844], Loss: 0.1471\n",
      "Epoch [3/4], Step [631/3844], Loss: 0.1447\n",
      "Epoch [3/4], Step [632/3844], Loss: 0.0915\n",
      "Epoch [3/4], Step [633/3844], Loss: 0.1245\n",
      "Epoch [3/4], Step [634/3844], Loss: 0.1002\n",
      "Epoch [3/4], Step [635/3844], Loss: 0.1278\n",
      "Epoch [3/4], Step [636/3844], Loss: 0.1513\n",
      "Epoch [3/4], Step [637/3844], Loss: 0.1649\n",
      "Epoch [3/4], Step [638/3844], Loss: 0.1247\n",
      "Epoch [3/4], Step [639/3844], Loss: 0.0947\n",
      "Epoch [3/4], Step [640/3844], Loss: 0.0784\n",
      "Epoch [3/4], Step [641/3844], Loss: 0.1562\n",
      "Epoch [3/4], Step [642/3844], Loss: 0.1755\n",
      "Epoch [3/4], Step [643/3844], Loss: 0.1479\n",
      "Epoch [3/4], Step [644/3844], Loss: 0.1342\n",
      "Epoch [3/4], Step [645/3844], Loss: 0.0869\n",
      "Epoch [3/4], Step [646/3844], Loss: 0.0751\n",
      "Epoch [3/4], Step [647/3844], Loss: 0.0694\n",
      "Epoch [3/4], Step [648/3844], Loss: 0.0932\n",
      "Epoch [3/4], Step [649/3844], Loss: 0.0964\n",
      "Epoch [3/4], Step [650/3844], Loss: 0.0696\n",
      "Epoch [3/4], Step [651/3844], Loss: 0.0712\n",
      "Epoch [3/4], Step [652/3844], Loss: 0.0930\n",
      "Epoch [3/4], Step [653/3844], Loss: 0.0742\n",
      "Epoch [3/4], Step [654/3844], Loss: 0.0840\n",
      "Epoch [3/4], Step [655/3844], Loss: 0.0960\n",
      "Epoch [3/4], Step [656/3844], Loss: 0.1008\n",
      "Epoch [3/4], Step [657/3844], Loss: 0.0902\n",
      "Epoch [3/4], Step [658/3844], Loss: 0.0785\n",
      "Epoch [3/4], Step [659/3844], Loss: 0.1590\n",
      "Epoch [3/4], Step [660/3844], Loss: 0.1011\n",
      "Epoch [3/4], Step [661/3844], Loss: 0.0894\n",
      "Epoch [3/4], Step [662/3844], Loss: 0.1159\n",
      "Epoch [3/4], Step [663/3844], Loss: 0.0805\n",
      "Epoch [3/4], Step [664/3844], Loss: 0.1548\n",
      "Epoch [3/4], Step [665/3844], Loss: 0.0753\n",
      "Epoch [3/4], Step [666/3844], Loss: 0.1446\n",
      "Epoch [3/4], Step [667/3844], Loss: 0.0825\n",
      "Epoch [3/4], Step [668/3844], Loss: 0.0573\n",
      "Epoch [3/4], Step [669/3844], Loss: 0.0920\n",
      "Epoch [3/4], Step [670/3844], Loss: 0.1362\n",
      "Epoch [3/4], Step [671/3844], Loss: 0.1528\n",
      "Epoch [3/4], Step [672/3844], Loss: 0.1614\n",
      "Epoch [3/4], Step [673/3844], Loss: 0.1161\n",
      "Epoch [3/4], Step [674/3844], Loss: 0.0878\n",
      "Epoch [3/4], Step [675/3844], Loss: 0.1506\n",
      "Epoch [3/4], Step [676/3844], Loss: 0.1741\n",
      "Epoch [3/4], Step [677/3844], Loss: 0.1242\n",
      "Epoch [3/4], Step [678/3844], Loss: 0.1585\n",
      "Epoch [3/4], Step [679/3844], Loss: 0.1388\n",
      "Epoch [3/4], Step [680/3844], Loss: 0.0942\n",
      "Epoch [3/4], Step [681/3844], Loss: 0.1288\n",
      "Epoch [3/4], Step [682/3844], Loss: 0.1430\n",
      "Epoch [3/4], Step [683/3844], Loss: 0.1664\n",
      "Epoch [3/4], Step [684/3844], Loss: 0.1460\n",
      "Epoch [3/4], Step [685/3844], Loss: 0.1762\n",
      "Epoch [3/4], Step [686/3844], Loss: 0.0704\n",
      "Epoch [3/4], Step [687/3844], Loss: 0.1338\n",
      "Epoch [3/4], Step [688/3844], Loss: 0.1216\n",
      "Epoch [3/4], Step [689/3844], Loss: 0.0673\n",
      "Epoch [3/4], Step [690/3844], Loss: 0.0636\n",
      "Epoch [3/4], Step [691/3844], Loss: 0.0976\n",
      "Epoch [3/4], Step [692/3844], Loss: 0.0519\n",
      "Epoch [3/4], Step [693/3844], Loss: 0.0964\n",
      "Epoch [3/4], Step [694/3844], Loss: 0.0835\n",
      "Epoch [3/4], Step [695/3844], Loss: 0.1453\n",
      "Epoch [3/4], Step [696/3844], Loss: 0.1051\n",
      "Epoch [3/4], Step [697/3844], Loss: 0.1659\n",
      "Epoch [3/4], Step [698/3844], Loss: 0.0807\n",
      "Epoch [3/4], Step [699/3844], Loss: 0.1577\n",
      "Epoch [3/4], Step [700/3844], Loss: 0.1049\n",
      "Epoch [3/4], Step [701/3844], Loss: 0.0765\n",
      "Epoch [3/4], Step [702/3844], Loss: 0.0854\n",
      "Epoch [3/4], Step [703/3844], Loss: 0.0695\n",
      "Epoch [3/4], Step [704/3844], Loss: 0.0893\n",
      "Epoch [3/4], Step [705/3844], Loss: 0.1561\n",
      "Epoch [3/4], Step [706/3844], Loss: 0.1021\n",
      "Epoch [3/4], Step [707/3844], Loss: 0.1578\n",
      "Epoch [3/4], Step [708/3844], Loss: 0.0852\n",
      "Epoch [3/4], Step [709/3844], Loss: 0.1421\n",
      "Epoch [3/4], Step [710/3844], Loss: 0.1027\n",
      "Epoch [3/4], Step [711/3844], Loss: 0.0907\n",
      "Epoch [3/4], Step [712/3844], Loss: 0.1412\n",
      "Epoch [3/4], Step [713/3844], Loss: 0.0720\n",
      "Epoch [3/4], Step [714/3844], Loss: 0.1196\n",
      "Epoch [3/4], Step [715/3844], Loss: 0.1521\n",
      "Epoch [3/4], Step [716/3844], Loss: 0.0995\n",
      "Epoch [3/4], Step [717/3844], Loss: 0.0936\n",
      "Epoch [3/4], Step [718/3844], Loss: 0.0765\n",
      "Epoch [3/4], Step [719/3844], Loss: 0.1102\n",
      "Epoch [3/4], Step [720/3844], Loss: 0.1559\n",
      "Epoch [3/4], Step [721/3844], Loss: 0.0828\n",
      "Epoch [3/4], Step [722/3844], Loss: 0.1478\n",
      "Epoch [3/4], Step [723/3844], Loss: 0.1352\n",
      "Epoch [3/4], Step [724/3844], Loss: 0.0698\n",
      "Epoch [3/4], Step [725/3844], Loss: 0.1121\n",
      "Epoch [3/4], Step [726/3844], Loss: 0.1194\n",
      "Epoch [3/4], Step [727/3844], Loss: 0.1097\n",
      "Epoch [3/4], Step [728/3844], Loss: 0.0784\n",
      "Epoch [3/4], Step [729/3844], Loss: 0.0922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/4], Step [730/3844], Loss: 0.0931\n",
      "Epoch [3/4], Step [731/3844], Loss: 0.1575\n",
      "Epoch [3/4], Step [732/3844], Loss: 0.1659\n",
      "Epoch [3/4], Step [733/3844], Loss: 0.0816\n",
      "Epoch [3/4], Step [734/3844], Loss: 0.1205\n",
      "Epoch [3/4], Step [735/3844], Loss: 0.1451\n",
      "Epoch [3/4], Step [736/3844], Loss: 0.1732\n",
      "Epoch [3/4], Step [737/3844], Loss: 0.1083\n",
      "Epoch [3/4], Step [738/3844], Loss: 0.0806\n",
      "Epoch [3/4], Step [739/3844], Loss: 0.1725\n",
      "Epoch [3/4], Step [740/3844], Loss: 0.0749\n",
      "Epoch [3/4], Step [741/3844], Loss: 0.1535\n",
      "Epoch [3/4], Step [742/3844], Loss: 0.0907\n",
      "Epoch [3/4], Step [743/3844], Loss: 0.0769\n",
      "Epoch [3/4], Step [744/3844], Loss: 0.1009\n",
      "Epoch [3/4], Step [745/3844], Loss: 0.1434\n",
      "Epoch [3/4], Step [746/3844], Loss: 0.0943\n",
      "Epoch [3/4], Step [747/3844], Loss: 0.0973\n",
      "Epoch [3/4], Step [748/3844], Loss: 0.1229\n",
      "Epoch [3/4], Step [749/3844], Loss: 0.0913\n",
      "Epoch [3/4], Step [750/3844], Loss: 0.0564\n",
      "Epoch [3/4], Step [751/3844], Loss: 0.1618\n",
      "Epoch [3/4], Step [752/3844], Loss: 0.1001\n",
      "Epoch [3/4], Step [753/3844], Loss: 0.1577\n",
      "Epoch [3/4], Step [754/3844], Loss: 0.0737\n",
      "Epoch [3/4], Step [755/3844], Loss: 0.0947\n",
      "Epoch [3/4], Step [756/3844], Loss: 0.1572\n",
      "Epoch [3/4], Step [757/3844], Loss: 0.1515\n",
      "Epoch [3/4], Step [758/3844], Loss: 0.1079\n",
      "Epoch [3/4], Step [759/3844], Loss: 0.0896\n",
      "Epoch [3/4], Step [760/3844], Loss: 0.1387\n",
      "Epoch [3/4], Step [761/3844], Loss: 0.0931\n",
      "Epoch [3/4], Step [762/3844], Loss: 0.1595\n",
      "Epoch [3/4], Step [763/3844], Loss: 0.0889\n",
      "Epoch [3/4], Step [764/3844], Loss: 0.1664\n",
      "Epoch [3/4], Step [765/3844], Loss: 0.1347\n",
      "Epoch [3/4], Step [766/3844], Loss: 0.0757\n",
      "Epoch [3/4], Step [767/3844], Loss: 0.1394\n",
      "Epoch [3/4], Step [768/3844], Loss: 0.1261\n",
      "Epoch [3/4], Step [769/3844], Loss: 0.0950\n",
      "Epoch [3/4], Step [770/3844], Loss: 0.0713\n",
      "Epoch [3/4], Step [771/3844], Loss: 0.0911\n",
      "Epoch [3/4], Step [772/3844], Loss: 0.1473\n",
      "Epoch [3/4], Step [773/3844], Loss: 0.0745\n",
      "Epoch [3/4], Step [774/3844], Loss: 0.1719\n",
      "Epoch [3/4], Step [775/3844], Loss: 0.0654\n",
      "Epoch [3/4], Step [776/3844], Loss: 0.0773\n",
      "Epoch [3/4], Step [777/3844], Loss: 0.1708\n",
      "Epoch [3/4], Step [778/3844], Loss: 0.0812\n",
      "Epoch [3/4], Step [779/3844], Loss: 0.0852\n",
      "Epoch [3/4], Step [780/3844], Loss: 0.0919\n",
      "Epoch [3/4], Step [781/3844], Loss: 0.1479\n",
      "Epoch [3/4], Step [782/3844], Loss: 0.1062\n",
      "Epoch [3/4], Step [783/3844], Loss: 0.1512\n",
      "Epoch [3/4], Step [784/3844], Loss: 0.0769\n",
      "Epoch [3/4], Step [785/3844], Loss: 0.1543\n",
      "Epoch [3/4], Step [786/3844], Loss: 0.0833\n",
      "Epoch [3/4], Step [787/3844], Loss: 0.1121\n",
      "Epoch [3/4], Step [788/3844], Loss: 0.0888\n",
      "Epoch [3/4], Step [789/3844], Loss: 0.0603\n",
      "Epoch [3/4], Step [790/3844], Loss: 0.0774\n",
      "Epoch [3/4], Step [791/3844], Loss: 0.1303\n",
      "Epoch [3/4], Step [792/3844], Loss: 0.1099\n",
      "Epoch [3/4], Step [793/3844], Loss: 0.0964\n",
      "Epoch [3/4], Step [794/3844], Loss: 0.0702\n",
      "Epoch [3/4], Step [795/3844], Loss: 0.1389\n",
      "Epoch [3/4], Step [796/3844], Loss: 0.1333\n",
      "Epoch [3/4], Step [797/3844], Loss: 0.1167\n",
      "Epoch [3/4], Step [798/3844], Loss: 0.0851\n",
      "Epoch [3/4], Step [799/3844], Loss: 0.0755\n",
      "Epoch [3/4], Step [800/3844], Loss: 0.0873\n",
      "Epoch [3/4], Step [801/3844], Loss: 0.0695\n",
      "Epoch [3/4], Step [802/3844], Loss: 0.0921\n",
      "Epoch [3/4], Step [803/3844], Loss: 0.1025\n",
      "Epoch [3/4], Step [804/3844], Loss: 0.0985\n",
      "Epoch [3/4], Step [805/3844], Loss: 0.1241\n",
      "Epoch [3/4], Step [806/3844], Loss: 0.1269\n",
      "Epoch [3/4], Step [807/3844], Loss: 0.0702\n",
      "Epoch [3/4], Step [808/3844], Loss: 0.1458\n",
      "Epoch [3/4], Step [809/3844], Loss: 0.0878\n",
      "Epoch [3/4], Step [810/3844], Loss: 0.1589\n",
      "Epoch [3/4], Step [811/3844], Loss: 0.1462\n",
      "Epoch [3/4], Step [812/3844], Loss: 0.1937\n",
      "Epoch [3/4], Step [813/3844], Loss: 0.1523\n",
      "Epoch [3/4], Step [814/3844], Loss: 0.0679\n",
      "Epoch [3/4], Step [815/3844], Loss: 0.1530\n",
      "Epoch [3/4], Step [816/3844], Loss: 0.0932\n",
      "Epoch [3/4], Step [817/3844], Loss: 0.1483\n",
      "Epoch [3/4], Step [818/3844], Loss: 0.0941\n",
      "Epoch [3/4], Step [819/3844], Loss: 0.1650\n",
      "Epoch [3/4], Step [820/3844], Loss: 0.1510\n",
      "Epoch [3/4], Step [821/3844], Loss: 0.1033\n",
      "Epoch [3/4], Step [822/3844], Loss: 0.1088\n",
      "Epoch [3/4], Step [823/3844], Loss: 0.0883\n",
      "Epoch [3/4], Step [824/3844], Loss: 0.0814\n",
      "Epoch [3/4], Step [825/3844], Loss: 0.0965\n",
      "Epoch [3/4], Step [826/3844], Loss: 0.1480\n",
      "Epoch [3/4], Step [827/3844], Loss: 0.1544\n",
      "Epoch [3/4], Step [828/3844], Loss: 0.1838\n",
      "Epoch [3/4], Step [829/3844], Loss: 0.1212\n",
      "Epoch [3/4], Step [830/3844], Loss: 0.1499\n",
      "Epoch [3/4], Step [831/3844], Loss: 0.0695\n",
      "Epoch [3/4], Step [832/3844], Loss: 0.0934\n",
      "Epoch [3/4], Step [833/3844], Loss: 0.0799\n",
      "Epoch [3/4], Step [834/3844], Loss: 0.0665\n",
      "Epoch [3/4], Step [835/3844], Loss: 0.1303\n",
      "Epoch [3/4], Step [836/3844], Loss: 0.0881\n",
      "Epoch [3/4], Step [837/3844], Loss: 0.0613\n",
      "Epoch [3/4], Step [838/3844], Loss: 0.0705\n",
      "Epoch [3/4], Step [839/3844], Loss: 0.0878\n",
      "Epoch [3/4], Step [840/3844], Loss: 0.0707\n",
      "Epoch [3/4], Step [841/3844], Loss: 0.0614\n",
      "Epoch [3/4], Step [842/3844], Loss: 0.1746\n",
      "Epoch [3/4], Step [843/3844], Loss: 0.0928\n",
      "Epoch [3/4], Step [844/3844], Loss: 0.1480\n",
      "Epoch [3/4], Step [845/3844], Loss: 0.1230\n",
      "Epoch [3/4], Step [846/3844], Loss: 0.1514\n",
      "Epoch [3/4], Step [847/3844], Loss: 0.1572\n",
      "Epoch [3/4], Step [848/3844], Loss: 0.0736\n",
      "Epoch [3/4], Step [849/3844], Loss: 0.0889\n",
      "Epoch [3/4], Step [850/3844], Loss: 0.0793\n",
      "Epoch [3/4], Step [851/3844], Loss: 0.1227\n",
      "Epoch [3/4], Step [852/3844], Loss: 0.1743\n",
      "Epoch [3/4], Step [853/3844], Loss: 0.1007\n",
      "Epoch [3/4], Step [854/3844], Loss: 0.0936\n",
      "Epoch [3/4], Step [855/3844], Loss: 0.1345\n",
      "Epoch [3/4], Step [856/3844], Loss: 0.1456\n",
      "Epoch [3/4], Step [857/3844], Loss: 0.0909\n",
      "Epoch [3/4], Step [858/3844], Loss: 0.0760\n",
      "Epoch [3/4], Step [859/3844], Loss: 0.1361\n",
      "Epoch [3/4], Step [860/3844], Loss: 0.0964\n",
      "Epoch [3/4], Step [861/3844], Loss: 0.1230\n",
      "Epoch [3/4], Step [862/3844], Loss: 0.0879\n",
      "Epoch [3/4], Step [863/3844], Loss: 0.0880\n",
      "Epoch [3/4], Step [864/3844], Loss: 0.1706\n",
      "Epoch [3/4], Step [865/3844], Loss: 0.0808\n",
      "Epoch [3/4], Step [866/3844], Loss: 0.1281\n",
      "Epoch [3/4], Step [867/3844], Loss: 0.1695\n",
      "Epoch [3/4], Step [868/3844], Loss: 0.0772\n",
      "Epoch [3/4], Step [869/3844], Loss: 0.1387\n",
      "Epoch [3/4], Step [870/3844], Loss: 0.1050\n",
      "Epoch [3/4], Step [871/3844], Loss: 0.0879\n",
      "Epoch [3/4], Step [872/3844], Loss: 0.1196\n",
      "Epoch [3/4], Step [873/3844], Loss: 0.1243\n",
      "Epoch [3/4], Step [874/3844], Loss: 0.1001\n",
      "Epoch [3/4], Step [875/3844], Loss: 0.1171\n",
      "Epoch [3/4], Step [876/3844], Loss: 0.0703\n",
      "Epoch [3/4], Step [877/3844], Loss: 0.0952\n",
      "Epoch [3/4], Step [878/3844], Loss: 0.0879\n",
      "Epoch [3/4], Step [879/3844], Loss: 0.0954\n",
      "Epoch [3/4], Step [880/3844], Loss: 0.0940\n",
      "Epoch [3/4], Step [881/3844], Loss: 0.0871\n",
      "Epoch [3/4], Step [882/3844], Loss: 0.1348\n",
      "Epoch [3/4], Step [883/3844], Loss: 0.0928\n",
      "Epoch [3/4], Step [884/3844], Loss: 0.1088\n",
      "Epoch [3/4], Step [885/3844], Loss: 0.1005\n",
      "Epoch [3/4], Step [886/3844], Loss: 0.1594\n",
      "Epoch [3/4], Step [887/3844], Loss: 0.0600\n",
      "Epoch [3/4], Step [888/3844], Loss: 0.0859\n",
      "Epoch [3/4], Step [889/3844], Loss: 0.0790\n",
      "Epoch [3/4], Step [890/3844], Loss: 0.1251\n",
      "Epoch [3/4], Step [891/3844], Loss: 0.0788\n",
      "Epoch [3/4], Step [892/3844], Loss: 0.0858\n",
      "Epoch [3/4], Step [893/3844], Loss: 0.1224\n",
      "Epoch [3/4], Step [894/3844], Loss: 0.1626\n",
      "Epoch [3/4], Step [895/3844], Loss: 0.1183\n",
      "Epoch [3/4], Step [896/3844], Loss: 0.1331\n",
      "Epoch [3/4], Step [897/3844], Loss: 0.0836\n",
      "Epoch [3/4], Step [898/3844], Loss: 0.0988\n",
      "Epoch [3/4], Step [899/3844], Loss: 0.1464\n",
      "Epoch [3/4], Step [900/3844], Loss: 0.1082\n",
      "Epoch [3/4], Step [901/3844], Loss: 0.0892\n",
      "Epoch [3/4], Step [902/3844], Loss: 0.0957\n",
      "Epoch [3/4], Step [903/3844], Loss: 0.0795\n",
      "Epoch [3/4], Step [904/3844], Loss: 0.1157\n",
      "Epoch [3/4], Step [905/3844], Loss: 0.1042\n",
      "Epoch [3/4], Step [906/3844], Loss: 0.1545\n",
      "Epoch [3/4], Step [907/3844], Loss: 0.0777\n",
      "Epoch [3/4], Step [908/3844], Loss: 0.0948\n",
      "Epoch [3/4], Step [909/3844], Loss: 0.0616\n",
      "Epoch [3/4], Step [910/3844], Loss: 0.0905\n",
      "Epoch [3/4], Step [911/3844], Loss: 0.0883\n",
      "Epoch [3/4], Step [912/3844], Loss: 0.1559\n",
      "Epoch [3/4], Step [913/3844], Loss: 0.0510\n",
      "Epoch [3/4], Step [914/3844], Loss: 0.0601\n",
      "Epoch [3/4], Step [915/3844], Loss: 0.1563\n",
      "Epoch [3/4], Step [916/3844], Loss: 0.1126\n",
      "Epoch [3/4], Step [917/3844], Loss: 0.0801\n",
      "Epoch [3/4], Step [918/3844], Loss: 0.0445\n",
      "Epoch [3/4], Step [919/3844], Loss: 0.0902\n",
      "Epoch [3/4], Step [920/3844], Loss: 0.1062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/4], Step [921/3844], Loss: 0.1070\n",
      "Epoch [3/4], Step [922/3844], Loss: 0.0740\n",
      "Epoch [3/4], Step [923/3844], Loss: 0.0917\n",
      "Epoch [3/4], Step [924/3844], Loss: 0.0529\n",
      "Epoch [3/4], Step [925/3844], Loss: 0.0952\n",
      "Epoch [3/4], Step [926/3844], Loss: 0.1387\n",
      "Epoch [3/4], Step [927/3844], Loss: 0.1000\n",
      "Epoch [3/4], Step [928/3844], Loss: 0.1222\n",
      "Epoch [3/4], Step [929/3844], Loss: 0.0924\n",
      "Epoch [3/4], Step [930/3844], Loss: 0.0902\n",
      "Epoch [3/4], Step [931/3844], Loss: 0.1343\n",
      "Epoch [3/4], Step [932/3844], Loss: 0.1439\n",
      "Epoch [3/4], Step [933/3844], Loss: 0.1539\n",
      "Epoch [3/4], Step [934/3844], Loss: 0.1093\n",
      "Epoch [3/4], Step [935/3844], Loss: 0.0947\n",
      "Epoch [3/4], Step [936/3844], Loss: 0.1600\n",
      "Epoch [3/4], Step [937/3844], Loss: 0.0783\n",
      "Epoch [3/4], Step [938/3844], Loss: 0.0902\n",
      "Epoch [3/4], Step [939/3844], Loss: 0.0940\n",
      "Epoch [3/4], Step [940/3844], Loss: 0.0883\n",
      "Epoch [3/4], Step [941/3844], Loss: 0.0591\n",
      "Epoch [3/4], Step [942/3844], Loss: 0.1256\n",
      "Epoch [3/4], Step [943/3844], Loss: 0.1289\n",
      "Epoch [3/4], Step [944/3844], Loss: 0.0880\n",
      "Epoch [3/4], Step [945/3844], Loss: 0.1136\n",
      "Epoch [3/4], Step [946/3844], Loss: 0.1034\n",
      "Epoch [3/4], Step [947/3844], Loss: 0.0794\n",
      "Epoch [3/4], Step [948/3844], Loss: 0.1286\n",
      "Epoch [3/4], Step [949/3844], Loss: 0.0979\n",
      "Epoch [3/4], Step [950/3844], Loss: 0.1298\n",
      "Epoch [3/4], Step [951/3844], Loss: 0.0920\n",
      "Epoch [3/4], Step [952/3844], Loss: 0.1256\n",
      "Epoch [3/4], Step [953/3844], Loss: 0.1203\n",
      "Epoch [3/4], Step [954/3844], Loss: 0.0866\n",
      "Epoch [3/4], Step [955/3844], Loss: 0.0949\n",
      "Epoch [3/4], Step [956/3844], Loss: 0.0808\n",
      "Epoch [3/4], Step [957/3844], Loss: 0.0637\n",
      "Epoch [3/4], Step [958/3844], Loss: 0.0657\n",
      "Epoch [3/4], Step [959/3844], Loss: 0.1826\n",
      "Epoch [3/4], Step [960/3844], Loss: 0.0801\n",
      "Epoch [3/4], Step [961/3844], Loss: 0.1061\n",
      "Epoch [3/4], Step [962/3844], Loss: 0.1554\n",
      "Epoch [3/4], Step [963/3844], Loss: 0.1354\n",
      "Epoch [3/4], Step [964/3844], Loss: 0.1535\n",
      "Epoch [3/4], Step [965/3844], Loss: 0.1479\n",
      "Epoch [3/4], Step [966/3844], Loss: 0.0884\n",
      "Epoch [3/4], Step [967/3844], Loss: 0.0921\n",
      "Epoch [3/4], Step [968/3844], Loss: 0.0986\n",
      "Epoch [3/4], Step [969/3844], Loss: 0.0687\n",
      "Epoch [3/4], Step [970/3844], Loss: 0.1633\n",
      "Epoch [3/4], Step [971/3844], Loss: 0.0926\n",
      "Epoch [3/4], Step [972/3844], Loss: 0.1186\n",
      "Epoch [3/4], Step [973/3844], Loss: 0.1524\n",
      "Epoch [3/4], Step [974/3844], Loss: 0.0788\n",
      "Epoch [3/4], Step [975/3844], Loss: 0.1067\n",
      "Epoch [3/4], Step [976/3844], Loss: 0.1393\n",
      "Epoch [3/4], Step [977/3844], Loss: 0.0898\n",
      "Epoch [3/4], Step [978/3844], Loss: 0.1631\n",
      "Epoch [3/4], Step [979/3844], Loss: 0.0880\n",
      "Epoch [3/4], Step [980/3844], Loss: 0.0784\n",
      "Epoch [3/4], Step [981/3844], Loss: 0.0752\n",
      "Epoch [3/4], Step [982/3844], Loss: 0.1703\n",
      "Epoch [3/4], Step [983/3844], Loss: 0.0541\n",
      "Epoch [3/4], Step [984/3844], Loss: 0.1581\n",
      "Epoch [3/4], Step [985/3844], Loss: 0.1506\n",
      "Epoch [3/4], Step [986/3844], Loss: 0.1136\n",
      "Epoch [3/4], Step [987/3844], Loss: 0.1421\n",
      "Epoch [3/4], Step [988/3844], Loss: 0.1592\n",
      "Epoch [3/4], Step [989/3844], Loss: 0.0801\n",
      "Epoch [3/4], Step [990/3844], Loss: 0.1211\n",
      "Epoch [3/4], Step [991/3844], Loss: 0.0788\n",
      "Epoch [3/4], Step [992/3844], Loss: 0.1204\n",
      "Epoch [3/4], Step [993/3844], Loss: 0.1223\n",
      "Epoch [3/4], Step [994/3844], Loss: 0.0964\n",
      "Epoch [3/4], Step [995/3844], Loss: 0.1291\n",
      "Epoch [3/4], Step [996/3844], Loss: 0.0916\n",
      "Epoch [3/4], Step [997/3844], Loss: 0.0840\n",
      "Epoch [3/4], Step [998/3844], Loss: 0.0762\n",
      "Epoch [3/4], Step [999/3844], Loss: 0.0589\n",
      "Epoch [3/4], Step [1000/3844], Loss: 0.0729\n",
      "Epoch [3/4], Step [1001/3844], Loss: 0.1066\n",
      "Epoch [3/4], Step [1002/3844], Loss: 0.0544\n",
      "Epoch [3/4], Step [1003/3844], Loss: 0.0965\n",
      "Epoch [3/4], Step [1004/3844], Loss: 0.0462\n",
      "Epoch [3/4], Step [1005/3844], Loss: 0.0903\n",
      "Epoch [3/4], Step [1006/3844], Loss: 0.1749\n",
      "Epoch [3/4], Step [1007/3844], Loss: 0.1183\n",
      "Epoch [3/4], Step [1008/3844], Loss: 0.1103\n",
      "Epoch [3/4], Step [1009/3844], Loss: 0.0999\n",
      "Epoch [3/4], Step [1010/3844], Loss: 0.1583\n",
      "Epoch [3/4], Step [1011/3844], Loss: 0.1806\n",
      "Epoch [3/4], Step [1012/3844], Loss: 0.1929\n",
      "Epoch [3/4], Step [1013/3844], Loss: 0.0604\n",
      "Epoch [3/4], Step [1014/3844], Loss: 0.1554\n",
      "Epoch [3/4], Step [1015/3844], Loss: 0.0984\n",
      "Epoch [3/4], Step [1016/3844], Loss: 0.0893\n",
      "Epoch [3/4], Step [1017/3844], Loss: 0.0895\n",
      "Epoch [3/4], Step [1018/3844], Loss: 0.1493\n",
      "Epoch [3/4], Step [1019/3844], Loss: 0.1431\n",
      "Epoch [3/4], Step [1020/3844], Loss: 0.0964\n",
      "Epoch [3/4], Step [1021/3844], Loss: 0.1665\n",
      "Epoch [3/4], Step [1022/3844], Loss: 0.1611\n",
      "Epoch [3/4], Step [1023/3844], Loss: 0.1478\n",
      "Epoch [3/4], Step [1024/3844], Loss: 0.1071\n",
      "Epoch [3/4], Step [1025/3844], Loss: 0.1383\n",
      "Epoch [3/4], Step [1026/3844], Loss: 0.0635\n",
      "Epoch [3/4], Step [1027/3844], Loss: 0.1123\n",
      "Epoch [3/4], Step [1028/3844], Loss: 0.1423\n",
      "Epoch [3/4], Step [1029/3844], Loss: 0.0997\n",
      "Epoch [3/4], Step [1030/3844], Loss: 0.1169\n",
      "Epoch [3/4], Step [1031/3844], Loss: 0.1519\n",
      "Epoch [3/4], Step [1032/3844], Loss: 0.1618\n",
      "Epoch [3/4], Step [1033/3844], Loss: 0.1398\n",
      "Epoch [3/4], Step [1034/3844], Loss: 0.0910\n",
      "Epoch [3/4], Step [1035/3844], Loss: 0.1077\n",
      "Epoch [3/4], Step [1036/3844], Loss: 0.1350\n",
      "Epoch [3/4], Step [1037/3844], Loss: 0.1241\n",
      "Epoch [3/4], Step [1038/3844], Loss: 0.1027\n",
      "Epoch [3/4], Step [1039/3844], Loss: 0.1187\n",
      "Epoch [3/4], Step [1040/3844], Loss: 0.1476\n",
      "Epoch [3/4], Step [1041/3844], Loss: 0.0999\n",
      "Epoch [3/4], Step [1042/3844], Loss: 0.0919\n",
      "Epoch [3/4], Step [1043/3844], Loss: 0.1225\n",
      "Epoch [3/4], Step [1044/3844], Loss: 0.1135\n",
      "Epoch [3/4], Step [1045/3844], Loss: 0.0761\n",
      "Epoch [3/4], Step [1046/3844], Loss: 0.1224\n",
      "Epoch [3/4], Step [1047/3844], Loss: 0.1496\n",
      "Epoch [3/4], Step [1048/3844], Loss: 0.0948\n",
      "Epoch [3/4], Step [1049/3844], Loss: 0.1429\n",
      "Epoch [3/4], Step [1050/3844], Loss: 0.0838\n",
      "Epoch [3/4], Step [1051/3844], Loss: 0.1016\n",
      "Epoch [3/4], Step [1052/3844], Loss: 0.0833\n",
      "Epoch [3/4], Step [1053/3844], Loss: 0.0850\n",
      "Epoch [3/4], Step [1054/3844], Loss: 0.1271\n",
      "Epoch [3/4], Step [1055/3844], Loss: 0.1347\n",
      "Epoch [3/4], Step [1056/3844], Loss: 0.1672\n",
      "Epoch [3/4], Step [1057/3844], Loss: 0.0637\n",
      "Epoch [3/4], Step [1058/3844], Loss: 0.1518\n",
      "Epoch [3/4], Step [1059/3844], Loss: 0.1047\n",
      "Epoch [3/4], Step [1060/3844], Loss: 0.1017\n",
      "Epoch [3/4], Step [1061/3844], Loss: 0.1293\n",
      "Epoch [3/4], Step [1062/3844], Loss: 0.1488\n",
      "Epoch [3/4], Step [1063/3844], Loss: 0.1306\n",
      "Epoch [3/4], Step [1064/3844], Loss: 0.1361\n",
      "Epoch [3/4], Step [1065/3844], Loss: 0.0780\n",
      "Epoch [3/4], Step [1066/3844], Loss: 0.0932\n",
      "Epoch [3/4], Step [1067/3844], Loss: 0.0951\n",
      "Epoch [3/4], Step [1068/3844], Loss: 0.0900\n",
      "Epoch [3/4], Step [1069/3844], Loss: 0.1029\n",
      "Epoch [3/4], Step [1070/3844], Loss: 0.0637\n",
      "Epoch [3/4], Step [1071/3844], Loss: 0.1630\n",
      "Epoch [3/4], Step [1072/3844], Loss: 0.0980\n",
      "Epoch [3/4], Step [1073/3844], Loss: 0.1316\n",
      "Epoch [3/4], Step [1074/3844], Loss: 0.1404\n",
      "Epoch [3/4], Step [1075/3844], Loss: 0.0803\n",
      "Epoch [3/4], Step [1076/3844], Loss: 0.0867\n",
      "Epoch [3/4], Step [1077/3844], Loss: 0.0980\n",
      "Epoch [3/4], Step [1078/3844], Loss: 0.0683\n",
      "Epoch [3/4], Step [1079/3844], Loss: 0.0895\n",
      "Epoch [3/4], Step [1080/3844], Loss: 0.1722\n",
      "Epoch [3/4], Step [1081/3844], Loss: 0.0886\n",
      "Epoch [3/4], Step [1082/3844], Loss: 0.1261\n",
      "Epoch [3/4], Step [1083/3844], Loss: 0.1374\n",
      "Epoch [3/4], Step [1084/3844], Loss: 0.1039\n",
      "Epoch [3/4], Step [1085/3844], Loss: 0.0583\n",
      "Epoch [3/4], Step [1086/3844], Loss: 0.1232\n",
      "Epoch [3/4], Step [1087/3844], Loss: 0.0808\n",
      "Epoch [3/4], Step [1088/3844], Loss: 0.1231\n",
      "Epoch [3/4], Step [1089/3844], Loss: 0.1273\n",
      "Epoch [3/4], Step [1090/3844], Loss: 0.1340\n",
      "Epoch [3/4], Step [1091/3844], Loss: 0.1036\n",
      "Epoch [3/4], Step [1092/3844], Loss: 0.1236\n",
      "Epoch [3/4], Step [1093/3844], Loss: 0.1397\n",
      "Epoch [3/4], Step [1094/3844], Loss: 0.0991\n",
      "Epoch [3/4], Step [1095/3844], Loss: 0.0831\n",
      "Epoch [3/4], Step [1096/3844], Loss: 0.1273\n",
      "Epoch [3/4], Step [1097/3844], Loss: 0.0918\n",
      "Epoch [3/4], Step [1098/3844], Loss: 0.1294\n",
      "Epoch [3/4], Step [1099/3844], Loss: 0.1011\n",
      "Epoch [3/4], Step [1100/3844], Loss: 0.1600\n",
      "Epoch [3/4], Step [1101/3844], Loss: 0.0959\n",
      "Epoch [3/4], Step [1102/3844], Loss: 0.0791\n",
      "Epoch [3/4], Step [1103/3844], Loss: 0.0617\n",
      "Epoch [3/4], Step [1104/3844], Loss: 0.1571\n",
      "Epoch [3/4], Step [1105/3844], Loss: 0.0762\n",
      "Epoch [3/4], Step [1106/3844], Loss: 0.1202\n",
      "Epoch [3/4], Step [1107/3844], Loss: 0.0939\n",
      "Epoch [3/4], Step [1108/3844], Loss: 0.0648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/4], Step [1109/3844], Loss: 0.1765\n",
      "Epoch [3/4], Step [1110/3844], Loss: 0.0699\n",
      "Epoch [3/4], Step [1111/3844], Loss: 0.0665\n",
      "Epoch [3/4], Step [1112/3844], Loss: 0.0923\n",
      "Epoch [3/4], Step [1113/3844], Loss: 0.1294\n",
      "Epoch [3/4], Step [1114/3844], Loss: 0.0510\n",
      "Epoch [3/4], Step [1115/3844], Loss: 0.1147\n",
      "Epoch [3/4], Step [1116/3844], Loss: 0.0826\n",
      "Epoch [3/4], Step [1117/3844], Loss: 0.0666\n",
      "Epoch [3/4], Step [1118/3844], Loss: 0.0920\n",
      "Epoch [3/4], Step [1119/3844], Loss: 0.0686\n",
      "Epoch [3/4], Step [1120/3844], Loss: 0.1484\n",
      "Epoch [3/4], Step [1121/3844], Loss: 0.0661\n",
      "Epoch [3/4], Step [1122/3844], Loss: 0.1493\n",
      "Epoch [3/4], Step [1123/3844], Loss: 0.1576\n",
      "Epoch [3/4], Step [1124/3844], Loss: 0.0771\n",
      "Epoch [3/4], Step [1125/3844], Loss: 0.0847\n",
      "Epoch [3/4], Step [1126/3844], Loss: 0.1387\n",
      "Epoch [3/4], Step [1127/3844], Loss: 0.0727\n",
      "Epoch [3/4], Step [1128/3844], Loss: 0.0883\n",
      "Epoch [3/4], Step [1129/3844], Loss: 0.1368\n",
      "Epoch [3/4], Step [1130/3844], Loss: 0.1496\n",
      "Epoch [3/4], Step [1131/3844], Loss: 0.1294\n",
      "Epoch [3/4], Step [1132/3844], Loss: 0.1410\n",
      "Epoch [3/4], Step [1133/3844], Loss: 0.1147\n",
      "Epoch [3/4], Step [1134/3844], Loss: 0.0795\n",
      "Epoch [3/4], Step [1135/3844], Loss: 0.0639\n",
      "Epoch [3/4], Step [1136/3844], Loss: 0.1498\n",
      "Epoch [3/4], Step [1137/3844], Loss: 0.1551\n",
      "Epoch [3/4], Step [1138/3844], Loss: 0.1546\n",
      "Epoch [3/4], Step [1139/3844], Loss: 0.0953\n",
      "Epoch [3/4], Step [1140/3844], Loss: 0.0872\n",
      "Epoch [3/4], Step [1141/3844], Loss: 0.1607\n",
      "Epoch [3/4], Step [1142/3844], Loss: 0.1249\n",
      "Epoch [3/4], Step [1143/3844], Loss: 0.1382\n",
      "Epoch [3/4], Step [1144/3844], Loss: 0.1217\n",
      "Epoch [3/4], Step [1145/3844], Loss: 0.0757\n",
      "Epoch [3/4], Step [1146/3844], Loss: 0.1337\n",
      "Epoch [3/4], Step [1147/3844], Loss: 0.1661\n",
      "Epoch [3/4], Step [1148/3844], Loss: 0.0730\n",
      "Epoch [3/4], Step [1149/3844], Loss: 0.0905\n",
      "Epoch [3/4], Step [1150/3844], Loss: 0.1618\n",
      "Epoch [3/4], Step [1151/3844], Loss: 0.0672\n",
      "Epoch [3/4], Step [1152/3844], Loss: 0.0547\n",
      "Epoch [3/4], Step [1153/3844], Loss: 0.1703\n",
      "Epoch [3/4], Step [1154/3844], Loss: 0.1656\n",
      "Epoch [3/4], Step [1155/3844], Loss: 0.1132\n",
      "Epoch [3/4], Step [1156/3844], Loss: 0.1108\n",
      "Epoch [3/4], Step [1157/3844], Loss: 0.1740\n",
      "Epoch [3/4], Step [1158/3844], Loss: 0.0778\n",
      "Epoch [3/4], Step [1159/3844], Loss: 0.0795\n",
      "Epoch [3/4], Step [1160/3844], Loss: 0.2005\n",
      "Epoch [3/4], Step [1161/3844], Loss: 0.1021\n",
      "Epoch [3/4], Step [1162/3844], Loss: 0.1540\n",
      "Epoch [3/4], Step [1163/3844], Loss: 0.0886\n",
      "Epoch [3/4], Step [1164/3844], Loss: 0.1306\n",
      "Epoch [3/4], Step [1165/3844], Loss: 0.1560\n",
      "Epoch [3/4], Step [1166/3844], Loss: 0.1574\n",
      "Epoch [3/4], Step [1167/3844], Loss: 0.1359\n",
      "Epoch [3/4], Step [1168/3844], Loss: 0.1161\n",
      "Epoch [3/4], Step [1169/3844], Loss: 0.1120\n",
      "Epoch [3/4], Step [1170/3844], Loss: 0.1426\n",
      "Epoch [3/4], Step [1171/3844], Loss: 0.1057\n",
      "Epoch [3/4], Step [1172/3844], Loss: 0.1085\n",
      "Epoch [3/4], Step [1173/3844], Loss: 0.1497\n",
      "Epoch [3/4], Step [1174/3844], Loss: 0.1129\n",
      "Epoch [3/4], Step [1175/3844], Loss: 0.1190\n",
      "Epoch [3/4], Step [1176/3844], Loss: 0.0881\n",
      "Epoch [3/4], Step [1177/3844], Loss: 0.0955\n",
      "Epoch [3/4], Step [1178/3844], Loss: 0.1122\n",
      "Epoch [3/4], Step [1179/3844], Loss: 0.1509\n",
      "Epoch [3/4], Step [1180/3844], Loss: 0.1011\n",
      "Epoch [3/4], Step [1181/3844], Loss: 0.0988\n",
      "Epoch [3/4], Step [1182/3844], Loss: 0.1392\n",
      "Epoch [3/4], Step [1183/3844], Loss: 0.1789\n",
      "Epoch [3/4], Step [1184/3844], Loss: 0.1448\n",
      "Epoch [3/4], Step [1185/3844], Loss: 0.0962\n",
      "Epoch [3/4], Step [1186/3844], Loss: 0.1275\n",
      "Epoch [3/4], Step [1187/3844], Loss: 0.1503\n",
      "Epoch [3/4], Step [1188/3844], Loss: 0.1099\n",
      "Epoch [3/4], Step [1189/3844], Loss: 0.0759\n",
      "Epoch [3/4], Step [1190/3844], Loss: 0.0802\n",
      "Epoch [3/4], Step [1191/3844], Loss: 0.0795\n",
      "Epoch [3/4], Step [1192/3844], Loss: 0.0988\n",
      "Epoch [3/4], Step [1193/3844], Loss: 0.1167\n",
      "Epoch [3/4], Step [1194/3844], Loss: 0.1418\n",
      "Epoch [3/4], Step [1195/3844], Loss: 0.1378\n",
      "Epoch [3/4], Step [1196/3844], Loss: 0.0987\n",
      "Epoch [3/4], Step [1197/3844], Loss: 0.0780\n",
      "Epoch [3/4], Step [1198/3844], Loss: 0.1622\n",
      "Epoch [3/4], Step [1199/3844], Loss: 0.1317\n",
      "Epoch [3/4], Step [1200/3844], Loss: 0.1093\n",
      "Epoch [3/4], Step [1201/3844], Loss: 0.0809\n",
      "Epoch [3/4], Step [1202/3844], Loss: 0.1262\n",
      "Epoch [3/4], Step [1203/3844], Loss: 0.0811\n",
      "Epoch [3/4], Step [1204/3844], Loss: 0.0900\n",
      "Epoch [3/4], Step [1205/3844], Loss: 0.0870\n",
      "Epoch [3/4], Step [1206/3844], Loss: 0.0770\n",
      "Epoch [3/4], Step [1207/3844], Loss: 0.1296\n",
      "Epoch [3/4], Step [1208/3844], Loss: 0.0947\n",
      "Epoch [3/4], Step [1209/3844], Loss: 0.0853\n",
      "Epoch [3/4], Step [1210/3844], Loss: 0.1172\n",
      "Epoch [3/4], Step [1211/3844], Loss: 0.0890\n",
      "Epoch [3/4], Step [1212/3844], Loss: 0.0868\n",
      "Epoch [3/4], Step [1213/3844], Loss: 0.0975\n",
      "Epoch [3/4], Step [1214/3844], Loss: 0.1271\n",
      "Epoch [3/4], Step [1215/3844], Loss: 0.1717\n",
      "Epoch [3/4], Step [1216/3844], Loss: 0.0908\n",
      "Epoch [3/4], Step [1217/3844], Loss: 0.1050\n",
      "Epoch [3/4], Step [1218/3844], Loss: 0.0822\n",
      "Epoch [3/4], Step [1219/3844], Loss: 0.0938\n",
      "Epoch [3/4], Step [1220/3844], Loss: 0.1376\n",
      "Epoch [3/4], Step [1221/3844], Loss: 0.0962\n",
      "Epoch [3/4], Step [1222/3844], Loss: 0.1518\n",
      "Epoch [3/4], Step [1223/3844], Loss: 0.1504\n",
      "Epoch [3/4], Step [1224/3844], Loss: 0.1587\n",
      "Epoch [3/4], Step [1225/3844], Loss: 0.1180\n",
      "Epoch [3/4], Step [1226/3844], Loss: 0.0671\n",
      "Epoch [3/4], Step [1227/3844], Loss: 0.1069\n",
      "Epoch [3/4], Step [1228/3844], Loss: 0.1177\n",
      "Epoch [3/4], Step [1229/3844], Loss: 0.0917\n",
      "Epoch [3/4], Step [1230/3844], Loss: 0.1069\n",
      "Epoch [3/4], Step [1231/3844], Loss: 0.0897\n",
      "Epoch [3/4], Step [1232/3844], Loss: 0.0911\n",
      "Epoch [3/4], Step [1233/3844], Loss: 0.1090\n",
      "Epoch [3/4], Step [1234/3844], Loss: 0.1575\n",
      "Epoch [3/4], Step [1235/3844], Loss: 0.0718\n",
      "Epoch [3/4], Step [1236/3844], Loss: 0.0799\n",
      "Epoch [3/4], Step [1237/3844], Loss: 0.1631\n",
      "Epoch [3/4], Step [1238/3844], Loss: 0.0927\n",
      "Epoch [3/4], Step [1239/3844], Loss: 0.1556\n",
      "Epoch [3/4], Step [1240/3844], Loss: 0.1226\n",
      "Epoch [3/4], Step [1241/3844], Loss: 0.1596\n",
      "Epoch [3/4], Step [1242/3844], Loss: 0.0835\n",
      "Epoch [3/4], Step [1243/3844], Loss: 0.0856\n",
      "Epoch [3/4], Step [1244/3844], Loss: 0.1209\n",
      "Epoch [3/4], Step [1245/3844], Loss: 0.0693\n",
      "Epoch [3/4], Step [1246/3844], Loss: 0.1047\n",
      "Epoch [3/4], Step [1247/3844], Loss: 0.1191\n",
      "Epoch [3/4], Step [1248/3844], Loss: 0.0548\n",
      "Epoch [3/4], Step [1249/3844], Loss: 0.0903\n",
      "Epoch [3/4], Step [1250/3844], Loss: 0.0758\n",
      "Epoch [3/4], Step [1251/3844], Loss: 0.1058\n",
      "Epoch [3/4], Step [1252/3844], Loss: 0.0676\n",
      "Epoch [3/4], Step [1253/3844], Loss: 0.1698\n",
      "Epoch [3/4], Step [1254/3844], Loss: 0.1023\n",
      "Epoch [3/4], Step [1255/3844], Loss: 0.1274\n",
      "Epoch [3/4], Step [1256/3844], Loss: 0.1408\n",
      "Epoch [3/4], Step [1257/3844], Loss: 0.0868\n",
      "Epoch [3/4], Step [1258/3844], Loss: 0.0776\n",
      "Epoch [3/4], Step [1259/3844], Loss: 0.1359\n",
      "Epoch [3/4], Step [1260/3844], Loss: 0.1171\n",
      "Epoch [3/4], Step [1261/3844], Loss: 0.0925\n",
      "Epoch [3/4], Step [1262/3844], Loss: 0.1028\n",
      "Epoch [3/4], Step [1263/3844], Loss: 0.1463\n",
      "Epoch [3/4], Step [1264/3844], Loss: 0.1314\n",
      "Epoch [3/4], Step [1265/3844], Loss: 0.0982\n",
      "Epoch [3/4], Step [1266/3844], Loss: 0.0984\n",
      "Epoch [3/4], Step [1267/3844], Loss: 0.1503\n",
      "Epoch [3/4], Step [1268/3844], Loss: 0.1174\n",
      "Epoch [3/4], Step [1269/3844], Loss: 0.0769\n",
      "Epoch [3/4], Step [1270/3844], Loss: 0.1224\n",
      "Epoch [3/4], Step [1271/3844], Loss: 0.1142\n",
      "Epoch [3/4], Step [1272/3844], Loss: 0.1595\n",
      "Epoch [3/4], Step [1273/3844], Loss: 0.1210\n",
      "Epoch [3/4], Step [1274/3844], Loss: 0.0761\n",
      "Epoch [3/4], Step [1275/3844], Loss: 0.0955\n",
      "Epoch [3/4], Step [1276/3844], Loss: 0.0979\n",
      "Epoch [3/4], Step [1277/3844], Loss: 0.1522\n",
      "Epoch [3/4], Step [1278/3844], Loss: 0.0881\n",
      "Epoch [3/4], Step [1279/3844], Loss: 0.0382\n",
      "Epoch [3/4], Step [1280/3844], Loss: 0.0851\n",
      "Epoch [3/4], Step [1281/3844], Loss: 0.0750\n",
      "Epoch [3/4], Step [1282/3844], Loss: 0.1396\n",
      "Epoch [3/4], Step [1283/3844], Loss: 0.0773\n",
      "Epoch [3/4], Step [1284/3844], Loss: 0.0910\n",
      "Epoch [3/4], Step [1285/3844], Loss: 0.1321\n",
      "Epoch [3/4], Step [1286/3844], Loss: 0.1218\n",
      "Epoch [3/4], Step [1287/3844], Loss: 0.1457\n",
      "Epoch [3/4], Step [1288/3844], Loss: 0.0841\n",
      "Epoch [3/4], Step [1289/3844], Loss: 0.1647\n",
      "Epoch [3/4], Step [1290/3844], Loss: 0.0649\n",
      "Epoch [3/4], Step [1291/3844], Loss: 0.1191\n",
      "Epoch [3/4], Step [1292/3844], Loss: 0.0859\n",
      "Epoch [3/4], Step [1293/3844], Loss: 0.0969\n",
      "Epoch [3/4], Step [1294/3844], Loss: 0.1037\n",
      "Epoch [3/4], Step [1295/3844], Loss: 0.1454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/4], Step [1296/3844], Loss: 0.0832\n",
      "Epoch [3/4], Step [1297/3844], Loss: 0.0599\n",
      "Epoch [3/4], Step [1298/3844], Loss: 0.0788\n",
      "Epoch [3/4], Step [1299/3844], Loss: 0.1384\n",
      "Epoch [3/4], Step [1300/3844], Loss: 0.0766\n",
      "Epoch [3/4], Step [1301/3844], Loss: 0.0715\n",
      "Epoch [3/4], Step [1302/3844], Loss: 0.0864\n",
      "Epoch [3/4], Step [1303/3844], Loss: 0.0841\n",
      "Epoch [3/4], Step [1304/3844], Loss: 0.0745\n",
      "Epoch [3/4], Step [1305/3844], Loss: 0.0688\n",
      "Epoch [3/4], Step [1306/3844], Loss: 0.0747\n",
      "Epoch [3/4], Step [1307/3844], Loss: 0.1541\n",
      "Epoch [3/4], Step [1308/3844], Loss: 0.1203\n",
      "Epoch [3/4], Step [1309/3844], Loss: 0.0793\n",
      "Epoch [3/4], Step [1310/3844], Loss: 0.0641\n",
      "Epoch [3/4], Step [1311/3844], Loss: 0.1057\n",
      "Epoch [3/4], Step [1312/3844], Loss: 0.0678\n",
      "Epoch [3/4], Step [1313/3844], Loss: 0.1212\n",
      "Epoch [3/4], Step [1314/3844], Loss: 0.0884\n",
      "Epoch [3/4], Step [1315/3844], Loss: 0.0603\n",
      "Epoch [3/4], Step [1316/3844], Loss: 0.1018\n",
      "Epoch [3/4], Step [1317/3844], Loss: 0.0704\n",
      "Epoch [3/4], Step [1318/3844], Loss: 0.1329\n",
      "Epoch [3/4], Step [1319/3844], Loss: 0.1201\n",
      "Epoch [3/4], Step [1320/3844], Loss: 0.0676\n",
      "Epoch [3/4], Step [1321/3844], Loss: 0.0989\n",
      "Epoch [3/4], Step [1322/3844], Loss: 0.1012\n",
      "Epoch [3/4], Step [1323/3844], Loss: 0.0829\n",
      "Epoch [3/4], Step [1324/3844], Loss: 0.0843\n",
      "Epoch [3/4], Step [1325/3844], Loss: 0.1403\n",
      "Epoch [3/4], Step [1326/3844], Loss: 0.0754\n",
      "Epoch [3/4], Step [1327/3844], Loss: 0.1059\n",
      "Epoch [3/4], Step [1328/3844], Loss: 0.1267\n",
      "Epoch [3/4], Step [1329/3844], Loss: 0.1435\n",
      "Epoch [3/4], Step [1330/3844], Loss: 0.0672\n",
      "Epoch [3/4], Step [1331/3844], Loss: 0.1356\n",
      "Epoch [3/4], Step [1332/3844], Loss: 0.1660\n",
      "Epoch [3/4], Step [1333/3844], Loss: 0.1669\n",
      "Epoch [3/4], Step [1334/3844], Loss: 0.0858\n",
      "Epoch [3/4], Step [1335/3844], Loss: 0.1512\n",
      "Epoch [3/4], Step [1336/3844], Loss: 0.0882\n",
      "Epoch [3/4], Step [1337/3844], Loss: 0.1022\n",
      "Epoch [3/4], Step [1338/3844], Loss: 0.0904\n",
      "Epoch [3/4], Step [1339/3844], Loss: 0.1051\n",
      "Epoch [3/4], Step [1340/3844], Loss: 0.0991\n",
      "Epoch [3/4], Step [1341/3844], Loss: 0.0734\n",
      "Epoch [3/4], Step [1342/3844], Loss: 0.0884\n",
      "Epoch [3/4], Step [1343/3844], Loss: 0.1691\n",
      "Epoch [3/4], Step [1344/3844], Loss: 0.1346\n",
      "Epoch [3/4], Step [1345/3844], Loss: 0.0816\n",
      "Epoch [3/4], Step [1346/3844], Loss: 0.0784\n",
      "Epoch [3/4], Step [1347/3844], Loss: 0.1183\n",
      "Epoch [3/4], Step [1348/3844], Loss: 0.1052\n",
      "Epoch [3/4], Step [1349/3844], Loss: 0.1435\n",
      "Epoch [3/4], Step [1350/3844], Loss: 0.1409\n",
      "Epoch [3/4], Step [1351/3844], Loss: 0.1040\n",
      "Epoch [3/4], Step [1352/3844], Loss: 0.1108\n",
      "Epoch [3/4], Step [1353/3844], Loss: 0.1347\n",
      "Epoch [3/4], Step [1354/3844], Loss: 0.1207\n",
      "Epoch [3/4], Step [1355/3844], Loss: 0.0896\n",
      "Epoch [3/4], Step [1356/3844], Loss: 0.0682\n",
      "Epoch [3/4], Step [1357/3844], Loss: 0.1264\n",
      "Epoch [3/4], Step [1358/3844], Loss: 0.0965\n",
      "Epoch [3/4], Step [1359/3844], Loss: 0.1149\n",
      "Epoch [3/4], Step [1360/3844], Loss: 0.1571\n",
      "Epoch [3/4], Step [1361/3844], Loss: 0.0792\n",
      "Epoch [3/4], Step [1362/3844], Loss: 0.0823\n",
      "Epoch [3/4], Step [1363/3844], Loss: 0.0889\n",
      "Epoch [3/4], Step [1364/3844], Loss: 0.1720\n",
      "Epoch [3/4], Step [1365/3844], Loss: 0.1103\n",
      "Epoch [3/4], Step [1366/3844], Loss: 0.1409\n",
      "Epoch [3/4], Step [1367/3844], Loss: 0.0804\n",
      "Epoch [3/4], Step [1368/3844], Loss: 0.0911\n",
      "Epoch [3/4], Step [1369/3844], Loss: 0.1167\n",
      "Epoch [3/4], Step [1370/3844], Loss: 0.0830\n",
      "Epoch [3/4], Step [1371/3844], Loss: 0.1788\n",
      "Epoch [3/4], Step [1372/3844], Loss: 0.1071\n",
      "Epoch [3/4], Step [1373/3844], Loss: 0.0950\n",
      "Epoch [3/4], Step [1374/3844], Loss: 0.1687\n",
      "Epoch [3/4], Step [1375/3844], Loss: 0.1442\n",
      "Epoch [3/4], Step [1376/3844], Loss: 0.0873\n",
      "Epoch [3/4], Step [1377/3844], Loss: 0.0435\n",
      "Epoch [3/4], Step [1378/3844], Loss: 0.1230\n",
      "Epoch [3/4], Step [1379/3844], Loss: 0.0997\n",
      "Epoch [3/4], Step [1380/3844], Loss: 0.0741\n",
      "Epoch [3/4], Step [1381/3844], Loss: 0.1086\n",
      "Epoch [3/4], Step [1382/3844], Loss: 0.1279\n",
      "Epoch [3/4], Step [1383/3844], Loss: 0.1587\n",
      "Epoch [3/4], Step [1384/3844], Loss: 0.1020\n",
      "Epoch [3/4], Step [1385/3844], Loss: 0.0865\n",
      "Epoch [3/4], Step [1386/3844], Loss: 0.0615\n",
      "Epoch [3/4], Step [1387/3844], Loss: 0.0988\n",
      "Epoch [3/4], Step [1388/3844], Loss: 0.0936\n",
      "Epoch [3/4], Step [1389/3844], Loss: 0.1090\n",
      "Epoch [3/4], Step [1390/3844], Loss: 0.1113\n",
      "Epoch [3/4], Step [1391/3844], Loss: 0.0705\n",
      "Epoch [3/4], Step [1392/3844], Loss: 0.0992\n",
      "Epoch [3/4], Step [1393/3844], Loss: 0.0826\n",
      "Epoch [3/4], Step [1394/3844], Loss: 0.0982\n",
      "Epoch [3/4], Step [1395/3844], Loss: 0.1444\n",
      "Epoch [3/4], Step [1396/3844], Loss: 0.0878\n",
      "Epoch [3/4], Step [1397/3844], Loss: 0.1982\n",
      "Epoch [3/4], Step [1398/3844], Loss: 0.1238\n",
      "Epoch [3/4], Step [1399/3844], Loss: 0.1583\n",
      "Epoch [3/4], Step [1400/3844], Loss: 0.0827\n",
      "Epoch [3/4], Step [1401/3844], Loss: 0.0882\n",
      "Epoch [3/4], Step [1402/3844], Loss: 0.0777\n",
      "Epoch [3/4], Step [1403/3844], Loss: 0.1376\n",
      "Epoch [3/4], Step [1404/3844], Loss: 0.0952\n",
      "Epoch [3/4], Step [1405/3844], Loss: 0.0643\n",
      "Epoch [3/4], Step [1406/3844], Loss: 0.0801\n",
      "Epoch [3/4], Step [1407/3844], Loss: 0.0684\n",
      "Epoch [3/4], Step [1408/3844], Loss: 0.0971\n",
      "Epoch [3/4], Step [1409/3844], Loss: 0.1893\n",
      "Epoch [3/4], Step [1410/3844], Loss: 0.0914\n",
      "Epoch [3/4], Step [1411/3844], Loss: 0.1389\n",
      "Epoch [3/4], Step [1412/3844], Loss: 0.0699\n",
      "Epoch [3/4], Step [1413/3844], Loss: 0.1632\n",
      "Epoch [3/4], Step [1414/3844], Loss: 0.1017\n",
      "Epoch [3/4], Step [1415/3844], Loss: 0.1239\n",
      "Epoch [3/4], Step [1416/3844], Loss: 0.1515\n",
      "Epoch [3/4], Step [1417/3844], Loss: 0.1511\n",
      "Epoch [3/4], Step [1418/3844], Loss: 0.0889\n",
      "Epoch [3/4], Step [1419/3844], Loss: 0.1356\n",
      "Epoch [3/4], Step [1420/3844], Loss: 0.0812\n",
      "Epoch [3/4], Step [1421/3844], Loss: 0.1408\n",
      "Epoch [3/4], Step [1422/3844], Loss: 0.0764\n",
      "Epoch [3/4], Step [1423/3844], Loss: 0.1188\n",
      "Epoch [3/4], Step [1424/3844], Loss: 0.0861\n",
      "Epoch [3/4], Step [1425/3844], Loss: 0.1597\n",
      "Epoch [3/4], Step [1426/3844], Loss: 0.1383\n",
      "Epoch [3/4], Step [1427/3844], Loss: 0.1037\n",
      "Epoch [3/4], Step [1428/3844], Loss: 0.0724\n",
      "Epoch [3/4], Step [1429/3844], Loss: 0.1646\n",
      "Epoch [3/4], Step [1430/3844], Loss: 0.0605\n",
      "Epoch [3/4], Step [1431/3844], Loss: 0.1297\n",
      "Epoch [3/4], Step [1432/3844], Loss: 0.1107\n",
      "Epoch [3/4], Step [1433/3844], Loss: 0.1486\n",
      "Epoch [3/4], Step [1434/3844], Loss: 0.1448\n",
      "Epoch [3/4], Step [1435/3844], Loss: 0.1001\n",
      "Epoch [3/4], Step [1436/3844], Loss: 0.1445\n",
      "Epoch [3/4], Step [1437/3844], Loss: 0.0879\n",
      "Epoch [3/4], Step [1438/3844], Loss: 0.0991\n",
      "Epoch [3/4], Step [1439/3844], Loss: 0.0714\n",
      "Epoch [3/4], Step [1440/3844], Loss: 0.1077\n",
      "Epoch [3/4], Step [1441/3844], Loss: 0.0826\n",
      "Epoch [3/4], Step [1442/3844], Loss: 0.1503\n",
      "Epoch [3/4], Step [1443/3844], Loss: 0.0744\n",
      "Epoch [3/4], Step [1444/3844], Loss: 0.1152\n",
      "Epoch [3/4], Step [1445/3844], Loss: 0.0821\n",
      "Epoch [3/4], Step [1446/3844], Loss: 0.1205\n",
      "Epoch [3/4], Step [1447/3844], Loss: 0.0850\n",
      "Epoch [3/4], Step [1448/3844], Loss: 0.1443\n",
      "Epoch [3/4], Step [1449/3844], Loss: 0.0810\n",
      "Epoch [3/4], Step [1450/3844], Loss: 0.0802\n",
      "Epoch [3/4], Step [1451/3844], Loss: 0.1158\n",
      "Epoch [3/4], Step [1452/3844], Loss: 0.0909\n",
      "Epoch [3/4], Step [1453/3844], Loss: 0.1847\n",
      "Epoch [3/4], Step [1454/3844], Loss: 0.1517\n",
      "Epoch [3/4], Step [1455/3844], Loss: 0.1388\n",
      "Epoch [3/4], Step [1456/3844], Loss: 0.0997\n",
      "Epoch [3/4], Step [1457/3844], Loss: 0.1389\n",
      "Epoch [3/4], Step [1458/3844], Loss: 0.1415\n",
      "Epoch [3/4], Step [1459/3844], Loss: 0.1187\n",
      "Epoch [3/4], Step [1460/3844], Loss: 0.1009\n",
      "Epoch [3/4], Step [1461/3844], Loss: 0.0793\n",
      "Epoch [3/4], Step [1462/3844], Loss: 0.1373\n",
      "Epoch [3/4], Step [1463/3844], Loss: 0.0712\n",
      "Epoch [3/4], Step [1464/3844], Loss: 0.1500\n",
      "Epoch [3/4], Step [1465/3844], Loss: 0.0754\n",
      "Epoch [3/4], Step [1466/3844], Loss: 0.0869\n",
      "Epoch [3/4], Step [1467/3844], Loss: 0.1215\n",
      "Epoch [3/4], Step [1468/3844], Loss: 0.0684\n",
      "Epoch [3/4], Step [1469/3844], Loss: 0.0971\n",
      "Epoch [3/4], Step [1470/3844], Loss: 0.1499\n",
      "Epoch [3/4], Step [1471/3844], Loss: 0.0704\n",
      "Epoch [3/4], Step [1472/3844], Loss: 0.0629\n",
      "Epoch [3/4], Step [1473/3844], Loss: 0.0693\n",
      "Epoch [3/4], Step [1474/3844], Loss: 0.1039\n",
      "Epoch [3/4], Step [1475/3844], Loss: 0.1006\n",
      "Epoch [3/4], Step [1476/3844], Loss: 0.1647\n",
      "Epoch [3/4], Step [1477/3844], Loss: 0.0854\n",
      "Epoch [3/4], Step [1478/3844], Loss: 0.1798\n",
      "Epoch [3/4], Step [1479/3844], Loss: 0.1384\n",
      "Epoch [3/4], Step [1480/3844], Loss: 0.1214\n",
      "Epoch [3/4], Step [1481/3844], Loss: 0.1377\n",
      "Epoch [3/4], Step [1482/3844], Loss: 0.1568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/4], Step [1483/3844], Loss: 0.1343\n",
      "Epoch [3/4], Step [1484/3844], Loss: 0.0851\n",
      "Epoch [3/4], Step [1485/3844], Loss: 0.1585\n",
      "Epoch [3/4], Step [1486/3844], Loss: 0.0795\n",
      "Epoch [3/4], Step [1487/3844], Loss: 0.1512\n",
      "Epoch [3/4], Step [1488/3844], Loss: 0.1688\n",
      "Epoch [3/4], Step [1489/3844], Loss: 0.0750\n",
      "Epoch [3/4], Step [1490/3844], Loss: 0.1551\n",
      "Epoch [3/4], Step [1491/3844], Loss: 0.0839\n",
      "Epoch [3/4], Step [1492/3844], Loss: 0.1706\n",
      "Epoch [3/4], Step [1493/3844], Loss: 0.0875\n",
      "Epoch [3/4], Step [1494/3844], Loss: 0.0927\n",
      "Epoch [3/4], Step [1495/3844], Loss: 0.1297\n",
      "Epoch [3/4], Step [1496/3844], Loss: 0.1429\n",
      "Epoch [3/4], Step [1497/3844], Loss: 0.0893\n",
      "Epoch [3/4], Step [1498/3844], Loss: 0.1621\n",
      "Epoch [3/4], Step [1499/3844], Loss: 0.0861\n",
      "Epoch [3/4], Step [1500/3844], Loss: 0.1688\n",
      "Epoch [3/4], Step [1501/3844], Loss: 0.0929\n",
      "Epoch [3/4], Step [1502/3844], Loss: 0.1023\n",
      "Epoch [3/4], Step [1503/3844], Loss: 0.0765\n",
      "Epoch [3/4], Step [1504/3844], Loss: 0.1387\n",
      "Epoch [3/4], Step [1505/3844], Loss: 0.0676\n",
      "Epoch [3/4], Step [1506/3844], Loss: 0.1368\n",
      "Epoch [3/4], Step [1507/3844], Loss: 0.0738\n",
      "Epoch [3/4], Step [1508/3844], Loss: 0.1341\n",
      "Epoch [3/4], Step [1509/3844], Loss: 0.0597\n",
      "Epoch [3/4], Step [1510/3844], Loss: 0.0541\n",
      "Epoch [3/4], Step [1511/3844], Loss: 0.0976\n",
      "Epoch [3/4], Step [1512/3844], Loss: 0.0735\n",
      "Epoch [3/4], Step [1513/3844], Loss: 0.1334\n",
      "Epoch [3/4], Step [1514/3844], Loss: 0.1090\n",
      "Epoch [3/4], Step [1515/3844], Loss: 0.1087\n",
      "Epoch [3/4], Step [1516/3844], Loss: 0.0776\n",
      "Epoch [3/4], Step [1517/3844], Loss: 0.0997\n",
      "Epoch [3/4], Step [1518/3844], Loss: 0.1983\n",
      "Epoch [3/4], Step [1519/3844], Loss: 0.1045\n",
      "Epoch [3/4], Step [1520/3844], Loss: 0.1008\n",
      "Epoch [3/4], Step [1521/3844], Loss: 0.1623\n",
      "Epoch [3/4], Step [1522/3844], Loss: 0.1234\n",
      "Epoch [3/4], Step [1523/3844], Loss: 0.1149\n",
      "Epoch [3/4], Step [1524/3844], Loss: 0.0701\n",
      "Epoch [3/4], Step [1525/3844], Loss: 0.0917\n",
      "Epoch [3/4], Step [1526/3844], Loss: 0.1203\n",
      "Epoch [3/4], Step [1527/3844], Loss: 0.1215\n",
      "Epoch [3/4], Step [1528/3844], Loss: 0.1376\n",
      "Epoch [3/4], Step [1529/3844], Loss: 0.0616\n",
      "Epoch [3/4], Step [1530/3844], Loss: 0.1669\n",
      "Epoch [3/4], Step [1531/3844], Loss: 0.1237\n",
      "Epoch [3/4], Step [1532/3844], Loss: 0.0600\n",
      "Epoch [3/4], Step [1533/3844], Loss: 0.0573\n",
      "Epoch [3/4], Step [1534/3844], Loss: 0.0541\n",
      "Epoch [3/4], Step [1535/3844], Loss: 0.1584\n",
      "Epoch [3/4], Step [1536/3844], Loss: 0.0696\n",
      "Epoch [3/4], Step [1537/3844], Loss: 0.1353\n",
      "Epoch [3/4], Step [1538/3844], Loss: 0.1741\n",
      "Epoch [3/4], Step [1539/3844], Loss: 0.1282\n",
      "Epoch [3/4], Step [1540/3844], Loss: 0.0820\n",
      "Epoch [3/4], Step [1541/3844], Loss: 0.1013\n",
      "Epoch [3/4], Step [1542/3844], Loss: 0.0859\n",
      "Epoch [3/4], Step [1543/3844], Loss: 0.0960\n",
      "Epoch [3/4], Step [1544/3844], Loss: 0.1563\n",
      "Epoch [3/4], Step [1545/3844], Loss: 0.0561\n",
      "Epoch [3/4], Step [1546/3844], Loss: 0.1523\n",
      "Epoch [3/4], Step [1547/3844], Loss: 0.1176\n",
      "Epoch [3/4], Step [1548/3844], Loss: 0.1408\n",
      "Epoch [3/4], Step [1549/3844], Loss: 0.0801\n",
      "Epoch [3/4], Step [1550/3844], Loss: 0.0895\n",
      "Epoch [3/4], Step [1551/3844], Loss: 0.0917\n",
      "Epoch [3/4], Step [1552/3844], Loss: 0.1373\n",
      "Epoch [3/4], Step [1553/3844], Loss: 0.1070\n",
      "Epoch [3/4], Step [1554/3844], Loss: 0.0973\n",
      "Epoch [3/4], Step [1555/3844], Loss: 0.0671\n",
      "Epoch [3/4], Step [1556/3844], Loss: 0.0686\n",
      "Epoch [3/4], Step [1557/3844], Loss: 0.1771\n",
      "Epoch [3/4], Step [1558/3844], Loss: 0.1540\n",
      "Epoch [3/4], Step [1559/3844], Loss: 0.0975\n",
      "Epoch [3/4], Step [1560/3844], Loss: 0.0769\n",
      "Epoch [3/4], Step [1561/3844], Loss: 0.0903\n",
      "Epoch [3/4], Step [1562/3844], Loss: 0.1327\n",
      "Epoch [3/4], Step [1563/3844], Loss: 0.0830\n",
      "Epoch [3/4], Step [1564/3844], Loss: 0.1762\n",
      "Epoch [3/4], Step [1565/3844], Loss: 0.0464\n",
      "Epoch [3/4], Step [1566/3844], Loss: 0.1038\n",
      "Epoch [3/4], Step [1567/3844], Loss: 0.0735\n",
      "Epoch [3/4], Step [1568/3844], Loss: 0.0772\n",
      "Epoch [3/4], Step [1569/3844], Loss: 0.0815\n",
      "Epoch [3/4], Step [1570/3844], Loss: 0.0847\n",
      "Epoch [3/4], Step [1571/3844], Loss: 0.1390\n",
      "Epoch [3/4], Step [1572/3844], Loss: 0.1144\n",
      "Epoch [3/4], Step [1573/3844], Loss: 0.0506\n",
      "Epoch [3/4], Step [1574/3844], Loss: 0.1696\n",
      "Epoch [3/4], Step [1575/3844], Loss: 0.1593\n",
      "Epoch [3/4], Step [1576/3844], Loss: 0.0855\n",
      "Epoch [3/4], Step [1577/3844], Loss: 0.1368\n",
      "Epoch [3/4], Step [1578/3844], Loss: 0.0854\n",
      "Epoch [3/4], Step [1579/3844], Loss: 0.1419\n",
      "Epoch [3/4], Step [1580/3844], Loss: 0.1457\n",
      "Epoch [3/4], Step [1581/3844], Loss: 0.0887\n",
      "Epoch [3/4], Step [1582/3844], Loss: 0.1126\n",
      "Epoch [3/4], Step [1583/3844], Loss: 0.1430\n",
      "Epoch [3/4], Step [1584/3844], Loss: 0.0837\n",
      "Epoch [3/4], Step [1585/3844], Loss: 0.1595\n",
      "Epoch [3/4], Step [1586/3844], Loss: 0.0991\n",
      "Epoch [3/4], Step [1587/3844], Loss: 0.1541\n",
      "Epoch [3/4], Step [1588/3844], Loss: 0.1749\n",
      "Epoch [3/4], Step [1589/3844], Loss: 0.0866\n",
      "Epoch [3/4], Step [1590/3844], Loss: 0.0738\n",
      "Epoch [3/4], Step [1591/3844], Loss: 0.1432\n",
      "Epoch [3/4], Step [1592/3844], Loss: 0.0847\n",
      "Epoch [3/4], Step [1593/3844], Loss: 0.1553\n",
      "Epoch [3/4], Step [1594/3844], Loss: 0.1291\n",
      "Epoch [3/4], Step [1595/3844], Loss: 0.1581\n",
      "Epoch [3/4], Step [1596/3844], Loss: 0.0611\n",
      "Epoch [3/4], Step [1597/3844], Loss: 0.1638\n",
      "Epoch [3/4], Step [1598/3844], Loss: 0.0867\n",
      "Epoch [3/4], Step [1599/3844], Loss: 0.1647\n",
      "Epoch [3/4], Step [1600/3844], Loss: 0.1413\n",
      "Epoch [3/4], Step [1601/3844], Loss: 0.1096\n",
      "Epoch [3/4], Step [1602/3844], Loss: 0.0783\n",
      "Epoch [3/4], Step [1603/3844], Loss: 0.1453\n",
      "Epoch [3/4], Step [1604/3844], Loss: 0.0992\n",
      "Epoch [3/4], Step [1605/3844], Loss: 0.0791\n",
      "Epoch [3/4], Step [1606/3844], Loss: 0.0769\n",
      "Epoch [3/4], Step [1607/3844], Loss: 0.1360\n",
      "Epoch [3/4], Step [1608/3844], Loss: 0.1486\n",
      "Epoch [3/4], Step [1609/3844], Loss: 0.1029\n",
      "Epoch [3/4], Step [1610/3844], Loss: 0.0899\n",
      "Epoch [3/4], Step [1611/3844], Loss: 0.1646\n",
      "Epoch [3/4], Step [1612/3844], Loss: 0.1183\n",
      "Epoch [3/4], Step [1613/3844], Loss: 0.0604\n",
      "Epoch [3/4], Step [1614/3844], Loss: 0.0839\n",
      "Epoch [3/4], Step [1615/3844], Loss: 0.0807\n",
      "Epoch [3/4], Step [1616/3844], Loss: 0.0804\n",
      "Epoch [3/4], Step [1617/3844], Loss: 0.1060\n",
      "Epoch [3/4], Step [1618/3844], Loss: 0.1478\n",
      "Epoch [3/4], Step [1619/3844], Loss: 0.0883\n",
      "Epoch [3/4], Step [1620/3844], Loss: 0.1045\n",
      "Epoch [3/4], Step [1621/3844], Loss: 0.1479\n",
      "Epoch [3/4], Step [1622/3844], Loss: 0.1114\n",
      "Epoch [3/4], Step [1623/3844], Loss: 0.1679\n",
      "Epoch [3/4], Step [1624/3844], Loss: 0.0813\n",
      "Epoch [3/4], Step [1625/3844], Loss: 0.0742\n",
      "Epoch [3/4], Step [1626/3844], Loss: 0.0837\n",
      "Epoch [3/4], Step [1627/3844], Loss: 0.1485\n",
      "Epoch [3/4], Step [1628/3844], Loss: 0.1023\n",
      "Epoch [3/4], Step [1629/3844], Loss: 0.1050\n",
      "Epoch [3/4], Step [1630/3844], Loss: 0.0795\n",
      "Epoch [3/4], Step [1631/3844], Loss: 0.1023\n",
      "Epoch [3/4], Step [1632/3844], Loss: 0.1650\n",
      "Epoch [3/4], Step [1633/3844], Loss: 0.0705\n",
      "Epoch [3/4], Step [1634/3844], Loss: 0.1186\n",
      "Epoch [3/4], Step [1635/3844], Loss: 0.1136\n",
      "Epoch [3/4], Step [1636/3844], Loss: 0.1554\n",
      "Epoch [3/4], Step [1637/3844], Loss: 0.0857\n",
      "Epoch [3/4], Step [1638/3844], Loss: 0.0909\n",
      "Epoch [3/4], Step [1639/3844], Loss: 0.0961\n",
      "Epoch [3/4], Step [1640/3844], Loss: 0.0977\n",
      "Epoch [3/4], Step [1641/3844], Loss: 0.1166\n",
      "Epoch [3/4], Step [1642/3844], Loss: 0.0885\n",
      "Epoch [3/4], Step [1643/3844], Loss: 0.1415\n",
      "Epoch [3/4], Step [1644/3844], Loss: 0.1579\n",
      "Epoch [3/4], Step [1645/3844], Loss: 0.0708\n",
      "Epoch [3/4], Step [1646/3844], Loss: 0.1167\n",
      "Epoch [3/4], Step [1647/3844], Loss: 0.0921\n",
      "Epoch [3/4], Step [1648/3844], Loss: 0.0997\n",
      "Epoch [3/4], Step [1649/3844], Loss: 0.0922\n",
      "Epoch [3/4], Step [1650/3844], Loss: 0.1101\n",
      "Epoch [3/4], Step [1651/3844], Loss: 0.0892\n",
      "Epoch [3/4], Step [1652/3844], Loss: 0.1183\n",
      "Epoch [3/4], Step [1653/3844], Loss: 0.0868\n",
      "Epoch [3/4], Step [1654/3844], Loss: 0.0899\n",
      "Epoch [3/4], Step [1655/3844], Loss: 0.1291\n",
      "Epoch [3/4], Step [1656/3844], Loss: 0.0823\n",
      "Epoch [3/4], Step [1657/3844], Loss: 0.1112\n",
      "Epoch [3/4], Step [1658/3844], Loss: 0.0626\n",
      "Epoch [3/4], Step [1659/3844], Loss: 0.1155\n",
      "Epoch [3/4], Step [1660/3844], Loss: 0.0880\n",
      "Epoch [3/4], Step [1661/3844], Loss: 0.1428\n",
      "Epoch [3/4], Step [1662/3844], Loss: 0.1078\n",
      "Epoch [3/4], Step [1663/3844], Loss: 0.0858\n",
      "Epoch [3/4], Step [1664/3844], Loss: 0.0951\n",
      "Epoch [3/4], Step [1665/3844], Loss: 0.1793\n",
      "Epoch [3/4], Step [1666/3844], Loss: 0.0682\n",
      "Epoch [3/4], Step [1667/3844], Loss: 0.1465\n",
      "Epoch [3/4], Step [1668/3844], Loss: 0.1756\n",
      "Epoch [3/4], Step [1669/3844], Loss: 0.0939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/4], Step [1670/3844], Loss: 0.1486\n",
      "Epoch [3/4], Step [1671/3844], Loss: 0.1345\n",
      "Epoch [3/4], Step [1672/3844], Loss: 0.0918\n",
      "Epoch [3/4], Step [1673/3844], Loss: 0.0526\n",
      "Epoch [3/4], Step [1674/3844], Loss: 0.0752\n",
      "Epoch [3/4], Step [1675/3844], Loss: 0.0735\n",
      "Epoch [3/4], Step [1676/3844], Loss: 0.1061\n",
      "Epoch [3/4], Step [1677/3844], Loss: 0.0493\n",
      "Epoch [3/4], Step [1678/3844], Loss: 0.0854\n",
      "Epoch [3/4], Step [1679/3844], Loss: 0.1708\n",
      "Epoch [3/4], Step [1680/3844], Loss: 0.0926\n",
      "Epoch [3/4], Step [1681/3844], Loss: 0.0882\n",
      "Epoch [3/4], Step [1682/3844], Loss: 0.0663\n",
      "Epoch [3/4], Step [1683/3844], Loss: 0.1771\n",
      "Epoch [3/4], Step [1684/3844], Loss: 0.0951\n",
      "Epoch [3/4], Step [1685/3844], Loss: 0.1248\n",
      "Epoch [3/4], Step [1686/3844], Loss: 0.0902\n",
      "Epoch [3/4], Step [1687/3844], Loss: 0.1331\n",
      "Epoch [3/4], Step [1688/3844], Loss: 0.0836\n",
      "Epoch [3/4], Step [1689/3844], Loss: 0.0657\n",
      "Epoch [3/4], Step [1690/3844], Loss: 0.0833\n",
      "Epoch [3/4], Step [1691/3844], Loss: 0.1439\n",
      "Epoch [3/4], Step [1692/3844], Loss: 0.1661\n",
      "Epoch [3/4], Step [1693/3844], Loss: 0.1421\n",
      "Epoch [3/4], Step [1694/3844], Loss: 0.1281\n",
      "Epoch [3/4], Step [1695/3844], Loss: 0.0920\n",
      "Epoch [3/4], Step [1696/3844], Loss: 0.1669\n",
      "Epoch [3/4], Step [1697/3844], Loss: 0.1187\n",
      "Epoch [3/4], Step [1698/3844], Loss: 0.1105\n",
      "Epoch [3/4], Step [1699/3844], Loss: 0.1163\n",
      "Epoch [3/4], Step [1700/3844], Loss: 0.1479\n",
      "Epoch [3/4], Step [1701/3844], Loss: 0.0983\n",
      "Epoch [3/4], Step [1702/3844], Loss: 0.1218\n",
      "Epoch [3/4], Step [1703/3844], Loss: 0.1276\n",
      "Epoch [3/4], Step [1704/3844], Loss: 0.1489\n",
      "Epoch [3/4], Step [1705/3844], Loss: 0.1052\n",
      "Epoch [3/4], Step [1706/3844], Loss: 0.1053\n",
      "Epoch [3/4], Step [1707/3844], Loss: 0.1360\n",
      "Epoch [3/4], Step [1708/3844], Loss: 0.1381\n",
      "Epoch [3/4], Step [1709/3844], Loss: 0.1309\n",
      "Epoch [3/4], Step [1710/3844], Loss: 0.1596\n",
      "Epoch [3/4], Step [1711/3844], Loss: 0.1046\n",
      "Epoch [3/4], Step [1712/3844], Loss: 0.0810\n",
      "Epoch [3/4], Step [1713/3844], Loss: 0.0827\n",
      "Epoch [3/4], Step [1714/3844], Loss: 0.0883\n",
      "Epoch [3/4], Step [1715/3844], Loss: 0.0911\n",
      "Epoch [3/4], Step [1716/3844], Loss: 0.0973\n",
      "Epoch [3/4], Step [1717/3844], Loss: 0.1520\n",
      "Epoch [3/4], Step [1718/3844], Loss: 0.1296\n",
      "Epoch [3/4], Step [1719/3844], Loss: 0.0987\n",
      "Epoch [3/4], Step [1720/3844], Loss: 0.0896\n",
      "Epoch [3/4], Step [1721/3844], Loss: 0.0944\n",
      "Epoch [3/4], Step [1722/3844], Loss: 0.1188\n",
      "Epoch [3/4], Step [1723/3844], Loss: 0.0816\n",
      "Epoch [3/4], Step [1724/3844], Loss: 0.1581\n",
      "Epoch [3/4], Step [1725/3844], Loss: 0.1491\n",
      "Epoch [3/4], Step [1726/3844], Loss: 0.1087\n",
      "Epoch [3/4], Step [1727/3844], Loss: 0.0963\n",
      "Epoch [3/4], Step [1728/3844], Loss: 0.1168\n",
      "Epoch [3/4], Step [1729/3844], Loss: 0.1468\n",
      "Epoch [3/4], Step [1730/3844], Loss: 0.1319\n",
      "Epoch [3/4], Step [1731/3844], Loss: 0.0898\n",
      "Epoch [3/4], Step [1732/3844], Loss: 0.1316\n",
      "Epoch [3/4], Step [1733/3844], Loss: 0.0978\n",
      "Epoch [3/4], Step [1734/3844], Loss: 0.0922\n",
      "Epoch [3/4], Step [1735/3844], Loss: 0.0836\n",
      "Epoch [3/4], Step [1736/3844], Loss: 0.1115\n",
      "Epoch [3/4], Step [1737/3844], Loss: 0.1616\n",
      "Epoch [3/4], Step [1738/3844], Loss: 0.0834\n",
      "Epoch [3/4], Step [1739/3844], Loss: 0.1393\n",
      "Epoch [3/4], Step [1740/3844], Loss: 0.0730\n",
      "Epoch [3/4], Step [1741/3844], Loss: 0.1366\n",
      "Epoch [3/4], Step [1742/3844], Loss: 0.1509\n",
      "Epoch [3/4], Step [1743/3844], Loss: 0.0500\n",
      "Epoch [3/4], Step [1744/3844], Loss: 0.1096\n",
      "Epoch [3/4], Step [1745/3844], Loss: 0.0708\n",
      "Epoch [3/4], Step [1746/3844], Loss: 0.1419\n",
      "Epoch [3/4], Step [1747/3844], Loss: 0.0750\n",
      "Epoch [3/4], Step [1748/3844], Loss: 0.1013\n",
      "Epoch [3/4], Step [1749/3844], Loss: 0.1000\n",
      "Epoch [3/4], Step [1750/3844], Loss: 0.1144\n",
      "Epoch [3/4], Step [1751/3844], Loss: 0.0835\n",
      "Epoch [3/4], Step [1752/3844], Loss: 0.0920\n",
      "Epoch [3/4], Step [1753/3844], Loss: 0.0566\n",
      "Epoch [3/4], Step [1754/3844], Loss: 0.1461\n",
      "Epoch [3/4], Step [1755/3844], Loss: 0.0515\n",
      "Epoch [3/4], Step [1756/3844], Loss: 0.0546\n",
      "Epoch [3/4], Step [1757/3844], Loss: 0.1301\n",
      "Epoch [3/4], Step [1758/3844], Loss: 0.1606\n",
      "Epoch [3/4], Step [1759/3844], Loss: 0.1161\n",
      "Epoch [3/4], Step [1760/3844], Loss: 0.0765\n",
      "Epoch [3/4], Step [1761/3844], Loss: 0.1227\n",
      "Epoch [3/4], Step [1762/3844], Loss: 0.0741\n",
      "Epoch [3/4], Step [1763/3844], Loss: 0.0907\n",
      "Epoch [3/4], Step [1764/3844], Loss: 0.0852\n",
      "Epoch [3/4], Step [1765/3844], Loss: 0.1220\n",
      "Epoch [3/4], Step [1766/3844], Loss: 0.1324\n",
      "Epoch [3/4], Step [1767/3844], Loss: 0.1095\n",
      "Epoch [3/4], Step [1768/3844], Loss: 0.1279\n",
      "Epoch [3/4], Step [1769/3844], Loss: 0.0962\n",
      "Epoch [3/4], Step [1770/3844], Loss: 0.1648\n",
      "Epoch [3/4], Step [1771/3844], Loss: 0.1485\n",
      "Epoch [3/4], Step [1772/3844], Loss: 0.0804\n",
      "Epoch [3/4], Step [1773/3844], Loss: 0.1495\n",
      "Epoch [3/4], Step [1774/3844], Loss: 0.0715\n",
      "Epoch [3/4], Step [1775/3844], Loss: 0.0843\n",
      "Epoch [3/4], Step [1776/3844], Loss: 0.1049\n",
      "Epoch [3/4], Step [1777/3844], Loss: 0.0624\n",
      "Epoch [3/4], Step [1778/3844], Loss: 0.1115\n",
      "Epoch [3/4], Step [1779/3844], Loss: 0.1123\n",
      "Epoch [3/4], Step [1780/3844], Loss: 0.1040\n",
      "Epoch [3/4], Step [1781/3844], Loss: 0.1465\n",
      "Epoch [3/4], Step [1782/3844], Loss: 0.0975\n",
      "Epoch [3/4], Step [1783/3844], Loss: 0.0783\n",
      "Epoch [3/4], Step [1784/3844], Loss: 0.0942\n",
      "Epoch [3/4], Step [1785/3844], Loss: 0.1337\n",
      "Epoch [3/4], Step [1786/3844], Loss: 0.0723\n",
      "Epoch [3/4], Step [1787/3844], Loss: 0.0598\n",
      "Epoch [3/4], Step [1788/3844], Loss: 0.0977\n",
      "Epoch [3/4], Step [1789/3844], Loss: 0.0725\n",
      "Epoch [3/4], Step [1790/3844], Loss: 0.1709\n",
      "Epoch [3/4], Step [1791/3844], Loss: 0.1904\n",
      "Epoch [3/4], Step [1792/3844], Loss: 0.0837\n",
      "Epoch [3/4], Step [1793/3844], Loss: 0.1656\n",
      "Epoch [3/4], Step [1794/3844], Loss: 0.1594\n",
      "Epoch [3/4], Step [1795/3844], Loss: 0.1546\n",
      "Epoch [3/4], Step [1796/3844], Loss: 0.1442\n",
      "Epoch [3/4], Step [1797/3844], Loss: 0.1519\n",
      "Epoch [3/4], Step [1798/3844], Loss: 0.0626\n",
      "Epoch [3/4], Step [1799/3844], Loss: 0.1200\n",
      "Epoch [3/4], Step [1800/3844], Loss: 0.1249\n",
      "Epoch [3/4], Step [1801/3844], Loss: 0.0670\n",
      "Epoch [3/4], Step [1802/3844], Loss: 0.1377\n",
      "Epoch [3/4], Step [1803/3844], Loss: 0.1228\n",
      "Epoch [3/4], Step [1804/3844], Loss: 0.0787\n",
      "Epoch [3/4], Step [1805/3844], Loss: 0.0883\n",
      "Epoch [3/4], Step [1806/3844], Loss: 0.0998\n",
      "Epoch [3/4], Step [1807/3844], Loss: 0.0863\n",
      "Epoch [3/4], Step [1808/3844], Loss: 0.1485\n",
      "Epoch [3/4], Step [1809/3844], Loss: 0.1366\n",
      "Epoch [3/4], Step [1810/3844], Loss: 0.1468\n",
      "Epoch [3/4], Step [1811/3844], Loss: 0.1410\n",
      "Epoch [3/4], Step [1812/3844], Loss: 0.1648\n",
      "Epoch [3/4], Step [1813/3844], Loss: 0.1178\n",
      "Epoch [3/4], Step [1814/3844], Loss: 0.0842\n",
      "Epoch [3/4], Step [1815/3844], Loss: 0.0809\n",
      "Epoch [3/4], Step [1816/3844], Loss: 0.1326\n",
      "Epoch [3/4], Step [1817/3844], Loss: 0.1319\n",
      "Epoch [3/4], Step [1818/3844], Loss: 0.0740\n",
      "Epoch [3/4], Step [1819/3844], Loss: 0.1106\n",
      "Epoch [3/4], Step [1820/3844], Loss: 0.1004\n",
      "Epoch [3/4], Step [1821/3844], Loss: 0.1579\n",
      "Epoch [3/4], Step [1822/3844], Loss: 0.0984\n",
      "Epoch [3/4], Step [1823/3844], Loss: 0.0785\n",
      "Epoch [3/4], Step [1824/3844], Loss: 0.1174\n",
      "Epoch [3/4], Step [1825/3844], Loss: 0.0623\n",
      "Epoch [3/4], Step [1826/3844], Loss: 0.1542\n",
      "Epoch [3/4], Step [1827/3844], Loss: 0.1038\n",
      "Epoch [3/4], Step [1828/3844], Loss: 0.1022\n",
      "Epoch [3/4], Step [1829/3844], Loss: 0.0962\n",
      "Epoch [3/4], Step [1830/3844], Loss: 0.0972\n",
      "Epoch [3/4], Step [1831/3844], Loss: 0.0839\n",
      "Epoch [3/4], Step [1832/3844], Loss: 0.0929\n",
      "Epoch [3/4], Step [1833/3844], Loss: 0.1420\n",
      "Epoch [3/4], Step [1834/3844], Loss: 0.1054\n",
      "Epoch [3/4], Step [1835/3844], Loss: 0.0949\n",
      "Epoch [3/4], Step [1836/3844], Loss: 0.1084\n",
      "Epoch [3/4], Step [1837/3844], Loss: 0.1384\n",
      "Epoch [3/4], Step [1838/3844], Loss: 0.1278\n",
      "Epoch [3/4], Step [1839/3844], Loss: 0.0725\n",
      "Epoch [3/4], Step [1840/3844], Loss: 0.1346\n",
      "Epoch [3/4], Step [1841/3844], Loss: 0.1013\n",
      "Epoch [3/4], Step [1842/3844], Loss: 0.0673\n",
      "Epoch [3/4], Step [1843/3844], Loss: 0.0733\n",
      "Epoch [3/4], Step [1844/3844], Loss: 0.1067\n",
      "Epoch [3/4], Step [1845/3844], Loss: 0.0958\n",
      "Epoch [3/4], Step [1846/3844], Loss: 0.1258\n",
      "Epoch [3/4], Step [1847/3844], Loss: 0.0903\n",
      "Epoch [3/4], Step [1848/3844], Loss: 0.0850\n",
      "Epoch [3/4], Step [1849/3844], Loss: 0.1582\n",
      "Epoch [3/4], Step [1850/3844], Loss: 0.1091\n",
      "Epoch [3/4], Step [1851/3844], Loss: 0.1390\n",
      "Epoch [3/4], Step [1852/3844], Loss: 0.0834\n",
      "Epoch [3/4], Step [1853/3844], Loss: 0.0950\n",
      "Epoch [3/4], Step [1854/3844], Loss: 0.0873\n",
      "Epoch [3/4], Step [1855/3844], Loss: 0.0710\n",
      "Epoch [3/4], Step [1856/3844], Loss: 0.0864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/4], Step [1857/3844], Loss: 0.1566\n",
      "Epoch [3/4], Step [1858/3844], Loss: 0.0773\n",
      "Epoch [3/4], Step [1859/3844], Loss: 0.1044\n",
      "Epoch [3/4], Step [1860/3844], Loss: 0.0973\n",
      "Epoch [3/4], Step [1861/3844], Loss: 0.0813\n",
      "Epoch [3/4], Step [1862/3844], Loss: 0.1185\n",
      "Epoch [3/4], Step [1863/3844], Loss: 0.0742\n",
      "Epoch [3/4], Step [1864/3844], Loss: 0.0721\n",
      "Epoch [3/4], Step [1865/3844], Loss: 0.1381\n",
      "Epoch [3/4], Step [1866/3844], Loss: 0.1599\n",
      "Epoch [3/4], Step [1867/3844], Loss: 0.1371\n",
      "Epoch [3/4], Step [1868/3844], Loss: 0.1093\n",
      "Epoch [3/4], Step [1869/3844], Loss: 0.1444\n",
      "Epoch [3/4], Step [1870/3844], Loss: 0.1362\n",
      "Epoch [3/4], Step [1871/3844], Loss: 0.0758\n",
      "Epoch [3/4], Step [1872/3844], Loss: 0.1121\n",
      "Epoch [3/4], Step [1873/3844], Loss: 0.1324\n",
      "Epoch [3/4], Step [1874/3844], Loss: 0.1596\n",
      "Epoch [3/4], Step [1875/3844], Loss: 0.1270\n",
      "Epoch [3/4], Step [1876/3844], Loss: 0.1528\n",
      "Epoch [3/4], Step [1877/3844], Loss: 0.1401\n",
      "Epoch [3/4], Step [1878/3844], Loss: 0.1062\n",
      "Epoch [3/4], Step [1879/3844], Loss: 0.0805\n",
      "Epoch [3/4], Step [1880/3844], Loss: 0.1350\n",
      "Epoch [3/4], Step [1881/3844], Loss: 0.0808\n",
      "Epoch [3/4], Step [1882/3844], Loss: 0.0767\n",
      "Epoch [3/4], Step [1883/3844], Loss: 0.0836\n",
      "Epoch [3/4], Step [1884/3844], Loss: 0.0708\n",
      "Epoch [3/4], Step [1885/3844], Loss: 0.1434\n",
      "Epoch [3/4], Step [1886/3844], Loss: 0.1549\n",
      "Epoch [3/4], Step [1887/3844], Loss: 0.0873\n",
      "Epoch [3/4], Step [1888/3844], Loss: 0.0924\n",
      "Epoch [3/4], Step [1889/3844], Loss: 0.1233\n",
      "Epoch [3/4], Step [1890/3844], Loss: 0.1208\n",
      "Epoch [3/4], Step [1891/3844], Loss: 0.0596\n",
      "Epoch [3/4], Step [1892/3844], Loss: 0.0879\n",
      "Epoch [3/4], Step [1893/3844], Loss: 0.1292\n",
      "Epoch [3/4], Step [1894/3844], Loss: 0.0965\n",
      "Epoch [3/4], Step [1895/3844], Loss: 0.0812\n",
      "Epoch [3/4], Step [1896/3844], Loss: 0.1366\n",
      "Epoch [3/4], Step [1897/3844], Loss: 0.1355\n",
      "Epoch [3/4], Step [1898/3844], Loss: 0.1429\n",
      "Epoch [3/4], Step [1899/3844], Loss: 0.0830\n",
      "Epoch [3/4], Step [1900/3844], Loss: 0.1117\n",
      "Epoch [3/4], Step [1901/3844], Loss: 0.1509\n",
      "Epoch [3/4], Step [1902/3844], Loss: 0.0899\n",
      "Epoch [3/4], Step [1903/3844], Loss: 0.0755\n",
      "Epoch [3/4], Step [1904/3844], Loss: 0.1298\n",
      "Epoch [3/4], Step [1905/3844], Loss: 0.1055\n",
      "Epoch [3/4], Step [1906/3844], Loss: 0.0715\n",
      "Epoch [3/4], Step [1907/3844], Loss: 0.1491\n",
      "Epoch [3/4], Step [1908/3844], Loss: 0.0850\n",
      "Epoch [3/4], Step [1909/3844], Loss: 0.1634\n",
      "Epoch [3/4], Step [1910/3844], Loss: 0.1007\n",
      "Epoch [3/4], Step [1911/3844], Loss: 0.0556\n",
      "Epoch [3/4], Step [1912/3844], Loss: 0.0855\n",
      "Epoch [3/4], Step [1913/3844], Loss: 0.1502\n",
      "Epoch [3/4], Step [1914/3844], Loss: 0.0656\n",
      "Epoch [3/4], Step [1915/3844], Loss: 0.0934\n",
      "Epoch [3/4], Step [1916/3844], Loss: 0.1233\n",
      "Epoch [3/4], Step [1917/3844], Loss: 0.1052\n",
      "Epoch [3/4], Step [1918/3844], Loss: 0.0797\n",
      "Epoch [3/4], Step [1919/3844], Loss: 0.0856\n",
      "Epoch [3/4], Step [1920/3844], Loss: 0.1828\n",
      "Epoch [3/4], Step [1921/3844], Loss: 0.0895\n",
      "Epoch [3/4], Step [1922/3844], Loss: 0.1149\n",
      "Epoch [3/4], Step [1923/3844], Loss: 0.0740\n",
      "Epoch [3/4], Step [1924/3844], Loss: 0.0790\n",
      "Epoch [3/4], Step [1925/3844], Loss: 0.1385\n",
      "Epoch [3/4], Step [1926/3844], Loss: 0.0982\n",
      "Epoch [3/4], Step [1927/3844], Loss: 0.0780\n",
      "Epoch [3/4], Step [1928/3844], Loss: 0.0781\n",
      "Epoch [3/4], Step [1929/3844], Loss: 0.1470\n",
      "Epoch [3/4], Step [1930/3844], Loss: 0.0896\n",
      "Epoch [3/4], Step [1931/3844], Loss: 0.1515\n",
      "Epoch [3/4], Step [1932/3844], Loss: 0.1410\n",
      "Epoch [3/4], Step [1933/3844], Loss: 0.1009\n",
      "Epoch [3/4], Step [1934/3844], Loss: 0.0833\n",
      "Epoch [3/4], Step [1935/3844], Loss: 0.1020\n",
      "Epoch [3/4], Step [1936/3844], Loss: 0.0992\n",
      "Epoch [3/4], Step [1937/3844], Loss: 0.1290\n",
      "Epoch [3/4], Step [1938/3844], Loss: 0.1566\n",
      "Epoch [3/4], Step [1939/3844], Loss: 0.0886\n",
      "Epoch [3/4], Step [1940/3844], Loss: 0.0631\n",
      "Epoch [3/4], Step [1941/3844], Loss: 0.0776\n",
      "Epoch [3/4], Step [1942/3844], Loss: 0.0712\n",
      "Epoch [3/4], Step [1943/3844], Loss: 0.0830\n",
      "Epoch [3/4], Step [1944/3844], Loss: 0.0851\n",
      "Epoch [3/4], Step [1945/3844], Loss: 0.0806\n",
      "Epoch [3/4], Step [1946/3844], Loss: 0.0711\n",
      "Epoch [3/4], Step [1947/3844], Loss: 0.0976\n",
      "Epoch [3/4], Step [1948/3844], Loss: 0.0475\n",
      "Epoch [3/4], Step [1949/3844], Loss: 0.1304\n",
      "Epoch [3/4], Step [1950/3844], Loss: 0.0874\n",
      "Epoch [3/4], Step [1951/3844], Loss: 0.1003\n",
      "Epoch [3/4], Step [1952/3844], Loss: 0.0508\n",
      "Epoch [3/4], Step [1953/3844], Loss: 0.0583\n",
      "Epoch [3/4], Step [1954/3844], Loss: 0.0614\n",
      "Epoch [3/4], Step [1955/3844], Loss: 0.0988\n",
      "Epoch [3/4], Step [1956/3844], Loss: 0.1300\n",
      "Epoch [3/4], Step [1957/3844], Loss: 0.1381\n",
      "Epoch [3/4], Step [1958/3844], Loss: 0.0809\n",
      "Epoch [3/4], Step [1959/3844], Loss: 0.0963\n",
      "Epoch [3/4], Step [1960/3844], Loss: 0.1408\n",
      "Epoch [3/4], Step [1961/3844], Loss: 0.0973\n",
      "Epoch [3/4], Step [1962/3844], Loss: 0.1636\n",
      "Epoch [3/4], Step [1963/3844], Loss: 0.1180\n",
      "Epoch [3/4], Step [1964/3844], Loss: 0.1749\n",
      "Epoch [3/4], Step [1965/3844], Loss: 0.0781\n",
      "Epoch [3/4], Step [1966/3844], Loss: 0.0924\n",
      "Epoch [3/4], Step [1967/3844], Loss: 0.0651\n",
      "Epoch [3/4], Step [1968/3844], Loss: 0.1368\n",
      "Epoch [3/4], Step [1969/3844], Loss: 0.1169\n",
      "Epoch [3/4], Step [1970/3844], Loss: 0.0877\n",
      "Epoch [3/4], Step [1971/3844], Loss: 0.0831\n",
      "Epoch [3/4], Step [1972/3844], Loss: 0.1079\n",
      "Epoch [3/4], Step [1973/3844], Loss: 0.1265\n",
      "Epoch [3/4], Step [1974/3844], Loss: 0.1236\n",
      "Epoch [3/4], Step [1975/3844], Loss: 0.0855\n",
      "Epoch [3/4], Step [1976/3844], Loss: 0.1220\n",
      "Epoch [3/4], Step [1977/3844], Loss: 0.1717\n",
      "Epoch [3/4], Step [1978/3844], Loss: 0.0839\n",
      "Epoch [3/4], Step [1979/3844], Loss: 0.0877\n",
      "Epoch [3/4], Step [1980/3844], Loss: 0.1707\n",
      "Epoch [3/4], Step [1981/3844], Loss: 0.1359\n",
      "Epoch [3/4], Step [1982/3844], Loss: 0.0929\n",
      "Epoch [3/4], Step [1983/3844], Loss: 0.1317\n",
      "Epoch [3/4], Step [1984/3844], Loss: 0.1477\n",
      "Epoch [3/4], Step [1985/3844], Loss: 0.1086\n",
      "Epoch [3/4], Step [1986/3844], Loss: 0.0858\n",
      "Epoch [3/4], Step [1987/3844], Loss: 0.1486\n",
      "Epoch [3/4], Step [1988/3844], Loss: 0.1168\n",
      "Epoch [3/4], Step [1989/3844], Loss: 0.0769\n",
      "Epoch [3/4], Step [1990/3844], Loss: 0.0899\n",
      "Epoch [3/4], Step [1991/3844], Loss: 0.1228\n",
      "Epoch [3/4], Step [1992/3844], Loss: 0.0923\n",
      "Epoch [3/4], Step [1993/3844], Loss: 0.0973\n",
      "Epoch [3/4], Step [1994/3844], Loss: 0.1361\n",
      "Epoch [3/4], Step [1995/3844], Loss: 0.0732\n",
      "Epoch [3/4], Step [1996/3844], Loss: 0.0795\n",
      "Epoch [3/4], Step [1997/3844], Loss: 0.0797\n",
      "Epoch [3/4], Step [1998/3844], Loss: 0.1059\n",
      "Epoch [3/4], Step [1999/3844], Loss: 0.0767\n",
      "Epoch [3/4], Step [2000/3844], Loss: 0.1007\n",
      "Epoch [3/4], Step [2001/3844], Loss: 0.1402\n",
      "Epoch [3/4], Step [2002/3844], Loss: 0.0985\n",
      "Epoch [3/4], Step [2003/3844], Loss: 0.1614\n",
      "Epoch [3/4], Step [2004/3844], Loss: 0.0868\n",
      "Epoch [3/4], Step [2005/3844], Loss: 0.1117\n",
      "Epoch [3/4], Step [2006/3844], Loss: 0.1533\n",
      "Epoch [3/4], Step [2007/3844], Loss: 0.1559\n",
      "Epoch [3/4], Step [2008/3844], Loss: 0.0663\n",
      "Epoch [3/4], Step [2009/3844], Loss: 0.1449\n",
      "Epoch [3/4], Step [2010/3844], Loss: 0.0850\n",
      "Epoch [3/4], Step [2011/3844], Loss: 0.0765\n",
      "Epoch [3/4], Step [2012/3844], Loss: 0.0626\n",
      "Epoch [3/4], Step [2013/3844], Loss: 0.1440\n",
      "Epoch [3/4], Step [2014/3844], Loss: 0.1651\n",
      "Epoch [3/4], Step [2015/3844], Loss: 0.1564\n",
      "Epoch [3/4], Step [2016/3844], Loss: 0.1347\n",
      "Epoch [3/4], Step [2017/3844], Loss: 0.0912\n",
      "Epoch [3/4], Step [2018/3844], Loss: 0.1510\n",
      "Epoch [3/4], Step [2019/3844], Loss: 0.0827\n",
      "Epoch [3/4], Step [2020/3844], Loss: 0.0822\n",
      "Epoch [3/4], Step [2021/3844], Loss: 0.1242\n",
      "Epoch [3/4], Step [2022/3844], Loss: 0.0731\n",
      "Epoch [3/4], Step [2023/3844], Loss: 0.1649\n",
      "Epoch [3/4], Step [2024/3844], Loss: 0.0641\n",
      "Epoch [3/4], Step [2025/3844], Loss: 0.1116\n",
      "Epoch [3/4], Step [2026/3844], Loss: 0.1076\n",
      "Epoch [3/4], Step [2027/3844], Loss: 0.1414\n",
      "Epoch [3/4], Step [2028/3844], Loss: 0.0732\n",
      "Epoch [3/4], Step [2029/3844], Loss: 0.1229\n",
      "Epoch [3/4], Step [2030/3844], Loss: 0.0841\n",
      "Epoch [3/4], Step [2031/3844], Loss: 0.1007\n",
      "Epoch [3/4], Step [2032/3844], Loss: 0.1483\n",
      "Epoch [3/4], Step [2033/3844], Loss: 0.1109\n",
      "Epoch [3/4], Step [2034/3844], Loss: 0.0824\n",
      "Epoch [3/4], Step [2035/3844], Loss: 0.0843\n",
      "Epoch [3/4], Step [2036/3844], Loss: 0.1407\n",
      "Epoch [3/4], Step [2037/3844], Loss: 0.0925\n",
      "Epoch [3/4], Step [2038/3844], Loss: 0.0875\n",
      "Epoch [3/4], Step [2039/3844], Loss: 0.1246\n",
      "Epoch [3/4], Step [2040/3844], Loss: 0.0852\n",
      "Epoch [3/4], Step [2041/3844], Loss: 0.1368\n",
      "Epoch [3/4], Step [2042/3844], Loss: 0.1293\n",
      "Epoch [3/4], Step [2043/3844], Loss: 0.0922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/4], Step [2044/3844], Loss: 0.1177\n",
      "Epoch [3/4], Step [2045/3844], Loss: 0.1712\n",
      "Epoch [3/4], Step [2046/3844], Loss: 0.1693\n",
      "Epoch [3/4], Step [2047/3844], Loss: 0.0725\n",
      "Epoch [3/4], Step [2048/3844], Loss: 0.1392\n",
      "Epoch [3/4], Step [2049/3844], Loss: 0.1526\n",
      "Epoch [3/4], Step [2050/3844], Loss: 0.0901\n",
      "Epoch [3/4], Step [2051/3844], Loss: 0.1058\n",
      "Epoch [3/4], Step [2052/3844], Loss: 0.0581\n",
      "Epoch [3/4], Step [2053/3844], Loss: 0.0762\n",
      "Epoch [3/4], Step [2054/3844], Loss: 0.0728\n",
      "Epoch [3/4], Step [2055/3844], Loss: 0.1717\n",
      "Epoch [3/4], Step [2056/3844], Loss: 0.1098\n",
      "Epoch [3/4], Step [2057/3844], Loss: 0.0802\n",
      "Epoch [3/4], Step [2058/3844], Loss: 0.1176\n",
      "Epoch [3/4], Step [2059/3844], Loss: 0.1714\n",
      "Epoch [3/4], Step [2060/3844], Loss: 0.0678\n",
      "Epoch [3/4], Step [2061/3844], Loss: 0.0712\n",
      "Epoch [3/4], Step [2062/3844], Loss: 0.0991\n",
      "Epoch [3/4], Step [2063/3844], Loss: 0.1486\n",
      "Epoch [3/4], Step [2064/3844], Loss: 0.0896\n",
      "Epoch [3/4], Step [2065/3844], Loss: 0.1565\n",
      "Epoch [3/4], Step [2066/3844], Loss: 0.1274\n",
      "Epoch [3/4], Step [2067/3844], Loss: 0.1131\n",
      "Epoch [3/4], Step [2068/3844], Loss: 0.1362\n",
      "Epoch [3/4], Step [2069/3844], Loss: 0.0891\n",
      "Epoch [3/4], Step [2070/3844], Loss: 0.1039\n",
      "Epoch [3/4], Step [2071/3844], Loss: 0.1214\n",
      "Epoch [3/4], Step [2072/3844], Loss: 0.1253\n",
      "Epoch [3/4], Step [2073/3844], Loss: 0.1608\n",
      "Epoch [3/4], Step [2074/3844], Loss: 0.0975\n",
      "Epoch [3/4], Step [2075/3844], Loss: 0.0916\n",
      "Epoch [3/4], Step [2076/3844], Loss: 0.0969\n",
      "Epoch [3/4], Step [2077/3844], Loss: 0.0931\n",
      "Epoch [3/4], Step [2078/3844], Loss: 0.1116\n",
      "Epoch [3/4], Step [2079/3844], Loss: 0.0986\n",
      "Epoch [3/4], Step [2080/3844], Loss: 0.0883\n",
      "Epoch [3/4], Step [2081/3844], Loss: 0.0793\n",
      "Epoch [3/4], Step [2082/3844], Loss: 0.0865\n",
      "Epoch [3/4], Step [2083/3844], Loss: 0.1515\n",
      "Epoch [3/4], Step [2084/3844], Loss: 0.0715\n",
      "Epoch [3/4], Step [2085/3844], Loss: 0.1566\n",
      "Epoch [3/4], Step [2086/3844], Loss: 0.0797\n",
      "Epoch [3/4], Step [2087/3844], Loss: 0.0779\n",
      "Epoch [3/4], Step [2088/3844], Loss: 0.1527\n",
      "Epoch [3/4], Step [2089/3844], Loss: 0.0891\n",
      "Epoch [3/4], Step [2090/3844], Loss: 0.1018\n",
      "Epoch [3/4], Step [2091/3844], Loss: 0.1390\n",
      "Epoch [3/4], Step [2092/3844], Loss: 0.1470\n",
      "Epoch [3/4], Step [2093/3844], Loss: 0.0743\n",
      "Epoch [3/4], Step [2094/3844], Loss: 0.1200\n",
      "Epoch [3/4], Step [2095/3844], Loss: 0.1373\n",
      "Epoch [3/4], Step [2096/3844], Loss: 0.1336\n",
      "Epoch [3/4], Step [2097/3844], Loss: 0.1004\n",
      "Epoch [3/4], Step [2098/3844], Loss: 0.1093\n",
      "Epoch [3/4], Step [2099/3844], Loss: 0.1198\n",
      "Epoch [3/4], Step [2100/3844], Loss: 0.1444\n",
      "Epoch [3/4], Step [2101/3844], Loss: 0.1222\n",
      "Epoch [3/4], Step [2102/3844], Loss: 0.0727\n",
      "Epoch [3/4], Step [2103/3844], Loss: 0.0855\n",
      "Epoch [3/4], Step [2104/3844], Loss: 0.0706\n",
      "Epoch [3/4], Step [2105/3844], Loss: 0.1351\n",
      "Epoch [3/4], Step [2106/3844], Loss: 0.0821\n",
      "Epoch [3/4], Step [2107/3844], Loss: 0.0995\n",
      "Epoch [3/4], Step [2108/3844], Loss: 0.1159\n",
      "Epoch [3/4], Step [2109/3844], Loss: 0.0534\n",
      "Epoch [3/4], Step [2110/3844], Loss: 0.0733\n",
      "Epoch [3/4], Step [2111/3844], Loss: 0.0684\n",
      "Epoch [3/4], Step [2112/3844], Loss: 0.1086\n",
      "Epoch [3/4], Step [2113/3844], Loss: 0.0665\n",
      "Epoch [3/4], Step [2114/3844], Loss: 0.1056\n",
      "Epoch [3/4], Step [2115/3844], Loss: 0.1271\n",
      "Epoch [3/4], Step [2116/3844], Loss: 0.1509\n",
      "Epoch [3/4], Step [2117/3844], Loss: 0.1421\n",
      "Epoch [3/4], Step [2118/3844], Loss: 0.1511\n",
      "Epoch [3/4], Step [2119/3844], Loss: 0.1444\n",
      "Epoch [3/4], Step [2120/3844], Loss: 0.0889\n",
      "Epoch [3/4], Step [2121/3844], Loss: 0.1416\n",
      "Epoch [3/4], Step [2122/3844], Loss: 0.1624\n",
      "Epoch [3/4], Step [2123/3844], Loss: 0.1058\n",
      "Epoch [3/4], Step [2124/3844], Loss: 0.1031\n",
      "Epoch [3/4], Step [2125/3844], Loss: 0.1527\n",
      "Epoch [3/4], Step [2126/3844], Loss: 0.1627\n",
      "Epoch [3/4], Step [2127/3844], Loss: 0.0714\n",
      "Epoch [3/4], Step [2128/3844], Loss: 0.1365\n",
      "Epoch [3/4], Step [2129/3844], Loss: 0.1333\n",
      "Epoch [3/4], Step [2130/3844], Loss: 0.0876\n",
      "Epoch [3/4], Step [2131/3844], Loss: 0.1527\n",
      "Epoch [3/4], Step [2132/3844], Loss: 0.0670\n",
      "Epoch [3/4], Step [2133/3844], Loss: 0.0597\n",
      "Epoch [3/4], Step [2134/3844], Loss: 0.0823\n",
      "Epoch [3/4], Step [2135/3844], Loss: 0.0646\n",
      "Epoch [3/4], Step [2136/3844], Loss: 0.1130\n",
      "Epoch [3/4], Step [2137/3844], Loss: 0.0999\n",
      "Epoch [3/4], Step [2138/3844], Loss: 0.0780\n",
      "Epoch [3/4], Step [2139/3844], Loss: 0.1303\n",
      "Epoch [3/4], Step [2140/3844], Loss: 0.0844\n",
      "Epoch [3/4], Step [2141/3844], Loss: 0.1351\n",
      "Epoch [3/4], Step [2142/3844], Loss: 0.0929\n",
      "Epoch [3/4], Step [2143/3844], Loss: 0.0812\n",
      "Epoch [3/4], Step [2144/3844], Loss: 0.1328\n",
      "Epoch [3/4], Step [2145/3844], Loss: 0.0771\n",
      "Epoch [3/4], Step [2146/3844], Loss: 0.0688\n",
      "Epoch [3/4], Step [2147/3844], Loss: 0.1104\n",
      "Epoch [3/4], Step [2148/3844], Loss: 0.0757\n",
      "Epoch [3/4], Step [2149/3844], Loss: 0.0807\n",
      "Epoch [3/4], Step [2150/3844], Loss: 0.1731\n",
      "Epoch [3/4], Step [2151/3844], Loss: 0.0996\n",
      "Epoch [3/4], Step [2152/3844], Loss: 0.1022\n",
      "Epoch [3/4], Step [2153/3844], Loss: 0.1463\n",
      "Epoch [3/4], Step [2154/3844], Loss: 0.1330\n",
      "Epoch [3/4], Step [2155/3844], Loss: 0.0874\n",
      "Epoch [3/4], Step [2156/3844], Loss: 0.1496\n",
      "Epoch [3/4], Step [2157/3844], Loss: 0.1279\n",
      "Epoch [3/4], Step [2158/3844], Loss: 0.1272\n",
      "Epoch [3/4], Step [2159/3844], Loss: 0.0895\n",
      "Epoch [3/4], Step [2160/3844], Loss: 0.1251\n",
      "Epoch [3/4], Step [2161/3844], Loss: 0.1021\n",
      "Epoch [3/4], Step [2162/3844], Loss: 0.1462\n",
      "Epoch [3/4], Step [2163/3844], Loss: 0.0889\n",
      "Epoch [3/4], Step [2164/3844], Loss: 0.0975\n",
      "Epoch [3/4], Step [2165/3844], Loss: 0.1486\n",
      "Epoch [3/4], Step [2166/3844], Loss: 0.0917\n",
      "Epoch [3/4], Step [2167/3844], Loss: 0.0705\n",
      "Epoch [3/4], Step [2168/3844], Loss: 0.1375\n",
      "Epoch [3/4], Step [2169/3844], Loss: 0.1357\n",
      "Epoch [3/4], Step [2170/3844], Loss: 0.1008\n",
      "Epoch [3/4], Step [2171/3844], Loss: 0.1658\n",
      "Epoch [3/4], Step [2172/3844], Loss: 0.1435\n",
      "Epoch [3/4], Step [2173/3844], Loss: 0.1387\n",
      "Epoch [3/4], Step [2174/3844], Loss: 0.1100\n",
      "Epoch [3/4], Step [2175/3844], Loss: 0.0559\n",
      "Epoch [3/4], Step [2176/3844], Loss: 0.1067\n",
      "Epoch [3/4], Step [2177/3844], Loss: 0.0950\n",
      "Epoch [3/4], Step [2178/3844], Loss: 0.0959\n",
      "Epoch [3/4], Step [2179/3844], Loss: 0.1439\n",
      "Epoch [3/4], Step [2180/3844], Loss: 0.0842\n",
      "Epoch [3/4], Step [2181/3844], Loss: 0.1127\n",
      "Epoch [3/4], Step [2182/3844], Loss: 0.1204\n",
      "Epoch [3/4], Step [2183/3844], Loss: 0.1274\n",
      "Epoch [3/4], Step [2184/3844], Loss: 0.0972\n",
      "Epoch [3/4], Step [2185/3844], Loss: 0.0927\n",
      "Epoch [3/4], Step [2186/3844], Loss: 0.0971\n",
      "Epoch [3/4], Step [2187/3844], Loss: 0.1665\n",
      "Epoch [3/4], Step [2188/3844], Loss: 0.1205\n",
      "Epoch [3/4], Step [2189/3844], Loss: 0.0791\n",
      "Epoch [3/4], Step [2190/3844], Loss: 0.0963\n",
      "Epoch [3/4], Step [2191/3844], Loss: 0.1035\n",
      "Epoch [3/4], Step [2192/3844], Loss: 0.1584\n",
      "Epoch [3/4], Step [2193/3844], Loss: 0.1482\n",
      "Epoch [3/4], Step [2194/3844], Loss: 0.0812\n",
      "Epoch [3/4], Step [2195/3844], Loss: 0.0838\n",
      "Epoch [3/4], Step [2196/3844], Loss: 0.0835\n",
      "Epoch [3/4], Step [2197/3844], Loss: 0.0967\n",
      "Epoch [3/4], Step [2198/3844], Loss: 0.1330\n",
      "Epoch [3/4], Step [2199/3844], Loss: 0.0798\n",
      "Epoch [3/4], Step [2200/3844], Loss: 0.0854\n",
      "Epoch [3/4], Step [2201/3844], Loss: 0.1483\n",
      "Epoch [3/4], Step [2202/3844], Loss: 0.0804\n",
      "Epoch [3/4], Step [2203/3844], Loss: 0.0662\n",
      "Epoch [3/4], Step [2204/3844], Loss: 0.0786\n",
      "Epoch [3/4], Step [2205/3844], Loss: 0.0612\n",
      "Epoch [3/4], Step [2206/3844], Loss: 0.0895\n",
      "Epoch [3/4], Step [2207/3844], Loss: 0.1081\n",
      "Epoch [3/4], Step [2208/3844], Loss: 0.0936\n",
      "Epoch [3/4], Step [2209/3844], Loss: 0.1020\n",
      "Epoch [3/4], Step [2210/3844], Loss: 0.1338\n",
      "Epoch [3/4], Step [2211/3844], Loss: 0.1592\n",
      "Epoch [3/4], Step [2212/3844], Loss: 0.1421\n",
      "Epoch [3/4], Step [2213/3844], Loss: 0.1310\n",
      "Epoch [3/4], Step [2214/3844], Loss: 0.1239\n",
      "Epoch [3/4], Step [2215/3844], Loss: 0.0846\n",
      "Epoch [3/4], Step [2216/3844], Loss: 0.0954\n",
      "Epoch [3/4], Step [2217/3844], Loss: 0.0954\n",
      "Epoch [3/4], Step [2218/3844], Loss: 0.1037\n",
      "Epoch [3/4], Step [2219/3844], Loss: 0.1188\n",
      "Epoch [3/4], Step [2220/3844], Loss: 0.0663\n",
      "Epoch [3/4], Step [2221/3844], Loss: 0.0950\n",
      "Epoch [3/4], Step [2222/3844], Loss: 0.0827\n",
      "Epoch [3/4], Step [2223/3844], Loss: 0.0729\n",
      "Epoch [3/4], Step [2224/3844], Loss: 0.0636\n",
      "Epoch [3/4], Step [2225/3844], Loss: 0.0843\n",
      "Epoch [3/4], Step [2226/3844], Loss: 0.1192\n",
      "Epoch [3/4], Step [2227/3844], Loss: 0.1011\n",
      "Epoch [3/4], Step [2228/3844], Loss: 0.1290\n",
      "Epoch [3/4], Step [2229/3844], Loss: 0.0926\n",
      "Epoch [3/4], Step [2230/3844], Loss: 0.1630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/4], Step [2231/3844], Loss: 0.1051\n",
      "Epoch [3/4], Step [2232/3844], Loss: 0.0756\n",
      "Epoch [3/4], Step [2233/3844], Loss: 0.0954\n",
      "Epoch [3/4], Step [2234/3844], Loss: 0.1461\n",
      "Epoch [3/4], Step [2235/3844], Loss: 0.1495\n",
      "Epoch [3/4], Step [2236/3844], Loss: 0.0788\n",
      "Epoch [3/4], Step [2237/3844], Loss: 0.0957\n",
      "Epoch [3/4], Step [2238/3844], Loss: 0.0821\n",
      "Epoch [3/4], Step [2239/3844], Loss: 0.1443\n",
      "Epoch [3/4], Step [2240/3844], Loss: 0.1134\n",
      "Epoch [3/4], Step [2241/3844], Loss: 0.1223\n",
      "Epoch [3/4], Step [2242/3844], Loss: 0.0917\n",
      "Epoch [3/4], Step [2243/3844], Loss: 0.1074\n",
      "Epoch [3/4], Step [2244/3844], Loss: 0.1480\n",
      "Epoch [3/4], Step [2245/3844], Loss: 0.0970\n",
      "Epoch [3/4], Step [2246/3844], Loss: 0.1162\n",
      "Epoch [3/4], Step [2247/3844], Loss: 0.0719\n",
      "Epoch [3/4], Step [2248/3844], Loss: 0.0792\n",
      "Epoch [3/4], Step [2249/3844], Loss: 0.1708\n",
      "Epoch [3/4], Step [2250/3844], Loss: 0.1172\n",
      "Epoch [3/4], Step [2251/3844], Loss: 0.0972\n",
      "Epoch [3/4], Step [2252/3844], Loss: 0.0594\n",
      "Epoch [3/4], Step [2253/3844], Loss: 0.0740\n",
      "Epoch [3/4], Step [2254/3844], Loss: 0.0994\n",
      "Epoch [3/4], Step [2255/3844], Loss: 0.1291\n",
      "Epoch [3/4], Step [2256/3844], Loss: 0.1063\n",
      "Epoch [3/4], Step [2257/3844], Loss: 0.0858\n",
      "Epoch [3/4], Step [2258/3844], Loss: 0.1229\n",
      "Epoch [3/4], Step [2259/3844], Loss: 0.0929\n",
      "Epoch [3/4], Step [2260/3844], Loss: 0.1496\n",
      "Epoch [3/4], Step [2261/3844], Loss: 0.1184\n",
      "Epoch [3/4], Step [2262/3844], Loss: 0.0835\n",
      "Epoch [3/4], Step [2263/3844], Loss: 0.1241\n",
      "Epoch [3/4], Step [2264/3844], Loss: 0.1086\n",
      "Epoch [3/4], Step [2265/3844], Loss: 0.0890\n",
      "Epoch [3/4], Step [2266/3844], Loss: 0.0752\n",
      "Epoch [3/4], Step [2267/3844], Loss: 0.0672\n",
      "Epoch [3/4], Step [2268/3844], Loss: 0.1255\n",
      "Epoch [3/4], Step [2269/3844], Loss: 0.0795\n",
      "Epoch [3/4], Step [2270/3844], Loss: 0.0713\n",
      "Epoch [3/4], Step [2271/3844], Loss: 0.0916\n",
      "Epoch [3/4], Step [2272/3844], Loss: 0.1046\n",
      "Epoch [3/4], Step [2273/3844], Loss: 0.1594\n",
      "Epoch [3/4], Step [2274/3844], Loss: 0.1069\n",
      "Epoch [3/4], Step [2275/3844], Loss: 0.1109\n",
      "Epoch [3/4], Step [2276/3844], Loss: 0.1519\n",
      "Epoch [3/4], Step [2277/3844], Loss: 0.1216\n",
      "Epoch [3/4], Step [2278/3844], Loss: 0.1574\n",
      "Epoch [3/4], Step [2279/3844], Loss: 0.1026\n",
      "Epoch [3/4], Step [2280/3844], Loss: 0.1462\n",
      "Epoch [3/4], Step [2281/3844], Loss: 0.0879\n",
      "Epoch [3/4], Step [2282/3844], Loss: 0.0530\n",
      "Epoch [3/4], Step [2283/3844], Loss: 0.1380\n",
      "Epoch [3/4], Step [2284/3844], Loss: 0.0709\n",
      "Epoch [3/4], Step [2285/3844], Loss: 0.0790\n",
      "Epoch [3/4], Step [2286/3844], Loss: 0.1113\n",
      "Epoch [3/4], Step [2287/3844], Loss: 0.1594\n",
      "Epoch [3/4], Step [2288/3844], Loss: 0.0976\n",
      "Epoch [3/4], Step [2289/3844], Loss: 0.0925\n",
      "Epoch [3/4], Step [2290/3844], Loss: 0.1631\n",
      "Epoch [3/4], Step [2291/3844], Loss: 0.0736\n",
      "Epoch [3/4], Step [2292/3844], Loss: 0.0719\n",
      "Epoch [3/4], Step [2293/3844], Loss: 0.1690\n",
      "Epoch [3/4], Step [2294/3844], Loss: 0.1735\n",
      "Epoch [3/4], Step [2295/3844], Loss: 0.1111\n",
      "Epoch [3/4], Step [2296/3844], Loss: 0.1017\n",
      "Epoch [3/4], Step [2297/3844], Loss: 0.1154\n",
      "Epoch [3/4], Step [2298/3844], Loss: 0.0997\n",
      "Epoch [3/4], Step [2299/3844], Loss: 0.1611\n",
      "Epoch [3/4], Step [2300/3844], Loss: 0.1509\n",
      "Epoch [3/4], Step [2301/3844], Loss: 0.1089\n",
      "Epoch [3/4], Step [2302/3844], Loss: 0.1566\n",
      "Epoch [3/4], Step [2303/3844], Loss: 0.1168\n",
      "Epoch [3/4], Step [2304/3844], Loss: 0.1676\n",
      "Epoch [3/4], Step [2305/3844], Loss: 0.0917\n",
      "Epoch [3/4], Step [2306/3844], Loss: 0.1283\n",
      "Epoch [3/4], Step [2307/3844], Loss: 0.1396\n",
      "Epoch [3/4], Step [2308/3844], Loss: 0.0721\n",
      "Epoch [3/4], Step [2309/3844], Loss: 0.1483\n",
      "Epoch [3/4], Step [2310/3844], Loss: 0.1504\n",
      "Epoch [3/4], Step [2311/3844], Loss: 0.1215\n",
      "Epoch [3/4], Step [2312/3844], Loss: 0.1159\n",
      "Epoch [3/4], Step [2313/3844], Loss: 0.1382\n",
      "Epoch [3/4], Step [2314/3844], Loss: 0.0847\n",
      "Epoch [3/4], Step [2315/3844], Loss: 0.1096\n",
      "Epoch [3/4], Step [2316/3844], Loss: 0.0714\n",
      "Epoch [3/4], Step [2317/3844], Loss: 0.0794\n",
      "Epoch [3/4], Step [2318/3844], Loss: 0.1073\n",
      "Epoch [3/4], Step [2319/3844], Loss: 0.0914\n",
      "Epoch [3/4], Step [2320/3844], Loss: 0.1238\n",
      "Epoch [3/4], Step [2321/3844], Loss: 0.0790\n",
      "Epoch [3/4], Step [2322/3844], Loss: 0.1450\n",
      "Epoch [3/4], Step [2323/3844], Loss: 0.1253\n",
      "Epoch [3/4], Step [2324/3844], Loss: 0.1186\n",
      "Epoch [3/4], Step [2325/3844], Loss: 0.0732\n",
      "Epoch [3/4], Step [2326/3844], Loss: 0.0763\n",
      "Epoch [3/4], Step [2327/3844], Loss: 0.1290\n",
      "Epoch [3/4], Step [2328/3844], Loss: 0.1114\n",
      "Epoch [3/4], Step [2329/3844], Loss: 0.1004\n",
      "Epoch [3/4], Step [2330/3844], Loss: 0.1346\n",
      "Epoch [3/4], Step [2331/3844], Loss: 0.0741\n",
      "Epoch [3/4], Step [2332/3844], Loss: 0.0809\n",
      "Epoch [3/4], Step [2333/3844], Loss: 0.0787\n",
      "Epoch [3/4], Step [2334/3844], Loss: 0.0775\n",
      "Epoch [3/4], Step [2335/3844], Loss: 0.1839\n",
      "Epoch [3/4], Step [2336/3844], Loss: 0.0797\n",
      "Epoch [3/4], Step [2337/3844], Loss: 0.0894\n",
      "Epoch [3/4], Step [2338/3844], Loss: 0.1138\n",
      "Epoch [3/4], Step [2339/3844], Loss: 0.0905\n",
      "Epoch [3/4], Step [2340/3844], Loss: 0.0948\n",
      "Epoch [3/4], Step [2341/3844], Loss: 0.0773\n",
      "Epoch [3/4], Step [2342/3844], Loss: 0.1060\n",
      "Epoch [3/4], Step [2343/3844], Loss: 0.1579\n",
      "Epoch [3/4], Step [2344/3844], Loss: 0.1317\n",
      "Epoch [3/4], Step [2345/3844], Loss: 0.0711\n",
      "Epoch [3/4], Step [2346/3844], Loss: 0.1741\n",
      "Epoch [3/4], Step [2347/3844], Loss: 0.1271\n",
      "Epoch [3/4], Step [2348/3844], Loss: 0.0652\n",
      "Epoch [3/4], Step [2349/3844], Loss: 0.1500\n",
      "Epoch [3/4], Step [2350/3844], Loss: 0.1506\n",
      "Epoch [3/4], Step [2351/3844], Loss: 0.0806\n",
      "Epoch [3/4], Step [2352/3844], Loss: 0.1477\n",
      "Epoch [3/4], Step [2353/3844], Loss: 0.0984\n",
      "Epoch [3/4], Step [2354/3844], Loss: 0.1000\n",
      "Epoch [3/4], Step [2355/3844], Loss: 0.1258\n",
      "Epoch [3/4], Step [2356/3844], Loss: 0.1031\n",
      "Epoch [3/4], Step [2357/3844], Loss: 0.1684\n",
      "Epoch [3/4], Step [2358/3844], Loss: 0.1296\n",
      "Epoch [3/4], Step [2359/3844], Loss: 0.1449\n",
      "Epoch [3/4], Step [2360/3844], Loss: 0.0869\n",
      "Epoch [3/4], Step [2361/3844], Loss: 0.1460\n",
      "Epoch [3/4], Step [2362/3844], Loss: 0.0813\n",
      "Epoch [3/4], Step [2363/3844], Loss: 0.1242\n",
      "Epoch [3/4], Step [2364/3844], Loss: 0.1222\n",
      "Epoch [3/4], Step [2365/3844], Loss: 0.1309\n",
      "Epoch [3/4], Step [2366/3844], Loss: 0.0770\n",
      "Epoch [3/4], Step [2367/3844], Loss: 0.1268\n",
      "Epoch [3/4], Step [2368/3844], Loss: 0.2073\n",
      "Epoch [3/4], Step [2369/3844], Loss: 0.1716\n",
      "Epoch [3/4], Step [2370/3844], Loss: 0.0811\n",
      "Epoch [3/4], Step [2371/3844], Loss: 0.0821\n",
      "Epoch [3/4], Step [2372/3844], Loss: 0.1068\n",
      "Epoch [3/4], Step [2373/3844], Loss: 0.0735\n",
      "Epoch [3/4], Step [2374/3844], Loss: 0.1025\n",
      "Epoch [3/4], Step [2375/3844], Loss: 0.1470\n",
      "Epoch [3/4], Step [2376/3844], Loss: 0.0675\n",
      "Epoch [3/4], Step [2377/3844], Loss: 0.0942\n",
      "Epoch [3/4], Step [2378/3844], Loss: 0.1109\n",
      "Epoch [3/4], Step [2379/3844], Loss: 0.1406\n",
      "Epoch [3/4], Step [2380/3844], Loss: 0.0852\n",
      "Epoch [3/4], Step [2381/3844], Loss: 0.0574\n",
      "Epoch [3/4], Step [2382/3844], Loss: 0.0824\n",
      "Epoch [3/4], Step [2383/3844], Loss: 0.0967\n",
      "Epoch [3/4], Step [2384/3844], Loss: 0.1076\n",
      "Epoch [3/4], Step [2385/3844], Loss: 0.1309\n",
      "Epoch [3/4], Step [2386/3844], Loss: 0.1478\n",
      "Epoch [3/4], Step [2387/3844], Loss: 0.0711\n",
      "Epoch [3/4], Step [2388/3844], Loss: 0.1150\n",
      "Epoch [3/4], Step [2389/3844], Loss: 0.1224\n",
      "Epoch [3/4], Step [2390/3844], Loss: 0.0690\n",
      "Epoch [3/4], Step [2391/3844], Loss: 0.1588\n",
      "Epoch [3/4], Step [2392/3844], Loss: 0.0772\n",
      "Epoch [3/4], Step [2393/3844], Loss: 0.1223\n",
      "Epoch [3/4], Step [2394/3844], Loss: 0.1102\n",
      "Epoch [3/4], Step [2395/3844], Loss: 0.1106\n",
      "Epoch [3/4], Step [2396/3844], Loss: 0.0750\n",
      "Epoch [3/4], Step [2397/3844], Loss: 0.1676\n",
      "Epoch [3/4], Step [2398/3844], Loss: 0.1142\n",
      "Epoch [3/4], Step [2399/3844], Loss: 0.1049\n",
      "Epoch [3/4], Step [2400/3844], Loss: 0.0881\n",
      "Epoch [3/4], Step [2401/3844], Loss: 0.1495\n",
      "Epoch [3/4], Step [2402/3844], Loss: 0.1289\n",
      "Epoch [3/4], Step [2403/3844], Loss: 0.1518\n",
      "Epoch [3/4], Step [2404/3844], Loss: 0.0746\n",
      "Epoch [3/4], Step [2405/3844], Loss: 0.1616\n",
      "Epoch [3/4], Step [2406/3844], Loss: 0.1550\n",
      "Epoch [3/4], Step [2407/3844], Loss: 0.0780\n",
      "Epoch [3/4], Step [2408/3844], Loss: 0.0714\n",
      "Epoch [3/4], Step [2409/3844], Loss: 0.0977\n",
      "Epoch [3/4], Step [2410/3844], Loss: 0.0813\n",
      "Epoch [3/4], Step [2411/3844], Loss: 0.1472\n",
      "Epoch [3/4], Step [2412/3844], Loss: 0.1874\n",
      "Epoch [3/4], Step [2413/3844], Loss: 0.0705\n",
      "Epoch [3/4], Step [2414/3844], Loss: 0.0852\n",
      "Epoch [3/4], Step [2415/3844], Loss: 0.1402\n",
      "Epoch [3/4], Step [2416/3844], Loss: 0.1777\n",
      "Epoch [3/4], Step [2417/3844], Loss: 0.0800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/4], Step [2418/3844], Loss: 0.0804\n",
      "Epoch [3/4], Step [2419/3844], Loss: 0.1233\n",
      "Epoch [3/4], Step [2420/3844], Loss: 0.1010\n",
      "Epoch [3/4], Step [2421/3844], Loss: 0.1032\n",
      "Epoch [3/4], Step [2422/3844], Loss: 0.0827\n",
      "Epoch [3/4], Step [2423/3844], Loss: 0.0701\n",
      "Epoch [3/4], Step [2424/3844], Loss: 0.1160\n",
      "Epoch [3/4], Step [2425/3844], Loss: 0.1216\n",
      "Epoch [3/4], Step [2426/3844], Loss: 0.0800\n",
      "Epoch [3/4], Step [2427/3844], Loss: 0.0703\n",
      "Epoch [3/4], Step [2428/3844], Loss: 0.1246\n",
      "Epoch [3/4], Step [2429/3844], Loss: 0.0662\n",
      "Epoch [3/4], Step [2430/3844], Loss: 0.1010\n",
      "Epoch [3/4], Step [2431/3844], Loss: 0.0757\n",
      "Epoch [3/4], Step [2432/3844], Loss: 0.0649\n",
      "Epoch [3/4], Step [2433/3844], Loss: 0.0866\n",
      "Epoch [3/4], Step [2434/3844], Loss: 0.1167\n",
      "Epoch [3/4], Step [2435/3844], Loss: 0.1009\n",
      "Epoch [3/4], Step [2436/3844], Loss: 0.1280\n",
      "Epoch [3/4], Step [2437/3844], Loss: 0.1125\n",
      "Epoch [3/4], Step [2438/3844], Loss: 0.1172\n",
      "Epoch [3/4], Step [2439/3844], Loss: 0.0605\n",
      "Epoch [3/4], Step [2440/3844], Loss: 0.1136\n",
      "Epoch [3/4], Step [2441/3844], Loss: 0.1672\n",
      "Epoch [3/4], Step [2442/3844], Loss: 0.1646\n",
      "Epoch [3/4], Step [2443/3844], Loss: 0.0921\n",
      "Epoch [3/4], Step [2444/3844], Loss: 0.0621\n",
      "Epoch [3/4], Step [2445/3844], Loss: 0.1037\n",
      "Epoch [3/4], Step [2446/3844], Loss: 0.1361\n",
      "Epoch [3/4], Step [2447/3844], Loss: 0.0777\n",
      "Epoch [3/4], Step [2448/3844], Loss: 0.1463\n",
      "Epoch [3/4], Step [2449/3844], Loss: 0.0694\n",
      "Epoch [3/4], Step [2450/3844], Loss: 0.0853\n",
      "Epoch [3/4], Step [2451/3844], Loss: 0.0668\n",
      "Epoch [3/4], Step [2452/3844], Loss: 0.1260\n",
      "Epoch [3/4], Step [2453/3844], Loss: 0.1072\n",
      "Epoch [3/4], Step [2454/3844], Loss: 0.1545\n",
      "Epoch [3/4], Step [2455/3844], Loss: 0.0665\n",
      "Epoch [3/4], Step [2456/3844], Loss: 0.1643\n",
      "Epoch [3/4], Step [2457/3844], Loss: 0.0332\n",
      "Epoch [3/4], Step [2458/3844], Loss: 0.0488\n",
      "Epoch [3/4], Step [2459/3844], Loss: 0.1717\n",
      "Epoch [3/4], Step [2460/3844], Loss: 0.1522\n",
      "Epoch [3/4], Step [2461/3844], Loss: 0.1225\n",
      "Epoch [3/4], Step [2462/3844], Loss: 0.0525\n",
      "Epoch [3/4], Step [2463/3844], Loss: 0.1209\n",
      "Epoch [3/4], Step [2464/3844], Loss: 0.1455\n",
      "Epoch [3/4], Step [2465/3844], Loss: 0.0685\n",
      "Epoch [3/4], Step [2466/3844], Loss: 0.1433\n",
      "Epoch [3/4], Step [2467/3844], Loss: 0.1744\n",
      "Epoch [3/4], Step [2468/3844], Loss: 0.0706\n",
      "Epoch [3/4], Step [2469/3844], Loss: 0.1281\n",
      "Epoch [3/4], Step [2470/3844], Loss: 0.0968\n",
      "Epoch [3/4], Step [2471/3844], Loss: 0.1708\n",
      "Epoch [3/4], Step [2472/3844], Loss: 0.1064\n",
      "Epoch [3/4], Step [2473/3844], Loss: 0.1109\n",
      "Epoch [3/4], Step [2474/3844], Loss: 0.1638\n",
      "Epoch [3/4], Step [2475/3844], Loss: 0.0756\n",
      "Epoch [3/4], Step [2476/3844], Loss: 0.1000\n",
      "Epoch [3/4], Step [2477/3844], Loss: 0.0785\n",
      "Epoch [3/4], Step [2478/3844], Loss: 0.0826\n",
      "Epoch [3/4], Step [2479/3844], Loss: 0.0898\n",
      "Epoch [3/4], Step [2480/3844], Loss: 0.0973\n",
      "Epoch [3/4], Step [2481/3844], Loss: 0.1530\n",
      "Epoch [3/4], Step [2482/3844], Loss: 0.1035\n",
      "Epoch [3/4], Step [2483/3844], Loss: 0.1227\n",
      "Epoch [3/4], Step [2484/3844], Loss: 0.1009\n",
      "Epoch [3/4], Step [2485/3844], Loss: 0.1144\n",
      "Epoch [3/4], Step [2486/3844], Loss: 0.1354\n",
      "Epoch [3/4], Step [2487/3844], Loss: 0.1326\n",
      "Epoch [3/4], Step [2488/3844], Loss: 0.0940\n",
      "Epoch [3/4], Step [2489/3844], Loss: 0.1019\n",
      "Epoch [3/4], Step [2490/3844], Loss: 0.0914\n",
      "Epoch [3/4], Step [2491/3844], Loss: 0.0728\n",
      "Epoch [3/4], Step [2492/3844], Loss: 0.0954\n",
      "Epoch [3/4], Step [2493/3844], Loss: 0.1265\n",
      "Epoch [3/4], Step [2494/3844], Loss: 0.0855\n",
      "Epoch [3/4], Step [2495/3844], Loss: 0.0968\n",
      "Epoch [3/4], Step [2496/3844], Loss: 0.1775\n",
      "Epoch [3/4], Step [2497/3844], Loss: 0.0721\n",
      "Epoch [3/4], Step [2498/3844], Loss: 0.0861\n",
      "Epoch [3/4], Step [2499/3844], Loss: 0.0853\n",
      "Epoch [3/4], Step [2500/3844], Loss: 0.0869\n",
      "Epoch [3/4], Step [2501/3844], Loss: 0.0995\n",
      "Epoch [3/4], Step [2502/3844], Loss: 0.0657\n",
      "Epoch [3/4], Step [2503/3844], Loss: 0.1413\n",
      "Epoch [3/4], Step [2504/3844], Loss: 0.0723\n",
      "Epoch [3/4], Step [2505/3844], Loss: 0.1034\n",
      "Epoch [3/4], Step [2506/3844], Loss: 0.0978\n",
      "Epoch [3/4], Step [2507/3844], Loss: 0.0906\n",
      "Epoch [3/4], Step [2508/3844], Loss: 0.0815\n",
      "Epoch [3/4], Step [2509/3844], Loss: 0.1208\n",
      "Epoch [3/4], Step [2510/3844], Loss: 0.0860\n",
      "Epoch [3/4], Step [2511/3844], Loss: 0.1157\n",
      "Epoch [3/4], Step [2512/3844], Loss: 0.0846\n",
      "Epoch [3/4], Step [2513/3844], Loss: 0.0911\n",
      "Epoch [3/4], Step [2514/3844], Loss: 0.1376\n",
      "Epoch [3/4], Step [2515/3844], Loss: 0.0938\n",
      "Epoch [3/4], Step [2516/3844], Loss: 0.1014\n",
      "Epoch [3/4], Step [2517/3844], Loss: 0.1439\n",
      "Epoch [3/4], Step [2518/3844], Loss: 0.1227\n",
      "Epoch [3/4], Step [2519/3844], Loss: 0.0936\n",
      "Epoch [3/4], Step [2520/3844], Loss: 0.0919\n",
      "Epoch [3/4], Step [2521/3844], Loss: 0.1435\n",
      "Epoch [3/4], Step [2522/3844], Loss: 0.0906\n",
      "Epoch [3/4], Step [2523/3844], Loss: 0.0887\n",
      "Epoch [3/4], Step [2524/3844], Loss: 0.1558\n",
      "Epoch [3/4], Step [2525/3844], Loss: 0.1062\n",
      "Epoch [3/4], Step [2526/3844], Loss: 0.1312\n",
      "Epoch [3/4], Step [2527/3844], Loss: 0.0841\n",
      "Epoch [3/4], Step [2528/3844], Loss: 0.1112\n",
      "Epoch [3/4], Step [2529/3844], Loss: 0.1249\n",
      "Epoch [3/4], Step [2530/3844], Loss: 0.0774\n",
      "Epoch [3/4], Step [2531/3844], Loss: 0.1390\n",
      "Epoch [3/4], Step [2532/3844], Loss: 0.0708\n",
      "Epoch [3/4], Step [2533/3844], Loss: 0.1151\n",
      "Epoch [3/4], Step [2534/3844], Loss: 0.1280\n",
      "Epoch [3/4], Step [2535/3844], Loss: 0.1137\n",
      "Epoch [3/4], Step [2536/3844], Loss: 0.1287\n",
      "Epoch [3/4], Step [2537/3844], Loss: 0.0987\n",
      "Epoch [3/4], Step [2538/3844], Loss: 0.0751\n",
      "Epoch [3/4], Step [2539/3844], Loss: 0.0810\n",
      "Epoch [3/4], Step [2540/3844], Loss: 0.1251\n",
      "Epoch [3/4], Step [2541/3844], Loss: 0.1389\n",
      "Epoch [3/4], Step [2542/3844], Loss: 0.1324\n",
      "Epoch [3/4], Step [2543/3844], Loss: 0.0963\n",
      "Epoch [3/4], Step [2544/3844], Loss: 0.1241\n",
      "Epoch [3/4], Step [2545/3844], Loss: 0.1282\n",
      "Epoch [3/4], Step [2546/3844], Loss: 0.0685\n",
      "Epoch [3/4], Step [2547/3844], Loss: 0.0900\n",
      "Epoch [3/4], Step [2548/3844], Loss: 0.0912\n",
      "Epoch [3/4], Step [2549/3844], Loss: 0.0832\n",
      "Epoch [3/4], Step [2550/3844], Loss: 0.1061\n",
      "Epoch [3/4], Step [2551/3844], Loss: 0.0757\n",
      "Epoch [3/4], Step [2552/3844], Loss: 0.0440\n",
      "Epoch [3/4], Step [2553/3844], Loss: 0.0805\n",
      "Epoch [3/4], Step [2554/3844], Loss: 0.0435\n",
      "Epoch [3/4], Step [2555/3844], Loss: 0.1180\n",
      "Epoch [3/4], Step [2556/3844], Loss: 0.1503\n",
      "Epoch [3/4], Step [2557/3844], Loss: 0.1064\n",
      "Epoch [3/4], Step [2558/3844], Loss: 0.1178\n",
      "Epoch [3/4], Step [2559/3844], Loss: 0.0539\n",
      "Epoch [3/4], Step [2560/3844], Loss: 0.1359\n",
      "Epoch [3/4], Step [2561/3844], Loss: 0.1615\n",
      "Epoch [3/4], Step [2562/3844], Loss: 0.0973\n",
      "Epoch [3/4], Step [2563/3844], Loss: 0.0546\n",
      "Epoch [3/4], Step [2564/3844], Loss: 0.1748\n",
      "Epoch [3/4], Step [2565/3844], Loss: 0.0887\n",
      "Epoch [3/4], Step [2566/3844], Loss: 0.0813\n",
      "Epoch [3/4], Step [2567/3844], Loss: 0.0843\n",
      "Epoch [3/4], Step [2568/3844], Loss: 0.1120\n",
      "Epoch [3/4], Step [2569/3844], Loss: 0.1194\n",
      "Epoch [3/4], Step [2570/3844], Loss: 0.0744\n",
      "Epoch [3/4], Step [2571/3844], Loss: 0.0819\n",
      "Epoch [3/4], Step [2572/3844], Loss: 0.1069\n",
      "Epoch [3/4], Step [2573/3844], Loss: 0.0684\n",
      "Epoch [3/4], Step [2574/3844], Loss: 0.0695\n",
      "Epoch [3/4], Step [2575/3844], Loss: 0.0806\n",
      "Epoch [3/4], Step [2576/3844], Loss: 0.1374\n",
      "Epoch [3/4], Step [2577/3844], Loss: 0.0764\n",
      "Epoch [3/4], Step [2578/3844], Loss: 0.1528\n",
      "Epoch [3/4], Step [2579/3844], Loss: 0.0613\n",
      "Epoch [3/4], Step [2580/3844], Loss: 0.0710\n",
      "Epoch [3/4], Step [2581/3844], Loss: 0.1623\n",
      "Epoch [3/4], Step [2582/3844], Loss: 0.1505\n",
      "Epoch [3/4], Step [2583/3844], Loss: 0.1543\n",
      "Epoch [3/4], Step [2584/3844], Loss: 0.1201\n",
      "Epoch [3/4], Step [2585/3844], Loss: 0.1176\n",
      "Epoch [3/4], Step [2586/3844], Loss: 0.0893\n",
      "Epoch [3/4], Step [2587/3844], Loss: 0.1324\n",
      "Epoch [3/4], Step [2588/3844], Loss: 0.0883\n",
      "Epoch [3/4], Step [2589/3844], Loss: 0.1165\n",
      "Epoch [3/4], Step [2590/3844], Loss: 0.1610\n",
      "Epoch [3/4], Step [2591/3844], Loss: 0.0891\n",
      "Epoch [3/4], Step [2592/3844], Loss: 0.0776\n",
      "Epoch [3/4], Step [2593/3844], Loss: 0.0928\n",
      "Epoch [3/4], Step [2594/3844], Loss: 0.0916\n",
      "Epoch [3/4], Step [2595/3844], Loss: 0.1239\n",
      "Epoch [3/4], Step [2596/3844], Loss: 0.1112\n",
      "Epoch [3/4], Step [2597/3844], Loss: 0.1147\n",
      "Epoch [3/4], Step [2598/3844], Loss: 0.1550\n",
      "Epoch [3/4], Step [2599/3844], Loss: 0.1204\n",
      "Epoch [3/4], Step [2600/3844], Loss: 0.0798\n",
      "Epoch [3/4], Step [2601/3844], Loss: 0.0758\n",
      "Epoch [3/4], Step [2602/3844], Loss: 0.0741\n",
      "Epoch [3/4], Step [2603/3844], Loss: 0.0990\n",
      "Epoch [3/4], Step [2604/3844], Loss: 0.0580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/4], Step [2605/3844], Loss: 0.0745\n",
      "Epoch [3/4], Step [2606/3844], Loss: 0.0814\n",
      "Epoch [3/4], Step [2607/3844], Loss: 0.0682\n",
      "Epoch [3/4], Step [2608/3844], Loss: 0.1546\n",
      "Epoch [3/4], Step [2609/3844], Loss: 0.1327\n",
      "Epoch [3/4], Step [2610/3844], Loss: 0.0580\n",
      "Epoch [3/4], Step [2611/3844], Loss: 0.1230\n",
      "Epoch [3/4], Step [2612/3844], Loss: 0.0860\n",
      "Epoch [3/4], Step [2613/3844], Loss: 0.0587\n",
      "Epoch [3/4], Step [2614/3844], Loss: 0.1170\n",
      "Epoch [3/4], Step [2615/3844], Loss: 0.1284\n",
      "Epoch [3/4], Step [2616/3844], Loss: 0.1187\n",
      "Epoch [3/4], Step [2617/3844], Loss: 0.0927\n",
      "Epoch [3/4], Step [2618/3844], Loss: 0.1130\n",
      "Epoch [3/4], Step [2619/3844], Loss: 0.1165\n",
      "Epoch [3/4], Step [2620/3844], Loss: 0.1362\n",
      "Epoch [3/4], Step [2621/3844], Loss: 0.1601\n",
      "Epoch [3/4], Step [2622/3844], Loss: 0.0963\n",
      "Epoch [3/4], Step [2623/3844], Loss: 0.0984\n",
      "Epoch [3/4], Step [2624/3844], Loss: 0.0815\n",
      "Epoch [3/4], Step [2625/3844], Loss: 0.0739\n",
      "Epoch [3/4], Step [2626/3844], Loss: 0.0970\n",
      "Epoch [3/4], Step [2627/3844], Loss: 0.0431\n",
      "Epoch [3/4], Step [2628/3844], Loss: 0.1042\n",
      "Epoch [3/4], Step [2629/3844], Loss: 0.1723\n",
      "Epoch [3/4], Step [2630/3844], Loss: 0.1220\n",
      "Epoch [3/4], Step [2631/3844], Loss: 0.0473\n",
      "Epoch [3/4], Step [2632/3844], Loss: 0.1648\n",
      "Epoch [3/4], Step [2633/3844], Loss: 0.0754\n",
      "Epoch [3/4], Step [2634/3844], Loss: 0.1211\n",
      "Epoch [3/4], Step [2635/3844], Loss: 0.0765\n",
      "Epoch [3/4], Step [2636/3844], Loss: 0.1005\n",
      "Epoch [3/4], Step [2637/3844], Loss: 0.1327\n",
      "Epoch [3/4], Step [2638/3844], Loss: 0.1160\n",
      "Epoch [3/4], Step [2639/3844], Loss: 0.1439\n",
      "Epoch [3/4], Step [2640/3844], Loss: 0.1591\n",
      "Epoch [3/4], Step [2641/3844], Loss: 0.1691\n",
      "Epoch [3/4], Step [2642/3844], Loss: 0.0805\n",
      "Epoch [3/4], Step [2643/3844], Loss: 0.0792\n",
      "Epoch [3/4], Step [2644/3844], Loss: 0.1338\n",
      "Epoch [3/4], Step [2645/3844], Loss: 0.1514\n",
      "Epoch [3/4], Step [2646/3844], Loss: 0.0908\n",
      "Epoch [3/4], Step [2647/3844], Loss: 0.0845\n",
      "Epoch [3/4], Step [2648/3844], Loss: 0.1123\n",
      "Epoch [3/4], Step [2649/3844], Loss: 0.1181\n",
      "Epoch [3/4], Step [2650/3844], Loss: 0.1682\n",
      "Epoch [3/4], Step [2651/3844], Loss: 0.0781\n",
      "Epoch [3/4], Step [2652/3844], Loss: 0.1525\n",
      "Epoch [3/4], Step [2653/3844], Loss: 0.1486\n",
      "Epoch [3/4], Step [2654/3844], Loss: 0.0477\n",
      "Epoch [3/4], Step [2655/3844], Loss: 0.0981\n",
      "Epoch [3/4], Step [2656/3844], Loss: 0.1042\n",
      "Epoch [3/4], Step [2657/3844], Loss: 0.0914\n",
      "Epoch [3/4], Step [2658/3844], Loss: 0.1480\n",
      "Epoch [3/4], Step [2659/3844], Loss: 0.1499\n",
      "Epoch [3/4], Step [2660/3844], Loss: 0.0999\n",
      "Epoch [3/4], Step [2661/3844], Loss: 0.1222\n",
      "Epoch [3/4], Step [2662/3844], Loss: 0.1250\n",
      "Epoch [3/4], Step [2663/3844], Loss: 0.0851\n",
      "Epoch [3/4], Step [2664/3844], Loss: 0.1552\n",
      "Epoch [3/4], Step [2665/3844], Loss: 0.1658\n",
      "Epoch [3/4], Step [2666/3844], Loss: 0.0516\n",
      "Epoch [3/4], Step [2667/3844], Loss: 0.1548\n",
      "Epoch [3/4], Step [2668/3844], Loss: 0.1125\n",
      "Epoch [3/4], Step [2669/3844], Loss: 0.0729\n",
      "Epoch [3/4], Step [2670/3844], Loss: 0.1446\n",
      "Epoch [3/4], Step [2671/3844], Loss: 0.1198\n",
      "Epoch [3/4], Step [2672/3844], Loss: 0.1569\n",
      "Epoch [3/4], Step [2673/3844], Loss: 0.1697\n",
      "Epoch [3/4], Step [2674/3844], Loss: 0.1469\n",
      "Epoch [3/4], Step [2675/3844], Loss: 0.1109\n",
      "Epoch [3/4], Step [2676/3844], Loss: 0.0461\n",
      "Epoch [3/4], Step [2677/3844], Loss: 0.0833\n",
      "Epoch [3/4], Step [2678/3844], Loss: 0.1412\n",
      "Epoch [3/4], Step [2679/3844], Loss: 0.0735\n",
      "Epoch [3/4], Step [2680/3844], Loss: 0.1251\n",
      "Epoch [3/4], Step [2681/3844], Loss: 0.1285\n",
      "Epoch [3/4], Step [2682/3844], Loss: 0.0814\n",
      "Epoch [3/4], Step [2683/3844], Loss: 0.0660\n",
      "Epoch [3/4], Step [2684/3844], Loss: 0.1349\n",
      "Epoch [3/4], Step [2685/3844], Loss: 0.0959\n",
      "Epoch [3/4], Step [2686/3844], Loss: 0.0606\n",
      "Epoch [3/4], Step [2687/3844], Loss: 0.1187\n",
      "Epoch [3/4], Step [2688/3844], Loss: 0.1149\n",
      "Epoch [3/4], Step [2689/3844], Loss: 0.1458\n",
      "Epoch [3/4], Step [2690/3844], Loss: 0.0938\n",
      "Epoch [3/4], Step [2691/3844], Loss: 0.1015\n",
      "Epoch [3/4], Step [2692/3844], Loss: 0.0898\n",
      "Epoch [3/4], Step [2693/3844], Loss: 0.0947\n",
      "Epoch [3/4], Step [2694/3844], Loss: 0.0791\n",
      "Epoch [3/4], Step [2695/3844], Loss: 0.0780\n",
      "Epoch [3/4], Step [2696/3844], Loss: 0.0704\n",
      "Epoch [3/4], Step [2697/3844], Loss: 0.1193\n",
      "Epoch [3/4], Step [2698/3844], Loss: 0.1083\n",
      "Epoch [3/4], Step [2699/3844], Loss: 0.0565\n",
      "Epoch [3/4], Step [2700/3844], Loss: 0.1665\n",
      "Epoch [3/4], Step [2701/3844], Loss: 0.1568\n",
      "Epoch [3/4], Step [2702/3844], Loss: 0.0622\n",
      "Epoch [3/4], Step [2703/3844], Loss: 0.0705\n",
      "Epoch [3/4], Step [2704/3844], Loss: 0.0993\n",
      "Epoch [3/4], Step [2705/3844], Loss: 0.0643\n",
      "Epoch [3/4], Step [2706/3844], Loss: 0.0476\n",
      "Epoch [3/4], Step [2707/3844], Loss: 0.0655\n",
      "Epoch [3/4], Step [2708/3844], Loss: 0.1689\n",
      "Epoch [3/4], Step [2709/3844], Loss: 0.1403\n",
      "Epoch [3/4], Step [2710/3844], Loss: 0.0773\n",
      "Epoch [3/4], Step [2711/3844], Loss: 0.0479\n",
      "Epoch [3/4], Step [2712/3844], Loss: 0.0926\n",
      "Epoch [3/4], Step [2713/3844], Loss: 0.1021\n",
      "Epoch [3/4], Step [2714/3844], Loss: 0.1386\n",
      "Epoch [3/4], Step [2715/3844], Loss: 0.1247\n",
      "Epoch [3/4], Step [2716/3844], Loss: 0.1091\n",
      "Epoch [3/4], Step [2717/3844], Loss: 0.0987\n",
      "Epoch [3/4], Step [2718/3844], Loss: 0.0915\n",
      "Epoch [3/4], Step [2719/3844], Loss: 0.0910\n",
      "Epoch [3/4], Step [2720/3844], Loss: 0.1619\n",
      "Epoch [3/4], Step [2721/3844], Loss: 0.1721\n",
      "Epoch [3/4], Step [2722/3844], Loss: 0.1060\n",
      "Epoch [3/4], Step [2723/3844], Loss: 0.0810\n",
      "Epoch [3/4], Step [2724/3844], Loss: 0.0664\n",
      "Epoch [3/4], Step [2725/3844], Loss: 0.0839\n",
      "Epoch [3/4], Step [2726/3844], Loss: 0.0742\n",
      "Epoch [3/4], Step [2727/3844], Loss: 0.1603\n",
      "Epoch [3/4], Step [2728/3844], Loss: 0.0697\n",
      "Epoch [3/4], Step [2729/3844], Loss: 0.1487\n",
      "Epoch [3/4], Step [2730/3844], Loss: 0.1188\n",
      "Epoch [3/4], Step [2731/3844], Loss: 0.1267\n",
      "Epoch [3/4], Step [2732/3844], Loss: 0.1216\n",
      "Epoch [3/4], Step [2733/3844], Loss: 0.1315\n",
      "Epoch [3/4], Step [2734/3844], Loss: 0.0776\n",
      "Epoch [3/4], Step [2735/3844], Loss: 0.1438\n",
      "Epoch [3/4], Step [2736/3844], Loss: 0.1244\n",
      "Epoch [3/4], Step [2737/3844], Loss: 0.1674\n",
      "Epoch [3/4], Step [2738/3844], Loss: 0.0970\n",
      "Epoch [3/4], Step [2739/3844], Loss: 0.1234\n",
      "Epoch [3/4], Step [2740/3844], Loss: 0.1641\n",
      "Epoch [3/4], Step [2741/3844], Loss: 0.0821\n",
      "Epoch [3/4], Step [2742/3844], Loss: 0.0969\n",
      "Epoch [3/4], Step [2743/3844], Loss: 0.1740\n",
      "Epoch [3/4], Step [2744/3844], Loss: 0.1436\n",
      "Epoch [3/4], Step [2745/3844], Loss: 0.1054\n",
      "Epoch [3/4], Step [2746/3844], Loss: 0.1157\n",
      "Epoch [3/4], Step [2747/3844], Loss: 0.1007\n",
      "Epoch [3/4], Step [2748/3844], Loss: 0.1220\n",
      "Epoch [3/4], Step [2749/3844], Loss: 0.0535\n",
      "Epoch [3/4], Step [2750/3844], Loss: 0.0773\n",
      "Epoch [3/4], Step [2751/3844], Loss: 0.0758\n",
      "Epoch [3/4], Step [2752/3844], Loss: 0.0842\n",
      "Epoch [3/4], Step [2753/3844], Loss: 0.1203\n",
      "Epoch [3/4], Step [2754/3844], Loss: 0.1482\n",
      "Epoch [3/4], Step [2755/3844], Loss: 0.1504\n",
      "Epoch [3/4], Step [2756/3844], Loss: 0.0590\n",
      "Epoch [3/4], Step [2757/3844], Loss: 0.0664\n",
      "Epoch [3/4], Step [2758/3844], Loss: 0.1375\n",
      "Epoch [3/4], Step [2759/3844], Loss: 0.0888\n",
      "Epoch [3/4], Step [2760/3844], Loss: 0.0480\n",
      "Epoch [3/4], Step [2761/3844], Loss: 0.0748\n",
      "Epoch [3/4], Step [2762/3844], Loss: 0.1001\n",
      "Epoch [3/4], Step [2763/3844], Loss: 0.1528\n",
      "Epoch [3/4], Step [2764/3844], Loss: 0.0632\n",
      "Epoch [3/4], Step [2765/3844], Loss: 0.0654\n",
      "Epoch [3/4], Step [2766/3844], Loss: 0.0662\n",
      "Epoch [3/4], Step [2767/3844], Loss: 0.0963\n",
      "Epoch [3/4], Step [2768/3844], Loss: 0.1817\n",
      "Epoch [3/4], Step [2769/3844], Loss: 0.0738\n",
      "Epoch [3/4], Step [2770/3844], Loss: 0.0860\n",
      "Epoch [3/4], Step [2771/3844], Loss: 0.0702\n",
      "Epoch [3/4], Step [2772/3844], Loss: 0.1118\n",
      "Epoch [3/4], Step [2773/3844], Loss: 0.1384\n",
      "Epoch [3/4], Step [2774/3844], Loss: 0.0448\n",
      "Epoch [3/4], Step [2775/3844], Loss: 0.1228\n",
      "Epoch [3/4], Step [2776/3844], Loss: 0.0793\n",
      "Epoch [3/4], Step [2777/3844], Loss: 0.1129\n",
      "Epoch [3/4], Step [2778/3844], Loss: 0.0857\n",
      "Epoch [3/4], Step [2779/3844], Loss: 0.0720\n",
      "Epoch [3/4], Step [2780/3844], Loss: 0.1001\n",
      "Epoch [3/4], Step [2781/3844], Loss: 0.0863\n",
      "Epoch [3/4], Step [2782/3844], Loss: 0.0858\n",
      "Epoch [3/4], Step [2783/3844], Loss: 0.0714\n",
      "Epoch [3/4], Step [2784/3844], Loss: 0.0590\n",
      "Epoch [3/4], Step [2785/3844], Loss: 0.0954\n",
      "Epoch [3/4], Step [2786/3844], Loss: 0.1778\n",
      "Epoch [3/4], Step [2787/3844], Loss: 0.0900\n",
      "Epoch [3/4], Step [2788/3844], Loss: 0.0671\n",
      "Epoch [3/4], Step [2789/3844], Loss: 0.1739\n",
      "Epoch [3/4], Step [2790/3844], Loss: 0.1379\n",
      "Epoch [3/4], Step [2791/3844], Loss: 0.0567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/4], Step [2792/3844], Loss: 0.1086\n",
      "Epoch [3/4], Step [2793/3844], Loss: 0.0860\n",
      "Epoch [3/4], Step [2794/3844], Loss: 0.1167\n",
      "Epoch [3/4], Step [2795/3844], Loss: 0.0647\n",
      "Epoch [3/4], Step [2796/3844], Loss: 0.1027\n",
      "Epoch [3/4], Step [2797/3844], Loss: 0.0689\n",
      "Epoch [3/4], Step [2798/3844], Loss: 0.0617\n",
      "Epoch [3/4], Step [2799/3844], Loss: 0.1398\n",
      "Epoch [3/4], Step [2800/3844], Loss: 0.0840\n",
      "Epoch [3/4], Step [2801/3844], Loss: 0.1125\n",
      "Epoch [3/4], Step [2802/3844], Loss: 0.0812\n",
      "Epoch [3/4], Step [2803/3844], Loss: 0.0565\n",
      "Epoch [3/4], Step [2804/3844], Loss: 0.1183\n",
      "Epoch [3/4], Step [2805/3844], Loss: 0.0920\n",
      "Epoch [3/4], Step [2806/3844], Loss: 0.0538\n",
      "Epoch [3/4], Step [2807/3844], Loss: 0.0945\n",
      "Epoch [3/4], Step [2808/3844], Loss: 0.1524\n",
      "Epoch [3/4], Step [2809/3844], Loss: 0.0688\n",
      "Epoch [3/4], Step [2810/3844], Loss: 0.0948\n",
      "Epoch [3/4], Step [2811/3844], Loss: 0.1014\n",
      "Epoch [3/4], Step [2812/3844], Loss: 0.1290\n",
      "Epoch [3/4], Step [2813/3844], Loss: 0.1257\n",
      "Epoch [3/4], Step [2814/3844], Loss: 0.0533\n",
      "Epoch [3/4], Step [2815/3844], Loss: 0.1573\n",
      "Epoch [3/4], Step [2816/3844], Loss: 0.0807\n",
      "Epoch [3/4], Step [2817/3844], Loss: 0.1692\n",
      "Epoch [3/4], Step [2818/3844], Loss: 0.1297\n",
      "Epoch [3/4], Step [2819/3844], Loss: 0.1091\n",
      "Epoch [3/4], Step [2820/3844], Loss: 0.0878\n",
      "Epoch [3/4], Step [2821/3844], Loss: 0.1440\n",
      "Epoch [3/4], Step [2822/3844], Loss: 0.0659\n",
      "Epoch [3/4], Step [2823/3844], Loss: 0.0872\n",
      "Epoch [3/4], Step [2824/3844], Loss: 0.0783\n",
      "Epoch [3/4], Step [2825/3844], Loss: 0.0863\n",
      "Epoch [3/4], Step [2826/3844], Loss: 0.0920\n",
      "Epoch [3/4], Step [2827/3844], Loss: 0.0970\n",
      "Epoch [3/4], Step [2828/3844], Loss: 0.0859\n",
      "Epoch [3/4], Step [2829/3844], Loss: 0.0753\n",
      "Epoch [3/4], Step [2830/3844], Loss: 0.0917\n",
      "Epoch [3/4], Step [2831/3844], Loss: 0.1029\n",
      "Epoch [3/4], Step [2832/3844], Loss: 0.0540\n",
      "Epoch [3/4], Step [2833/3844], Loss: 0.0881\n",
      "Epoch [3/4], Step [2834/3844], Loss: 0.1223\n",
      "Epoch [3/4], Step [2835/3844], Loss: 0.0613\n",
      "Epoch [3/4], Step [2836/3844], Loss: 0.1336\n",
      "Epoch [3/4], Step [2837/3844], Loss: 0.1379\n",
      "Epoch [3/4], Step [2838/3844], Loss: 0.0775\n",
      "Epoch [3/4], Step [2839/3844], Loss: 0.1465\n",
      "Epoch [3/4], Step [2840/3844], Loss: 0.0819\n",
      "Epoch [3/4], Step [2841/3844], Loss: 0.0937\n",
      "Epoch [3/4], Step [2842/3844], Loss: 0.0706\n",
      "Epoch [3/4], Step [2843/3844], Loss: 0.0755\n",
      "Epoch [3/4], Step [2844/3844], Loss: 0.2087\n",
      "Epoch [3/4], Step [2845/3844], Loss: 0.1056\n",
      "Epoch [3/4], Step [2846/3844], Loss: 0.0848\n",
      "Epoch [3/4], Step [2847/3844], Loss: 0.1091\n",
      "Epoch [3/4], Step [2848/3844], Loss: 0.1828\n",
      "Epoch [3/4], Step [2849/3844], Loss: 0.1650\n",
      "Epoch [3/4], Step [2850/3844], Loss: 0.1420\n",
      "Epoch [3/4], Step [2851/3844], Loss: 0.1573\n",
      "Epoch [3/4], Step [2852/3844], Loss: 0.0487\n",
      "Epoch [3/4], Step [2853/3844], Loss: 0.1231\n",
      "Epoch [3/4], Step [2854/3844], Loss: 0.0767\n",
      "Epoch [3/4], Step [2855/3844], Loss: 0.0905\n",
      "Epoch [3/4], Step [2856/3844], Loss: 0.1316\n",
      "Epoch [3/4], Step [2857/3844], Loss: 0.0685\n",
      "Epoch [3/4], Step [2858/3844], Loss: 0.0774\n",
      "Epoch [3/4], Step [2859/3844], Loss: 0.0692\n",
      "Epoch [3/4], Step [2860/3844], Loss: 0.2005\n",
      "Epoch [3/4], Step [2861/3844], Loss: 0.1038\n",
      "Epoch [3/4], Step [2862/3844], Loss: 0.0726\n",
      "Epoch [3/4], Step [2863/3844], Loss: 0.0970\n",
      "Epoch [3/4], Step [2864/3844], Loss: 0.1164\n",
      "Epoch [3/4], Step [2865/3844], Loss: 0.1622\n",
      "Epoch [3/4], Step [2866/3844], Loss: 0.0661\n",
      "Epoch [3/4], Step [2867/3844], Loss: 0.0847\n",
      "Epoch [3/4], Step [2868/3844], Loss: 0.1152\n",
      "Epoch [3/4], Step [2869/3844], Loss: 0.0703\n",
      "Epoch [3/4], Step [2870/3844], Loss: 0.0760\n",
      "Epoch [3/4], Step [2871/3844], Loss: 0.0586\n",
      "Epoch [3/4], Step [2872/3844], Loss: 0.0943\n",
      "Epoch [3/4], Step [2873/3844], Loss: 0.0478\n",
      "Epoch [3/4], Step [2874/3844], Loss: 0.1018\n",
      "Epoch [3/4], Step [2875/3844], Loss: 0.1188\n",
      "Epoch [3/4], Step [2876/3844], Loss: 0.0718\n",
      "Epoch [3/4], Step [2877/3844], Loss: 0.1594\n",
      "Epoch [3/4], Step [2878/3844], Loss: 0.0626\n",
      "Epoch [3/4], Step [2879/3844], Loss: 0.0983\n",
      "Epoch [3/4], Step [2880/3844], Loss: 0.1269\n",
      "Epoch [3/4], Step [2881/3844], Loss: 0.0607\n",
      "Epoch [3/4], Step [2882/3844], Loss: 0.0580\n",
      "Epoch [3/4], Step [2883/3844], Loss: 0.1348\n",
      "Epoch [3/4], Step [2884/3844], Loss: 0.1519\n",
      "Epoch [3/4], Step [2885/3844], Loss: 0.0899\n",
      "Epoch [3/4], Step [2886/3844], Loss: 0.0803\n",
      "Epoch [3/4], Step [2887/3844], Loss: 0.0966\n",
      "Epoch [3/4], Step [2888/3844], Loss: 0.1489\n",
      "Epoch [3/4], Step [2889/3844], Loss: 0.0940\n",
      "Epoch [3/4], Step [2890/3844], Loss: 0.0649\n",
      "Epoch [3/4], Step [2891/3844], Loss: 0.0731\n",
      "Epoch [3/4], Step [2892/3844], Loss: 0.0687\n",
      "Epoch [3/4], Step [2893/3844], Loss: 0.0924\n",
      "Epoch [3/4], Step [2894/3844], Loss: 0.0807\n",
      "Epoch [3/4], Step [2895/3844], Loss: 0.1187\n",
      "Epoch [3/4], Step [2896/3844], Loss: 0.0564\n",
      "Epoch [3/4], Step [2897/3844], Loss: 0.0724\n",
      "Epoch [3/4], Step [2898/3844], Loss: 0.1166\n",
      "Epoch [3/4], Step [2899/3844], Loss: 0.1297\n",
      "Epoch [3/4], Step [2900/3844], Loss: 0.1340\n",
      "Epoch [3/4], Step [2901/3844], Loss: 0.1331\n",
      "Epoch [3/4], Step [2902/3844], Loss: 0.1608\n",
      "Epoch [3/4], Step [2903/3844], Loss: 0.0901\n",
      "Epoch [3/4], Step [2904/3844], Loss: 0.0801\n",
      "Epoch [3/4], Step [2905/3844], Loss: 0.1637\n",
      "Epoch [3/4], Step [2906/3844], Loss: 0.0917\n",
      "Epoch [3/4], Step [2907/3844], Loss: 0.1514\n",
      "Epoch [3/4], Step [2908/3844], Loss: 0.0868\n",
      "Epoch [3/4], Step [2909/3844], Loss: 0.0621\n",
      "Epoch [3/4], Step [2910/3844], Loss: 0.0695\n",
      "Epoch [3/4], Step [2911/3844], Loss: 0.1410\n",
      "Epoch [3/4], Step [2912/3844], Loss: 0.0809\n",
      "Epoch [3/4], Step [2913/3844], Loss: 0.1285\n",
      "Epoch [3/4], Step [2914/3844], Loss: 0.0759\n",
      "Epoch [3/4], Step [2915/3844], Loss: 0.0728\n",
      "Epoch [3/4], Step [2916/3844], Loss: 0.0965\n",
      "Epoch [3/4], Step [2917/3844], Loss: 0.0603\n",
      "Epoch [3/4], Step [2918/3844], Loss: 0.0769\n",
      "Epoch [3/4], Step [2919/3844], Loss: 0.1855\n",
      "Epoch [3/4], Step [2920/3844], Loss: 0.0691\n",
      "Epoch [3/4], Step [2921/3844], Loss: 0.0648\n",
      "Epoch [3/4], Step [2922/3844], Loss: 0.1102\n",
      "Epoch [3/4], Step [2923/3844], Loss: 0.0739\n",
      "Epoch [3/4], Step [2924/3844], Loss: 0.1989\n",
      "Epoch [3/4], Step [2925/3844], Loss: 0.0642\n",
      "Epoch [3/4], Step [2926/3844], Loss: 0.0885\n",
      "Epoch [3/4], Step [2927/3844], Loss: 0.1541\n",
      "Epoch [3/4], Step [2928/3844], Loss: 0.0679\n",
      "Epoch [3/4], Step [2929/3844], Loss: 0.1623\n",
      "Epoch [3/4], Step [2930/3844], Loss: 0.0706\n",
      "Epoch [3/4], Step [2931/3844], Loss: 0.1270\n",
      "Epoch [3/4], Step [2932/3844], Loss: 0.1735\n",
      "Epoch [3/4], Step [2933/3844], Loss: 0.1336\n",
      "Epoch [3/4], Step [2934/3844], Loss: 0.1269\n",
      "Epoch [3/4], Step [2935/3844], Loss: 0.0609\n",
      "Epoch [3/4], Step [2936/3844], Loss: 0.0736\n",
      "Epoch [3/4], Step [2937/3844], Loss: 0.1460\n",
      "Epoch [3/4], Step [2938/3844], Loss: 0.1104\n",
      "Epoch [3/4], Step [2939/3844], Loss: 0.1316\n",
      "Epoch [3/4], Step [2940/3844], Loss: 0.0688\n",
      "Epoch [3/4], Step [2941/3844], Loss: 0.1458\n",
      "Epoch [3/4], Step [2942/3844], Loss: 0.1237\n",
      "Epoch [3/4], Step [2943/3844], Loss: 0.0753\n",
      "Epoch [3/4], Step [2944/3844], Loss: 0.0807\n",
      "Epoch [3/4], Step [2945/3844], Loss: 0.0827\n",
      "Epoch [3/4], Step [2946/3844], Loss: 0.0707\n",
      "Epoch [3/4], Step [2947/3844], Loss: 0.1400\n",
      "Epoch [3/4], Step [2948/3844], Loss: 0.1656\n",
      "Epoch [3/4], Step [2949/3844], Loss: 0.0571\n",
      "Epoch [3/4], Step [2950/3844], Loss: 0.1109\n",
      "Epoch [3/4], Step [2951/3844], Loss: 0.0886\n",
      "Epoch [3/4], Step [2952/3844], Loss: 0.1160\n",
      "Epoch [3/4], Step [2953/3844], Loss: 0.0740\n",
      "Epoch [3/4], Step [2954/3844], Loss: 0.0895\n",
      "Epoch [3/4], Step [2955/3844], Loss: 0.0588\n",
      "Epoch [3/4], Step [2956/3844], Loss: 0.1131\n",
      "Epoch [3/4], Step [2957/3844], Loss: 0.1495\n",
      "Epoch [3/4], Step [2958/3844], Loss: 0.0879\n",
      "Epoch [3/4], Step [2959/3844], Loss: 0.1183\n",
      "Epoch [3/4], Step [2960/3844], Loss: 0.0924\n",
      "Epoch [3/4], Step [2961/3844], Loss: 0.1259\n",
      "Epoch [3/4], Step [2962/3844], Loss: 0.1384\n",
      "Epoch [3/4], Step [2963/3844], Loss: 0.0698\n",
      "Epoch [3/4], Step [2964/3844], Loss: 0.0587\n",
      "Epoch [3/4], Step [2965/3844], Loss: 0.0962\n",
      "Epoch [3/4], Step [2966/3844], Loss: 0.1602\n",
      "Epoch [3/4], Step [2967/3844], Loss: 0.0978\n",
      "Epoch [3/4], Step [2968/3844], Loss: 0.0836\n",
      "Epoch [3/4], Step [2969/3844], Loss: 0.0975\n",
      "Epoch [3/4], Step [2970/3844], Loss: 0.1086\n",
      "Epoch [3/4], Step [2971/3844], Loss: 0.0884\n",
      "Epoch [3/4], Step [2972/3844], Loss: 0.0834\n",
      "Epoch [3/4], Step [2973/3844], Loss: 0.1116\n",
      "Epoch [3/4], Step [2974/3844], Loss: 0.1622\n",
      "Epoch [3/4], Step [2975/3844], Loss: 0.1041\n",
      "Epoch [3/4], Step [2976/3844], Loss: 0.1304\n",
      "Epoch [3/4], Step [2977/3844], Loss: 0.0700\n",
      "Epoch [3/4], Step [2978/3844], Loss: 0.1011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/4], Step [2979/3844], Loss: 0.1217\n",
      "Epoch [3/4], Step [2980/3844], Loss: 0.0576\n",
      "Epoch [3/4], Step [2981/3844], Loss: 0.1361\n",
      "Epoch [3/4], Step [2982/3844], Loss: 0.0597\n",
      "Epoch [3/4], Step [2983/3844], Loss: 0.1623\n",
      "Epoch [3/4], Step [2984/3844], Loss: 0.0518\n",
      "Epoch [3/4], Step [2985/3844], Loss: 0.1038\n",
      "Epoch [3/4], Step [2986/3844], Loss: 0.0989\n",
      "Epoch [3/4], Step [2987/3844], Loss: 0.0911\n",
      "Epoch [3/4], Step [2988/3844], Loss: 0.1068\n",
      "Epoch [3/4], Step [2989/3844], Loss: 0.0778\n",
      "Epoch [3/4], Step [2990/3844], Loss: 0.0915\n",
      "Epoch [3/4], Step [2991/3844], Loss: 0.1028\n",
      "Epoch [3/4], Step [2992/3844], Loss: 0.1367\n",
      "Epoch [3/4], Step [2993/3844], Loss: 0.0972\n",
      "Epoch [3/4], Step [2994/3844], Loss: 0.1371\n",
      "Epoch [3/4], Step [2995/3844], Loss: 0.0997\n",
      "Epoch [3/4], Step [2996/3844], Loss: 0.0850\n",
      "Epoch [3/4], Step [2997/3844], Loss: 0.1527\n",
      "Epoch [3/4], Step [2998/3844], Loss: 0.0654\n",
      "Epoch [3/4], Step [2999/3844], Loss: 0.0877\n",
      "Epoch [3/4], Step [3000/3844], Loss: 0.1327\n",
      "Epoch [3/4], Step [3001/3844], Loss: 0.0464\n",
      "Epoch [3/4], Step [3002/3844], Loss: 0.0803\n",
      "Epoch [3/4], Step [3003/3844], Loss: 0.0815\n",
      "Epoch [3/4], Step [3004/3844], Loss: 0.1147\n",
      "Epoch [3/4], Step [3005/3844], Loss: 0.0815\n",
      "Epoch [3/4], Step [3006/3844], Loss: 0.1171\n",
      "Epoch [3/4], Step [3007/3844], Loss: 0.1211\n",
      "Epoch [3/4], Step [3008/3844], Loss: 0.0734\n",
      "Epoch [3/4], Step [3009/3844], Loss: 0.0978\n",
      "Epoch [3/4], Step [3010/3844], Loss: 0.0672\n",
      "Epoch [3/4], Step [3011/3844], Loss: 0.1201\n",
      "Epoch [3/4], Step [3012/3844], Loss: 0.1538\n",
      "Epoch [3/4], Step [3013/3844], Loss: 0.1116\n",
      "Epoch [3/4], Step [3014/3844], Loss: 0.0764\n",
      "Epoch [3/4], Step [3015/3844], Loss: 0.1311\n",
      "Epoch [3/4], Step [3016/3844], Loss: 0.0743\n",
      "Epoch [3/4], Step [3017/3844], Loss: 0.0436\n",
      "Epoch [3/4], Step [3018/3844], Loss: 0.0880\n",
      "Epoch [3/4], Step [3019/3844], Loss: 0.0497\n",
      "Epoch [3/4], Step [3020/3844], Loss: 0.1107\n",
      "Epoch [3/4], Step [3021/3844], Loss: 0.1155\n",
      "Epoch [3/4], Step [3022/3844], Loss: 0.1651\n",
      "Epoch [3/4], Step [3023/3844], Loss: 0.1390\n",
      "Epoch [3/4], Step [3024/3844], Loss: 0.0619\n",
      "Epoch [3/4], Step [3025/3844], Loss: 0.0824\n",
      "Epoch [3/4], Step [3026/3844], Loss: 0.0728\n",
      "Epoch [3/4], Step [3027/3844], Loss: 0.1030\n",
      "Epoch [3/4], Step [3028/3844], Loss: 0.0578\n",
      "Epoch [3/4], Step [3029/3844], Loss: 0.1442\n",
      "Epoch [3/4], Step [3030/3844], Loss: 0.1009\n",
      "Epoch [3/4], Step [3031/3844], Loss: 0.0657\n",
      "Epoch [3/4], Step [3032/3844], Loss: 0.1406\n",
      "Epoch [3/4], Step [3033/3844], Loss: 0.0650\n",
      "Epoch [3/4], Step [3034/3844], Loss: 0.1141\n",
      "Epoch [3/4], Step [3035/3844], Loss: 0.1009\n",
      "Epoch [3/4], Step [3036/3844], Loss: 0.0420\n",
      "Epoch [3/4], Step [3037/3844], Loss: 0.1316\n",
      "Epoch [3/4], Step [3038/3844], Loss: 0.0665\n",
      "Epoch [3/4], Step [3039/3844], Loss: 0.0560\n",
      "Epoch [3/4], Step [3040/3844], Loss: 0.0597\n",
      "Epoch [3/4], Step [3041/3844], Loss: 0.0876\n",
      "Epoch [3/4], Step [3042/3844], Loss: 0.0872\n",
      "Epoch [3/4], Step [3043/3844], Loss: 0.0621\n",
      "Epoch [3/4], Step [3044/3844], Loss: 0.1144\n",
      "Epoch [3/4], Step [3045/3844], Loss: 0.1110\n",
      "Epoch [3/4], Step [3046/3844], Loss: 0.1226\n",
      "Epoch [3/4], Step [3047/3844], Loss: 0.0908\n",
      "Epoch [3/4], Step [3048/3844], Loss: 0.0878\n",
      "Epoch [3/4], Step [3049/3844], Loss: 0.1680\n",
      "Epoch [3/4], Step [3050/3844], Loss: 0.0805\n",
      "Epoch [3/4], Step [3051/3844], Loss: 0.1645\n",
      "Epoch [3/4], Step [3052/3844], Loss: 0.1189\n",
      "Epoch [3/4], Step [3053/3844], Loss: 0.1362\n",
      "Epoch [3/4], Step [3054/3844], Loss: 0.1264\n",
      "Epoch [3/4], Step [3055/3844], Loss: 0.1079\n",
      "Epoch [3/4], Step [3056/3844], Loss: 0.0966\n",
      "Epoch [3/4], Step [3057/3844], Loss: 0.0940\n",
      "Epoch [3/4], Step [3058/3844], Loss: 0.1183\n",
      "Epoch [3/4], Step [3059/3844], Loss: 0.0673\n",
      "Epoch [3/4], Step [3060/3844], Loss: 0.1164\n",
      "Epoch [3/4], Step [3061/3844], Loss: 0.1430\n",
      "Epoch [3/4], Step [3062/3844], Loss: 0.1096\n",
      "Epoch [3/4], Step [3063/3844], Loss: 0.1831\n",
      "Epoch [3/4], Step [3064/3844], Loss: 0.1112\n",
      "Epoch [3/4], Step [3065/3844], Loss: 0.0929\n",
      "Epoch [3/4], Step [3066/3844], Loss: 0.1917\n",
      "Epoch [3/4], Step [3067/3844], Loss: 0.1160\n",
      "Epoch [3/4], Step [3068/3844], Loss: 0.1870\n",
      "Epoch [3/4], Step [3069/3844], Loss: 0.1501\n",
      "Epoch [3/4], Step [3070/3844], Loss: 0.1084\n",
      "Epoch [3/4], Step [3071/3844], Loss: 0.0977\n",
      "Epoch [3/4], Step [3072/3844], Loss: 0.0735\n",
      "Epoch [3/4], Step [3073/3844], Loss: 0.0925\n",
      "Epoch [3/4], Step [3074/3844], Loss: 0.0961\n",
      "Epoch [3/4], Step [3075/3844], Loss: 0.1057\n",
      "Epoch [3/4], Step [3076/3844], Loss: 0.0897\n",
      "Epoch [3/4], Step [3077/3844], Loss: 0.1524\n",
      "Epoch [3/4], Step [3078/3844], Loss: 0.0696\n",
      "Epoch [3/4], Step [3079/3844], Loss: 0.0965\n",
      "Epoch [3/4], Step [3080/3844], Loss: 0.1419\n",
      "Epoch [3/4], Step [3081/3844], Loss: 0.1354\n",
      "Epoch [3/4], Step [3082/3844], Loss: 0.0631\n",
      "Epoch [3/4], Step [3083/3844], Loss: 0.0770\n",
      "Epoch [3/4], Step [3084/3844], Loss: 0.1297\n",
      "Epoch [3/4], Step [3085/3844], Loss: 0.0798\n",
      "Epoch [3/4], Step [3086/3844], Loss: 0.1092\n",
      "Epoch [3/4], Step [3087/3844], Loss: 0.1396\n",
      "Epoch [3/4], Step [3088/3844], Loss: 0.0713\n",
      "Epoch [3/4], Step [3089/3844], Loss: 0.1228\n",
      "Epoch [3/4], Step [3090/3844], Loss: 0.0798\n",
      "Epoch [3/4], Step [3091/3844], Loss: 0.1433\n",
      "Epoch [3/4], Step [3092/3844], Loss: 0.1624\n",
      "Epoch [3/4], Step [3093/3844], Loss: 0.0716\n",
      "Epoch [3/4], Step [3094/3844], Loss: 0.1275\n",
      "Epoch [3/4], Step [3095/3844], Loss: 0.0772\n",
      "Epoch [3/4], Step [3096/3844], Loss: 0.1005\n",
      "Epoch [3/4], Step [3097/3844], Loss: 0.0634\n",
      "Epoch [3/4], Step [3098/3844], Loss: 0.0562\n",
      "Epoch [3/4], Step [3099/3844], Loss: 0.0842\n",
      "Epoch [3/4], Step [3100/3844], Loss: 0.1138\n",
      "Epoch [3/4], Step [3101/3844], Loss: 0.1284\n",
      "Epoch [3/4], Step [3102/3844], Loss: 0.1065\n",
      "Epoch [3/4], Step [3103/3844], Loss: 0.1186\n",
      "Epoch [3/4], Step [3104/3844], Loss: 0.0353\n",
      "Epoch [3/4], Step [3105/3844], Loss: 0.1055\n",
      "Epoch [3/4], Step [3106/3844], Loss: 0.0737\n",
      "Epoch [3/4], Step [3107/3844], Loss: 0.1505\n",
      "Epoch [3/4], Step [3108/3844], Loss: 0.1377\n",
      "Epoch [3/4], Step [3109/3844], Loss: 0.0746\n",
      "Epoch [3/4], Step [3110/3844], Loss: 0.1244\n",
      "Epoch [3/4], Step [3111/3844], Loss: 0.1520\n",
      "Epoch [3/4], Step [3112/3844], Loss: 0.0477\n",
      "Epoch [3/4], Step [3113/3844], Loss: 0.0686\n",
      "Epoch [3/4], Step [3114/3844], Loss: 0.0898\n",
      "Epoch [3/4], Step [3115/3844], Loss: 0.0951\n",
      "Epoch [3/4], Step [3116/3844], Loss: 0.0528\n",
      "Epoch [3/4], Step [3117/3844], Loss: 0.1505\n",
      "Epoch [3/4], Step [3118/3844], Loss: 0.1069\n",
      "Epoch [3/4], Step [3119/3844], Loss: 0.1089\n",
      "Epoch [3/4], Step [3120/3844], Loss: 0.1362\n",
      "Epoch [3/4], Step [3121/3844], Loss: 0.1560\n",
      "Epoch [3/4], Step [3122/3844], Loss: 0.1368\n",
      "Epoch [3/4], Step [3123/3844], Loss: 0.1199\n",
      "Epoch [3/4], Step [3124/3844], Loss: 0.0794\n",
      "Epoch [3/4], Step [3125/3844], Loss: 0.1556\n",
      "Epoch [3/4], Step [3126/3844], Loss: 0.0909\n",
      "Epoch [3/4], Step [3127/3844], Loss: 0.0863\n",
      "Epoch [3/4], Step [3128/3844], Loss: 0.1387\n",
      "Epoch [3/4], Step [3129/3844], Loss: 0.1053\n",
      "Epoch [3/4], Step [3130/3844], Loss: 0.1491\n",
      "Epoch [3/4], Step [3131/3844], Loss: 0.1005\n",
      "Epoch [3/4], Step [3132/3844], Loss: 0.0791\n",
      "Epoch [3/4], Step [3133/3844], Loss: 0.0814\n",
      "Epoch [3/4], Step [3134/3844], Loss: 0.0887\n",
      "Epoch [3/4], Step [3135/3844], Loss: 0.0725\n",
      "Epoch [3/4], Step [3136/3844], Loss: 0.1248\n",
      "Epoch [3/4], Step [3137/3844], Loss: 0.0765\n",
      "Epoch [3/4], Step [3138/3844], Loss: 0.0765\n",
      "Epoch [3/4], Step [3139/3844], Loss: 0.0621\n",
      "Epoch [3/4], Step [3140/3844], Loss: 0.0718\n",
      "Epoch [3/4], Step [3141/3844], Loss: 0.1284\n",
      "Epoch [3/4], Step [3142/3844], Loss: 0.1627\n",
      "Epoch [3/4], Step [3143/3844], Loss: 0.0606\n",
      "Epoch [3/4], Step [3144/3844], Loss: 0.0838\n",
      "Epoch [3/4], Step [3145/3844], Loss: 0.0701\n",
      "Epoch [3/4], Step [3146/3844], Loss: 0.0746\n",
      "Epoch [3/4], Step [3147/3844], Loss: 0.0910\n",
      "Epoch [3/4], Step [3148/3844], Loss: 0.1608\n",
      "Epoch [3/4], Step [3149/3844], Loss: 0.1471\n",
      "Epoch [3/4], Step [3150/3844], Loss: 0.0802\n",
      "Epoch [3/4], Step [3151/3844], Loss: 0.1216\n",
      "Epoch [3/4], Step [3152/3844], Loss: 0.0728\n",
      "Epoch [3/4], Step [3153/3844], Loss: 0.1232\n",
      "Epoch [3/4], Step [3154/3844], Loss: 0.0889\n",
      "Epoch [3/4], Step [3155/3844], Loss: 0.1524\n",
      "Epoch [3/4], Step [3156/3844], Loss: 0.1293\n",
      "Epoch [3/4], Step [3157/3844], Loss: 0.1230\n",
      "Epoch [3/4], Step [3158/3844], Loss: 0.1030\n",
      "Epoch [3/4], Step [3159/3844], Loss: 0.0966\n",
      "Epoch [3/4], Step [3160/3844], Loss: 0.0840\n",
      "Epoch [3/4], Step [3161/3844], Loss: 0.0836\n",
      "Epoch [3/4], Step [3162/3844], Loss: 0.0800\n",
      "Epoch [3/4], Step [3163/3844], Loss: 0.1597\n",
      "Epoch [3/4], Step [3164/3844], Loss: 0.0951\n",
      "Epoch [3/4], Step [3165/3844], Loss: 0.0809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/4], Step [3166/3844], Loss: 0.0787\n",
      "Epoch [3/4], Step [3167/3844], Loss: 0.1402\n",
      "Epoch [3/4], Step [3168/3844], Loss: 0.0875\n",
      "Epoch [3/4], Step [3169/3844], Loss: 0.0814\n",
      "Epoch [3/4], Step [3170/3844], Loss: 0.0930\n",
      "Epoch [3/4], Step [3171/3844], Loss: 0.0926\n",
      "Epoch [3/4], Step [3172/3844], Loss: 0.1054\n",
      "Epoch [3/4], Step [3173/3844], Loss: 0.0766\n",
      "Epoch [3/4], Step [3174/3844], Loss: 0.0735\n",
      "Epoch [3/4], Step [3175/3844], Loss: 0.0914\n",
      "Epoch [3/4], Step [3176/3844], Loss: 0.1007\n",
      "Epoch [3/4], Step [3177/3844], Loss: 0.0716\n",
      "Epoch [3/4], Step [3178/3844], Loss: 0.0742\n",
      "Epoch [3/4], Step [3179/3844], Loss: 0.1028\n",
      "Epoch [3/4], Step [3180/3844], Loss: 0.1392\n",
      "Epoch [3/4], Step [3181/3844], Loss: 0.0991\n",
      "Epoch [3/4], Step [3182/3844], Loss: 0.0908\n",
      "Epoch [3/4], Step [3183/3844], Loss: 0.1214\n",
      "Epoch [3/4], Step [3184/3844], Loss: 0.0786\n",
      "Epoch [3/4], Step [3185/3844], Loss: 0.0931\n",
      "Epoch [3/4], Step [3186/3844], Loss: 0.0887\n",
      "Epoch [3/4], Step [3187/3844], Loss: 0.0487\n",
      "Epoch [3/4], Step [3188/3844], Loss: 0.0771\n",
      "Epoch [3/4], Step [3189/3844], Loss: 0.0985\n",
      "Epoch [3/4], Step [3190/3844], Loss: 0.1220\n",
      "Epoch [3/4], Step [3191/3844], Loss: 0.1583\n",
      "Epoch [3/4], Step [3192/3844], Loss: 0.0728\n",
      "Epoch [3/4], Step [3193/3844], Loss: 0.1123\n",
      "Epoch [3/4], Step [3194/3844], Loss: 0.1421\n",
      "Epoch [3/4], Step [3195/3844], Loss: 0.0943\n",
      "Epoch [3/4], Step [3196/3844], Loss: 0.1555\n",
      "Epoch [3/4], Step [3197/3844], Loss: 0.0604\n",
      "Epoch [3/4], Step [3198/3844], Loss: 0.1206\n",
      "Epoch [3/4], Step [3199/3844], Loss: 0.0778\n",
      "Epoch [3/4], Step [3200/3844], Loss: 0.0973\n",
      "Epoch [3/4], Step [3201/3844], Loss: 0.0872\n",
      "Epoch [3/4], Step [3202/3844], Loss: 0.1043\n",
      "Epoch [3/4], Step [3203/3844], Loss: 0.0932\n",
      "Epoch [3/4], Step [3204/3844], Loss: 0.0640\n",
      "Epoch [3/4], Step [3205/3844], Loss: 0.0854\n",
      "Epoch [3/4], Step [3206/3844], Loss: 0.0957\n",
      "Epoch [3/4], Step [3207/3844], Loss: 0.0704\n",
      "Epoch [3/4], Step [3208/3844], Loss: 0.1481\n",
      "Epoch [3/4], Step [3209/3844], Loss: 0.0748\n",
      "Epoch [3/4], Step [3210/3844], Loss: 0.1018\n",
      "Epoch [3/4], Step [3211/3844], Loss: 0.0719\n",
      "Epoch [3/4], Step [3212/3844], Loss: 0.0717\n",
      "Epoch [3/4], Step [3213/3844], Loss: 0.0737\n",
      "Epoch [3/4], Step [3214/3844], Loss: 0.1605\n",
      "Epoch [3/4], Step [3215/3844], Loss: 0.1279\n",
      "Epoch [3/4], Step [3216/3844], Loss: 0.1468\n",
      "Epoch [3/4], Step [3217/3844], Loss: 0.1167\n",
      "Epoch [3/4], Step [3218/3844], Loss: 0.0962\n",
      "Epoch [3/4], Step [3219/3844], Loss: 0.0676\n",
      "Epoch [3/4], Step [3220/3844], Loss: 0.0639\n",
      "Epoch [3/4], Step [3221/3844], Loss: 0.0872\n",
      "Epoch [3/4], Step [3222/3844], Loss: 0.0506\n",
      "Epoch [3/4], Step [3223/3844], Loss: 0.1140\n",
      "Epoch [3/4], Step [3224/3844], Loss: 0.1615\n",
      "Epoch [3/4], Step [3225/3844], Loss: 0.0899\n",
      "Epoch [3/4], Step [3226/3844], Loss: 0.1388\n",
      "Epoch [3/4], Step [3227/3844], Loss: 0.0836\n",
      "Epoch [3/4], Step [3228/3844], Loss: 0.0987\n",
      "Epoch [3/4], Step [3229/3844], Loss: 0.0745\n",
      "Epoch [3/4], Step [3230/3844], Loss: 0.1305\n",
      "Epoch [3/4], Step [3231/3844], Loss: 0.0976\n",
      "Epoch [3/4], Step [3232/3844], Loss: 0.1938\n",
      "Epoch [3/4], Step [3233/3844], Loss: 0.0807\n",
      "Epoch [3/4], Step [3234/3844], Loss: 0.0715\n",
      "Epoch [3/4], Step [3235/3844], Loss: 0.1741\n",
      "Epoch [3/4], Step [3236/3844], Loss: 0.0654\n",
      "Epoch [3/4], Step [3237/3844], Loss: 0.1340\n",
      "Epoch [3/4], Step [3238/3844], Loss: 0.1527\n",
      "Epoch [3/4], Step [3239/3844], Loss: 0.0787\n",
      "Epoch [3/4], Step [3240/3844], Loss: 0.1434\n",
      "Epoch [3/4], Step [3241/3844], Loss: 0.1364\n",
      "Epoch [3/4], Step [3242/3844], Loss: 0.0923\n",
      "Epoch [3/4], Step [3243/3844], Loss: 0.0753\n",
      "Epoch [3/4], Step [3244/3844], Loss: 0.0643\n",
      "Epoch [3/4], Step [3245/3844], Loss: 0.1597\n",
      "Epoch [3/4], Step [3246/3844], Loss: 0.0965\n",
      "Epoch [3/4], Step [3247/3844], Loss: 0.1157\n",
      "Epoch [3/4], Step [3248/3844], Loss: 0.0718\n",
      "Epoch [3/4], Step [3249/3844], Loss: 0.0839\n",
      "Epoch [3/4], Step [3250/3844], Loss: 0.0741\n",
      "Epoch [3/4], Step [3251/3844], Loss: 0.0836\n",
      "Epoch [3/4], Step [3252/3844], Loss: 0.0956\n",
      "Epoch [3/4], Step [3253/3844], Loss: 0.0710\n",
      "Epoch [3/4], Step [3254/3844], Loss: 0.0871\n",
      "Epoch [3/4], Step [3255/3844], Loss: 0.0937\n",
      "Epoch [3/4], Step [3256/3844], Loss: 0.0751\n",
      "Epoch [3/4], Step [3257/3844], Loss: 0.0645\n",
      "Epoch [3/4], Step [3258/3844], Loss: 0.0770\n",
      "Epoch [3/4], Step [3259/3844], Loss: 0.0706\n",
      "Epoch [3/4], Step [3260/3844], Loss: 0.1454\n",
      "Epoch [3/4], Step [3261/3844], Loss: 0.1222\n",
      "Epoch [3/4], Step [3262/3844], Loss: 0.0739\n",
      "Epoch [3/4], Step [3263/3844], Loss: 0.0666\n",
      "Epoch [3/4], Step [3264/3844], Loss: 0.0893\n",
      "Epoch [3/4], Step [3265/3844], Loss: 0.0827\n",
      "Epoch [3/4], Step [3266/3844], Loss: 0.1631\n",
      "Epoch [3/4], Step [3267/3844], Loss: 0.0745\n",
      "Epoch [3/4], Step [3268/3844], Loss: 0.0861\n",
      "Epoch [3/4], Step [3269/3844], Loss: 0.1549\n",
      "Epoch [3/4], Step [3270/3844], Loss: 0.1449\n",
      "Epoch [3/4], Step [3271/3844], Loss: 0.1225\n",
      "Epoch [3/4], Step [3272/3844], Loss: 0.1102\n",
      "Epoch [3/4], Step [3273/3844], Loss: 0.0809\n",
      "Epoch [3/4], Step [3274/3844], Loss: 0.1164\n",
      "Epoch [3/4], Step [3275/3844], Loss: 0.0799\n",
      "Epoch [3/4], Step [3276/3844], Loss: 0.1478\n",
      "Epoch [3/4], Step [3277/3844], Loss: 0.1312\n",
      "Epoch [3/4], Step [3278/3844], Loss: 0.1535\n",
      "Epoch [3/4], Step [3279/3844], Loss: 0.1044\n",
      "Epoch [3/4], Step [3280/3844], Loss: 0.1118\n",
      "Epoch [3/4], Step [3281/3844], Loss: 0.1306\n",
      "Epoch [3/4], Step [3282/3844], Loss: 0.0961\n",
      "Epoch [3/4], Step [3283/3844], Loss: 0.1621\n",
      "Epoch [3/4], Step [3284/3844], Loss: 0.1676\n",
      "Epoch [3/4], Step [3285/3844], Loss: 0.1359\n",
      "Epoch [3/4], Step [3286/3844], Loss: 0.1022\n",
      "Epoch [3/4], Step [3287/3844], Loss: 0.1524\n",
      "Epoch [3/4], Step [3288/3844], Loss: 0.0769\n",
      "Epoch [3/4], Step [3289/3844], Loss: 0.0702\n",
      "Epoch [3/4], Step [3290/3844], Loss: 0.1557\n",
      "Epoch [3/4], Step [3291/3844], Loss: 0.1294\n",
      "Epoch [3/4], Step [3292/3844], Loss: 0.1038\n",
      "Epoch [3/4], Step [3293/3844], Loss: 0.0776\n",
      "Epoch [3/4], Step [3294/3844], Loss: 0.0661\n",
      "Epoch [3/4], Step [3295/3844], Loss: 0.1118\n",
      "Epoch [3/4], Step [3296/3844], Loss: 0.0925\n",
      "Epoch [3/4], Step [3297/3844], Loss: 0.1019\n",
      "Epoch [3/4], Step [3298/3844], Loss: 0.1083\n",
      "Epoch [3/4], Step [3299/3844], Loss: 0.0877\n",
      "Epoch [3/4], Step [3300/3844], Loss: 0.0686\n",
      "Epoch [3/4], Step [3301/3844], Loss: 0.1126\n",
      "Epoch [3/4], Step [3302/3844], Loss: 0.1260\n",
      "Epoch [3/4], Step [3303/3844], Loss: 0.0499\n",
      "Epoch [3/4], Step [3304/3844], Loss: 0.1371\n",
      "Epoch [3/4], Step [3305/3844], Loss: 0.0924\n",
      "Epoch [3/4], Step [3306/3844], Loss: 0.0621\n",
      "Epoch [3/4], Step [3307/3844], Loss: 0.1302\n",
      "Epoch [3/4], Step [3308/3844], Loss: 0.1018\n",
      "Epoch [3/4], Step [3309/3844], Loss: 0.0607\n",
      "Epoch [3/4], Step [3310/3844], Loss: 0.0853\n",
      "Epoch [3/4], Step [3311/3844], Loss: 0.1378\n",
      "Epoch [3/4], Step [3312/3844], Loss: 0.0942\n",
      "Epoch [3/4], Step [3313/3844], Loss: 0.0732\n",
      "Epoch [3/4], Step [3314/3844], Loss: 0.1551\n",
      "Epoch [3/4], Step [3315/3844], Loss: 0.0722\n",
      "Epoch [3/4], Step [3316/3844], Loss: 0.1164\n",
      "Epoch [3/4], Step [3317/3844], Loss: 0.0842\n",
      "Epoch [3/4], Step [3318/3844], Loss: 0.1013\n",
      "Epoch [3/4], Step [3319/3844], Loss: 0.1122\n",
      "Epoch [3/4], Step [3320/3844], Loss: 0.1412\n",
      "Epoch [3/4], Step [3321/3844], Loss: 0.0827\n",
      "Epoch [3/4], Step [3322/3844], Loss: 0.1334\n",
      "Epoch [3/4], Step [3323/3844], Loss: 0.1582\n",
      "Epoch [3/4], Step [3324/3844], Loss: 0.0879\n",
      "Epoch [3/4], Step [3325/3844], Loss: 0.0760\n",
      "Epoch [3/4], Step [3326/3844], Loss: 0.0945\n",
      "Epoch [3/4], Step [3327/3844], Loss: 0.0927\n",
      "Epoch [3/4], Step [3328/3844], Loss: 0.1030\n",
      "Epoch [3/4], Step [3329/3844], Loss: 0.1096\n",
      "Epoch [3/4], Step [3330/3844], Loss: 0.1311\n",
      "Epoch [3/4], Step [3331/3844], Loss: 0.1297\n",
      "Epoch [3/4], Step [3332/3844], Loss: 0.0883\n",
      "Epoch [3/4], Step [3333/3844], Loss: 0.1320\n",
      "Epoch [3/4], Step [3334/3844], Loss: 0.0530\n",
      "Epoch [3/4], Step [3335/3844], Loss: 0.0529\n",
      "Epoch [3/4], Step [3336/3844], Loss: 0.0542\n",
      "Epoch [3/4], Step [3337/3844], Loss: 0.0985\n",
      "Epoch [3/4], Step [3338/3844], Loss: 0.1334\n",
      "Epoch [3/4], Step [3339/3844], Loss: 0.0743\n",
      "Epoch [3/4], Step [3340/3844], Loss: 0.0735\n",
      "Epoch [3/4], Step [3341/3844], Loss: 0.0961\n",
      "Epoch [3/4], Step [3342/3844], Loss: 0.1493\n",
      "Epoch [3/4], Step [3343/3844], Loss: 0.1295\n",
      "Epoch [3/4], Step [3344/3844], Loss: 0.0862\n",
      "Epoch [3/4], Step [3345/3844], Loss: 0.0907\n",
      "Epoch [3/4], Step [3346/3844], Loss: 0.0825\n",
      "Epoch [3/4], Step [3347/3844], Loss: 0.0577\n",
      "Epoch [3/4], Step [3348/3844], Loss: 0.1011\n",
      "Epoch [3/4], Step [3349/3844], Loss: 0.0780\n",
      "Epoch [3/4], Step [3350/3844], Loss: 0.1101\n",
      "Epoch [3/4], Step [3351/3844], Loss: 0.1135\n",
      "Epoch [3/4], Step [3352/3844], Loss: 0.0817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/4], Step [3353/3844], Loss: 0.0847\n",
      "Epoch [3/4], Step [3354/3844], Loss: 0.1581\n",
      "Epoch [3/4], Step [3355/3844], Loss: 0.0904\n",
      "Epoch [3/4], Step [3356/3844], Loss: 0.0601\n",
      "Epoch [3/4], Step [3357/3844], Loss: 0.0924\n",
      "Epoch [3/4], Step [3358/3844], Loss: 0.0761\n",
      "Epoch [3/4], Step [3359/3844], Loss: 0.0798\n",
      "Epoch [3/4], Step [3360/3844], Loss: 0.0934\n",
      "Epoch [3/4], Step [3361/3844], Loss: 0.1396\n",
      "Epoch [3/4], Step [3362/3844], Loss: 0.0718\n",
      "Epoch [3/4], Step [3363/3844], Loss: 0.0836\n",
      "Epoch [3/4], Step [3364/3844], Loss: 0.0750\n",
      "Epoch [3/4], Step [3365/3844], Loss: 0.0961\n",
      "Epoch [3/4], Step [3366/3844], Loss: 0.1266\n",
      "Epoch [3/4], Step [3367/3844], Loss: 0.0462\n",
      "Epoch [3/4], Step [3368/3844], Loss: 0.0583\n",
      "Epoch [3/4], Step [3369/3844], Loss: 0.1649\n",
      "Epoch [3/4], Step [3370/3844], Loss: 0.0565\n",
      "Epoch [3/4], Step [3371/3844], Loss: 0.1237\n",
      "Epoch [3/4], Step [3372/3844], Loss: 0.1174\n",
      "Epoch [3/4], Step [3373/3844], Loss: 0.1207\n",
      "Epoch [3/4], Step [3374/3844], Loss: 0.0910\n",
      "Epoch [3/4], Step [3375/3844], Loss: 0.1319\n",
      "Epoch [3/4], Step [3376/3844], Loss: 0.1307\n",
      "Epoch [3/4], Step [3377/3844], Loss: 0.0899\n",
      "Epoch [3/4], Step [3378/3844], Loss: 0.0681\n",
      "Epoch [3/4], Step [3379/3844], Loss: 0.0506\n",
      "Epoch [3/4], Step [3380/3844], Loss: 0.1167\n",
      "Epoch [3/4], Step [3381/3844], Loss: 0.0645\n",
      "Epoch [3/4], Step [3382/3844], Loss: 0.0695\n",
      "Epoch [3/4], Step [3383/3844], Loss: 0.0639\n",
      "Epoch [3/4], Step [3384/3844], Loss: 0.0782\n",
      "Epoch [3/4], Step [3385/3844], Loss: 0.0602\n",
      "Epoch [3/4], Step [3386/3844], Loss: 0.1708\n",
      "Epoch [3/4], Step [3387/3844], Loss: 0.0861\n",
      "Epoch [3/4], Step [3388/3844], Loss: 0.0612\n",
      "Epoch [3/4], Step [3389/3844], Loss: 0.1124\n",
      "Epoch [3/4], Step [3390/3844], Loss: 0.0823\n",
      "Epoch [3/4], Step [3391/3844], Loss: 0.0673\n",
      "Epoch [3/4], Step [3392/3844], Loss: 0.1378\n",
      "Epoch [3/4], Step [3393/3844], Loss: 0.0929\n",
      "Epoch [3/4], Step [3394/3844], Loss: 0.0646\n",
      "Epoch [3/4], Step [3395/3844], Loss: 0.0497\n",
      "Epoch [3/4], Step [3396/3844], Loss: 0.0886\n",
      "Epoch [3/4], Step [3397/3844], Loss: 0.0886\n",
      "Epoch [3/4], Step [3398/3844], Loss: 0.0835\n",
      "Epoch [3/4], Step [3399/3844], Loss: 0.0937\n",
      "Epoch [3/4], Step [3400/3844], Loss: 0.1247\n",
      "Epoch [3/4], Step [3401/3844], Loss: 0.1302\n",
      "Epoch [3/4], Step [3402/3844], Loss: 0.1467\n",
      "Epoch [3/4], Step [3403/3844], Loss: 0.0686\n",
      "Epoch [3/4], Step [3404/3844], Loss: 0.1020\n",
      "Epoch [3/4], Step [3405/3844], Loss: 0.1333\n",
      "Epoch [3/4], Step [3406/3844], Loss: 0.0616\n",
      "Epoch [3/4], Step [3407/3844], Loss: 0.1060\n",
      "Epoch [3/4], Step [3408/3844], Loss: 0.0715\n",
      "Epoch [3/4], Step [3409/3844], Loss: 0.0756\n",
      "Epoch [3/4], Step [3410/3844], Loss: 0.0850\n",
      "Epoch [3/4], Step [3411/3844], Loss: 0.1251\n",
      "Epoch [3/4], Step [3412/3844], Loss: 0.0890\n",
      "Epoch [3/4], Step [3413/3844], Loss: 0.1253\n",
      "Epoch [3/4], Step [3414/3844], Loss: 0.0864\n",
      "Epoch [3/4], Step [3415/3844], Loss: 0.1262\n",
      "Epoch [3/4], Step [3416/3844], Loss: 0.0849\n",
      "Epoch [3/4], Step [3417/3844], Loss: 0.1125\n",
      "Epoch [3/4], Step [3418/3844], Loss: 0.1003\n",
      "Epoch [3/4], Step [3419/3844], Loss: 0.0847\n",
      "Epoch [3/4], Step [3420/3844], Loss: 0.1216\n",
      "Epoch [3/4], Step [3421/3844], Loss: 0.0814\n",
      "Epoch [3/4], Step [3422/3844], Loss: 0.1352\n",
      "Epoch [3/4], Step [3423/3844], Loss: 0.0506\n",
      "Epoch [3/4], Step [3424/3844], Loss: 0.0930\n",
      "Epoch [3/4], Step [3425/3844], Loss: 0.1039\n",
      "Epoch [3/4], Step [3426/3844], Loss: 0.0746\n",
      "Epoch [3/4], Step [3427/3844], Loss: 0.0987\n",
      "Epoch [3/4], Step [3428/3844], Loss: 0.1796\n",
      "Epoch [3/4], Step [3429/3844], Loss: 0.0808\n",
      "Epoch [3/4], Step [3430/3844], Loss: 0.0798\n",
      "Epoch [3/4], Step [3431/3844], Loss: 0.0578\n",
      "Epoch [3/4], Step [3432/3844], Loss: 0.0624\n",
      "Epoch [3/4], Step [3433/3844], Loss: 0.1541\n",
      "Epoch [3/4], Step [3434/3844], Loss: 0.1065\n",
      "Epoch [3/4], Step [3435/3844], Loss: 0.0886\n",
      "Epoch [3/4], Step [3436/3844], Loss: 0.1379\n",
      "Epoch [3/4], Step [3437/3844], Loss: 0.1132\n",
      "Epoch [3/4], Step [3438/3844], Loss: 0.0783\n",
      "Epoch [3/4], Step [3439/3844], Loss: 0.1544\n",
      "Epoch [3/4], Step [3440/3844], Loss: 0.0852\n",
      "Epoch [3/4], Step [3441/3844], Loss: 0.1527\n",
      "Epoch [3/4], Step [3442/3844], Loss: 0.1382\n",
      "Epoch [3/4], Step [3443/3844], Loss: 0.1278\n",
      "Epoch [3/4], Step [3444/3844], Loss: 0.1000\n",
      "Epoch [3/4], Step [3445/3844], Loss: 0.0779\n",
      "Epoch [3/4], Step [3446/3844], Loss: 0.0570\n",
      "Epoch [3/4], Step [3447/3844], Loss: 0.1625\n",
      "Epoch [3/4], Step [3448/3844], Loss: 0.1780\n",
      "Epoch [3/4], Step [3449/3844], Loss: 0.0974\n",
      "Epoch [3/4], Step [3450/3844], Loss: 0.1673\n",
      "Epoch [3/4], Step [3451/3844], Loss: 0.0811\n",
      "Epoch [3/4], Step [3452/3844], Loss: 0.1172\n",
      "Epoch [3/4], Step [3453/3844], Loss: 0.0729\n",
      "Epoch [3/4], Step [3454/3844], Loss: 0.0719\n",
      "Epoch [3/4], Step [3455/3844], Loss: 0.1579\n",
      "Epoch [3/4], Step [3456/3844], Loss: 0.1169\n",
      "Epoch [3/4], Step [3457/3844], Loss: 0.0865\n",
      "Epoch [3/4], Step [3458/3844], Loss: 0.0858\n",
      "Epoch [3/4], Step [3459/3844], Loss: 0.0805\n",
      "Epoch [3/4], Step [3460/3844], Loss: 0.0933\n",
      "Epoch [3/4], Step [3461/3844], Loss: 0.0913\n",
      "Epoch [3/4], Step [3462/3844], Loss: 0.1228\n",
      "Epoch [3/4], Step [3463/3844], Loss: 0.1445\n",
      "Epoch [3/4], Step [3464/3844], Loss: 0.0810\n",
      "Epoch [3/4], Step [3465/3844], Loss: 0.0805\n",
      "Epoch [3/4], Step [3466/3844], Loss: 0.0795\n",
      "Epoch [3/4], Step [3467/3844], Loss: 0.1476\n",
      "Epoch [3/4], Step [3468/3844], Loss: 0.0923\n",
      "Epoch [3/4], Step [3469/3844], Loss: 0.0596\n",
      "Epoch [3/4], Step [3470/3844], Loss: 0.0981\n",
      "Epoch [3/4], Step [3471/3844], Loss: 0.0871\n",
      "Epoch [3/4], Step [3472/3844], Loss: 0.0970\n",
      "Epoch [3/4], Step [3473/3844], Loss: 0.0992\n",
      "Epoch [3/4], Step [3474/3844], Loss: 0.0552\n",
      "Epoch [3/4], Step [3475/3844], Loss: 0.0905\n",
      "Epoch [3/4], Step [3476/3844], Loss: 0.0780\n",
      "Epoch [3/4], Step [3477/3844], Loss: 0.1164\n",
      "Epoch [3/4], Step [3478/3844], Loss: 0.0752\n",
      "Epoch [3/4], Step [3479/3844], Loss: 0.0653\n",
      "Epoch [3/4], Step [3480/3844], Loss: 0.0981\n",
      "Epoch [3/4], Step [3481/3844], Loss: 0.1590\n",
      "Epoch [3/4], Step [3482/3844], Loss: 0.1280\n",
      "Epoch [3/4], Step [3483/3844], Loss: 0.0525\n",
      "Epoch [3/4], Step [3484/3844], Loss: 0.0785\n",
      "Epoch [3/4], Step [3485/3844], Loss: 0.0668\n",
      "Epoch [3/4], Step [3486/3844], Loss: 0.1086\n",
      "Epoch [3/4], Step [3487/3844], Loss: 0.0365\n",
      "Epoch [3/4], Step [3488/3844], Loss: 0.1653\n",
      "Epoch [3/4], Step [3489/3844], Loss: 0.0723\n",
      "Epoch [3/4], Step [3490/3844], Loss: 0.0959\n",
      "Epoch [3/4], Step [3491/3844], Loss: 0.0975\n",
      "Epoch [3/4], Step [3492/3844], Loss: 0.1383\n",
      "Epoch [3/4], Step [3493/3844], Loss: 0.0824\n",
      "Epoch [3/4], Step [3494/3844], Loss: 0.0753\n",
      "Epoch [3/4], Step [3495/3844], Loss: 0.1511\n",
      "Epoch [3/4], Step [3496/3844], Loss: 0.1371\n",
      "Epoch [3/4], Step [3497/3844], Loss: 0.0495\n",
      "Epoch [3/4], Step [3498/3844], Loss: 0.0979\n",
      "Epoch [3/4], Step [3499/3844], Loss: 0.1176\n",
      "Epoch [3/4], Step [3500/3844], Loss: 0.1624\n",
      "Epoch [3/4], Step [3501/3844], Loss: 0.0784\n",
      "Epoch [3/4], Step [3502/3844], Loss: 0.0765\n",
      "Epoch [3/4], Step [3503/3844], Loss: 0.1206\n",
      "Epoch [3/4], Step [3504/3844], Loss: 0.0672\n",
      "Epoch [3/4], Step [3505/3844], Loss: 0.1893\n",
      "Epoch [3/4], Step [3506/3844], Loss: 0.1370\n",
      "Epoch [3/4], Step [3507/3844], Loss: 0.1566\n",
      "Epoch [3/4], Step [3508/3844], Loss: 0.0642\n",
      "Epoch [3/4], Step [3509/3844], Loss: 0.0656\n",
      "Epoch [3/4], Step [3510/3844], Loss: 0.0994\n",
      "Epoch [3/4], Step [3511/3844], Loss: 0.0733\n",
      "Epoch [3/4], Step [3512/3844], Loss: 0.0920\n",
      "Epoch [3/4], Step [3513/3844], Loss: 0.0712\n",
      "Epoch [3/4], Step [3514/3844], Loss: 0.0599\n",
      "Epoch [3/4], Step [3515/3844], Loss: 0.0359\n",
      "Epoch [3/4], Step [3516/3844], Loss: 0.0460\n",
      "Epoch [3/4], Step [3517/3844], Loss: 0.0637\n",
      "Epoch [3/4], Step [3518/3844], Loss: 0.0883\n",
      "Epoch [3/4], Step [3519/3844], Loss: 0.1051\n",
      "Epoch [3/4], Step [3520/3844], Loss: 0.0840\n",
      "Epoch [3/4], Step [3521/3844], Loss: 0.1701\n",
      "Epoch [3/4], Step [3522/3844], Loss: 0.1241\n",
      "Epoch [3/4], Step [3523/3844], Loss: 0.0690\n",
      "Epoch [3/4], Step [3524/3844], Loss: 0.0735\n",
      "Epoch [3/4], Step [3525/3844], Loss: 0.1302\n",
      "Epoch [3/4], Step [3526/3844], Loss: 0.1173\n",
      "Epoch [3/4], Step [3527/3844], Loss: 0.0740\n",
      "Epoch [3/4], Step [3528/3844], Loss: 0.1500\n",
      "Epoch [3/4], Step [3529/3844], Loss: 0.1132\n",
      "Epoch [3/4], Step [3530/3844], Loss: 0.0932\n",
      "Epoch [3/4], Step [3531/3844], Loss: 0.1530\n",
      "Epoch [3/4], Step [3532/3844], Loss: 0.0568\n",
      "Epoch [3/4], Step [3533/3844], Loss: 0.1542\n",
      "Epoch [3/4], Step [3534/3844], Loss: 0.1256\n",
      "Epoch [3/4], Step [3535/3844], Loss: 0.0596\n",
      "Epoch [3/4], Step [3536/3844], Loss: 0.0817\n",
      "Epoch [3/4], Step [3537/3844], Loss: 0.0470\n",
      "Epoch [3/4], Step [3538/3844], Loss: 0.0785\n",
      "Epoch [3/4], Step [3539/3844], Loss: 0.0764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/4], Step [3540/3844], Loss: 0.0826\n",
      "Epoch [3/4], Step [3541/3844], Loss: 0.0790\n",
      "Epoch [3/4], Step [3542/3844], Loss: 0.1058\n",
      "Epoch [3/4], Step [3543/3844], Loss: 0.1545\n",
      "Epoch [3/4], Step [3544/3844], Loss: 0.1914\n",
      "Epoch [3/4], Step [3545/3844], Loss: 0.0627\n",
      "Epoch [3/4], Step [3546/3844], Loss: 0.1024\n",
      "Epoch [3/4], Step [3547/3844], Loss: 0.0911\n",
      "Epoch [3/4], Step [3548/3844], Loss: 0.0868\n",
      "Epoch [3/4], Step [3549/3844], Loss: 0.0717\n",
      "Epoch [3/4], Step [3550/3844], Loss: 0.0947\n",
      "Epoch [3/4], Step [3551/3844], Loss: 0.1448\n",
      "Epoch [3/4], Step [3552/3844], Loss: 0.1440\n",
      "Epoch [3/4], Step [3553/3844], Loss: 0.0557\n",
      "Epoch [3/4], Step [3554/3844], Loss: 0.1235\n",
      "Epoch [3/4], Step [3555/3844], Loss: 0.0886\n",
      "Epoch [3/4], Step [3556/3844], Loss: 0.0620\n",
      "Epoch [3/4], Step [3557/3844], Loss: 0.1011\n",
      "Epoch [3/4], Step [3558/3844], Loss: 0.0793\n",
      "Epoch [3/4], Step [3559/3844], Loss: 0.1034\n",
      "Epoch [3/4], Step [3560/3844], Loss: 0.0805\n",
      "Epoch [3/4], Step [3561/3844], Loss: 0.0798\n",
      "Epoch [3/4], Step [3562/3844], Loss: 0.1176\n",
      "Epoch [3/4], Step [3563/3844], Loss: 0.0953\n",
      "Epoch [3/4], Step [3564/3844], Loss: 0.1556\n",
      "Epoch [3/4], Step [3565/3844], Loss: 0.0822\n",
      "Epoch [3/4], Step [3566/3844], Loss: 0.1161\n",
      "Epoch [3/4], Step [3567/3844], Loss: 0.0830\n",
      "Epoch [3/4], Step [3568/3844], Loss: 0.0555\n",
      "Epoch [3/4], Step [3569/3844], Loss: 0.1622\n",
      "Epoch [3/4], Step [3570/3844], Loss: 0.1054\n",
      "Epoch [3/4], Step [3571/3844], Loss: 0.1893\n",
      "Epoch [3/4], Step [3572/3844], Loss: 0.1283\n",
      "Epoch [3/4], Step [3573/3844], Loss: 0.0853\n",
      "Epoch [3/4], Step [3574/3844], Loss: 0.0880\n",
      "Epoch [3/4], Step [3575/3844], Loss: 0.0577\n",
      "Epoch [3/4], Step [3576/3844], Loss: 0.1082\n",
      "Epoch [3/4], Step [3577/3844], Loss: 0.1520\n",
      "Epoch [3/4], Step [3578/3844], Loss: 0.1651\n",
      "Epoch [3/4], Step [3579/3844], Loss: 0.0857\n",
      "Epoch [3/4], Step [3580/3844], Loss: 0.0330\n",
      "Epoch [3/4], Step [3581/3844], Loss: 0.0577\n",
      "Epoch [3/4], Step [3582/3844], Loss: 0.0922\n",
      "Epoch [3/4], Step [3583/3844], Loss: 0.1727\n",
      "Epoch [3/4], Step [3584/3844], Loss: 0.1493\n",
      "Epoch [3/4], Step [3585/3844], Loss: 0.1303\n",
      "Epoch [3/4], Step [3586/3844], Loss: 0.1552\n",
      "Epoch [3/4], Step [3587/3844], Loss: 0.1624\n",
      "Epoch [3/4], Step [3588/3844], Loss: 0.1630\n",
      "Epoch [3/4], Step [3589/3844], Loss: 0.0756\n",
      "Epoch [3/4], Step [3590/3844], Loss: 0.1180\n",
      "Epoch [3/4], Step [3591/3844], Loss: 0.0732\n",
      "Epoch [3/4], Step [3592/3844], Loss: 0.1030\n",
      "Epoch [3/4], Step [3593/3844], Loss: 0.1022\n",
      "Epoch [3/4], Step [3594/3844], Loss: 0.0860\n",
      "Epoch [3/4], Step [3595/3844], Loss: 0.0556\n",
      "Epoch [3/4], Step [3596/3844], Loss: 0.1319\n",
      "Epoch [3/4], Step [3597/3844], Loss: 0.1125\n",
      "Epoch [3/4], Step [3598/3844], Loss: 0.1111\n",
      "Epoch [3/4], Step [3599/3844], Loss: 0.1575\n",
      "Epoch [3/4], Step [3600/3844], Loss: 0.0990\n",
      "Epoch [3/4], Step [3601/3844], Loss: 0.0994\n",
      "Epoch [3/4], Step [3602/3844], Loss: 0.0628\n",
      "Epoch [3/4], Step [3603/3844], Loss: 0.1418\n",
      "Epoch [3/4], Step [3604/3844], Loss: 0.1117\n",
      "Epoch [3/4], Step [3605/3844], Loss: 0.0529\n",
      "Epoch [3/4], Step [3606/3844], Loss: 0.0776\n",
      "Epoch [3/4], Step [3607/3844], Loss: 0.1353\n",
      "Epoch [3/4], Step [3608/3844], Loss: 0.1669\n",
      "Epoch [3/4], Step [3609/3844], Loss: 0.0773\n",
      "Epoch [3/4], Step [3610/3844], Loss: 0.1178\n",
      "Epoch [3/4], Step [3611/3844], Loss: 0.0815\n",
      "Epoch [3/4], Step [3612/3844], Loss: 0.1004\n",
      "Epoch [3/4], Step [3613/3844], Loss: 0.0861\n",
      "Epoch [3/4], Step [3614/3844], Loss: 0.0775\n",
      "Epoch [3/4], Step [3615/3844], Loss: 0.0943\n",
      "Epoch [3/4], Step [3616/3844], Loss: 0.1706\n",
      "Epoch [3/4], Step [3617/3844], Loss: 0.1409\n",
      "Epoch [3/4], Step [3618/3844], Loss: 0.0921\n",
      "Epoch [3/4], Step [3619/3844], Loss: 0.0857\n",
      "Epoch [3/4], Step [3620/3844], Loss: 0.1030\n",
      "Epoch [3/4], Step [3621/3844], Loss: 0.1255\n",
      "Epoch [3/4], Step [3622/3844], Loss: 0.0890\n",
      "Epoch [3/4], Step [3623/3844], Loss: 0.1430\n",
      "Epoch [3/4], Step [3624/3844], Loss: 0.0959\n",
      "Epoch [3/4], Step [3625/3844], Loss: 0.0688\n",
      "Epoch [3/4], Step [3626/3844], Loss: 0.1030\n",
      "Epoch [3/4], Step [3627/3844], Loss: 0.1543\n",
      "Epoch [3/4], Step [3628/3844], Loss: 0.1026\n",
      "Epoch [3/4], Step [3629/3844], Loss: 0.0992\n",
      "Epoch [3/4], Step [3630/3844], Loss: 0.0924\n",
      "Epoch [3/4], Step [3631/3844], Loss: 0.0956\n",
      "Epoch [3/4], Step [3632/3844], Loss: 0.0751\n",
      "Epoch [3/4], Step [3633/3844], Loss: 0.1037\n",
      "Epoch [3/4], Step [3634/3844], Loss: 0.0538\n",
      "Epoch [3/4], Step [3635/3844], Loss: 0.1248\n",
      "Epoch [3/4], Step [3636/3844], Loss: 0.1273\n",
      "Epoch [3/4], Step [3637/3844], Loss: 0.1476\n",
      "Epoch [3/4], Step [3638/3844], Loss: 0.1471\n",
      "Epoch [3/4], Step [3639/3844], Loss: 0.0978\n",
      "Epoch [3/4], Step [3640/3844], Loss: 0.1373\n",
      "Epoch [3/4], Step [3641/3844], Loss: 0.0688\n",
      "Epoch [3/4], Step [3642/3844], Loss: 0.0528\n",
      "Epoch [3/4], Step [3643/3844], Loss: 0.1191\n",
      "Epoch [3/4], Step [3644/3844], Loss: 0.0780\n",
      "Epoch [3/4], Step [3645/3844], Loss: 0.1158\n",
      "Epoch [3/4], Step [3646/3844], Loss: 0.0779\n",
      "Epoch [3/4], Step [3647/3844], Loss: 0.0713\n",
      "Epoch [3/4], Step [3648/3844], Loss: 0.1512\n",
      "Epoch [3/4], Step [3649/3844], Loss: 0.1304\n",
      "Epoch [3/4], Step [3650/3844], Loss: 0.0802\n",
      "Epoch [3/4], Step [3651/3844], Loss: 0.0758\n",
      "Epoch [3/4], Step [3652/3844], Loss: 0.1622\n",
      "Epoch [3/4], Step [3653/3844], Loss: 0.0849\n",
      "Epoch [3/4], Step [3654/3844], Loss: 0.1636\n",
      "Epoch [3/4], Step [3655/3844], Loss: 0.0366\n",
      "Epoch [3/4], Step [3656/3844], Loss: 0.0714\n",
      "Epoch [3/4], Step [3657/3844], Loss: 0.0946\n",
      "Epoch [3/4], Step [3658/3844], Loss: 0.0962\n",
      "Epoch [3/4], Step [3659/3844], Loss: 0.1153\n",
      "Epoch [3/4], Step [3660/3844], Loss: 0.1015\n",
      "Epoch [3/4], Step [3661/3844], Loss: 0.0757\n",
      "Epoch [3/4], Step [3662/3844], Loss: 0.1007\n",
      "Epoch [3/4], Step [3663/3844], Loss: 0.1084\n",
      "Epoch [3/4], Step [3664/3844], Loss: 0.0778\n",
      "Epoch [3/4], Step [3665/3844], Loss: 0.0729\n",
      "Epoch [3/4], Step [3666/3844], Loss: 0.0921\n",
      "Epoch [3/4], Step [3667/3844], Loss: 0.1435\n",
      "Epoch [3/4], Step [3668/3844], Loss: 0.1232\n",
      "Epoch [3/4], Step [3669/3844], Loss: 0.1609\n",
      "Epoch [3/4], Step [3670/3844], Loss: 0.1326\n",
      "Epoch [3/4], Step [3671/3844], Loss: 0.0732\n",
      "Epoch [3/4], Step [3672/3844], Loss: 0.0885\n",
      "Epoch [3/4], Step [3673/3844], Loss: 0.0669\n",
      "Epoch [3/4], Step [3674/3844], Loss: 0.0772\n",
      "Epoch [3/4], Step [3675/3844], Loss: 0.1520\n",
      "Epoch [3/4], Step [3676/3844], Loss: 0.0652\n",
      "Epoch [3/4], Step [3677/3844], Loss: 0.1554\n",
      "Epoch [3/4], Step [3678/3844], Loss: 0.0674\n",
      "Epoch [3/4], Step [3679/3844], Loss: 0.1320\n",
      "Epoch [3/4], Step [3680/3844], Loss: 0.0863\n",
      "Epoch [3/4], Step [3681/3844], Loss: 0.1121\n",
      "Epoch [3/4], Step [3682/3844], Loss: 0.1115\n",
      "Epoch [3/4], Step [3683/3844], Loss: 0.1269\n",
      "Epoch [3/4], Step [3684/3844], Loss: 0.1400\n",
      "Epoch [3/4], Step [3685/3844], Loss: 0.1356\n",
      "Epoch [3/4], Step [3686/3844], Loss: 0.0811\n",
      "Epoch [3/4], Step [3687/3844], Loss: 0.0893\n",
      "Epoch [3/4], Step [3688/3844], Loss: 0.0800\n",
      "Epoch [3/4], Step [3689/3844], Loss: 0.0839\n",
      "Epoch [3/4], Step [3690/3844], Loss: 0.0584\n",
      "Epoch [3/4], Step [3691/3844], Loss: 0.1568\n",
      "Epoch [3/4], Step [3692/3844], Loss: 0.1099\n",
      "Epoch [3/4], Step [3693/3844], Loss: 0.1160\n",
      "Epoch [3/4], Step [3694/3844], Loss: 0.0768\n",
      "Epoch [3/4], Step [3695/3844], Loss: 0.0739\n",
      "Epoch [3/4], Step [3696/3844], Loss: 0.1705\n",
      "Epoch [3/4], Step [3697/3844], Loss: 0.0787\n",
      "Epoch [3/4], Step [3698/3844], Loss: 0.0921\n",
      "Epoch [3/4], Step [3699/3844], Loss: 0.0749\n",
      "Epoch [3/4], Step [3700/3844], Loss: 0.0455\n",
      "Epoch [3/4], Step [3701/3844], Loss: 0.0645\n",
      "Epoch [3/4], Step [3702/3844], Loss: 0.0417\n",
      "Epoch [3/4], Step [3703/3844], Loss: 0.0770\n",
      "Epoch [3/4], Step [3704/3844], Loss: 0.0890\n",
      "Epoch [3/4], Step [3705/3844], Loss: 0.0912\n",
      "Epoch [3/4], Step [3706/3844], Loss: 0.0876\n",
      "Epoch [3/4], Step [3707/3844], Loss: 0.0730\n",
      "Epoch [3/4], Step [3708/3844], Loss: 0.1300\n",
      "Epoch [3/4], Step [3709/3844], Loss: 0.1128\n",
      "Epoch [3/4], Step [3710/3844], Loss: 0.0970\n",
      "Epoch [3/4], Step [3711/3844], Loss: 0.1556\n",
      "Epoch [3/4], Step [3712/3844], Loss: 0.0712\n",
      "Epoch [3/4], Step [3713/3844], Loss: 0.1142\n",
      "Epoch [3/4], Step [3714/3844], Loss: 0.1204\n",
      "Epoch [3/4], Step [3715/3844], Loss: 0.0915\n",
      "Epoch [3/4], Step [3716/3844], Loss: 0.0897\n",
      "Epoch [3/4], Step [3717/3844], Loss: 0.0629\n",
      "Epoch [3/4], Step [3718/3844], Loss: 0.1124\n",
      "Epoch [3/4], Step [3719/3844], Loss: 0.0598\n",
      "Epoch [3/4], Step [3720/3844], Loss: 0.0788\n",
      "Epoch [3/4], Step [3721/3844], Loss: 0.0994\n",
      "Epoch [3/4], Step [3722/3844], Loss: 0.0457\n",
      "Epoch [3/4], Step [3723/3844], Loss: 0.0622\n",
      "Epoch [3/4], Step [3724/3844], Loss: 0.0996\n",
      "Epoch [3/4], Step [3725/3844], Loss: 0.0776\n",
      "Epoch [3/4], Step [3726/3844], Loss: 0.0574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/4], Step [3727/3844], Loss: 0.0785\n",
      "Epoch [3/4], Step [3728/3844], Loss: 0.0829\n",
      "Epoch [3/4], Step [3729/3844], Loss: 0.0543\n",
      "Epoch [3/4], Step [3730/3844], Loss: 0.0938\n",
      "Epoch [3/4], Step [3731/3844], Loss: 0.1612\n",
      "Epoch [3/4], Step [3732/3844], Loss: 0.0827\n",
      "Epoch [3/4], Step [3733/3844], Loss: 0.0778\n",
      "Epoch [3/4], Step [3734/3844], Loss: 0.0854\n",
      "Epoch [3/4], Step [3735/3844], Loss: 0.1122\n",
      "Epoch [3/4], Step [3736/3844], Loss: 0.1323\n",
      "Epoch [3/4], Step [3737/3844], Loss: 0.0836\n",
      "Epoch [3/4], Step [3738/3844], Loss: 0.1196\n",
      "Epoch [3/4], Step [3739/3844], Loss: 0.1244\n",
      "Epoch [3/4], Step [3740/3844], Loss: 0.0890\n",
      "Epoch [3/4], Step [3741/3844], Loss: 0.0648\n",
      "Epoch [3/4], Step [3742/3844], Loss: 0.1109\n",
      "Epoch [3/4], Step [3743/3844], Loss: 0.0552\n",
      "Epoch [3/4], Step [3744/3844], Loss: 0.1274\n",
      "Epoch [3/4], Step [3745/3844], Loss: 0.1189\n",
      "Epoch [3/4], Step [3746/3844], Loss: 0.1740\n",
      "Epoch [3/4], Step [3747/3844], Loss: 0.0832\n",
      "Epoch [3/4], Step [3748/3844], Loss: 0.1350\n",
      "Epoch [3/4], Step [3749/3844], Loss: 0.1370\n",
      "Epoch [3/4], Step [3750/3844], Loss: 0.1134\n",
      "Epoch [3/4], Step [3751/3844], Loss: 0.0699\n",
      "Epoch [3/4], Step [3752/3844], Loss: 0.1042\n",
      "Epoch [3/4], Step [3753/3844], Loss: 0.0800\n",
      "Epoch [3/4], Step [3754/3844], Loss: 0.0685\n",
      "Epoch [3/4], Step [3755/3844], Loss: 0.0511\n",
      "Epoch [3/4], Step [3756/3844], Loss: 0.0812\n",
      "Epoch [3/4], Step [3757/3844], Loss: 0.1362\n",
      "Epoch [3/4], Step [3758/3844], Loss: 0.1488\n",
      "Epoch [3/4], Step [3759/3844], Loss: 0.0680\n",
      "Epoch [3/4], Step [3760/3844], Loss: 0.0783\n",
      "Epoch [3/4], Step [3761/3844], Loss: 0.1016\n",
      "Epoch [3/4], Step [3762/3844], Loss: 0.1174\n",
      "Epoch [3/4], Step [3763/3844], Loss: 0.0736\n",
      "Epoch [3/4], Step [3764/3844], Loss: 0.0997\n",
      "Epoch [3/4], Step [3765/3844], Loss: 0.1137\n",
      "Epoch [3/4], Step [3766/3844], Loss: 0.0870\n",
      "Epoch [3/4], Step [3767/3844], Loss: 0.1338\n",
      "Epoch [3/4], Step [3768/3844], Loss: 0.1181\n",
      "Epoch [3/4], Step [3769/3844], Loss: 0.0692\n",
      "Epoch [3/4], Step [3770/3844], Loss: 0.0816\n",
      "Epoch [3/4], Step [3771/3844], Loss: 0.1046\n",
      "Epoch [3/4], Step [3772/3844], Loss: 0.0785\n",
      "Epoch [3/4], Step [3773/3844], Loss: 0.0900\n",
      "Epoch [3/4], Step [3774/3844], Loss: 0.0995\n",
      "Epoch [3/4], Step [3775/3844], Loss: 0.0919\n",
      "Epoch [3/4], Step [3776/3844], Loss: 0.0867\n",
      "Epoch [3/4], Step [3777/3844], Loss: 0.1357\n",
      "Epoch [3/4], Step [3778/3844], Loss: 0.0735\n",
      "Epoch [3/4], Step [3779/3844], Loss: 0.1201\n",
      "Epoch [3/4], Step [3780/3844], Loss: 0.0826\n",
      "Epoch [3/4], Step [3781/3844], Loss: 0.0890\n",
      "Epoch [3/4], Step [3782/3844], Loss: 0.1304\n",
      "Epoch [3/4], Step [3783/3844], Loss: 0.0858\n",
      "Epoch [3/4], Step [3784/3844], Loss: 0.0865\n",
      "Epoch [3/4], Step [3785/3844], Loss: 0.1052\n",
      "Epoch [3/4], Step [3786/3844], Loss: 0.0879\n",
      "Epoch [3/4], Step [3787/3844], Loss: 0.0916\n",
      "Epoch [3/4], Step [3788/3844], Loss: 0.1131\n",
      "Epoch [3/4], Step [3789/3844], Loss: 0.1214\n",
      "Epoch [3/4], Step [3790/3844], Loss: 0.1092\n",
      "Epoch [3/4], Step [3791/3844], Loss: 0.0895\n",
      "Epoch [3/4], Step [3792/3844], Loss: 0.0889\n",
      "Epoch [3/4], Step [3793/3844], Loss: 0.0597\n",
      "Epoch [3/4], Step [3794/3844], Loss: 0.0792\n",
      "Epoch [3/4], Step [3795/3844], Loss: 0.0762\n",
      "Epoch [3/4], Step [3796/3844], Loss: 0.1610\n",
      "Epoch [3/4], Step [3797/3844], Loss: 0.1228\n",
      "Epoch [3/4], Step [3798/3844], Loss: 0.0975\n",
      "Epoch [3/4], Step [3799/3844], Loss: 0.0932\n",
      "Epoch [3/4], Step [3800/3844], Loss: 0.0753\n",
      "Epoch [3/4], Step [3801/3844], Loss: 0.0538\n",
      "Epoch [3/4], Step [3802/3844], Loss: 0.0743\n",
      "Epoch [3/4], Step [3803/3844], Loss: 0.0970\n",
      "Epoch [3/4], Step [3804/3844], Loss: 0.1616\n",
      "Epoch [3/4], Step [3805/3844], Loss: 0.1496\n",
      "Epoch [3/4], Step [3806/3844], Loss: 0.1576\n",
      "Epoch [3/4], Step [3807/3844], Loss: 0.0534\n",
      "Epoch [3/4], Step [3808/3844], Loss: 0.0977\n",
      "Epoch [3/4], Step [3809/3844], Loss: 0.0566\n",
      "Epoch [3/4], Step [3810/3844], Loss: 0.1146\n",
      "Epoch [3/4], Step [3811/3844], Loss: 0.1359\n",
      "Epoch [3/4], Step [3812/3844], Loss: 0.0952\n",
      "Epoch [3/4], Step [3813/3844], Loss: 0.0592\n",
      "Epoch [3/4], Step [3814/3844], Loss: 0.1335\n",
      "Epoch [3/4], Step [3815/3844], Loss: 0.0985\n",
      "Epoch [3/4], Step [3816/3844], Loss: 0.0529\n",
      "Epoch [3/4], Step [3817/3844], Loss: 0.1125\n",
      "Epoch [3/4], Step [3818/3844], Loss: 0.0698\n",
      "Epoch [3/4], Step [3819/3844], Loss: 0.1365\n",
      "Epoch [3/4], Step [3820/3844], Loss: 0.0681\n",
      "Epoch [3/4], Step [3821/3844], Loss: 0.0711\n",
      "Epoch [3/4], Step [3822/3844], Loss: 0.0541\n",
      "Epoch [3/4], Step [3823/3844], Loss: 0.1296\n",
      "Epoch [3/4], Step [3824/3844], Loss: 0.0789\n",
      "Epoch [3/4], Step [3825/3844], Loss: 0.0735\n",
      "Epoch [3/4], Step [3826/3844], Loss: 0.1570\n",
      "Epoch [3/4], Step [3827/3844], Loss: 0.1511\n",
      "Epoch [3/4], Step [3828/3844], Loss: 0.1022\n",
      "Epoch [3/4], Step [3829/3844], Loss: 0.1057\n",
      "Epoch [3/4], Step [3830/3844], Loss: 0.1017\n",
      "Epoch [3/4], Step [3831/3844], Loss: 0.0710\n",
      "Epoch [3/4], Step [3832/3844], Loss: 0.1044\n",
      "Epoch [3/4], Step [3833/3844], Loss: 0.1103\n",
      "Epoch [3/4], Step [3834/3844], Loss: 0.1721\n",
      "Epoch [3/4], Step [3835/3844], Loss: 0.0485\n",
      "Epoch [3/4], Step [3836/3844], Loss: 0.0866\n",
      "Epoch [3/4], Step [3837/3844], Loss: 0.0719\n",
      "Epoch [3/4], Step [3838/3844], Loss: 0.1437\n",
      "Epoch [3/4], Step [3839/3844], Loss: 0.0570\n",
      "Epoch [3/4], Step [3840/3844], Loss: 0.1041\n",
      "Epoch [3/4], Step [3841/3844], Loss: 0.0782\n",
      "Epoch [3/4], Step [3842/3844], Loss: 0.0896\n",
      "Epoch [3/4], Step [3843/3844], Loss: 0.1038\n",
      "\n",
      "train-loss: 0.1390,\n",
      "Validation [3/4], Step [0/379], Loss: 0.0191\n",
      "Validation [3/4], Step [1/379], Loss: 0.0248\n",
      "Validation [3/4], Step [2/379], Loss: 0.0391\n",
      "Validation [3/4], Step [3/379], Loss: 0.0291\n",
      "Validation [3/4], Step [4/379], Loss: 0.0510\n",
      "Validation [3/4], Step [5/379], Loss: 0.0325\n",
      "Validation [3/4], Step [6/379], Loss: 0.0359\n",
      "Validation [3/4], Step [7/379], Loss: 0.0278\n",
      "Validation [3/4], Step [8/379], Loss: 0.0430\n",
      "Validation [3/4], Step [9/379], Loss: 0.0240\n",
      "Validation [3/4], Step [10/379], Loss: 0.0357\n",
      "Validation [3/4], Step [11/379], Loss: 0.0196\n",
      "Validation [3/4], Step [12/379], Loss: 0.0335\n",
      "Validation [3/4], Step [13/379], Loss: 0.0236\n",
      "Validation [3/4], Step [14/379], Loss: 0.0223\n",
      "Validation [3/4], Step [15/379], Loss: 0.0333\n",
      "Validation [3/4], Step [16/379], Loss: 0.0294\n",
      "Validation [3/4], Step [17/379], Loss: 0.0327\n",
      "Validation [3/4], Step [18/379], Loss: 0.0295\n",
      "Validation [3/4], Step [19/379], Loss: 0.0468\n",
      "Validation [3/4], Step [20/379], Loss: 0.0154\n",
      "Validation [3/4], Step [21/379], Loss: 0.0274\n",
      "Validation [3/4], Step [22/379], Loss: 0.0295\n",
      "Validation [3/4], Step [23/379], Loss: 0.0257\n",
      "Validation [3/4], Step [24/379], Loss: 0.0339\n",
      "Validation [3/4], Step [25/379], Loss: 0.0201\n",
      "Validation [3/4], Step [26/379], Loss: 0.0243\n",
      "Validation [3/4], Step [27/379], Loss: 0.0283\n",
      "Validation [3/4], Step [28/379], Loss: 0.0343\n",
      "Validation [3/4], Step [29/379], Loss: 0.0209\n",
      "Validation [3/4], Step [30/379], Loss: 0.0210\n",
      "Validation [3/4], Step [31/379], Loss: 0.0232\n",
      "Validation [3/4], Step [32/379], Loss: 0.0317\n",
      "Validation [3/4], Step [33/379], Loss: 0.0490\n",
      "Validation [3/4], Step [34/379], Loss: 0.0283\n",
      "Validation [3/4], Step [35/379], Loss: 0.0290\n",
      "Validation [3/4], Step [36/379], Loss: 0.0232\n",
      "Validation [3/4], Step [37/379], Loss: 0.0246\n",
      "Validation [3/4], Step [38/379], Loss: 0.0272\n",
      "Validation [3/4], Step [39/379], Loss: 0.0426\n",
      "Validation [3/4], Step [40/379], Loss: 0.0435\n",
      "Validation [3/4], Step [41/379], Loss: 0.0298\n",
      "Validation [3/4], Step [42/379], Loss: 0.0206\n",
      "Validation [3/4], Step [43/379], Loss: 0.0269\n",
      "Validation [3/4], Step [44/379], Loss: 0.0260\n",
      "Validation [3/4], Step [45/379], Loss: 0.0321\n",
      "Validation [3/4], Step [46/379], Loss: 0.0451\n",
      "Validation [3/4], Step [47/379], Loss: 0.0330\n",
      "Validation [3/4], Step [48/379], Loss: 0.0322\n",
      "Validation [3/4], Step [49/379], Loss: 0.0288\n",
      "Validation [3/4], Step [50/379], Loss: 0.0253\n",
      "Validation [3/4], Step [51/379], Loss: 0.0341\n",
      "Validation [3/4], Step [52/379], Loss: 0.0354\n",
      "Validation [3/4], Step [53/379], Loss: 0.0238\n",
      "Validation [3/4], Step [54/379], Loss: 0.0272\n",
      "Validation [3/4], Step [55/379], Loss: 0.0308\n",
      "Validation [3/4], Step [56/379], Loss: 0.0202\n",
      "Validation [3/4], Step [57/379], Loss: 0.0166\n",
      "Validation [3/4], Step [58/379], Loss: 0.0252\n",
      "Validation [3/4], Step [59/379], Loss: 0.0315\n",
      "Validation [3/4], Step [60/379], Loss: 0.0346\n",
      "Validation [3/4], Step [61/379], Loss: 0.0280\n",
      "Validation [3/4], Step [62/379], Loss: 0.0199\n",
      "Validation [3/4], Step [63/379], Loss: 0.0235\n",
      "Validation [3/4], Step [64/379], Loss: 0.0439\n",
      "Validation [3/4], Step [65/379], Loss: 0.0357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation [3/4], Step [66/379], Loss: 0.0195\n",
      "Validation [3/4], Step [67/379], Loss: 0.0260\n",
      "Validation [3/4], Step [68/379], Loss: 0.0273\n",
      "Validation [3/4], Step [69/379], Loss: 0.0366\n",
      "Validation [3/4], Step [70/379], Loss: 0.0347\n",
      "Validation [3/4], Step [71/379], Loss: 0.0449\n",
      "Validation [3/4], Step [72/379], Loss: 0.0279\n",
      "Validation [3/4], Step [73/379], Loss: 0.0199\n",
      "Validation [3/4], Step [74/379], Loss: 0.0387\n",
      "Validation [3/4], Step [75/379], Loss: 0.0393\n",
      "Validation [3/4], Step [76/379], Loss: 0.0246\n",
      "Validation [3/4], Step [77/379], Loss: 0.0344\n",
      "Validation [3/4], Step [78/379], Loss: 0.0356\n",
      "Validation [3/4], Step [79/379], Loss: 0.0354\n",
      "Validation [3/4], Step [80/379], Loss: 0.0506\n",
      "Validation [3/4], Step [81/379], Loss: 0.0310\n",
      "Validation [3/4], Step [82/379], Loss: 0.0315\n",
      "Validation [3/4], Step [83/379], Loss: 0.0153\n",
      "Validation [3/4], Step [84/379], Loss: 0.0277\n",
      "Validation [3/4], Step [85/379], Loss: 0.0354\n",
      "Validation [3/4], Step [86/379], Loss: 0.0299\n",
      "Validation [3/4], Step [87/379], Loss: 0.0413\n",
      "Validation [3/4], Step [88/379], Loss: 0.0253\n",
      "Validation [3/4], Step [89/379], Loss: 0.0274\n",
      "Validation [3/4], Step [90/379], Loss: 0.0179\n",
      "Validation [3/4], Step [91/379], Loss: 0.0249\n",
      "Validation [3/4], Step [92/379], Loss: 0.0474\n",
      "Validation [3/4], Step [93/379], Loss: 0.0320\n",
      "Validation [3/4], Step [94/379], Loss: 0.0341\n",
      "Validation [3/4], Step [95/379], Loss: 0.0393\n",
      "Validation [3/4], Step [96/379], Loss: 0.0231\n",
      "Validation [3/4], Step [97/379], Loss: 0.0267\n",
      "Validation [3/4], Step [98/379], Loss: 0.0306\n",
      "Validation [3/4], Step [99/379], Loss: 0.0167\n",
      "Validation [3/4], Step [100/379], Loss: 0.0203\n",
      "Validation [3/4], Step [101/379], Loss: 0.0368\n",
      "Validation [3/4], Step [102/379], Loss: 0.0462\n",
      "Validation [3/4], Step [103/379], Loss: 0.0189\n",
      "Validation [3/4], Step [104/379], Loss: 0.0294\n",
      "Validation [3/4], Step [105/379], Loss: 0.0336\n",
      "Validation [3/4], Step [106/379], Loss: 0.0254\n",
      "Validation [3/4], Step [107/379], Loss: 0.0335\n",
      "Validation [3/4], Step [108/379], Loss: 0.0263\n",
      "Validation [3/4], Step [109/379], Loss: 0.0158\n",
      "Validation [3/4], Step [110/379], Loss: 0.0391\n",
      "Validation [3/4], Step [111/379], Loss: 0.0330\n",
      "Validation [3/4], Step [112/379], Loss: 0.0316\n",
      "Validation [3/4], Step [113/379], Loss: 0.0400\n",
      "Validation [3/4], Step [114/379], Loss: 0.0339\n",
      "Validation [3/4], Step [115/379], Loss: 0.0237\n",
      "Validation [3/4], Step [116/379], Loss: 0.0261\n",
      "Validation [3/4], Step [117/379], Loss: 0.0282\n",
      "Validation [3/4], Step [118/379], Loss: 0.0270\n",
      "Validation [3/4], Step [119/379], Loss: 0.0194\n",
      "Validation [3/4], Step [120/379], Loss: 0.0245\n",
      "Validation [3/4], Step [121/379], Loss: 0.0281\n",
      "Validation [3/4], Step [122/379], Loss: 0.0232\n",
      "Validation [3/4], Step [123/379], Loss: 0.0270\n",
      "Validation [3/4], Step [124/379], Loss: 0.0257\n",
      "Validation [3/4], Step [125/379], Loss: 0.0449\n",
      "Validation [3/4], Step [126/379], Loss: 0.0411\n",
      "Validation [3/4], Step [127/379], Loss: 0.0235\n",
      "Validation [3/4], Step [128/379], Loss: 0.0471\n",
      "Validation [3/4], Step [129/379], Loss: 0.0263\n",
      "Validation [3/4], Step [130/379], Loss: 0.0342\n",
      "Validation [3/4], Step [131/379], Loss: 0.0202\n",
      "Validation [3/4], Step [132/379], Loss: 0.0169\n",
      "Validation [3/4], Step [133/379], Loss: 0.0259\n",
      "Validation [3/4], Step [134/379], Loss: 0.0282\n",
      "Validation [3/4], Step [135/379], Loss: 0.0266\n",
      "Validation [3/4], Step [136/379], Loss: 0.0227\n",
      "Validation [3/4], Step [137/379], Loss: 0.0285\n",
      "Validation [3/4], Step [138/379], Loss: 0.0230\n",
      "Validation [3/4], Step [139/379], Loss: 0.0384\n",
      "Validation [3/4], Step [140/379], Loss: 0.0191\n",
      "Validation [3/4], Step [141/379], Loss: 0.0549\n",
      "Validation [3/4], Step [142/379], Loss: 0.0205\n",
      "Validation [3/4], Step [143/379], Loss: 0.0218\n",
      "Validation [3/4], Step [144/379], Loss: 0.0138\n",
      "Validation [3/4], Step [145/379], Loss: 0.0470\n",
      "Validation [3/4], Step [146/379], Loss: 0.0340\n",
      "Validation [3/4], Step [147/379], Loss: 0.0549\n",
      "Validation [3/4], Step [148/379], Loss: 0.0251\n",
      "Validation [3/4], Step [149/379], Loss: 0.0325\n",
      "Validation [3/4], Step [150/379], Loss: 0.0216\n",
      "Validation [3/4], Step [151/379], Loss: 0.0391\n",
      "Validation [3/4], Step [152/379], Loss: 0.0289\n",
      "Validation [3/4], Step [153/379], Loss: 0.0179\n",
      "Validation [3/4], Step [154/379], Loss: 0.0253\n",
      "Validation [3/4], Step [155/379], Loss: 0.0279\n",
      "Validation [3/4], Step [156/379], Loss: 0.0347\n",
      "Validation [3/4], Step [157/379], Loss: 0.0234\n",
      "Validation [3/4], Step [158/379], Loss: 0.0364\n",
      "Validation [3/4], Step [159/379], Loss: 0.0291\n",
      "Validation [3/4], Step [160/379], Loss: 0.0303\n",
      "Validation [3/4], Step [161/379], Loss: 0.0265\n",
      "Validation [3/4], Step [162/379], Loss: 0.0279\n",
      "Validation [3/4], Step [163/379], Loss: 0.0315\n",
      "Validation [3/4], Step [164/379], Loss: 0.0219\n",
      "Validation [3/4], Step [165/379], Loss: 0.0252\n",
      "Validation [3/4], Step [166/379], Loss: 0.0449\n",
      "Validation [3/4], Step [167/379], Loss: 0.0300\n",
      "Validation [3/4], Step [168/379], Loss: 0.0412\n",
      "Validation [3/4], Step [169/379], Loss: 0.0272\n",
      "Validation [3/4], Step [170/379], Loss: 0.0272\n",
      "Validation [3/4], Step [171/379], Loss: 0.0174\n",
      "Validation [3/4], Step [172/379], Loss: 0.0417\n",
      "Validation [3/4], Step [173/379], Loss: 0.0266\n",
      "Validation [3/4], Step [174/379], Loss: 0.0332\n",
      "Validation [3/4], Step [175/379], Loss: 0.0242\n",
      "Validation [3/4], Step [176/379], Loss: 0.0300\n",
      "Validation [3/4], Step [177/379], Loss: 0.0376\n",
      "Validation [3/4], Step [178/379], Loss: 0.0241\n",
      "Validation [3/4], Step [179/379], Loss: 0.0237\n",
      "Validation [3/4], Step [180/379], Loss: 0.0457\n",
      "Validation [3/4], Step [181/379], Loss: 0.0213\n",
      "Validation [3/4], Step [182/379], Loss: 0.0216\n",
      "Validation [3/4], Step [183/379], Loss: 0.0206\n",
      "Validation [3/4], Step [184/379], Loss: 0.0435\n",
      "Validation [3/4], Step [185/379], Loss: 0.0249\n",
      "Validation [3/4], Step [186/379], Loss: 0.0247\n",
      "Validation [3/4], Step [187/379], Loss: 0.0280\n",
      "Validation [3/4], Step [188/379], Loss: 0.0316\n",
      "Validation [3/4], Step [189/379], Loss: 0.0344\n",
      "Validation [3/4], Step [190/379], Loss: 0.0333\n",
      "Validation [3/4], Step [191/379], Loss: 0.0283\n",
      "Validation [3/4], Step [192/379], Loss: 0.0240\n",
      "Validation [3/4], Step [193/379], Loss: 0.0426\n",
      "Validation [3/4], Step [194/379], Loss: 0.0441\n",
      "Validation [3/4], Step [195/379], Loss: 0.0513\n",
      "Validation [3/4], Step [196/379], Loss: 0.0384\n",
      "Validation [3/4], Step [197/379], Loss: 0.0294\n",
      "Validation [3/4], Step [198/379], Loss: 0.0556\n",
      "Validation [3/4], Step [199/379], Loss: 0.0161\n",
      "Validation [3/4], Step [200/379], Loss: 0.0324\n",
      "Validation [3/4], Step [201/379], Loss: 0.0318\n",
      "Validation [3/4], Step [202/379], Loss: 0.0296\n",
      "Validation [3/4], Step [203/379], Loss: 0.0298\n",
      "Validation [3/4], Step [204/379], Loss: 0.0355\n",
      "Validation [3/4], Step [205/379], Loss: 0.0416\n",
      "Validation [3/4], Step [206/379], Loss: 0.0224\n",
      "Validation [3/4], Step [207/379], Loss: 0.0330\n",
      "Validation [3/4], Step [208/379], Loss: 0.0178\n",
      "Validation [3/4], Step [209/379], Loss: 0.0259\n",
      "Validation [3/4], Step [210/379], Loss: 0.0342\n",
      "Validation [3/4], Step [211/379], Loss: 0.0337\n",
      "Validation [3/4], Step [212/379], Loss: 0.0217\n",
      "Validation [3/4], Step [213/379], Loss: 0.0465\n",
      "Validation [3/4], Step [214/379], Loss: 0.0331\n",
      "Validation [3/4], Step [215/379], Loss: 0.0315\n",
      "Validation [3/4], Step [216/379], Loss: 0.0414\n",
      "Validation [3/4], Step [217/379], Loss: 0.0309\n",
      "Validation [3/4], Step [218/379], Loss: 0.0362\n",
      "Validation [3/4], Step [219/379], Loss: 0.0355\n",
      "Validation [3/4], Step [220/379], Loss: 0.0276\n",
      "Validation [3/4], Step [221/379], Loss: 0.0249\n",
      "Validation [3/4], Step [222/379], Loss: 0.0314\n",
      "Validation [3/4], Step [223/379], Loss: 0.0378\n",
      "Validation [3/4], Step [224/379], Loss: 0.0278\n",
      "Validation [3/4], Step [225/379], Loss: 0.0221\n",
      "Validation [3/4], Step [226/379], Loss: 0.0250\n",
      "Validation [3/4], Step [227/379], Loss: 0.0237\n",
      "Validation [3/4], Step [228/379], Loss: 0.0424\n",
      "Validation [3/4], Step [229/379], Loss: 0.0309\n",
      "Validation [3/4], Step [230/379], Loss: 0.0282\n",
      "Validation [3/4], Step [231/379], Loss: 0.0250\n",
      "Validation [3/4], Step [232/379], Loss: 0.0311\n",
      "Validation [3/4], Step [233/379], Loss: 0.0430\n",
      "Validation [3/4], Step [234/379], Loss: 0.0268\n",
      "Validation [3/4], Step [235/379], Loss: 0.0208\n",
      "Validation [3/4], Step [236/379], Loss: 0.0410\n",
      "Validation [3/4], Step [237/379], Loss: 0.0332\n",
      "Validation [3/4], Step [238/379], Loss: 0.0463\n",
      "Validation [3/4], Step [239/379], Loss: 0.0459\n",
      "Validation [3/4], Step [240/379], Loss: 0.0232\n",
      "Validation [3/4], Step [241/379], Loss: 0.0183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation [3/4], Step [242/379], Loss: 0.0401\n",
      "Validation [3/4], Step [243/379], Loss: 0.0310\n",
      "Validation [3/4], Step [244/379], Loss: 0.0222\n",
      "Validation [3/4], Step [245/379], Loss: 0.0287\n",
      "Validation [3/4], Step [246/379], Loss: 0.0330\n",
      "Validation [3/4], Step [247/379], Loss: 0.0201\n",
      "Validation [3/4], Step [248/379], Loss: 0.0369\n",
      "Validation [3/4], Step [249/379], Loss: 0.0303\n",
      "Validation [3/4], Step [250/379], Loss: 0.0362\n",
      "Validation [3/4], Step [251/379], Loss: 0.0408\n",
      "Validation [3/4], Step [252/379], Loss: 0.0448\n",
      "Validation [3/4], Step [253/379], Loss: 0.0313\n",
      "Validation [3/4], Step [254/379], Loss: 0.0271\n",
      "Validation [3/4], Step [255/379], Loss: 0.0356\n",
      "Validation [3/4], Step [256/379], Loss: 0.0189\n",
      "Validation [3/4], Step [257/379], Loss: 0.0347\n",
      "Validation [3/4], Step [258/379], Loss: 0.0344\n",
      "Validation [3/4], Step [259/379], Loss: 0.0261\n",
      "Validation [3/4], Step [260/379], Loss: 0.0324\n",
      "Validation [3/4], Step [261/379], Loss: 0.0223\n",
      "Validation [3/4], Step [262/379], Loss: 0.0300\n",
      "Validation [3/4], Step [263/379], Loss: 0.0259\n",
      "Validation [3/4], Step [264/379], Loss: 0.0197\n",
      "Validation [3/4], Step [265/379], Loss: 0.0259\n",
      "Validation [3/4], Step [266/379], Loss: 0.0371\n",
      "Validation [3/4], Step [267/379], Loss: 0.0222\n",
      "Validation [3/4], Step [268/379], Loss: 0.0249\n",
      "Validation [3/4], Step [269/379], Loss: 0.0357\n",
      "Validation [3/4], Step [270/379], Loss: 0.0261\n",
      "Validation [3/4], Step [271/379], Loss: 0.0249\n",
      "Validation [3/4], Step [272/379], Loss: 0.0230\n",
      "Validation [3/4], Step [273/379], Loss: 0.0377\n",
      "Validation [3/4], Step [274/379], Loss: 0.0353\n",
      "Validation [3/4], Step [275/379], Loss: 0.0379\n",
      "Validation [3/4], Step [276/379], Loss: 0.0158\n",
      "Validation [3/4], Step [277/379], Loss: 0.0260\n",
      "Validation [3/4], Step [278/379], Loss: 0.0248\n",
      "Validation [3/4], Step [279/379], Loss: 0.0186\n",
      "Validation [3/4], Step [280/379], Loss: 0.0327\n",
      "Validation [3/4], Step [281/379], Loss: 0.0426\n",
      "Validation [3/4], Step [282/379], Loss: 0.0210\n",
      "Validation [3/4], Step [283/379], Loss: 0.0233\n",
      "Validation [3/4], Step [284/379], Loss: 0.0334\n",
      "Validation [3/4], Step [285/379], Loss: 0.0255\n",
      "Validation [3/4], Step [286/379], Loss: 0.0258\n",
      "Validation [3/4], Step [287/379], Loss: 0.0225\n",
      "Validation [3/4], Step [288/379], Loss: 0.0338\n",
      "Validation [3/4], Step [289/379], Loss: 0.0403\n",
      "Validation [3/4], Step [290/379], Loss: 0.0184\n",
      "Validation [3/4], Step [291/379], Loss: 0.0319\n",
      "Validation [3/4], Step [292/379], Loss: 0.0312\n",
      "Validation [3/4], Step [293/379], Loss: 0.0305\n",
      "Validation [3/4], Step [294/379], Loss: 0.0335\n",
      "Validation [3/4], Step [295/379], Loss: 0.0235\n",
      "Validation [3/4], Step [296/379], Loss: 0.0344\n",
      "Validation [3/4], Step [297/379], Loss: 0.0223\n",
      "Validation [3/4], Step [298/379], Loss: 0.0261\n",
      "Validation [3/4], Step [299/379], Loss: 0.0334\n",
      "Validation [3/4], Step [300/379], Loss: 0.0208\n",
      "Validation [3/4], Step [301/379], Loss: 0.0283\n",
      "Validation [3/4], Step [302/379], Loss: 0.0312\n",
      "Validation [3/4], Step [303/379], Loss: 0.0239\n",
      "Validation [3/4], Step [304/379], Loss: 0.0224\n",
      "Validation [3/4], Step [305/379], Loss: 0.0263\n",
      "Validation [3/4], Step [306/379], Loss: 0.0341\n",
      "Validation [3/4], Step [307/379], Loss: 0.0249\n",
      "Validation [3/4], Step [308/379], Loss: 0.0221\n",
      "Validation [3/4], Step [309/379], Loss: 0.0266\n",
      "Validation [3/4], Step [310/379], Loss: 0.0193\n",
      "Validation [3/4], Step [311/379], Loss: 0.0211\n",
      "Validation [3/4], Step [312/379], Loss: 0.0348\n",
      "Validation [3/4], Step [313/379], Loss: 0.0442\n",
      "Validation [3/4], Step [314/379], Loss: 0.0185\n",
      "Validation [3/4], Step [315/379], Loss: 0.0216\n",
      "Validation [3/4], Step [316/379], Loss: 0.0201\n",
      "Validation [3/4], Step [317/379], Loss: 0.0262\n",
      "Validation [3/4], Step [318/379], Loss: 0.0381\n",
      "Validation [3/4], Step [319/379], Loss: 0.0294\n",
      "Validation [3/4], Step [320/379], Loss: 0.0221\n",
      "Validation [3/4], Step [321/379], Loss: 0.0255\n",
      "Validation [3/4], Step [322/379], Loss: 0.0247\n",
      "Validation [3/4], Step [323/379], Loss: 0.0303\n",
      "Validation [3/4], Step [324/379], Loss: 0.0204\n",
      "Validation [3/4], Step [325/379], Loss: 0.0324\n",
      "Validation [3/4], Step [326/379], Loss: 0.0325\n",
      "Validation [3/4], Step [327/379], Loss: 0.0223\n",
      "Validation [3/4], Step [328/379], Loss: 0.0294\n",
      "Validation [3/4], Step [329/379], Loss: 0.0316\n",
      "Validation [3/4], Step [330/379], Loss: 0.0240\n",
      "Validation [3/4], Step [331/379], Loss: 0.0408\n",
      "Validation [3/4], Step [332/379], Loss: 0.0461\n",
      "Validation [3/4], Step [333/379], Loss: 0.0263\n",
      "Validation [3/4], Step [334/379], Loss: 0.0401\n",
      "Validation [3/4], Step [335/379], Loss: 0.0457\n",
      "Validation [3/4], Step [336/379], Loss: 0.0467\n",
      "Validation [3/4], Step [337/379], Loss: 0.0201\n",
      "Validation [3/4], Step [338/379], Loss: 0.0321\n",
      "Validation [3/4], Step [339/379], Loss: 0.0276\n",
      "Validation [3/4], Step [340/379], Loss: 0.0158\n",
      "Validation [3/4], Step [341/379], Loss: 0.0228\n",
      "Validation [3/4], Step [342/379], Loss: 0.0274\n",
      "Validation [3/4], Step [343/379], Loss: 0.0364\n",
      "Validation [3/4], Step [344/379], Loss: 0.0274\n",
      "Validation [3/4], Step [345/379], Loss: 0.0281\n",
      "Validation [3/4], Step [346/379], Loss: 0.0232\n",
      "Validation [3/4], Step [347/379], Loss: 0.0252\n",
      "Validation [3/4], Step [348/379], Loss: 0.0258\n",
      "Validation [3/4], Step [349/379], Loss: 0.0430\n",
      "Validation [3/4], Step [350/379], Loss: 0.0323\n",
      "Validation [3/4], Step [351/379], Loss: 0.0216\n",
      "Validation [3/4], Step [352/379], Loss: 0.0362\n",
      "Validation [3/4], Step [353/379], Loss: 0.0283\n",
      "Validation [3/4], Step [354/379], Loss: 0.0250\n",
      "Validation [3/4], Step [355/379], Loss: 0.0184\n",
      "Validation [3/4], Step [356/379], Loss: 0.0257\n",
      "Validation [3/4], Step [357/379], Loss: 0.0298\n",
      "Validation [3/4], Step [358/379], Loss: 0.0232\n",
      "Validation [3/4], Step [359/379], Loss: 0.0235\n",
      "Validation [3/4], Step [360/379], Loss: 0.0180\n",
      "Validation [3/4], Step [361/379], Loss: 0.0392\n",
      "Validation [3/4], Step [362/379], Loss: 0.0251\n",
      "Validation [3/4], Step [363/379], Loss: 0.0231\n",
      "Validation [3/4], Step [364/379], Loss: 0.0315\n",
      "Validation [3/4], Step [365/379], Loss: 0.0447\n",
      "Validation [3/4], Step [366/379], Loss: 0.0240\n",
      "Validation [3/4], Step [367/379], Loss: 0.0605\n",
      "Validation [3/4], Step [368/379], Loss: 0.0341\n",
      "Validation [3/4], Step [369/379], Loss: 0.0340\n",
      "Validation [3/4], Step [370/379], Loss: 0.0211\n",
      "Validation [3/4], Step [371/379], Loss: 0.0440\n",
      "Validation [3/4], Step [372/379], Loss: 0.0213\n",
      "Validation [3/4], Step [373/379], Loss: 0.0479\n",
      "Validation [3/4], Step [374/379], Loss: 0.0185\n",
      "Validation [3/4], Step [375/379], Loss: 0.0264\n",
      "Validation [3/4], Step [376/379], Loss: 0.0313\n",
      "Validation [3/4], Step [377/379], Loss: 0.0519\n",
      "Validation [3/4], Step [378/379], Loss: 0.0280\n",
      "validation loss: 0.0567, \n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 4\n",
      "\n",
      "Epoch [4/4], Step [0/3844], Loss: 0.0768\n",
      "Epoch [4/4], Step [1/3844], Loss: 0.0940\n",
      "Epoch [4/4], Step [2/3844], Loss: 0.0550\n",
      "Epoch [4/4], Step [3/3844], Loss: 0.1299\n",
      "Epoch [4/4], Step [4/3844], Loss: 0.0981\n",
      "Epoch [4/4], Step [5/3844], Loss: 0.1184\n",
      "Epoch [4/4], Step [6/3844], Loss: 0.0980\n",
      "Epoch [4/4], Step [7/3844], Loss: 0.1453\n",
      "Epoch [4/4], Step [8/3844], Loss: 0.1290\n",
      "Epoch [4/4], Step [9/3844], Loss: 0.0689\n",
      "Epoch [4/4], Step [10/3844], Loss: 0.1407\n",
      "Epoch [4/4], Step [11/3844], Loss: 0.0488\n",
      "Epoch [4/4], Step [12/3844], Loss: 0.1312\n",
      "Epoch [4/4], Step [13/3844], Loss: 0.0927\n",
      "Epoch [4/4], Step [14/3844], Loss: 0.0616\n",
      "Epoch [4/4], Step [15/3844], Loss: 0.1120\n",
      "Epoch [4/4], Step [16/3844], Loss: 0.1404\n",
      "Epoch [4/4], Step [17/3844], Loss: 0.1186\n",
      "Epoch [4/4], Step [18/3844], Loss: 0.1019\n",
      "Epoch [4/4], Step [19/3844], Loss: 0.1515\n",
      "Epoch [4/4], Step [20/3844], Loss: 0.0702\n",
      "Epoch [4/4], Step [21/3844], Loss: 0.0889\n",
      "Epoch [4/4], Step [22/3844], Loss: 0.1340\n",
      "Epoch [4/4], Step [23/3844], Loss: 0.1542\n",
      "Epoch [4/4], Step [24/3844], Loss: 0.0702\n",
      "Epoch [4/4], Step [25/3844], Loss: 0.0664\n",
      "Epoch [4/4], Step [26/3844], Loss: 0.1344\n",
      "Epoch [4/4], Step [27/3844], Loss: 0.0796\n",
      "Epoch [4/4], Step [28/3844], Loss: 0.0641\n",
      "Epoch [4/4], Step [29/3844], Loss: 0.1792\n",
      "Epoch [4/4], Step [30/3844], Loss: 0.0752\n",
      "Epoch [4/4], Step [31/3844], Loss: 0.0960\n",
      "Epoch [4/4], Step [32/3844], Loss: 0.1816\n",
      "Epoch [4/4], Step [33/3844], Loss: 0.0623\n",
      "Epoch [4/4], Step [34/3844], Loss: 0.1225\n",
      "Epoch [4/4], Step [35/3844], Loss: 0.0641\n",
      "Epoch [4/4], Step [36/3844], Loss: 0.0991\n",
      "Epoch [4/4], Step [37/3844], Loss: 0.1197\n",
      "Epoch [4/4], Step [38/3844], Loss: 0.0870\n",
      "Epoch [4/4], Step [39/3844], Loss: 0.0943\n",
      "Epoch [4/4], Step [40/3844], Loss: 0.1197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/4], Step [41/3844], Loss: 0.0738\n",
      "Epoch [4/4], Step [42/3844], Loss: 0.1498\n",
      "Epoch [4/4], Step [43/3844], Loss: 0.0879\n",
      "Epoch [4/4], Step [44/3844], Loss: 0.1626\n",
      "Epoch [4/4], Step [45/3844], Loss: 0.0711\n",
      "Epoch [4/4], Step [46/3844], Loss: 0.1087\n",
      "Epoch [4/4], Step [47/3844], Loss: 0.0791\n",
      "Epoch [4/4], Step [48/3844], Loss: 0.0918\n",
      "Epoch [4/4], Step [49/3844], Loss: 0.0920\n",
      "Epoch [4/4], Step [50/3844], Loss: 0.1045\n",
      "Epoch [4/4], Step [51/3844], Loss: 0.0605\n",
      "Epoch [4/4], Step [52/3844], Loss: 0.0900\n",
      "Epoch [4/4], Step [53/3844], Loss: 0.0816\n",
      "Epoch [4/4], Step [54/3844], Loss: 0.1035\n",
      "Epoch [4/4], Step [55/3844], Loss: 0.1009\n",
      "Epoch [4/4], Step [56/3844], Loss: 0.1220\n",
      "Epoch [4/4], Step [57/3844], Loss: 0.1575\n",
      "Epoch [4/4], Step [58/3844], Loss: 0.0504\n",
      "Epoch [4/4], Step [59/3844], Loss: 0.0708\n",
      "Epoch [4/4], Step [60/3844], Loss: 0.0888\n",
      "Epoch [4/4], Step [61/3844], Loss: 0.1039\n",
      "Epoch [4/4], Step [62/3844], Loss: 0.0927\n",
      "Epoch [4/4], Step [63/3844], Loss: 0.1249\n",
      "Epoch [4/4], Step [64/3844], Loss: 0.1077\n",
      "Epoch [4/4], Step [65/3844], Loss: 0.1380\n",
      "Epoch [4/4], Step [66/3844], Loss: 0.1057\n",
      "Epoch [4/4], Step [67/3844], Loss: 0.1255\n",
      "Epoch [4/4], Step [68/3844], Loss: 0.1260\n",
      "Epoch [4/4], Step [69/3844], Loss: 0.1100\n",
      "Epoch [4/4], Step [70/3844], Loss: 0.0761\n",
      "Epoch [4/4], Step [71/3844], Loss: 0.0671\n",
      "Epoch [4/4], Step [72/3844], Loss: 0.0746\n",
      "Epoch [4/4], Step [73/3844], Loss: 0.1273\n",
      "Epoch [4/4], Step [74/3844], Loss: 0.0601\n",
      "Epoch [4/4], Step [75/3844], Loss: 0.0808\n",
      "Epoch [4/4], Step [76/3844], Loss: 0.0703\n",
      "Epoch [4/4], Step [77/3844], Loss: 0.1059\n",
      "Epoch [4/4], Step [78/3844], Loss: 0.0991\n",
      "Epoch [4/4], Step [79/3844], Loss: 0.1518\n",
      "Epoch [4/4], Step [80/3844], Loss: 0.1207\n",
      "Epoch [4/4], Step [81/3844], Loss: 0.0850\n",
      "Epoch [4/4], Step [82/3844], Loss: 0.0793\n",
      "Epoch [4/4], Step [83/3844], Loss: 0.1675\n",
      "Epoch [4/4], Step [84/3844], Loss: 0.0721\n",
      "Epoch [4/4], Step [85/3844], Loss: 0.1293\n",
      "Epoch [4/4], Step [86/3844], Loss: 0.0705\n",
      "Epoch [4/4], Step [87/3844], Loss: 0.1439\n",
      "Epoch [4/4], Step [88/3844], Loss: 0.1105\n",
      "Epoch [4/4], Step [89/3844], Loss: 0.1187\n",
      "Epoch [4/4], Step [90/3844], Loss: 0.1502\n",
      "Epoch [4/4], Step [91/3844], Loss: 0.1164\n",
      "Epoch [4/4], Step [92/3844], Loss: 0.0591\n",
      "Epoch [4/4], Step [93/3844], Loss: 0.0817\n",
      "Epoch [4/4], Step [94/3844], Loss: 0.1223\n",
      "Epoch [4/4], Step [95/3844], Loss: 0.1269\n",
      "Epoch [4/4], Step [96/3844], Loss: 0.1164\n",
      "Epoch [4/4], Step [97/3844], Loss: 0.0672\n",
      "Epoch [4/4], Step [98/3844], Loss: 0.1238\n",
      "Epoch [4/4], Step [99/3844], Loss: 0.1047\n",
      "Epoch [4/4], Step [100/3844], Loss: 0.0757\n",
      "Epoch [4/4], Step [101/3844], Loss: 0.0622\n",
      "Epoch [4/4], Step [102/3844], Loss: 0.0631\n",
      "Epoch [4/4], Step [103/3844], Loss: 0.0855\n",
      "Epoch [4/4], Step [104/3844], Loss: 0.1090\n",
      "Epoch [4/4], Step [105/3844], Loss: 0.0517\n",
      "Epoch [4/4], Step [106/3844], Loss: 0.0548\n",
      "Epoch [4/4], Step [107/3844], Loss: 0.0595\n",
      "Epoch [4/4], Step [108/3844], Loss: 0.0552\n",
      "Epoch [4/4], Step [109/3844], Loss: 0.1405\n",
      "Epoch [4/4], Step [110/3844], Loss: 0.1279\n",
      "Epoch [4/4], Step [111/3844], Loss: 0.0676\n",
      "Epoch [4/4], Step [112/3844], Loss: 0.0882\n",
      "Epoch [4/4], Step [113/3844], Loss: 0.0892\n",
      "Epoch [4/4], Step [114/3844], Loss: 0.0806\n",
      "Epoch [4/4], Step [115/3844], Loss: 0.1242\n",
      "Epoch [4/4], Step [116/3844], Loss: 0.1581\n",
      "Epoch [4/4], Step [117/3844], Loss: 0.0743\n",
      "Epoch [4/4], Step [118/3844], Loss: 0.1124\n",
      "Epoch [4/4], Step [119/3844], Loss: 0.1806\n",
      "Epoch [4/4], Step [120/3844], Loss: 0.1167\n",
      "Epoch [4/4], Step [121/3844], Loss: 0.1462\n",
      "Epoch [4/4], Step [122/3844], Loss: 0.1303\n",
      "Epoch [4/4], Step [123/3844], Loss: 0.1249\n",
      "Epoch [4/4], Step [124/3844], Loss: 0.1048\n",
      "Epoch [4/4], Step [125/3844], Loss: 0.1118\n",
      "Epoch [4/4], Step [126/3844], Loss: 0.1360\n",
      "Epoch [4/4], Step [127/3844], Loss: 0.1363\n",
      "Epoch [4/4], Step [128/3844], Loss: 0.0952\n",
      "Epoch [4/4], Step [129/3844], Loss: 0.0801\n",
      "Epoch [4/4], Step [130/3844], Loss: 0.0708\n",
      "Epoch [4/4], Step [131/3844], Loss: 0.0645\n",
      "Epoch [4/4], Step [132/3844], Loss: 0.1674\n",
      "Epoch [4/4], Step [133/3844], Loss: 0.0709\n",
      "Epoch [4/4], Step [134/3844], Loss: 0.0735\n",
      "Epoch [4/4], Step [135/3844], Loss: 0.0954\n",
      "Epoch [4/4], Step [136/3844], Loss: 0.0928\n",
      "Epoch [4/4], Step [137/3844], Loss: 0.1038\n",
      "Epoch [4/4], Step [138/3844], Loss: 0.0931\n",
      "Epoch [4/4], Step [139/3844], Loss: 0.0444\n",
      "Epoch [4/4], Step [140/3844], Loss: 0.0993\n",
      "Epoch [4/4], Step [141/3844], Loss: 0.0695\n",
      "Epoch [4/4], Step [142/3844], Loss: 0.1594\n",
      "Epoch [4/4], Step [143/3844], Loss: 0.0544\n",
      "Epoch [4/4], Step [144/3844], Loss: 0.1353\n",
      "Epoch [4/4], Step [145/3844], Loss: 0.0658\n",
      "Epoch [4/4], Step [146/3844], Loss: 0.0951\n",
      "Epoch [4/4], Step [147/3844], Loss: 0.1381\n",
      "Epoch [4/4], Step [148/3844], Loss: 0.1046\n",
      "Epoch [4/4], Step [149/3844], Loss: 0.1028\n",
      "Epoch [4/4], Step [150/3844], Loss: 0.1024\n",
      "Epoch [4/4], Step [151/3844], Loss: 0.1069\n",
      "Epoch [4/4], Step [152/3844], Loss: 0.0803\n",
      "Epoch [4/4], Step [153/3844], Loss: 0.1142\n",
      "Epoch [4/4], Step [154/3844], Loss: 0.1643\n",
      "Epoch [4/4], Step [155/3844], Loss: 0.0311\n",
      "Epoch [4/4], Step [156/3844], Loss: 0.1485\n",
      "Epoch [4/4], Step [157/3844], Loss: 0.0886\n",
      "Epoch [4/4], Step [158/3844], Loss: 0.0894\n",
      "Epoch [4/4], Step [159/3844], Loss: 0.0671\n",
      "Epoch [4/4], Step [160/3844], Loss: 0.0784\n",
      "Epoch [4/4], Step [161/3844], Loss: 0.0963\n",
      "Epoch [4/4], Step [162/3844], Loss: 0.1128\n",
      "Epoch [4/4], Step [163/3844], Loss: 0.1700\n",
      "Epoch [4/4], Step [164/3844], Loss: 0.0515\n",
      "Epoch [4/4], Step [165/3844], Loss: 0.1545\n",
      "Epoch [4/4], Step [166/3844], Loss: 0.0631\n",
      "Epoch [4/4], Step [167/3844], Loss: 0.1459\n",
      "Epoch [4/4], Step [168/3844], Loss: 0.1390\n",
      "Epoch [4/4], Step [169/3844], Loss: 0.0965\n",
      "Epoch [4/4], Step [170/3844], Loss: 0.0770\n",
      "Epoch [4/4], Step [171/3844], Loss: 0.0820\n",
      "Epoch [4/4], Step [172/3844], Loss: 0.1268\n",
      "Epoch [4/4], Step [173/3844], Loss: 0.1073\n",
      "Epoch [4/4], Step [174/3844], Loss: 0.0978\n",
      "Epoch [4/4], Step [175/3844], Loss: 0.0808\n",
      "Epoch [4/4], Step [176/3844], Loss: 0.0774\n",
      "Epoch [4/4], Step [177/3844], Loss: 0.1004\n",
      "Epoch [4/4], Step [178/3844], Loss: 0.1280\n",
      "Epoch [4/4], Step [179/3844], Loss: 0.1671\n",
      "Epoch [4/4], Step [180/3844], Loss: 0.0713\n",
      "Epoch [4/4], Step [181/3844], Loss: 0.0824\n",
      "Epoch [4/4], Step [182/3844], Loss: 0.0747\n",
      "Epoch [4/4], Step [183/3844], Loss: 0.1128\n",
      "Epoch [4/4], Step [184/3844], Loss: 0.0742\n",
      "Epoch [4/4], Step [185/3844], Loss: 0.1047\n",
      "Epoch [4/4], Step [186/3844], Loss: 0.1355\n",
      "Epoch [4/4], Step [187/3844], Loss: 0.0596\n",
      "Epoch [4/4], Step [188/3844], Loss: 0.0679\n",
      "Epoch [4/4], Step [189/3844], Loss: 0.1249\n",
      "Epoch [4/4], Step [190/3844], Loss: 0.0651\n",
      "Epoch [4/4], Step [191/3844], Loss: 0.0855\n",
      "Epoch [4/4], Step [192/3844], Loss: 0.0686\n",
      "Epoch [4/4], Step [193/3844], Loss: 0.0480\n",
      "Epoch [4/4], Step [194/3844], Loss: 0.1056\n",
      "Epoch [4/4], Step [195/3844], Loss: 0.0627\n",
      "Epoch [4/4], Step [196/3844], Loss: 0.0656\n",
      "Epoch [4/4], Step [197/3844], Loss: 0.1554\n",
      "Epoch [4/4], Step [198/3844], Loss: 0.0445\n",
      "Epoch [4/4], Step [199/3844], Loss: 0.1135\n",
      "Epoch [4/4], Step [200/3844], Loss: 0.1384\n",
      "Epoch [4/4], Step [201/3844], Loss: 0.1404\n",
      "Epoch [4/4], Step [202/3844], Loss: 0.1375\n",
      "Epoch [4/4], Step [203/3844], Loss: 0.0467\n",
      "Epoch [4/4], Step [204/3844], Loss: 0.0785\n",
      "Epoch [4/4], Step [205/3844], Loss: 0.1280\n",
      "Epoch [4/4], Step [206/3844], Loss: 0.0914\n",
      "Epoch [4/4], Step [207/3844], Loss: 0.1478\n",
      "Epoch [4/4], Step [208/3844], Loss: 0.0309\n",
      "Epoch [4/4], Step [209/3844], Loss: 0.1366\n",
      "Epoch [4/4], Step [210/3844], Loss: 0.0704\n",
      "Epoch [4/4], Step [211/3844], Loss: 0.0823\n",
      "Epoch [4/4], Step [212/3844], Loss: 0.0525\n",
      "Epoch [4/4], Step [213/3844], Loss: 0.0998\n",
      "Epoch [4/4], Step [214/3844], Loss: 0.0675\n",
      "Epoch [4/4], Step [215/3844], Loss: 0.0951\n",
      "Epoch [4/4], Step [216/3844], Loss: 0.0558\n",
      "Epoch [4/4], Step [217/3844], Loss: 0.1298\n",
      "Epoch [4/4], Step [218/3844], Loss: 0.1783\n",
      "Epoch [4/4], Step [219/3844], Loss: 0.0611\n",
      "Epoch [4/4], Step [220/3844], Loss: 0.1933\n",
      "Epoch [4/4], Step [221/3844], Loss: 0.0531\n",
      "Epoch [4/4], Step [222/3844], Loss: 0.0935\n",
      "Epoch [4/4], Step [223/3844], Loss: 0.1440\n",
      "Epoch [4/4], Step [224/3844], Loss: 0.0824\n",
      "Epoch [4/4], Step [225/3844], Loss: 0.1016\n",
      "Epoch [4/4], Step [226/3844], Loss: 0.0705\n",
      "Epoch [4/4], Step [227/3844], Loss: 0.1471\n",
      "Epoch [4/4], Step [228/3844], Loss: 0.1636\n",
      "Epoch [4/4], Step [229/3844], Loss: 0.1035\n",
      "Epoch [4/4], Step [230/3844], Loss: 0.1135\n",
      "Epoch [4/4], Step [231/3844], Loss: 0.0828\n",
      "Epoch [4/4], Step [232/3844], Loss: 0.0601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/4], Step [233/3844], Loss: 0.0496\n",
      "Epoch [4/4], Step [234/3844], Loss: 0.0972\n",
      "Epoch [4/4], Step [235/3844], Loss: 0.1535\n",
      "Epoch [4/4], Step [236/3844], Loss: 0.0590\n",
      "Epoch [4/4], Step [237/3844], Loss: 0.1314\n",
      "Epoch [4/4], Step [238/3844], Loss: 0.0931\n",
      "Epoch [4/4], Step [239/3844], Loss: 0.1537\n",
      "Epoch [4/4], Step [240/3844], Loss: 0.0832\n",
      "Epoch [4/4], Step [241/3844], Loss: 0.1337\n",
      "Epoch [4/4], Step [242/3844], Loss: 0.0666\n",
      "Epoch [4/4], Step [243/3844], Loss: 0.0801\n",
      "Epoch [4/4], Step [244/3844], Loss: 0.1742\n",
      "Epoch [4/4], Step [245/3844], Loss: 0.0558\n",
      "Epoch [4/4], Step [246/3844], Loss: 0.0872\n",
      "Epoch [4/4], Step [247/3844], Loss: 0.1267\n",
      "Epoch [4/4], Step [248/3844], Loss: 0.0819\n",
      "Epoch [4/4], Step [249/3844], Loss: 0.1564\n",
      "Epoch [4/4], Step [250/3844], Loss: 0.1618\n",
      "Epoch [4/4], Step [251/3844], Loss: 0.0729\n",
      "Epoch [4/4], Step [252/3844], Loss: 0.0996\n",
      "Epoch [4/4], Step [253/3844], Loss: 0.0660\n",
      "Epoch [4/4], Step [254/3844], Loss: 0.1030\n",
      "Epoch [4/4], Step [255/3844], Loss: 0.1605\n",
      "Epoch [4/4], Step [256/3844], Loss: 0.1277\n",
      "Epoch [4/4], Step [257/3844], Loss: 0.1539\n",
      "Epoch [4/4], Step [258/3844], Loss: 0.1343\n",
      "Epoch [4/4], Step [259/3844], Loss: 0.1658\n",
      "Epoch [4/4], Step [260/3844], Loss: 0.0538\n",
      "Epoch [4/4], Step [261/3844], Loss: 0.1514\n",
      "Epoch [4/4], Step [262/3844], Loss: 0.1243\n",
      "Epoch [4/4], Step [263/3844], Loss: 0.0924\n",
      "Epoch [4/4], Step [264/3844], Loss: 0.1159\n",
      "Epoch [4/4], Step [265/3844], Loss: 0.0599\n",
      "Epoch [4/4], Step [266/3844], Loss: 0.0742\n",
      "Epoch [4/4], Step [267/3844], Loss: 0.1034\n",
      "Epoch [4/4], Step [268/3844], Loss: 0.1077\n",
      "Epoch [4/4], Step [269/3844], Loss: 0.0991\n",
      "Epoch [4/4], Step [270/3844], Loss: 0.0516\n",
      "Epoch [4/4], Step [271/3844], Loss: 0.1612\n",
      "Epoch [4/4], Step [272/3844], Loss: 0.0684\n",
      "Epoch [4/4], Step [273/3844], Loss: 0.0741\n",
      "Epoch [4/4], Step [274/3844], Loss: 0.1200\n",
      "Epoch [4/4], Step [275/3844], Loss: 0.1164\n",
      "Epoch [4/4], Step [276/3844], Loss: 0.1481\n",
      "Epoch [4/4], Step [277/3844], Loss: 0.0759\n",
      "Epoch [4/4], Step [278/3844], Loss: 0.0910\n",
      "Epoch [4/4], Step [279/3844], Loss: 0.1118\n",
      "Epoch [4/4], Step [280/3844], Loss: 0.1193\n",
      "Epoch [4/4], Step [281/3844], Loss: 0.1125\n",
      "Epoch [4/4], Step [282/3844], Loss: 0.0850\n",
      "Epoch [4/4], Step [283/3844], Loss: 0.1453\n",
      "Epoch [4/4], Step [284/3844], Loss: 0.1297\n",
      "Epoch [4/4], Step [285/3844], Loss: 0.0627\n",
      "Epoch [4/4], Step [286/3844], Loss: 0.0719\n",
      "Epoch [4/4], Step [287/3844], Loss: 0.0904\n",
      "Epoch [4/4], Step [288/3844], Loss: 0.1179\n",
      "Epoch [4/4], Step [289/3844], Loss: 0.0747\n",
      "Epoch [4/4], Step [290/3844], Loss: 0.1556\n",
      "Epoch [4/4], Step [291/3844], Loss: 0.1629\n",
      "Epoch [4/4], Step [292/3844], Loss: 0.1038\n",
      "Epoch [4/4], Step [293/3844], Loss: 0.0574\n",
      "Epoch [4/4], Step [294/3844], Loss: 0.0799\n",
      "Epoch [4/4], Step [295/3844], Loss: 0.0610\n",
      "Epoch [4/4], Step [296/3844], Loss: 0.0545\n",
      "Epoch [4/4], Step [297/3844], Loss: 0.0837\n",
      "Epoch [4/4], Step [298/3844], Loss: 0.0799\n",
      "Epoch [4/4], Step [299/3844], Loss: 0.1160\n",
      "Epoch [4/4], Step [300/3844], Loss: 0.1230\n",
      "Epoch [4/4], Step [301/3844], Loss: 0.0841\n",
      "Epoch [4/4], Step [302/3844], Loss: 0.1492\n",
      "Epoch [4/4], Step [303/3844], Loss: 0.0548\n",
      "Epoch [4/4], Step [304/3844], Loss: 0.1279\n",
      "Epoch [4/4], Step [305/3844], Loss: 0.1665\n",
      "Epoch [4/4], Step [306/3844], Loss: 0.1642\n",
      "Epoch [4/4], Step [307/3844], Loss: 0.1097\n",
      "Epoch [4/4], Step [308/3844], Loss: 0.1176\n",
      "Epoch [4/4], Step [309/3844], Loss: 0.0482\n",
      "Epoch [4/4], Step [310/3844], Loss: 0.0844\n",
      "Epoch [4/4], Step [311/3844], Loss: 0.0636\n",
      "Epoch [4/4], Step [312/3844], Loss: 0.0725\n",
      "Epoch [4/4], Step [313/3844], Loss: 0.0824\n",
      "Epoch [4/4], Step [314/3844], Loss: 0.0945\n",
      "Epoch [4/4], Step [315/3844], Loss: 0.1012\n",
      "Epoch [4/4], Step [316/3844], Loss: 0.0835\n",
      "Epoch [4/4], Step [317/3844], Loss: 0.0836\n",
      "Epoch [4/4], Step [318/3844], Loss: 0.1178\n",
      "Epoch [4/4], Step [319/3844], Loss: 0.0660\n",
      "Epoch [4/4], Step [320/3844], Loss: 0.1137\n",
      "Epoch [4/4], Step [321/3844], Loss: 0.0597\n",
      "Epoch [4/4], Step [322/3844], Loss: 0.0789\n",
      "Epoch [4/4], Step [323/3844], Loss: 0.1589\n",
      "Epoch [4/4], Step [324/3844], Loss: 0.0979\n",
      "Epoch [4/4], Step [325/3844], Loss: 0.1284\n",
      "Epoch [4/4], Step [326/3844], Loss: 0.0630\n",
      "Epoch [4/4], Step [327/3844], Loss: 0.0472\n",
      "Epoch [4/4], Step [328/3844], Loss: 0.1335\n",
      "Epoch [4/4], Step [329/3844], Loss: 0.1219\n",
      "Epoch [4/4], Step [330/3844], Loss: 0.1794\n",
      "Epoch [4/4], Step [331/3844], Loss: 0.0949\n",
      "Epoch [4/4], Step [332/3844], Loss: 0.1035\n",
      "Epoch [4/4], Step [333/3844], Loss: 0.0904\n",
      "Epoch [4/4], Step [334/3844], Loss: 0.0842\n",
      "Epoch [4/4], Step [335/3844], Loss: 0.0643\n",
      "Epoch [4/4], Step [336/3844], Loss: 0.0803\n",
      "Epoch [4/4], Step [337/3844], Loss: 0.0870\n",
      "Epoch [4/4], Step [338/3844], Loss: 0.0645\n",
      "Epoch [4/4], Step [339/3844], Loss: 0.1428\n",
      "Epoch [4/4], Step [340/3844], Loss: 0.0667\n",
      "Epoch [4/4], Step [341/3844], Loss: 0.1291\n",
      "Epoch [4/4], Step [342/3844], Loss: 0.0949\n",
      "Epoch [4/4], Step [343/3844], Loss: 0.0782\n",
      "Epoch [4/4], Step [344/3844], Loss: 0.0747\n",
      "Epoch [4/4], Step [345/3844], Loss: 0.1415\n",
      "Epoch [4/4], Step [346/3844], Loss: 0.1655\n",
      "Epoch [4/4], Step [347/3844], Loss: 0.1067\n",
      "Epoch [4/4], Step [348/3844], Loss: 0.0653\n",
      "Epoch [4/4], Step [349/3844], Loss: 0.0506\n",
      "Epoch [4/4], Step [350/3844], Loss: 0.1391\n",
      "Epoch [4/4], Step [351/3844], Loss: 0.0390\n",
      "Epoch [4/4], Step [352/3844], Loss: 0.1194\n",
      "Epoch [4/4], Step [353/3844], Loss: 0.0728\n",
      "Epoch [4/4], Step [354/3844], Loss: 0.1415\n",
      "Epoch [4/4], Step [355/3844], Loss: 0.0621\n",
      "Epoch [4/4], Step [356/3844], Loss: 0.1241\n",
      "Epoch [4/4], Step [357/3844], Loss: 0.0860\n",
      "Epoch [4/4], Step [358/3844], Loss: 0.0956\n",
      "Epoch [4/4], Step [359/3844], Loss: 0.1117\n",
      "Epoch [4/4], Step [360/3844], Loss: 0.0764\n",
      "Epoch [4/4], Step [361/3844], Loss: 0.0849\n",
      "Epoch [4/4], Step [362/3844], Loss: 0.1350\n",
      "Epoch [4/4], Step [363/3844], Loss: 0.0706\n",
      "Epoch [4/4], Step [364/3844], Loss: 0.1003\n",
      "Epoch [4/4], Step [365/3844], Loss: 0.0875\n",
      "Epoch [4/4], Step [366/3844], Loss: 0.0694\n",
      "Epoch [4/4], Step [367/3844], Loss: 0.0810\n",
      "Epoch [4/4], Step [368/3844], Loss: 0.1810\n",
      "Epoch [4/4], Step [369/3844], Loss: 0.0893\n",
      "Epoch [4/4], Step [370/3844], Loss: 0.0740\n",
      "Epoch [4/4], Step [371/3844], Loss: 0.1542\n",
      "Epoch [4/4], Step [372/3844], Loss: 0.0762\n",
      "Epoch [4/4], Step [373/3844], Loss: 0.0772\n",
      "Epoch [4/4], Step [374/3844], Loss: 0.1312\n",
      "Epoch [4/4], Step [375/3844], Loss: 0.1350\n",
      "Epoch [4/4], Step [376/3844], Loss: 0.1007\n",
      "Epoch [4/4], Step [377/3844], Loss: 0.1512\n",
      "Epoch [4/4], Step [378/3844], Loss: 0.1475\n",
      "Epoch [4/4], Step [379/3844], Loss: 0.0966\n",
      "Epoch [4/4], Step [380/3844], Loss: 0.1381\n",
      "Epoch [4/4], Step [381/3844], Loss: 0.0793\n",
      "Epoch [4/4], Step [382/3844], Loss: 0.0977\n",
      "Epoch [4/4], Step [383/3844], Loss: 0.1587\n",
      "Epoch [4/4], Step [384/3844], Loss: 0.1290\n",
      "Epoch [4/4], Step [385/3844], Loss: 0.0557\n",
      "Epoch [4/4], Step [386/3844], Loss: 0.0859\n",
      "Epoch [4/4], Step [387/3844], Loss: 0.0924\n",
      "Epoch [4/4], Step [388/3844], Loss: 0.0534\n",
      "Epoch [4/4], Step [389/3844], Loss: 0.1574\n",
      "Epoch [4/4], Step [390/3844], Loss: 0.0749\n",
      "Epoch [4/4], Step [391/3844], Loss: 0.0740\n",
      "Epoch [4/4], Step [392/3844], Loss: 0.0865\n",
      "Epoch [4/4], Step [393/3844], Loss: 0.1307\n",
      "Epoch [4/4], Step [394/3844], Loss: 0.0886\n",
      "Epoch [4/4], Step [395/3844], Loss: 0.1357\n",
      "Epoch [4/4], Step [396/3844], Loss: 0.0764\n",
      "Epoch [4/4], Step [397/3844], Loss: 0.1601\n",
      "Epoch [4/4], Step [398/3844], Loss: 0.1418\n",
      "Epoch [4/4], Step [399/3844], Loss: 0.0851\n",
      "Epoch [4/4], Step [400/3844], Loss: 0.0746\n",
      "Epoch [4/4], Step [401/3844], Loss: 0.0918\n",
      "Epoch [4/4], Step [402/3844], Loss: 0.0804\n",
      "Epoch [4/4], Step [403/3844], Loss: 0.1347\n",
      "Epoch [4/4], Step [404/3844], Loss: 0.0764\n",
      "Epoch [4/4], Step [405/3844], Loss: 0.1562\n",
      "Epoch [4/4], Step [406/3844], Loss: 0.1158\n",
      "Epoch [4/4], Step [407/3844], Loss: 0.0694\n",
      "Epoch [4/4], Step [408/3844], Loss: 0.0942\n",
      "Epoch [4/4], Step [409/3844], Loss: 0.1599\n",
      "Epoch [4/4], Step [410/3844], Loss: 0.0661\n",
      "Epoch [4/4], Step [411/3844], Loss: 0.0881\n",
      "Epoch [4/4], Step [412/3844], Loss: 0.1199\n",
      "Epoch [4/4], Step [413/3844], Loss: 0.1115\n",
      "Epoch [4/4], Step [414/3844], Loss: 0.1334\n",
      "Epoch [4/4], Step [415/3844], Loss: 0.1366\n",
      "Epoch [4/4], Step [416/3844], Loss: 0.0750\n",
      "Epoch [4/4], Step [417/3844], Loss: 0.1356\n",
      "Epoch [4/4], Step [418/3844], Loss: 0.0754\n",
      "Epoch [4/4], Step [419/3844], Loss: 0.0808\n",
      "Epoch [4/4], Step [420/3844], Loss: 0.0774\n",
      "Epoch [4/4], Step [421/3844], Loss: 0.1336\n",
      "Epoch [4/4], Step [422/3844], Loss: 0.0664\n",
      "Epoch [4/4], Step [423/3844], Loss: 0.1359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/4], Step [424/3844], Loss: 0.1398\n",
      "Epoch [4/4], Step [425/3844], Loss: 0.0438\n",
      "Epoch [4/4], Step [426/3844], Loss: 0.0875\n",
      "Epoch [4/4], Step [427/3844], Loss: 0.0868\n",
      "Epoch [4/4], Step [428/3844], Loss: 0.0818\n",
      "Epoch [4/4], Step [429/3844], Loss: 0.0957\n",
      "Epoch [4/4], Step [430/3844], Loss: 0.1601\n",
      "Epoch [4/4], Step [431/3844], Loss: 0.0946\n",
      "Epoch [4/4], Step [432/3844], Loss: 0.0806\n",
      "Epoch [4/4], Step [433/3844], Loss: 0.0676\n",
      "Epoch [4/4], Step [434/3844], Loss: 0.1123\n",
      "Epoch [4/4], Step [435/3844], Loss: 0.0545\n",
      "Epoch [4/4], Step [436/3844], Loss: 0.1558\n",
      "Epoch [4/4], Step [437/3844], Loss: 0.0286\n",
      "Epoch [4/4], Step [438/3844], Loss: 0.0624\n",
      "Epoch [4/4], Step [439/3844], Loss: 0.0544\n",
      "Epoch [4/4], Step [440/3844], Loss: 0.0868\n",
      "Epoch [4/4], Step [441/3844], Loss: 0.1054\n",
      "Epoch [4/4], Step [442/3844], Loss: 0.1254\n",
      "Epoch [4/4], Step [443/3844], Loss: 0.1293\n",
      "Epoch [4/4], Step [444/3844], Loss: 0.1348\n",
      "Epoch [4/4], Step [445/3844], Loss: 0.1260\n",
      "Epoch [4/4], Step [446/3844], Loss: 0.0932\n",
      "Epoch [4/4], Step [447/3844], Loss: 0.1041\n",
      "Epoch [4/4], Step [448/3844], Loss: 0.0737\n",
      "Epoch [4/4], Step [449/3844], Loss: 0.0965\n",
      "Epoch [4/4], Step [450/3844], Loss: 0.0724\n",
      "Epoch [4/4], Step [451/3844], Loss: 0.0791\n",
      "Epoch [4/4], Step [452/3844], Loss: 0.0620\n",
      "Epoch [4/4], Step [453/3844], Loss: 0.1481\n",
      "Epoch [4/4], Step [454/3844], Loss: 0.1266\n",
      "Epoch [4/4], Step [455/3844], Loss: 0.0730\n",
      "Epoch [4/4], Step [456/3844], Loss: 0.0722\n",
      "Epoch [4/4], Step [457/3844], Loss: 0.1464\n",
      "Epoch [4/4], Step [458/3844], Loss: 0.0784\n",
      "Epoch [4/4], Step [459/3844], Loss: 0.1127\n",
      "Epoch [4/4], Step [460/3844], Loss: 0.0665\n",
      "Epoch [4/4], Step [461/3844], Loss: 0.0966\n",
      "Epoch [4/4], Step [462/3844], Loss: 0.1345\n",
      "Epoch [4/4], Step [463/3844], Loss: 0.0881\n",
      "Epoch [4/4], Step [464/3844], Loss: 0.0859\n",
      "Epoch [4/4], Step [465/3844], Loss: 0.1413\n",
      "Epoch [4/4], Step [466/3844], Loss: 0.0617\n",
      "Epoch [4/4], Step [467/3844], Loss: 0.1281\n",
      "Epoch [4/4], Step [468/3844], Loss: 0.1501\n",
      "Epoch [4/4], Step [469/3844], Loss: 0.0843\n",
      "Epoch [4/4], Step [470/3844], Loss: 0.0537\n",
      "Epoch [4/4], Step [471/3844], Loss: 0.1384\n",
      "Epoch [4/4], Step [472/3844], Loss: 0.0969\n",
      "Epoch [4/4], Step [473/3844], Loss: 0.0593\n",
      "Epoch [4/4], Step [474/3844], Loss: 0.0847\n",
      "Epoch [4/4], Step [475/3844], Loss: 0.1518\n",
      "Epoch [4/4], Step [476/3844], Loss: 0.0682\n",
      "Epoch [4/4], Step [477/3844], Loss: 0.1023\n",
      "Epoch [4/4], Step [478/3844], Loss: 0.0841\n",
      "Epoch [4/4], Step [479/3844], Loss: 0.1163\n",
      "Epoch [4/4], Step [480/3844], Loss: 0.1614\n",
      "Epoch [4/4], Step [481/3844], Loss: 0.0479\n",
      "Epoch [4/4], Step [482/3844], Loss: 0.0697\n",
      "Epoch [4/4], Step [483/3844], Loss: 0.1322\n",
      "Epoch [4/4], Step [484/3844], Loss: 0.0927\n",
      "Epoch [4/4], Step [485/3844], Loss: 0.1093\n",
      "Epoch [4/4], Step [486/3844], Loss: 0.1318\n",
      "Epoch [4/4], Step [487/3844], Loss: 0.0833\n",
      "Epoch [4/4], Step [488/3844], Loss: 0.0705\n",
      "Epoch [4/4], Step [489/3844], Loss: 0.0903\n",
      "Epoch [4/4], Step [490/3844], Loss: 0.0464\n",
      "Epoch [4/4], Step [491/3844], Loss: 0.0308\n",
      "Epoch [4/4], Step [492/3844], Loss: 0.0731\n",
      "Epoch [4/4], Step [493/3844], Loss: 0.0556\n",
      "Epoch [4/4], Step [494/3844], Loss: 0.1480\n",
      "Epoch [4/4], Step [495/3844], Loss: 0.0689\n",
      "Epoch [4/4], Step [496/3844], Loss: 0.1073\n",
      "Epoch [4/4], Step [497/3844], Loss: 0.1226\n",
      "Epoch [4/4], Step [498/3844], Loss: 0.0905\n",
      "Epoch [4/4], Step [499/3844], Loss: 0.0591\n",
      "Epoch [4/4], Step [500/3844], Loss: 0.1508\n",
      "Epoch [4/4], Step [501/3844], Loss: 0.0816\n",
      "Epoch [4/4], Step [502/3844], Loss: 0.0917\n",
      "Epoch [4/4], Step [503/3844], Loss: 0.0787\n",
      "Epoch [4/4], Step [504/3844], Loss: 0.0827\n",
      "Epoch [4/4], Step [505/3844], Loss: 0.0438\n",
      "Epoch [4/4], Step [506/3844], Loss: 0.0718\n",
      "Epoch [4/4], Step [507/3844], Loss: 0.0992\n",
      "Epoch [4/4], Step [508/3844], Loss: 0.1290\n",
      "Epoch [4/4], Step [509/3844], Loss: 0.1337\n",
      "Epoch [4/4], Step [510/3844], Loss: 0.0915\n",
      "Epoch [4/4], Step [511/3844], Loss: 0.0955\n",
      "Epoch [4/4], Step [512/3844], Loss: 0.0478\n",
      "Epoch [4/4], Step [513/3844], Loss: 0.1268\n",
      "Epoch [4/4], Step [514/3844], Loss: 0.0912\n",
      "Epoch [4/4], Step [515/3844], Loss: 0.1419\n",
      "Epoch [4/4], Step [516/3844], Loss: 0.0788\n",
      "Epoch [4/4], Step [517/3844], Loss: 0.1543\n",
      "Epoch [4/4], Step [518/3844], Loss: 0.1633\n",
      "Epoch [4/4], Step [519/3844], Loss: 0.1233\n",
      "Epoch [4/4], Step [520/3844], Loss: 0.1007\n",
      "Epoch [4/4], Step [521/3844], Loss: 0.0866\n",
      "Epoch [4/4], Step [522/3844], Loss: 0.0942\n",
      "Epoch [4/4], Step [523/3844], Loss: 0.1536\n",
      "Epoch [4/4], Step [524/3844], Loss: 0.0992\n",
      "Epoch [4/4], Step [525/3844], Loss: 0.0758\n",
      "Epoch [4/4], Step [526/3844], Loss: 0.0543\n",
      "Epoch [4/4], Step [527/3844], Loss: 0.1092\n",
      "Epoch [4/4], Step [528/3844], Loss: 0.0600\n",
      "Epoch [4/4], Step [529/3844], Loss: 0.0900\n",
      "Epoch [4/4], Step [530/3844], Loss: 0.0838\n",
      "Epoch [4/4], Step [531/3844], Loss: 0.0615\n",
      "Epoch [4/4], Step [532/3844], Loss: 0.0666\n",
      "Epoch [4/4], Step [533/3844], Loss: 0.1093\n",
      "Epoch [4/4], Step [534/3844], Loss: 0.1109\n",
      "Epoch [4/4], Step [535/3844], Loss: 0.0806\n",
      "Epoch [4/4], Step [536/3844], Loss: 0.0882\n",
      "Epoch [4/4], Step [537/3844], Loss: 0.1177\n",
      "Epoch [4/4], Step [538/3844], Loss: 0.1116\n",
      "Epoch [4/4], Step [539/3844], Loss: 0.0556\n",
      "Epoch [4/4], Step [540/3844], Loss: 0.1720\n",
      "Epoch [4/4], Step [541/3844], Loss: 0.0857\n",
      "Epoch [4/4], Step [542/3844], Loss: 0.0678\n",
      "Epoch [4/4], Step [543/3844], Loss: 0.0553\n",
      "Epoch [4/4], Step [544/3844], Loss: 0.1105\n",
      "Epoch [4/4], Step [545/3844], Loss: 0.1085\n",
      "Epoch [4/4], Step [546/3844], Loss: 0.1199\n",
      "Epoch [4/4], Step [547/3844], Loss: 0.1272\n",
      "Epoch [4/4], Step [548/3844], Loss: 0.1502\n",
      "Epoch [4/4], Step [549/3844], Loss: 0.1422\n",
      "Epoch [4/4], Step [550/3844], Loss: 0.0663\n",
      "Epoch [4/4], Step [551/3844], Loss: 0.0820\n",
      "Epoch [4/4], Step [552/3844], Loss: 0.0630\n",
      "Epoch [4/4], Step [553/3844], Loss: 0.1680\n",
      "Epoch [4/4], Step [554/3844], Loss: 0.0982\n",
      "Epoch [4/4], Step [555/3844], Loss: 0.1107\n",
      "Epoch [4/4], Step [556/3844], Loss: 0.0462\n",
      "Epoch [4/4], Step [557/3844], Loss: 0.0671\n",
      "Epoch [4/4], Step [558/3844], Loss: 0.1384\n",
      "Epoch [4/4], Step [559/3844], Loss: 0.1539\n",
      "Epoch [4/4], Step [560/3844], Loss: 0.1231\n",
      "Epoch [4/4], Step [561/3844], Loss: 0.1583\n",
      "Epoch [4/4], Step [562/3844], Loss: 0.1560\n",
      "Epoch [4/4], Step [563/3844], Loss: 0.0771\n",
      "Epoch [4/4], Step [564/3844], Loss: 0.0697\n",
      "Epoch [4/4], Step [565/3844], Loss: 0.1546\n",
      "Epoch [4/4], Step [566/3844], Loss: 0.0589\n",
      "Epoch [4/4], Step [567/3844], Loss: 0.0813\n",
      "Epoch [4/4], Step [568/3844], Loss: 0.1112\n",
      "Epoch [4/4], Step [569/3844], Loss: 0.1510\n",
      "Epoch [4/4], Step [570/3844], Loss: 0.1027\n",
      "Epoch [4/4], Step [571/3844], Loss: 0.1050\n",
      "Epoch [4/4], Step [572/3844], Loss: 0.1019\n",
      "Epoch [4/4], Step [573/3844], Loss: 0.1598\n",
      "Epoch [4/4], Step [574/3844], Loss: 0.0842\n",
      "Epoch [4/4], Step [575/3844], Loss: 0.0953\n",
      "Epoch [4/4], Step [576/3844], Loss: 0.0813\n",
      "Epoch [4/4], Step [577/3844], Loss: 0.0576\n",
      "Epoch [4/4], Step [578/3844], Loss: 0.0745\n",
      "Epoch [4/4], Step [579/3844], Loss: 0.1198\n",
      "Epoch [4/4], Step [580/3844], Loss: 0.1132\n",
      "Epoch [4/4], Step [581/3844], Loss: 0.0478\n",
      "Epoch [4/4], Step [582/3844], Loss: 0.1275\n",
      "Epoch [4/4], Step [583/3844], Loss: 0.1253\n",
      "Epoch [4/4], Step [584/3844], Loss: 0.1293\n",
      "Epoch [4/4], Step [585/3844], Loss: 0.0898\n",
      "Epoch [4/4], Step [586/3844], Loss: 0.0687\n",
      "Epoch [4/4], Step [587/3844], Loss: 0.0942\n",
      "Epoch [4/4], Step [588/3844], Loss: 0.1533\n",
      "Epoch [4/4], Step [589/3844], Loss: 0.0956\n",
      "Epoch [4/4], Step [590/3844], Loss: 0.1229\n",
      "Epoch [4/4], Step [591/3844], Loss: 0.0734\n",
      "Epoch [4/4], Step [592/3844], Loss: 0.1155\n",
      "Epoch [4/4], Step [593/3844], Loss: 0.1104\n",
      "Epoch [4/4], Step [594/3844], Loss: 0.1715\n",
      "Epoch [4/4], Step [595/3844], Loss: 0.0688\n",
      "Epoch [4/4], Step [596/3844], Loss: 0.0847\n",
      "Epoch [4/4], Step [597/3844], Loss: 0.0896\n",
      "Epoch [4/4], Step [598/3844], Loss: 0.0843\n",
      "Epoch [4/4], Step [599/3844], Loss: 0.0853\n",
      "Epoch [4/4], Step [600/3844], Loss: 0.1576\n",
      "Epoch [4/4], Step [601/3844], Loss: 0.1496\n",
      "Epoch [4/4], Step [602/3844], Loss: 0.1631\n",
      "Epoch [4/4], Step [603/3844], Loss: 0.0973\n",
      "Epoch [4/4], Step [604/3844], Loss: 0.0986\n",
      "Epoch [4/4], Step [605/3844], Loss: 0.0753\n",
      "Epoch [4/4], Step [606/3844], Loss: 0.1615\n",
      "Epoch [4/4], Step [607/3844], Loss: 0.1387\n",
      "Epoch [4/4], Step [608/3844], Loss: 0.0758\n",
      "Epoch [4/4], Step [609/3844], Loss: 0.0939\n",
      "Epoch [4/4], Step [610/3844], Loss: 0.1129\n",
      "Epoch [4/4], Step [611/3844], Loss: 0.0730\n",
      "Epoch [4/4], Step [612/3844], Loss: 0.0907\n",
      "Epoch [4/4], Step [613/3844], Loss: 0.0938\n",
      "Epoch [4/4], Step [614/3844], Loss: 0.0987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/4], Step [615/3844], Loss: 0.0689\n",
      "Epoch [4/4], Step [616/3844], Loss: 0.0723\n",
      "Epoch [4/4], Step [617/3844], Loss: 0.0883\n",
      "Epoch [4/4], Step [618/3844], Loss: 0.1448\n",
      "Epoch [4/4], Step [619/3844], Loss: 0.1383\n",
      "Epoch [4/4], Step [620/3844], Loss: 0.0635\n",
      "Epoch [4/4], Step [621/3844], Loss: 0.0624\n",
      "Epoch [4/4], Step [622/3844], Loss: 0.0570\n",
      "Epoch [4/4], Step [623/3844], Loss: 0.0849\n",
      "Epoch [4/4], Step [624/3844], Loss: 0.1021\n",
      "Epoch [4/4], Step [625/3844], Loss: 0.0807\n",
      "Epoch [4/4], Step [626/3844], Loss: 0.0560\n",
      "Epoch [4/4], Step [627/3844], Loss: 0.1713\n",
      "Epoch [4/4], Step [628/3844], Loss: 0.0762\n",
      "Epoch [4/4], Step [629/3844], Loss: 0.0624\n",
      "Epoch [4/4], Step [630/3844], Loss: 0.1409\n",
      "Epoch [4/4], Step [631/3844], Loss: 0.0973\n",
      "Epoch [4/4], Step [632/3844], Loss: 0.0787\n",
      "Epoch [4/4], Step [633/3844], Loss: 0.0641\n",
      "Epoch [4/4], Step [634/3844], Loss: 0.1042\n",
      "Epoch [4/4], Step [635/3844], Loss: 0.1197\n",
      "Epoch [4/4], Step [636/3844], Loss: 0.1281\n",
      "Epoch [4/4], Step [637/3844], Loss: 0.1585\n",
      "Epoch [4/4], Step [638/3844], Loss: 0.1163\n",
      "Epoch [4/4], Step [639/3844], Loss: 0.0856\n",
      "Epoch [4/4], Step [640/3844], Loss: 0.0641\n",
      "Epoch [4/4], Step [641/3844], Loss: 0.1484\n",
      "Epoch [4/4], Step [642/3844], Loss: 0.1713\n",
      "Epoch [4/4], Step [643/3844], Loss: 0.1489\n",
      "Epoch [4/4], Step [644/3844], Loss: 0.1271\n",
      "Epoch [4/4], Step [645/3844], Loss: 0.0934\n",
      "Epoch [4/4], Step [646/3844], Loss: 0.0702\n",
      "Epoch [4/4], Step [647/3844], Loss: 0.0672\n",
      "Epoch [4/4], Step [648/3844], Loss: 0.0724\n",
      "Epoch [4/4], Step [649/3844], Loss: 0.0983\n",
      "Epoch [4/4], Step [650/3844], Loss: 0.0689\n",
      "Epoch [4/4], Step [651/3844], Loss: 0.0631\n",
      "Epoch [4/4], Step [652/3844], Loss: 0.0741\n",
      "Epoch [4/4], Step [653/3844], Loss: 0.0685\n",
      "Epoch [4/4], Step [654/3844], Loss: 0.0620\n",
      "Epoch [4/4], Step [655/3844], Loss: 0.0788\n",
      "Epoch [4/4], Step [656/3844], Loss: 0.0975\n",
      "Epoch [4/4], Step [657/3844], Loss: 0.0843\n",
      "Epoch [4/4], Step [658/3844], Loss: 0.0688\n",
      "Epoch [4/4], Step [659/3844], Loss: 0.1526\n",
      "Epoch [4/4], Step [660/3844], Loss: 0.1020\n",
      "Epoch [4/4], Step [661/3844], Loss: 0.0825\n",
      "Epoch [4/4], Step [662/3844], Loss: 0.1059\n",
      "Epoch [4/4], Step [663/3844], Loss: 0.0686\n",
      "Epoch [4/4], Step [664/3844], Loss: 0.1505\n",
      "Epoch [4/4], Step [665/3844], Loss: 0.0519\n",
      "Epoch [4/4], Step [666/3844], Loss: 0.1339\n",
      "Epoch [4/4], Step [667/3844], Loss: 0.0766\n",
      "Epoch [4/4], Step [668/3844], Loss: 0.0478\n",
      "Epoch [4/4], Step [669/3844], Loss: 0.0831\n",
      "Epoch [4/4], Step [670/3844], Loss: 0.1534\n",
      "Epoch [4/4], Step [671/3844], Loss: 0.1433\n",
      "Epoch [4/4], Step [672/3844], Loss: 0.1485\n",
      "Epoch [4/4], Step [673/3844], Loss: 0.0862\n",
      "Epoch [4/4], Step [674/3844], Loss: 0.0653\n",
      "Epoch [4/4], Step [675/3844], Loss: 0.1621\n",
      "Epoch [4/4], Step [676/3844], Loss: 0.1842\n",
      "Epoch [4/4], Step [677/3844], Loss: 0.1220\n",
      "Epoch [4/4], Step [678/3844], Loss: 0.1552\n",
      "Epoch [4/4], Step [679/3844], Loss: 0.1277\n",
      "Epoch [4/4], Step [680/3844], Loss: 0.0910\n",
      "Epoch [4/4], Step [681/3844], Loss: 0.1237\n",
      "Epoch [4/4], Step [682/3844], Loss: 0.1128\n",
      "Epoch [4/4], Step [683/3844], Loss: 0.1099\n",
      "Epoch [4/4], Step [684/3844], Loss: 0.1374\n",
      "Epoch [4/4], Step [685/3844], Loss: 0.1798\n",
      "Epoch [4/4], Step [686/3844], Loss: 0.0560\n",
      "Epoch [4/4], Step [687/3844], Loss: 0.1329\n",
      "Epoch [4/4], Step [688/3844], Loss: 0.1125\n",
      "Epoch [4/4], Step [689/3844], Loss: 0.0603\n",
      "Epoch [4/4], Step [690/3844], Loss: 0.0619\n",
      "Epoch [4/4], Step [691/3844], Loss: 0.0958\n",
      "Epoch [4/4], Step [692/3844], Loss: 0.0474\n",
      "Epoch [4/4], Step [693/3844], Loss: 0.0849\n",
      "Epoch [4/4], Step [694/3844], Loss: 0.0650\n",
      "Epoch [4/4], Step [695/3844], Loss: 0.0934\n",
      "Epoch [4/4], Step [696/3844], Loss: 0.0927\n",
      "Epoch [4/4], Step [697/3844], Loss: 0.1723\n",
      "Epoch [4/4], Step [698/3844], Loss: 0.0864\n",
      "Epoch [4/4], Step [699/3844], Loss: 0.1098\n",
      "Epoch [4/4], Step [700/3844], Loss: 0.0802\n",
      "Epoch [4/4], Step [701/3844], Loss: 0.0801\n",
      "Epoch [4/4], Step [702/3844], Loss: 0.0747\n",
      "Epoch [4/4], Step [703/3844], Loss: 0.0646\n",
      "Epoch [4/4], Step [704/3844], Loss: 0.0832\n",
      "Epoch [4/4], Step [705/3844], Loss: 0.1525\n",
      "Epoch [4/4], Step [706/3844], Loss: 0.0869\n",
      "Epoch [4/4], Step [707/3844], Loss: 0.1487\n",
      "Epoch [4/4], Step [708/3844], Loss: 0.0846\n",
      "Epoch [4/4], Step [709/3844], Loss: 0.1409\n",
      "Epoch [4/4], Step [710/3844], Loss: 0.1051\n",
      "Epoch [4/4], Step [711/3844], Loss: 0.0893\n",
      "Epoch [4/4], Step [712/3844], Loss: 0.1055\n",
      "Epoch [4/4], Step [713/3844], Loss: 0.0550\n",
      "Epoch [4/4], Step [714/3844], Loss: 0.1276\n",
      "Epoch [4/4], Step [715/3844], Loss: 0.1465\n",
      "Epoch [4/4], Step [716/3844], Loss: 0.0941\n",
      "Epoch [4/4], Step [717/3844], Loss: 0.0745\n",
      "Epoch [4/4], Step [718/3844], Loss: 0.0609\n",
      "Epoch [4/4], Step [719/3844], Loss: 0.0985\n",
      "Epoch [4/4], Step [720/3844], Loss: 0.1517\n",
      "Epoch [4/4], Step [721/3844], Loss: 0.0675\n",
      "Epoch [4/4], Step [722/3844], Loss: 0.1343\n",
      "Epoch [4/4], Step [723/3844], Loss: 0.1196\n",
      "Epoch [4/4], Step [724/3844], Loss: 0.0662\n",
      "Epoch [4/4], Step [725/3844], Loss: 0.0974\n",
      "Epoch [4/4], Step [726/3844], Loss: 0.1083\n",
      "Epoch [4/4], Step [727/3844], Loss: 0.0789\n",
      "Epoch [4/4], Step [728/3844], Loss: 0.0762\n",
      "Epoch [4/4], Step [729/3844], Loss: 0.0751\n",
      "Epoch [4/4], Step [730/3844], Loss: 0.0670\n",
      "Epoch [4/4], Step [731/3844], Loss: 0.1352\n",
      "Epoch [4/4], Step [732/3844], Loss: 0.1371\n",
      "Epoch [4/4], Step [733/3844], Loss: 0.0815\n",
      "Epoch [4/4], Step [734/3844], Loss: 0.1008\n",
      "Epoch [4/4], Step [735/3844], Loss: 0.1201\n",
      "Epoch [4/4], Step [736/3844], Loss: 0.1613\n",
      "Epoch [4/4], Step [737/3844], Loss: 0.0919\n",
      "Epoch [4/4], Step [738/3844], Loss: 0.0857\n",
      "Epoch [4/4], Step [739/3844], Loss: 0.1586\n",
      "Epoch [4/4], Step [740/3844], Loss: 0.0551\n",
      "Epoch [4/4], Step [741/3844], Loss: 0.1641\n",
      "Epoch [4/4], Step [742/3844], Loss: 0.0791\n",
      "Epoch [4/4], Step [743/3844], Loss: 0.0501\n",
      "Epoch [4/4], Step [744/3844], Loss: 0.0840\n",
      "Epoch [4/4], Step [745/3844], Loss: 0.1623\n",
      "Epoch [4/4], Step [746/3844], Loss: 0.0852\n",
      "Epoch [4/4], Step [747/3844], Loss: 0.0914\n",
      "Epoch [4/4], Step [748/3844], Loss: 0.1225\n",
      "Epoch [4/4], Step [749/3844], Loss: 0.0857\n",
      "Epoch [4/4], Step [750/3844], Loss: 0.0451\n",
      "Epoch [4/4], Step [751/3844], Loss: 0.1577\n",
      "Epoch [4/4], Step [752/3844], Loss: 0.0819\n",
      "Epoch [4/4], Step [753/3844], Loss: 0.1577\n",
      "Epoch [4/4], Step [754/3844], Loss: 0.0770\n",
      "Epoch [4/4], Step [755/3844], Loss: 0.0889\n",
      "Epoch [4/4], Step [756/3844], Loss: 0.1531\n",
      "Epoch [4/4], Step [757/3844], Loss: 0.1236\n",
      "Epoch [4/4], Step [758/3844], Loss: 0.0699\n",
      "Epoch [4/4], Step [759/3844], Loss: 0.0876\n",
      "Epoch [4/4], Step [760/3844], Loss: 0.1422\n",
      "Epoch [4/4], Step [761/3844], Loss: 0.0895\n",
      "Epoch [4/4], Step [762/3844], Loss: 0.1156\n",
      "Epoch [4/4], Step [763/3844], Loss: 0.0979\n",
      "Epoch [4/4], Step [764/3844], Loss: 0.1661\n",
      "Epoch [4/4], Step [765/3844], Loss: 0.1163\n",
      "Epoch [4/4], Step [766/3844], Loss: 0.0654\n",
      "Epoch [4/4], Step [767/3844], Loss: 0.1012\n",
      "Epoch [4/4], Step [768/3844], Loss: 0.1212\n",
      "Epoch [4/4], Step [769/3844], Loss: 0.0680\n",
      "Epoch [4/4], Step [770/3844], Loss: 0.0655\n",
      "Epoch [4/4], Step [771/3844], Loss: 0.0551\n",
      "Epoch [4/4], Step [772/3844], Loss: 0.1161\n",
      "Epoch [4/4], Step [773/3844], Loss: 0.0683\n",
      "Epoch [4/4], Step [774/3844], Loss: 0.1428\n",
      "Epoch [4/4], Step [775/3844], Loss: 0.0591\n",
      "Epoch [4/4], Step [776/3844], Loss: 0.0720\n",
      "Epoch [4/4], Step [777/3844], Loss: 0.1614\n",
      "Epoch [4/4], Step [778/3844], Loss: 0.0618\n",
      "Epoch [4/4], Step [779/3844], Loss: 0.0785\n",
      "Epoch [4/4], Step [780/3844], Loss: 0.0716\n",
      "Epoch [4/4], Step [781/3844], Loss: 0.1366\n",
      "Epoch [4/4], Step [782/3844], Loss: 0.0876\n",
      "Epoch [4/4], Step [783/3844], Loss: 0.1431\n",
      "Epoch [4/4], Step [784/3844], Loss: 0.0673\n",
      "Epoch [4/4], Step [785/3844], Loss: 0.1552\n",
      "Epoch [4/4], Step [786/3844], Loss: 0.0704\n",
      "Epoch [4/4], Step [787/3844], Loss: 0.1018\n",
      "Epoch [4/4], Step [788/3844], Loss: 0.0836\n",
      "Epoch [4/4], Step [789/3844], Loss: 0.0518\n",
      "Epoch [4/4], Step [790/3844], Loss: 0.0603\n",
      "Epoch [4/4], Step [791/3844], Loss: 0.0959\n",
      "Epoch [4/4], Step [792/3844], Loss: 0.0875\n",
      "Epoch [4/4], Step [793/3844], Loss: 0.0803\n",
      "Epoch [4/4], Step [794/3844], Loss: 0.0693\n",
      "Epoch [4/4], Step [795/3844], Loss: 0.0977\n",
      "Epoch [4/4], Step [796/3844], Loss: 0.1202\n",
      "Epoch [4/4], Step [797/3844], Loss: 0.1005\n",
      "Epoch [4/4], Step [798/3844], Loss: 0.0844\n",
      "Epoch [4/4], Step [799/3844], Loss: 0.0677\n",
      "Epoch [4/4], Step [800/3844], Loss: 0.0755\n",
      "Epoch [4/4], Step [801/3844], Loss: 0.0541\n",
      "Epoch [4/4], Step [802/3844], Loss: 0.0901\n",
      "Epoch [4/4], Step [803/3844], Loss: 0.0893\n",
      "Epoch [4/4], Step [804/3844], Loss: 0.0798\n",
      "Epoch [4/4], Step [805/3844], Loss: 0.1188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/4], Step [806/3844], Loss: 0.1217\n",
      "Epoch [4/4], Step [807/3844], Loss: 0.0743\n",
      "Epoch [4/4], Step [808/3844], Loss: 0.0838\n",
      "Epoch [4/4], Step [809/3844], Loss: 0.0737\n",
      "Epoch [4/4], Step [810/3844], Loss: 0.1365\n",
      "Epoch [4/4], Step [811/3844], Loss: 0.1289\n",
      "Epoch [4/4], Step [812/3844], Loss: 0.1709\n",
      "Epoch [4/4], Step [813/3844], Loss: 0.1307\n",
      "Epoch [4/4], Step [814/3844], Loss: 0.0540\n",
      "Epoch [4/4], Step [815/3844], Loss: 0.1606\n",
      "Epoch [4/4], Step [816/3844], Loss: 0.0852\n",
      "Epoch [4/4], Step [817/3844], Loss: 0.1442\n",
      "Epoch [4/4], Step [818/3844], Loss: 0.0889\n",
      "Epoch [4/4], Step [819/3844], Loss: 0.1787\n",
      "Epoch [4/4], Step [820/3844], Loss: 0.1180\n",
      "Epoch [4/4], Step [821/3844], Loss: 0.1005\n",
      "Epoch [4/4], Step [822/3844], Loss: 0.0932\n",
      "Epoch [4/4], Step [823/3844], Loss: 0.1032\n",
      "Epoch [4/4], Step [824/3844], Loss: 0.0759\n",
      "Epoch [4/4], Step [825/3844], Loss: 0.0848\n",
      "Epoch [4/4], Step [826/3844], Loss: 0.1108\n",
      "Epoch [4/4], Step [827/3844], Loss: 0.1513\n",
      "Epoch [4/4], Step [828/3844], Loss: 0.1308\n",
      "Epoch [4/4], Step [829/3844], Loss: 0.1196\n",
      "Epoch [4/4], Step [830/3844], Loss: 0.1293\n",
      "Epoch [4/4], Step [831/3844], Loss: 0.0664\n",
      "Epoch [4/4], Step [832/3844], Loss: 0.1050\n",
      "Epoch [4/4], Step [833/3844], Loss: 0.0781\n",
      "Epoch [4/4], Step [834/3844], Loss: 0.0505\n",
      "Epoch [4/4], Step [835/3844], Loss: 0.0999\n",
      "Epoch [4/4], Step [836/3844], Loss: 0.1011\n",
      "Epoch [4/4], Step [837/3844], Loss: 0.0514\n",
      "Epoch [4/4], Step [838/3844], Loss: 0.0643\n",
      "Epoch [4/4], Step [839/3844], Loss: 0.0826\n",
      "Epoch [4/4], Step [840/3844], Loss: 0.0685\n",
      "Epoch [4/4], Step [841/3844], Loss: 0.0667\n",
      "Epoch [4/4], Step [842/3844], Loss: 0.1648\n",
      "Epoch [4/4], Step [843/3844], Loss: 0.0790\n",
      "Epoch [4/4], Step [844/3844], Loss: 0.1187\n",
      "Epoch [4/4], Step [845/3844], Loss: 0.1182\n",
      "Epoch [4/4], Step [846/3844], Loss: 0.1101\n",
      "Epoch [4/4], Step [847/3844], Loss: 0.1558\n",
      "Epoch [4/4], Step [848/3844], Loss: 0.0784\n",
      "Epoch [4/4], Step [849/3844], Loss: 0.0867\n",
      "Epoch [4/4], Step [850/3844], Loss: 0.0694\n",
      "Epoch [4/4], Step [851/3844], Loss: 0.1234\n",
      "Epoch [4/4], Step [852/3844], Loss: 0.1707\n",
      "Epoch [4/4], Step [853/3844], Loss: 0.0853\n",
      "Epoch [4/4], Step [854/3844], Loss: 0.0934\n",
      "Epoch [4/4], Step [855/3844], Loss: 0.1420\n",
      "Epoch [4/4], Step [856/3844], Loss: 0.1432\n",
      "Epoch [4/4], Step [857/3844], Loss: 0.0908\n",
      "Epoch [4/4], Step [858/3844], Loss: 0.0656\n",
      "Epoch [4/4], Step [859/3844], Loss: 0.1250\n",
      "Epoch [4/4], Step [860/3844], Loss: 0.0817\n",
      "Epoch [4/4], Step [861/3844], Loss: 0.1158\n",
      "Epoch [4/4], Step [862/3844], Loss: 0.0789\n",
      "Epoch [4/4], Step [863/3844], Loss: 0.0829\n",
      "Epoch [4/4], Step [864/3844], Loss: 0.1613\n",
      "Epoch [4/4], Step [865/3844], Loss: 0.0953\n",
      "Epoch [4/4], Step [866/3844], Loss: 0.0898\n",
      "Epoch [4/4], Step [867/3844], Loss: 0.1305\n",
      "Epoch [4/4], Step [868/3844], Loss: 0.0745\n",
      "Epoch [4/4], Step [869/3844], Loss: 0.1252\n",
      "Epoch [4/4], Step [870/3844], Loss: 0.0933\n",
      "Epoch [4/4], Step [871/3844], Loss: 0.1024\n",
      "Epoch [4/4], Step [872/3844], Loss: 0.1168\n",
      "Epoch [4/4], Step [873/3844], Loss: 0.1191\n",
      "Epoch [4/4], Step [874/3844], Loss: 0.0916\n",
      "Epoch [4/4], Step [875/3844], Loss: 0.0965\n",
      "Epoch [4/4], Step [876/3844], Loss: 0.0597\n",
      "Epoch [4/4], Step [877/3844], Loss: 0.0738\n",
      "Epoch [4/4], Step [878/3844], Loss: 0.0770\n",
      "Epoch [4/4], Step [879/3844], Loss: 0.0930\n",
      "Epoch [4/4], Step [880/3844], Loss: 0.1040\n",
      "Epoch [4/4], Step [881/3844], Loss: 0.0775\n",
      "Epoch [4/4], Step [882/3844], Loss: 0.1294\n",
      "Epoch [4/4], Step [883/3844], Loss: 0.0790\n",
      "Epoch [4/4], Step [884/3844], Loss: 0.0890\n",
      "Epoch [4/4], Step [885/3844], Loss: 0.1134\n",
      "Epoch [4/4], Step [886/3844], Loss: 0.1270\n",
      "Epoch [4/4], Step [887/3844], Loss: 0.0556\n",
      "Epoch [4/4], Step [888/3844], Loss: 0.0760\n",
      "Epoch [4/4], Step [889/3844], Loss: 0.0772\n",
      "Epoch [4/4], Step [890/3844], Loss: 0.1237\n",
      "Epoch [4/4], Step [891/3844], Loss: 0.0488\n",
      "Epoch [4/4], Step [892/3844], Loss: 0.0561\n",
      "Epoch [4/4], Step [893/3844], Loss: 0.1297\n",
      "Epoch [4/4], Step [894/3844], Loss: 0.1566\n",
      "Epoch [4/4], Step [895/3844], Loss: 0.1122\n",
      "Epoch [4/4], Step [896/3844], Loss: 0.1300\n",
      "Epoch [4/4], Step [897/3844], Loss: 0.0696\n",
      "Epoch [4/4], Step [898/3844], Loss: 0.0804\n",
      "Epoch [4/4], Step [899/3844], Loss: 0.1396\n",
      "Epoch [4/4], Step [900/3844], Loss: 0.1021\n",
      "Epoch [4/4], Step [901/3844], Loss: 0.0798\n",
      "Epoch [4/4], Step [902/3844], Loss: 0.0863\n",
      "Epoch [4/4], Step [903/3844], Loss: 0.0625\n",
      "Epoch [4/4], Step [904/3844], Loss: 0.0839\n",
      "Epoch [4/4], Step [905/3844], Loss: 0.0800\n",
      "Epoch [4/4], Step [906/3844], Loss: 0.1440\n",
      "Epoch [4/4], Step [907/3844], Loss: 0.0788\n",
      "Epoch [4/4], Step [908/3844], Loss: 0.0765\n",
      "Epoch [4/4], Step [909/3844], Loss: 0.0595\n",
      "Epoch [4/4], Step [910/3844], Loss: 0.0725\n",
      "Epoch [4/4], Step [911/3844], Loss: 0.0842\n",
      "Epoch [4/4], Step [912/3844], Loss: 0.1548\n",
      "Epoch [4/4], Step [913/3844], Loss: 0.0498\n",
      "Epoch [4/4], Step [914/3844], Loss: 0.0419\n",
      "Epoch [4/4], Step [915/3844], Loss: 0.1549\n",
      "Epoch [4/4], Step [916/3844], Loss: 0.0890\n",
      "Epoch [4/4], Step [917/3844], Loss: 0.0669\n",
      "Epoch [4/4], Step [918/3844], Loss: 0.0531\n",
      "Epoch [4/4], Step [919/3844], Loss: 0.0801\n",
      "Epoch [4/4], Step [920/3844], Loss: 0.1111\n",
      "Epoch [4/4], Step [921/3844], Loss: 0.0993\n",
      "Epoch [4/4], Step [922/3844], Loss: 0.0602\n",
      "Epoch [4/4], Step [923/3844], Loss: 0.0805\n",
      "Epoch [4/4], Step [924/3844], Loss: 0.0415\n",
      "Epoch [4/4], Step [925/3844], Loss: 0.0900\n",
      "Epoch [4/4], Step [926/3844], Loss: 0.1388\n",
      "Epoch [4/4], Step [927/3844], Loss: 0.1030\n",
      "Epoch [4/4], Step [928/3844], Loss: 0.1096\n",
      "Epoch [4/4], Step [929/3844], Loss: 0.0950\n",
      "Epoch [4/4], Step [930/3844], Loss: 0.1066\n",
      "Epoch [4/4], Step [931/3844], Loss: 0.1096\n",
      "Epoch [4/4], Step [932/3844], Loss: 0.1498\n",
      "Epoch [4/4], Step [933/3844], Loss: 0.1063\n",
      "Epoch [4/4], Step [934/3844], Loss: 0.1031\n",
      "Epoch [4/4], Step [935/3844], Loss: 0.0990\n",
      "Epoch [4/4], Step [936/3844], Loss: 0.1475\n",
      "Epoch [4/4], Step [937/3844], Loss: 0.0671\n",
      "Epoch [4/4], Step [938/3844], Loss: 0.0660\n",
      "Epoch [4/4], Step [939/3844], Loss: 0.0917\n",
      "Epoch [4/4], Step [940/3844], Loss: 0.0759\n",
      "Epoch [4/4], Step [941/3844], Loss: 0.0513\n",
      "Epoch [4/4], Step [942/3844], Loss: 0.1265\n",
      "Epoch [4/4], Step [943/3844], Loss: 0.0981\n",
      "Epoch [4/4], Step [944/3844], Loss: 0.0809\n",
      "Epoch [4/4], Step [945/3844], Loss: 0.1106\n",
      "Epoch [4/4], Step [946/3844], Loss: 0.0858\n",
      "Epoch [4/4], Step [947/3844], Loss: 0.0630\n",
      "Epoch [4/4], Step [948/3844], Loss: 0.1238\n",
      "Epoch [4/4], Step [949/3844], Loss: 0.0821\n",
      "Epoch [4/4], Step [950/3844], Loss: 0.1282\n",
      "Epoch [4/4], Step [951/3844], Loss: 0.0675\n",
      "Epoch [4/4], Step [952/3844], Loss: 0.1223\n",
      "Epoch [4/4], Step [953/3844], Loss: 0.1034\n",
      "Epoch [4/4], Step [954/3844], Loss: 0.0763\n",
      "Epoch [4/4], Step [955/3844], Loss: 0.0934\n",
      "Epoch [4/4], Step [956/3844], Loss: 0.0760\n",
      "Epoch [4/4], Step [957/3844], Loss: 0.0500\n",
      "Epoch [4/4], Step [958/3844], Loss: 0.0801\n",
      "Epoch [4/4], Step [959/3844], Loss: 0.1691\n",
      "Epoch [4/4], Step [960/3844], Loss: 0.0626\n",
      "Epoch [4/4], Step [961/3844], Loss: 0.0870\n",
      "Epoch [4/4], Step [962/3844], Loss: 0.1197\n",
      "Epoch [4/4], Step [963/3844], Loss: 0.1324\n",
      "Epoch [4/4], Step [964/3844], Loss: 0.1514\n",
      "Epoch [4/4], Step [965/3844], Loss: 0.1506\n",
      "Epoch [4/4], Step [966/3844], Loss: 0.0813\n",
      "Epoch [4/4], Step [967/3844], Loss: 0.0935\n",
      "Epoch [4/4], Step [968/3844], Loss: 0.0860\n",
      "Epoch [4/4], Step [969/3844], Loss: 0.0565\n",
      "Epoch [4/4], Step [970/3844], Loss: 0.1603\n",
      "Epoch [4/4], Step [971/3844], Loss: 0.0698\n",
      "Epoch [4/4], Step [972/3844], Loss: 0.0973\n",
      "Epoch [4/4], Step [973/3844], Loss: 0.1425\n",
      "Epoch [4/4], Step [974/3844], Loss: 0.0780\n",
      "Epoch [4/4], Step [975/3844], Loss: 0.1067\n",
      "Epoch [4/4], Step [976/3844], Loss: 0.1301\n",
      "Epoch [4/4], Step [977/3844], Loss: 0.0753\n",
      "Epoch [4/4], Step [978/3844], Loss: 0.1605\n",
      "Epoch [4/4], Step [979/3844], Loss: 0.0780\n",
      "Epoch [4/4], Step [980/3844], Loss: 0.0641\n",
      "Epoch [4/4], Step [981/3844], Loss: 0.0804\n",
      "Epoch [4/4], Step [982/3844], Loss: 0.1189\n",
      "Epoch [4/4], Step [983/3844], Loss: 0.0470\n",
      "Epoch [4/4], Step [984/3844], Loss: 0.1569\n",
      "Epoch [4/4], Step [985/3844], Loss: 0.1330\n",
      "Epoch [4/4], Step [986/3844], Loss: 0.1143\n",
      "Epoch [4/4], Step [987/3844], Loss: 0.1398\n",
      "Epoch [4/4], Step [988/3844], Loss: 0.1343\n",
      "Epoch [4/4], Step [989/3844], Loss: 0.0639\n",
      "Epoch [4/4], Step [990/3844], Loss: 0.1141\n",
      "Epoch [4/4], Step [991/3844], Loss: 0.0826\n",
      "Epoch [4/4], Step [992/3844], Loss: 0.1161\n",
      "Epoch [4/4], Step [993/3844], Loss: 0.1166\n",
      "Epoch [4/4], Step [994/3844], Loss: 0.0943\n",
      "Epoch [4/4], Step [995/3844], Loss: 0.1219\n",
      "Epoch [4/4], Step [996/3844], Loss: 0.0889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/4], Step [997/3844], Loss: 0.0773\n",
      "Epoch [4/4], Step [998/3844], Loss: 0.0796\n",
      "Epoch [4/4], Step [999/3844], Loss: 0.0438\n",
      "Epoch [4/4], Step [1000/3844], Loss: 0.0646\n",
      "Epoch [4/4], Step [1001/3844], Loss: 0.0976\n",
      "Epoch [4/4], Step [1002/3844], Loss: 0.0553\n",
      "Epoch [4/4], Step [1003/3844], Loss: 0.0763\n",
      "Epoch [4/4], Step [1004/3844], Loss: 0.0340\n",
      "Epoch [4/4], Step [1005/3844], Loss: 0.0669\n",
      "Epoch [4/4], Step [1006/3844], Loss: 0.1631\n",
      "Epoch [4/4], Step [1007/3844], Loss: 0.1227\n",
      "Epoch [4/4], Step [1008/3844], Loss: 0.1063\n",
      "Epoch [4/4], Step [1009/3844], Loss: 0.0953\n",
      "Epoch [4/4], Step [1010/3844], Loss: 0.1582\n",
      "Epoch [4/4], Step [1011/3844], Loss: 0.1737\n",
      "Epoch [4/4], Step [1012/3844], Loss: 0.1824\n",
      "Epoch [4/4], Step [1013/3844], Loss: 0.0543\n",
      "Epoch [4/4], Step [1014/3844], Loss: 0.1546\n",
      "Epoch [4/4], Step [1015/3844], Loss: 0.0938\n",
      "Epoch [4/4], Step [1016/3844], Loss: 0.0751\n",
      "Epoch [4/4], Step [1017/3844], Loss: 0.0635\n",
      "Epoch [4/4], Step [1018/3844], Loss: 0.1412\n",
      "Epoch [4/4], Step [1019/3844], Loss: 0.1406\n",
      "Epoch [4/4], Step [1020/3844], Loss: 0.0929\n",
      "Epoch [4/4], Step [1021/3844], Loss: 0.1666\n",
      "Epoch [4/4], Step [1022/3844], Loss: 0.1617\n",
      "Epoch [4/4], Step [1023/3844], Loss: 0.1225\n",
      "Epoch [4/4], Step [1024/3844], Loss: 0.0994\n",
      "Epoch [4/4], Step [1025/3844], Loss: 0.1136\n",
      "Epoch [4/4], Step [1026/3844], Loss: 0.0510\n",
      "Epoch [4/4], Step [1027/3844], Loss: 0.1021\n",
      "Epoch [4/4], Step [1028/3844], Loss: 0.1252\n",
      "Epoch [4/4], Step [1029/3844], Loss: 0.0809\n",
      "Epoch [4/4], Step [1030/3844], Loss: 0.0982\n",
      "Epoch [4/4], Step [1031/3844], Loss: 0.1439\n",
      "Epoch [4/4], Step [1032/3844], Loss: 0.1631\n",
      "Epoch [4/4], Step [1033/3844], Loss: 0.1373\n",
      "Epoch [4/4], Step [1034/3844], Loss: 0.0477\n",
      "Epoch [4/4], Step [1035/3844], Loss: 0.0821\n",
      "Epoch [4/4], Step [1036/3844], Loss: 0.1191\n",
      "Epoch [4/4], Step [1037/3844], Loss: 0.1088\n",
      "Epoch [4/4], Step [1038/3844], Loss: 0.0765\n",
      "Epoch [4/4], Step [1039/3844], Loss: 0.1150\n",
      "Epoch [4/4], Step [1040/3844], Loss: 0.1542\n",
      "Epoch [4/4], Step [1041/3844], Loss: 0.0961\n",
      "Epoch [4/4], Step [1042/3844], Loss: 0.0841\n",
      "Epoch [4/4], Step [1043/3844], Loss: 0.1170\n",
      "Epoch [4/4], Step [1044/3844], Loss: 0.0967\n",
      "Epoch [4/4], Step [1045/3844], Loss: 0.0659\n",
      "Epoch [4/4], Step [1046/3844], Loss: 0.1125\n",
      "Epoch [4/4], Step [1047/3844], Loss: 0.1503\n",
      "Epoch [4/4], Step [1048/3844], Loss: 0.0741\n",
      "Epoch [4/4], Step [1049/3844], Loss: 0.1459\n",
      "Epoch [4/4], Step [1050/3844], Loss: 0.0773\n",
      "Epoch [4/4], Step [1051/3844], Loss: 0.0961\n",
      "Epoch [4/4], Step [1052/3844], Loss: 0.0788\n",
      "Epoch [4/4], Step [1053/3844], Loss: 0.0698\n",
      "Epoch [4/4], Step [1054/3844], Loss: 0.1046\n",
      "Epoch [4/4], Step [1055/3844], Loss: 0.1186\n",
      "Epoch [4/4], Step [1056/3844], Loss: 0.1715\n",
      "Epoch [4/4], Step [1057/3844], Loss: 0.0443\n",
      "Epoch [4/4], Step [1058/3844], Loss: 0.1197\n",
      "Epoch [4/4], Step [1059/3844], Loss: 0.0951\n",
      "Epoch [4/4], Step [1060/3844], Loss: 0.0752\n",
      "Epoch [4/4], Step [1061/3844], Loss: 0.1010\n",
      "Epoch [4/4], Step [1062/3844], Loss: 0.1399\n",
      "Epoch [4/4], Step [1063/3844], Loss: 0.1020\n",
      "Epoch [4/4], Step [1064/3844], Loss: 0.1238\n",
      "Epoch [4/4], Step [1065/3844], Loss: 0.0813\n",
      "Epoch [4/4], Step [1066/3844], Loss: 0.0787\n",
      "Epoch [4/4], Step [1067/3844], Loss: 0.0854\n",
      "Epoch [4/4], Step [1068/3844], Loss: 0.0720\n",
      "Epoch [4/4], Step [1069/3844], Loss: 0.1037\n",
      "Epoch [4/4], Step [1070/3844], Loss: 0.0527\n",
      "Epoch [4/4], Step [1071/3844], Loss: 0.1650\n",
      "Epoch [4/4], Step [1072/3844], Loss: 0.0951\n",
      "Epoch [4/4], Step [1073/3844], Loss: 0.0796\n",
      "Epoch [4/4], Step [1074/3844], Loss: 0.1323\n",
      "Epoch [4/4], Step [1075/3844], Loss: 0.0752\n",
      "Epoch [4/4], Step [1076/3844], Loss: 0.0753\n",
      "Epoch [4/4], Step [1077/3844], Loss: 0.0960\n",
      "Epoch [4/4], Step [1078/3844], Loss: 0.0710\n",
      "Epoch [4/4], Step [1079/3844], Loss: 0.0764\n",
      "Epoch [4/4], Step [1080/3844], Loss: 0.1655\n",
      "Epoch [4/4], Step [1081/3844], Loss: 0.0753\n",
      "Epoch [4/4], Step [1082/3844], Loss: 0.1060\n",
      "Epoch [4/4], Step [1083/3844], Loss: 0.1338\n",
      "Epoch [4/4], Step [1084/3844], Loss: 0.0951\n",
      "Epoch [4/4], Step [1085/3844], Loss: 0.0491\n",
      "Epoch [4/4], Step [1086/3844], Loss: 0.1152\n",
      "Epoch [4/4], Step [1087/3844], Loss: 0.0801\n",
      "Epoch [4/4], Step [1088/3844], Loss: 0.1141\n",
      "Epoch [4/4], Step [1089/3844], Loss: 0.1229\n",
      "Epoch [4/4], Step [1090/3844], Loss: 0.1200\n",
      "Epoch [4/4], Step [1091/3844], Loss: 0.0867\n",
      "Epoch [4/4], Step [1092/3844], Loss: 0.1040\n",
      "Epoch [4/4], Step [1093/3844], Loss: 0.1308\n",
      "Epoch [4/4], Step [1094/3844], Loss: 0.0720\n",
      "Epoch [4/4], Step [1095/3844], Loss: 0.0682\n",
      "Epoch [4/4], Step [1096/3844], Loss: 0.1268\n",
      "Epoch [4/4], Step [1097/3844], Loss: 0.0762\n",
      "Epoch [4/4], Step [1098/3844], Loss: 0.1083\n",
      "Epoch [4/4], Step [1099/3844], Loss: 0.0995\n",
      "Epoch [4/4], Step [1100/3844], Loss: 0.1499\n",
      "Epoch [4/4], Step [1101/3844], Loss: 0.0829\n",
      "Epoch [4/4], Step [1102/3844], Loss: 0.0768\n",
      "Epoch [4/4], Step [1103/3844], Loss: 0.0635\n",
      "Epoch [4/4], Step [1104/3844], Loss: 0.1365\n",
      "Epoch [4/4], Step [1105/3844], Loss: 0.0587\n",
      "Epoch [4/4], Step [1106/3844], Loss: 0.0997\n",
      "Epoch [4/4], Step [1107/3844], Loss: 0.0765\n",
      "Epoch [4/4], Step [1108/3844], Loss: 0.0685\n",
      "Epoch [4/4], Step [1109/3844], Loss: 0.1524\n",
      "Epoch [4/4], Step [1110/3844], Loss: 0.0722\n",
      "Epoch [4/4], Step [1111/3844], Loss: 0.0495\n",
      "Epoch [4/4], Step [1112/3844], Loss: 0.0700\n",
      "Epoch [4/4], Step [1113/3844], Loss: 0.0909\n",
      "Epoch [4/4], Step [1114/3844], Loss: 0.0470\n",
      "Epoch [4/4], Step [1115/3844], Loss: 0.1023\n",
      "Epoch [4/4], Step [1116/3844], Loss: 0.0703\n",
      "Epoch [4/4], Step [1117/3844], Loss: 0.0473\n",
      "Epoch [4/4], Step [1118/3844], Loss: 0.0730\n",
      "Epoch [4/4], Step [1119/3844], Loss: 0.0563\n",
      "Epoch [4/4], Step [1120/3844], Loss: 0.1435\n",
      "Epoch [4/4], Step [1121/3844], Loss: 0.0514\n",
      "Epoch [4/4], Step [1122/3844], Loss: 0.1413\n",
      "Epoch [4/4], Step [1123/3844], Loss: 0.1466\n",
      "Epoch [4/4], Step [1124/3844], Loss: 0.0724\n",
      "Epoch [4/4], Step [1125/3844], Loss: 0.0489\n",
      "Epoch [4/4], Step [1126/3844], Loss: 0.1293\n",
      "Epoch [4/4], Step [1127/3844], Loss: 0.0723\n",
      "Epoch [4/4], Step [1128/3844], Loss: 0.0839\n",
      "Epoch [4/4], Step [1129/3844], Loss: 0.0790\n",
      "Epoch [4/4], Step [1130/3844], Loss: 0.1396\n",
      "Epoch [4/4], Step [1131/3844], Loss: 0.1008\n",
      "Epoch [4/4], Step [1132/3844], Loss: 0.1101\n",
      "Epoch [4/4], Step [1133/3844], Loss: 0.0953\n",
      "Epoch [4/4], Step [1134/3844], Loss: 0.0588\n",
      "Epoch [4/4], Step [1135/3844], Loss: 0.0485\n",
      "Epoch [4/4], Step [1136/3844], Loss: 0.1469\n",
      "Epoch [4/4], Step [1137/3844], Loss: 0.1528\n",
      "Epoch [4/4], Step [1138/3844], Loss: 0.1519\n",
      "Epoch [4/4], Step [1139/3844], Loss: 0.0926\n",
      "Epoch [4/4], Step [1140/3844], Loss: 0.0584\n",
      "Epoch [4/4], Step [1141/3844], Loss: 0.1405\n",
      "Epoch [4/4], Step [1142/3844], Loss: 0.1122\n",
      "Epoch [4/4], Step [1143/3844], Loss: 0.1316\n",
      "Epoch [4/4], Step [1144/3844], Loss: 0.1166\n",
      "Epoch [4/4], Step [1145/3844], Loss: 0.0708\n",
      "Epoch [4/4], Step [1146/3844], Loss: 0.1130\n",
      "Epoch [4/4], Step [1147/3844], Loss: 0.1688\n",
      "Epoch [4/4], Step [1148/3844], Loss: 0.0745\n",
      "Epoch [4/4], Step [1149/3844], Loss: 0.0829\n",
      "Epoch [4/4], Step [1150/3844], Loss: 0.1619\n",
      "Epoch [4/4], Step [1151/3844], Loss: 0.0542\n",
      "Epoch [4/4], Step [1152/3844], Loss: 0.0416\n",
      "Epoch [4/4], Step [1153/3844], Loss: 0.1697\n",
      "Epoch [4/4], Step [1154/3844], Loss: 0.1663\n",
      "Epoch [4/4], Step [1155/3844], Loss: 0.1065\n",
      "Epoch [4/4], Step [1156/3844], Loss: 0.0968\n",
      "Epoch [4/4], Step [1157/3844], Loss: 0.1362\n",
      "Epoch [4/4], Step [1158/3844], Loss: 0.0667\n",
      "Epoch [4/4], Step [1159/3844], Loss: 0.0695\n",
      "Epoch [4/4], Step [1160/3844], Loss: 0.1320\n",
      "Epoch [4/4], Step [1161/3844], Loss: 0.0869\n",
      "Epoch [4/4], Step [1162/3844], Loss: 0.1420\n",
      "Epoch [4/4], Step [1163/3844], Loss: 0.0788\n",
      "Epoch [4/4], Step [1164/3844], Loss: 0.1240\n",
      "Epoch [4/4], Step [1165/3844], Loss: 0.1739\n",
      "Epoch [4/4], Step [1166/3844], Loss: 0.1693\n",
      "Epoch [4/4], Step [1167/3844], Loss: 0.1317\n",
      "Epoch [4/4], Step [1168/3844], Loss: 0.1055\n",
      "Epoch [4/4], Step [1169/3844], Loss: 0.1056\n",
      "Epoch [4/4], Step [1170/3844], Loss: 0.1306\n",
      "Epoch [4/4], Step [1171/3844], Loss: 0.1009\n",
      "Epoch [4/4], Step [1172/3844], Loss: 0.1257\n",
      "Epoch [4/4], Step [1173/3844], Loss: 0.1496\n",
      "Epoch [4/4], Step [1174/3844], Loss: 0.1070\n",
      "Epoch [4/4], Step [1175/3844], Loss: 0.1112\n",
      "Epoch [4/4], Step [1176/3844], Loss: 0.0634\n",
      "Epoch [4/4], Step [1177/3844], Loss: 0.0823\n",
      "Epoch [4/4], Step [1178/3844], Loss: 0.0995\n",
      "Epoch [4/4], Step [1179/3844], Loss: 0.1225\n",
      "Epoch [4/4], Step [1180/3844], Loss: 0.0826\n",
      "Epoch [4/4], Step [1181/3844], Loss: 0.0899\n",
      "Epoch [4/4], Step [1182/3844], Loss: 0.1157\n",
      "Epoch [4/4], Step [1183/3844], Loss: 0.1746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/4], Step [1184/3844], Loss: 0.1091\n",
      "Epoch [4/4], Step [1185/3844], Loss: 0.0986\n",
      "Epoch [4/4], Step [1186/3844], Loss: 0.1030\n",
      "Epoch [4/4], Step [1187/3844], Loss: 0.1516\n",
      "Epoch [4/4], Step [1188/3844], Loss: 0.0800\n",
      "Epoch [4/4], Step [1189/3844], Loss: 0.0674\n",
      "Epoch [4/4], Step [1190/3844], Loss: 0.0809\n",
      "Epoch [4/4], Step [1191/3844], Loss: 0.0682\n",
      "Epoch [4/4], Step [1192/3844], Loss: 0.0838\n",
      "Epoch [4/4], Step [1193/3844], Loss: 0.0986\n",
      "Epoch [4/4], Step [1194/3844], Loss: 0.1354\n",
      "Epoch [4/4], Step [1195/3844], Loss: 0.1482\n",
      "Epoch [4/4], Step [1196/3844], Loss: 0.0822\n",
      "Epoch [4/4], Step [1197/3844], Loss: 0.0667\n",
      "Epoch [4/4], Step [1198/3844], Loss: 0.1077\n",
      "Epoch [4/4], Step [1199/3844], Loss: 0.1293\n",
      "Epoch [4/4], Step [1200/3844], Loss: 0.0966\n",
      "Epoch [4/4], Step [1201/3844], Loss: 0.0761\n",
      "Epoch [4/4], Step [1202/3844], Loss: 0.1026\n",
      "Epoch [4/4], Step [1203/3844], Loss: 0.0713\n",
      "Epoch [4/4], Step [1204/3844], Loss: 0.0809\n",
      "Epoch [4/4], Step [1205/3844], Loss: 0.0856\n",
      "Epoch [4/4], Step [1206/3844], Loss: 0.0724\n",
      "Epoch [4/4], Step [1207/3844], Loss: 0.1146\n",
      "Epoch [4/4], Step [1208/3844], Loss: 0.0902\n",
      "Epoch [4/4], Step [1209/3844], Loss: 0.0745\n",
      "Epoch [4/4], Step [1210/3844], Loss: 0.1266\n",
      "Epoch [4/4], Step [1211/3844], Loss: 0.0774\n",
      "Epoch [4/4], Step [1212/3844], Loss: 0.0780\n",
      "Epoch [4/4], Step [1213/3844], Loss: 0.0872\n",
      "Epoch [4/4], Step [1214/3844], Loss: 0.1089\n",
      "Epoch [4/4], Step [1215/3844], Loss: 0.1768\n",
      "Epoch [4/4], Step [1216/3844], Loss: 0.0730\n",
      "Epoch [4/4], Step [1217/3844], Loss: 0.0908\n",
      "Epoch [4/4], Step [1218/3844], Loss: 0.0780\n",
      "Epoch [4/4], Step [1219/3844], Loss: 0.0890\n",
      "Epoch [4/4], Step [1220/3844], Loss: 0.1241\n",
      "Epoch [4/4], Step [1221/3844], Loss: 0.1024\n",
      "Epoch [4/4], Step [1222/3844], Loss: 0.1448\n",
      "Epoch [4/4], Step [1223/3844], Loss: 0.1436\n",
      "Epoch [4/4], Step [1224/3844], Loss: 0.1379\n",
      "Epoch [4/4], Step [1225/3844], Loss: 0.1011\n",
      "Epoch [4/4], Step [1226/3844], Loss: 0.0749\n",
      "Epoch [4/4], Step [1227/3844], Loss: 0.0918\n",
      "Epoch [4/4], Step [1228/3844], Loss: 0.1014\n",
      "Epoch [4/4], Step [1229/3844], Loss: 0.0903\n",
      "Epoch [4/4], Step [1230/3844], Loss: 0.0906\n",
      "Epoch [4/4], Step [1231/3844], Loss: 0.0812\n",
      "Epoch [4/4], Step [1232/3844], Loss: 0.0922\n",
      "Epoch [4/4], Step [1233/3844], Loss: 0.1143\n",
      "Epoch [4/4], Step [1234/3844], Loss: 0.1632\n",
      "Epoch [4/4], Step [1235/3844], Loss: 0.0695\n",
      "Epoch [4/4], Step [1236/3844], Loss: 0.0709\n",
      "Epoch [4/4], Step [1237/3844], Loss: 0.1632\n",
      "Epoch [4/4], Step [1238/3844], Loss: 0.0707\n",
      "Epoch [4/4], Step [1239/3844], Loss: 0.1500\n",
      "Epoch [4/4], Step [1240/3844], Loss: 0.1163\n",
      "Epoch [4/4], Step [1241/3844], Loss: 0.1611\n",
      "Epoch [4/4], Step [1242/3844], Loss: 0.0861\n",
      "Epoch [4/4], Step [1243/3844], Loss: 0.0655\n",
      "Epoch [4/4], Step [1244/3844], Loss: 0.0979\n",
      "Epoch [4/4], Step [1245/3844], Loss: 0.0643\n",
      "Epoch [4/4], Step [1246/3844], Loss: 0.0873\n",
      "Epoch [4/4], Step [1247/3844], Loss: 0.1121\n",
      "Epoch [4/4], Step [1248/3844], Loss: 0.0610\n",
      "Epoch [4/4], Step [1249/3844], Loss: 0.0941\n",
      "Epoch [4/4], Step [1250/3844], Loss: 0.0748\n",
      "Epoch [4/4], Step [1251/3844], Loss: 0.1010\n",
      "Epoch [4/4], Step [1252/3844], Loss: 0.0555\n",
      "Epoch [4/4], Step [1253/3844], Loss: 0.1746\n",
      "Epoch [4/4], Step [1254/3844], Loss: 0.0852\n",
      "Epoch [4/4], Step [1255/3844], Loss: 0.1345\n",
      "Epoch [4/4], Step [1256/3844], Loss: 0.1501\n",
      "Epoch [4/4], Step [1257/3844], Loss: 0.0751\n",
      "Epoch [4/4], Step [1258/3844], Loss: 0.0735\n",
      "Epoch [4/4], Step [1259/3844], Loss: 0.1252\n",
      "Epoch [4/4], Step [1260/3844], Loss: 0.1016\n",
      "Epoch [4/4], Step [1261/3844], Loss: 0.0948\n",
      "Epoch [4/4], Step [1262/3844], Loss: 0.0821\n",
      "Epoch [4/4], Step [1263/3844], Loss: 0.1251\n",
      "Epoch [4/4], Step [1264/3844], Loss: 0.1267\n",
      "Epoch [4/4], Step [1265/3844], Loss: 0.0991\n",
      "Epoch [4/4], Step [1266/3844], Loss: 0.0895\n",
      "Epoch [4/4], Step [1267/3844], Loss: 0.1446\n",
      "Epoch [4/4], Step [1268/3844], Loss: 0.0851\n",
      "Epoch [4/4], Step [1269/3844], Loss: 0.0771\n",
      "Epoch [4/4], Step [1270/3844], Loss: 0.1183\n",
      "Epoch [4/4], Step [1271/3844], Loss: 0.1068\n",
      "Epoch [4/4], Step [1272/3844], Loss: 0.1606\n",
      "Epoch [4/4], Step [1273/3844], Loss: 0.1204\n",
      "Epoch [4/4], Step [1274/3844], Loss: 0.0598\n",
      "Epoch [4/4], Step [1275/3844], Loss: 0.0750\n",
      "Epoch [4/4], Step [1276/3844], Loss: 0.0896\n",
      "Epoch [4/4], Step [1277/3844], Loss: 0.1519\n",
      "Epoch [4/4], Step [1278/3844], Loss: 0.0804\n",
      "Epoch [4/4], Step [1279/3844], Loss: 0.0255\n",
      "Epoch [4/4], Step [1280/3844], Loss: 0.0795\n",
      "Epoch [4/4], Step [1281/3844], Loss: 0.0768\n",
      "Epoch [4/4], Step [1282/3844], Loss: 0.1394\n",
      "Epoch [4/4], Step [1283/3844], Loss: 0.0783\n",
      "Epoch [4/4], Step [1284/3844], Loss: 0.0788\n",
      "Epoch [4/4], Step [1285/3844], Loss: 0.1094\n",
      "Epoch [4/4], Step [1286/3844], Loss: 0.1138\n",
      "Epoch [4/4], Step [1287/3844], Loss: 0.1293\n",
      "Epoch [4/4], Step [1288/3844], Loss: 0.0840\n",
      "Epoch [4/4], Step [1289/3844], Loss: 0.1484\n",
      "Epoch [4/4], Step [1290/3844], Loss: 0.0564\n",
      "Epoch [4/4], Step [1291/3844], Loss: 0.1067\n",
      "Epoch [4/4], Step [1292/3844], Loss: 0.0716\n",
      "Epoch [4/4], Step [1293/3844], Loss: 0.0721\n",
      "Epoch [4/4], Step [1294/3844], Loss: 0.0790\n",
      "Epoch [4/4], Step [1295/3844], Loss: 0.1504\n",
      "Epoch [4/4], Step [1296/3844], Loss: 0.0813\n",
      "Epoch [4/4], Step [1297/3844], Loss: 0.0569\n",
      "Epoch [4/4], Step [1298/3844], Loss: 0.0785\n",
      "Epoch [4/4], Step [1299/3844], Loss: 0.1304\n",
      "Epoch [4/4], Step [1300/3844], Loss: 0.0677\n",
      "Epoch [4/4], Step [1301/3844], Loss: 0.0655\n",
      "Epoch [4/4], Step [1302/3844], Loss: 0.0853\n",
      "Epoch [4/4], Step [1303/3844], Loss: 0.0813\n",
      "Epoch [4/4], Step [1304/3844], Loss: 0.0542\n",
      "Epoch [4/4], Step [1305/3844], Loss: 0.0608\n",
      "Epoch [4/4], Step [1306/3844], Loss: 0.0648\n",
      "Epoch [4/4], Step [1307/3844], Loss: 0.1445\n",
      "Epoch [4/4], Step [1308/3844], Loss: 0.1042\n",
      "Epoch [4/4], Step [1309/3844], Loss: 0.0819\n",
      "Epoch [4/4], Step [1310/3844], Loss: 0.0462\n",
      "Epoch [4/4], Step [1311/3844], Loss: 0.0900\n",
      "Epoch [4/4], Step [1312/3844], Loss: 0.0649\n",
      "Epoch [4/4], Step [1313/3844], Loss: 0.1355\n",
      "Epoch [4/4], Step [1314/3844], Loss: 0.0719\n",
      "Epoch [4/4], Step [1315/3844], Loss: 0.0605\n",
      "Epoch [4/4], Step [1316/3844], Loss: 0.0808\n",
      "Epoch [4/4], Step [1317/3844], Loss: 0.0634\n",
      "Epoch [4/4], Step [1318/3844], Loss: 0.1047\n",
      "Epoch [4/4], Step [1319/3844], Loss: 0.1200\n",
      "Epoch [4/4], Step [1320/3844], Loss: 0.0556\n",
      "Epoch [4/4], Step [1321/3844], Loss: 0.0950\n",
      "Epoch [4/4], Step [1322/3844], Loss: 0.1049\n",
      "Epoch [4/4], Step [1323/3844], Loss: 0.0602\n",
      "Epoch [4/4], Step [1324/3844], Loss: 0.0739\n",
      "Epoch [4/4], Step [1325/3844], Loss: 0.1434\n",
      "Epoch [4/4], Step [1326/3844], Loss: 0.0607\n",
      "Epoch [4/4], Step [1327/3844], Loss: 0.0932\n",
      "Epoch [4/4], Step [1328/3844], Loss: 0.1207\n",
      "Epoch [4/4], Step [1329/3844], Loss: 0.1424\n",
      "Epoch [4/4], Step [1330/3844], Loss: 0.0618\n",
      "Epoch [4/4], Step [1331/3844], Loss: 0.1124\n",
      "Epoch [4/4], Step [1332/3844], Loss: 0.1667\n",
      "Epoch [4/4], Step [1333/3844], Loss: 0.1670\n",
      "Epoch [4/4], Step [1334/3844], Loss: 0.0793\n",
      "Epoch [4/4], Step [1335/3844], Loss: 0.1501\n",
      "Epoch [4/4], Step [1336/3844], Loss: 0.0661\n",
      "Epoch [4/4], Step [1337/3844], Loss: 0.0969\n",
      "Epoch [4/4], Step [1338/3844], Loss: 0.0751\n",
      "Epoch [4/4], Step [1339/3844], Loss: 0.1029\n",
      "Epoch [4/4], Step [1340/3844], Loss: 0.0887\n",
      "Epoch [4/4], Step [1341/3844], Loss: 0.0657\n",
      "Epoch [4/4], Step [1342/3844], Loss: 0.0707\n",
      "Epoch [4/4], Step [1343/3844], Loss: 0.1689\n",
      "Epoch [4/4], Step [1344/3844], Loss: 0.1389\n",
      "Epoch [4/4], Step [1345/3844], Loss: 0.0763\n",
      "Epoch [4/4], Step [1346/3844], Loss: 0.0655\n",
      "Epoch [4/4], Step [1347/3844], Loss: 0.1012\n",
      "Epoch [4/4], Step [1348/3844], Loss: 0.1156\n",
      "Epoch [4/4], Step [1349/3844], Loss: 0.1426\n",
      "Epoch [4/4], Step [1350/3844], Loss: 0.1226\n",
      "Epoch [4/4], Step [1351/3844], Loss: 0.0703\n",
      "Epoch [4/4], Step [1352/3844], Loss: 0.0950\n",
      "Epoch [4/4], Step [1353/3844], Loss: 0.1325\n",
      "Epoch [4/4], Step [1354/3844], Loss: 0.0866\n",
      "Epoch [4/4], Step [1355/3844], Loss: 0.0847\n",
      "Epoch [4/4], Step [1356/3844], Loss: 0.0424\n",
      "Epoch [4/4], Step [1357/3844], Loss: 0.1306\n",
      "Epoch [4/4], Step [1358/3844], Loss: 0.0741\n",
      "Epoch [4/4], Step [1359/3844], Loss: 0.1079\n",
      "Epoch [4/4], Step [1360/3844], Loss: 0.1444\n",
      "Epoch [4/4], Step [1361/3844], Loss: 0.0642\n",
      "Epoch [4/4], Step [1362/3844], Loss: 0.0727\n",
      "Epoch [4/4], Step [1363/3844], Loss: 0.0829\n",
      "Epoch [4/4], Step [1364/3844], Loss: 0.1525\n",
      "Epoch [4/4], Step [1365/3844], Loss: 0.0952\n",
      "Epoch [4/4], Step [1366/3844], Loss: 0.1170\n",
      "Epoch [4/4], Step [1367/3844], Loss: 0.0581\n",
      "Epoch [4/4], Step [1368/3844], Loss: 0.0779\n",
      "Epoch [4/4], Step [1369/3844], Loss: 0.1159\n",
      "Epoch [4/4], Step [1370/3844], Loss: 0.0819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/4], Step [1371/3844], Loss: 0.1512\n",
      "Epoch [4/4], Step [1372/3844], Loss: 0.1129\n",
      "Epoch [4/4], Step [1373/3844], Loss: 0.0907\n",
      "Epoch [4/4], Step [1374/3844], Loss: 0.1630\n",
      "Epoch [4/4], Step [1375/3844], Loss: 0.1445\n",
      "Epoch [4/4], Step [1376/3844], Loss: 0.0906\n",
      "Epoch [4/4], Step [1377/3844], Loss: 0.0282\n",
      "Epoch [4/4], Step [1378/3844], Loss: 0.1081\n",
      "Epoch [4/4], Step [1379/3844], Loss: 0.0812\n",
      "Epoch [4/4], Step [1380/3844], Loss: 0.0511\n",
      "Epoch [4/4], Step [1381/3844], Loss: 0.0849\n",
      "Epoch [4/4], Step [1382/3844], Loss: 0.1254\n",
      "Epoch [4/4], Step [1383/3844], Loss: 0.1482\n",
      "Epoch [4/4], Step [1384/3844], Loss: 0.0791\n",
      "Epoch [4/4], Step [1385/3844], Loss: 0.0724\n",
      "Epoch [4/4], Step [1386/3844], Loss: 0.0664\n",
      "Epoch [4/4], Step [1387/3844], Loss: 0.1035\n",
      "Epoch [4/4], Step [1388/3844], Loss: 0.0878\n",
      "Epoch [4/4], Step [1389/3844], Loss: 0.0973\n",
      "Epoch [4/4], Step [1390/3844], Loss: 0.0996\n",
      "Epoch [4/4], Step [1391/3844], Loss: 0.0732\n",
      "Epoch [4/4], Step [1392/3844], Loss: 0.0862\n",
      "Epoch [4/4], Step [1393/3844], Loss: 0.0743\n",
      "Epoch [4/4], Step [1394/3844], Loss: 0.0883\n",
      "Epoch [4/4], Step [1395/3844], Loss: 0.1353\n",
      "Epoch [4/4], Step [1396/3844], Loss: 0.0991\n",
      "Epoch [4/4], Step [1397/3844], Loss: 0.1834\n",
      "Epoch [4/4], Step [1398/3844], Loss: 0.1215\n",
      "Epoch [4/4], Step [1399/3844], Loss: 0.1422\n",
      "Epoch [4/4], Step [1400/3844], Loss: 0.0776\n",
      "Epoch [4/4], Step [1401/3844], Loss: 0.0967\n",
      "Epoch [4/4], Step [1402/3844], Loss: 0.0675\n",
      "Epoch [4/4], Step [1403/3844], Loss: 0.1288\n",
      "Epoch [4/4], Step [1404/3844], Loss: 0.1200\n",
      "Epoch [4/4], Step [1405/3844], Loss: 0.0696\n",
      "Epoch [4/4], Step [1406/3844], Loss: 0.0750\n",
      "Epoch [4/4], Step [1407/3844], Loss: 0.0624\n",
      "Epoch [4/4], Step [1408/3844], Loss: 0.0879\n",
      "Epoch [4/4], Step [1409/3844], Loss: 0.1818\n",
      "Epoch [4/4], Step [1410/3844], Loss: 0.0644\n",
      "Epoch [4/4], Step [1411/3844], Loss: 0.1212\n",
      "Epoch [4/4], Step [1412/3844], Loss: 0.0656\n",
      "Epoch [4/4], Step [1413/3844], Loss: 0.1586\n",
      "Epoch [4/4], Step [1414/3844], Loss: 0.1059\n",
      "Epoch [4/4], Step [1415/3844], Loss: 0.1097\n",
      "Epoch [4/4], Step [1416/3844], Loss: 0.1377\n",
      "Epoch [4/4], Step [1417/3844], Loss: 0.1514\n",
      "Epoch [4/4], Step [1418/3844], Loss: 0.0853\n",
      "Epoch [4/4], Step [1419/3844], Loss: 0.1386\n",
      "Epoch [4/4], Step [1420/3844], Loss: 0.0631\n",
      "Epoch [4/4], Step [1421/3844], Loss: 0.1405\n",
      "Epoch [4/4], Step [1422/3844], Loss: 0.0556\n",
      "Epoch [4/4], Step [1423/3844], Loss: 0.1318\n",
      "Epoch [4/4], Step [1424/3844], Loss: 0.0812\n",
      "Epoch [4/4], Step [1425/3844], Loss: 0.1493\n",
      "Epoch [4/4], Step [1426/3844], Loss: 0.1379\n",
      "Epoch [4/4], Step [1427/3844], Loss: 0.1057\n",
      "Epoch [4/4], Step [1428/3844], Loss: 0.0479\n",
      "Epoch [4/4], Step [1429/3844], Loss: 0.1558\n",
      "Epoch [4/4], Step [1430/3844], Loss: 0.0573\n",
      "Epoch [4/4], Step [1431/3844], Loss: 0.1197\n",
      "Epoch [4/4], Step [1432/3844], Loss: 0.1103\n",
      "Epoch [4/4], Step [1433/3844], Loss: 0.1502\n",
      "Epoch [4/4], Step [1434/3844], Loss: 0.1330\n",
      "Epoch [4/4], Step [1435/3844], Loss: 0.0920\n",
      "Epoch [4/4], Step [1436/3844], Loss: 0.1240\n",
      "Epoch [4/4], Step [1437/3844], Loss: 0.0815\n",
      "Epoch [4/4], Step [1438/3844], Loss: 0.1046\n",
      "Epoch [4/4], Step [1439/3844], Loss: 0.0609\n",
      "Epoch [4/4], Step [1440/3844], Loss: 0.0948\n",
      "Epoch [4/4], Step [1441/3844], Loss: 0.0714\n",
      "Epoch [4/4], Step [1442/3844], Loss: 0.1241\n",
      "Epoch [4/4], Step [1443/3844], Loss: 0.0691\n",
      "Epoch [4/4], Step [1444/3844], Loss: 0.0961\n",
      "Epoch [4/4], Step [1445/3844], Loss: 0.0649\n",
      "Epoch [4/4], Step [1446/3844], Loss: 0.1055\n",
      "Epoch [4/4], Step [1447/3844], Loss: 0.0784\n",
      "Epoch [4/4], Step [1448/3844], Loss: 0.1158\n",
      "Epoch [4/4], Step [1449/3844], Loss: 0.0688\n",
      "Epoch [4/4], Step [1450/3844], Loss: 0.0916\n",
      "Epoch [4/4], Step [1451/3844], Loss: 0.0917\n",
      "Epoch [4/4], Step [1452/3844], Loss: 0.0884\n",
      "Epoch [4/4], Step [1453/3844], Loss: 0.1601\n",
      "Epoch [4/4], Step [1454/3844], Loss: 0.1362\n",
      "Epoch [4/4], Step [1455/3844], Loss: 0.1021\n",
      "Epoch [4/4], Step [1456/3844], Loss: 0.0906\n",
      "Epoch [4/4], Step [1457/3844], Loss: 0.1166\n",
      "Epoch [4/4], Step [1458/3844], Loss: 0.1334\n",
      "Epoch [4/4], Step [1459/3844], Loss: 0.1030\n",
      "Epoch [4/4], Step [1460/3844], Loss: 0.0814\n",
      "Epoch [4/4], Step [1461/3844], Loss: 0.0710\n",
      "Epoch [4/4], Step [1462/3844], Loss: 0.1103\n",
      "Epoch [4/4], Step [1463/3844], Loss: 0.0568\n",
      "Epoch [4/4], Step [1464/3844], Loss: 0.1319\n",
      "Epoch [4/4], Step [1465/3844], Loss: 0.0808\n",
      "Epoch [4/4], Step [1466/3844], Loss: 0.0790\n",
      "Epoch [4/4], Step [1467/3844], Loss: 0.1211\n",
      "Epoch [4/4], Step [1468/3844], Loss: 0.0546\n",
      "Epoch [4/4], Step [1469/3844], Loss: 0.0870\n",
      "Epoch [4/4], Step [1470/3844], Loss: 0.1484\n",
      "Epoch [4/4], Step [1471/3844], Loss: 0.0599\n",
      "Epoch [4/4], Step [1472/3844], Loss: 0.0562\n",
      "Epoch [4/4], Step [1473/3844], Loss: 0.0647\n",
      "Epoch [4/4], Step [1474/3844], Loss: 0.0683\n",
      "Epoch [4/4], Step [1475/3844], Loss: 0.1054\n",
      "Epoch [4/4], Step [1476/3844], Loss: 0.1515\n",
      "Epoch [4/4], Step [1477/3844], Loss: 0.0640\n",
      "Epoch [4/4], Step [1478/3844], Loss: 0.1648\n",
      "Epoch [4/4], Step [1479/3844], Loss: 0.1174\n",
      "Epoch [4/4], Step [1480/3844], Loss: 0.1151\n",
      "Epoch [4/4], Step [1481/3844], Loss: 0.1405\n",
      "Epoch [4/4], Step [1482/3844], Loss: 0.1591\n",
      "Epoch [4/4], Step [1483/3844], Loss: 0.1379\n",
      "Epoch [4/4], Step [1484/3844], Loss: 0.0896\n",
      "Epoch [4/4], Step [1485/3844], Loss: 0.1365\n",
      "Epoch [4/4], Step [1486/3844], Loss: 0.0706\n",
      "Epoch [4/4], Step [1487/3844], Loss: 0.1266\n",
      "Epoch [4/4], Step [1488/3844], Loss: 0.1637\n",
      "Epoch [4/4], Step [1489/3844], Loss: 0.0664\n",
      "Epoch [4/4], Step [1490/3844], Loss: 0.1417\n",
      "Epoch [4/4], Step [1491/3844], Loss: 0.0605\n",
      "Epoch [4/4], Step [1492/3844], Loss: 0.1469\n",
      "Epoch [4/4], Step [1493/3844], Loss: 0.0821\n",
      "Epoch [4/4], Step [1494/3844], Loss: 0.0915\n",
      "Epoch [4/4], Step [1495/3844], Loss: 0.1059\n",
      "Epoch [4/4], Step [1496/3844], Loss: 0.1147\n",
      "Epoch [4/4], Step [1497/3844], Loss: 0.0877\n",
      "Epoch [4/4], Step [1498/3844], Loss: 0.1499\n",
      "Epoch [4/4], Step [1499/3844], Loss: 0.0961\n",
      "Epoch [4/4], Step [1500/3844], Loss: 0.1583\n",
      "Epoch [4/4], Step [1501/3844], Loss: 0.0723\n",
      "Epoch [4/4], Step [1502/3844], Loss: 0.1188\n",
      "Epoch [4/4], Step [1503/3844], Loss: 0.0639\n",
      "Epoch [4/4], Step [1504/3844], Loss: 0.1252\n",
      "Epoch [4/4], Step [1505/3844], Loss: 0.0628\n",
      "Epoch [4/4], Step [1506/3844], Loss: 0.1039\n",
      "Epoch [4/4], Step [1507/3844], Loss: 0.0540\n",
      "Epoch [4/4], Step [1508/3844], Loss: 0.1210\n",
      "Epoch [4/4], Step [1509/3844], Loss: 0.0441\n",
      "Epoch [4/4], Step [1510/3844], Loss: 0.0545\n",
      "Epoch [4/4], Step [1511/3844], Loss: 0.0744\n",
      "Epoch [4/4], Step [1512/3844], Loss: 0.0594\n",
      "Epoch [4/4], Step [1513/3844], Loss: 0.1064\n",
      "Epoch [4/4], Step [1514/3844], Loss: 0.0913\n",
      "Epoch [4/4], Step [1515/3844], Loss: 0.0757\n",
      "Epoch [4/4], Step [1516/3844], Loss: 0.0742\n",
      "Epoch [4/4], Step [1517/3844], Loss: 0.0781\n",
      "Epoch [4/4], Step [1518/3844], Loss: 0.1808\n",
      "Epoch [4/4], Step [1519/3844], Loss: 0.0935\n",
      "Epoch [4/4], Step [1520/3844], Loss: 0.0816\n",
      "Epoch [4/4], Step [1521/3844], Loss: 0.1438\n",
      "Epoch [4/4], Step [1522/3844], Loss: 0.1194\n",
      "Epoch [4/4], Step [1523/3844], Loss: 0.1106\n",
      "Epoch [4/4], Step [1524/3844], Loss: 0.0661\n",
      "Epoch [4/4], Step [1525/3844], Loss: 0.0841\n",
      "Epoch [4/4], Step [1526/3844], Loss: 0.1127\n",
      "Epoch [4/4], Step [1527/3844], Loss: 0.1046\n",
      "Epoch [4/4], Step [1528/3844], Loss: 0.1271\n",
      "Epoch [4/4], Step [1529/3844], Loss: 0.0478\n",
      "Epoch [4/4], Step [1530/3844], Loss: 0.1597\n",
      "Epoch [4/4], Step [1531/3844], Loss: 0.0916\n",
      "Epoch [4/4], Step [1532/3844], Loss: 0.0660\n",
      "Epoch [4/4], Step [1533/3844], Loss: 0.0491\n",
      "Epoch [4/4], Step [1534/3844], Loss: 0.0668\n",
      "Epoch [4/4], Step [1535/3844], Loss: 0.1359\n",
      "Epoch [4/4], Step [1536/3844], Loss: 0.0460\n",
      "Epoch [4/4], Step [1537/3844], Loss: 0.1216\n",
      "Epoch [4/4], Step [1538/3844], Loss: 0.1654\n",
      "Epoch [4/4], Step [1539/3844], Loss: 0.1167\n",
      "Epoch [4/4], Step [1540/3844], Loss: 0.0690\n",
      "Epoch [4/4], Step [1541/3844], Loss: 0.1029\n",
      "Epoch [4/4], Step [1542/3844], Loss: 0.0713\n",
      "Epoch [4/4], Step [1543/3844], Loss: 0.0838\n",
      "Epoch [4/4], Step [1544/3844], Loss: 0.1585\n",
      "Epoch [4/4], Step [1545/3844], Loss: 0.0517\n",
      "Epoch [4/4], Step [1546/3844], Loss: 0.1413\n",
      "Epoch [4/4], Step [1547/3844], Loss: 0.0980\n",
      "Epoch [4/4], Step [1548/3844], Loss: 0.1240\n",
      "Epoch [4/4], Step [1549/3844], Loss: 0.0730\n",
      "Epoch [4/4], Step [1550/3844], Loss: 0.0701\n",
      "Epoch [4/4], Step [1551/3844], Loss: 0.0768\n",
      "Epoch [4/4], Step [1552/3844], Loss: 0.1051\n",
      "Epoch [4/4], Step [1553/3844], Loss: 0.1011\n",
      "Epoch [4/4], Step [1554/3844], Loss: 0.0881\n",
      "Epoch [4/4], Step [1555/3844], Loss: 0.0530\n",
      "Epoch [4/4], Step [1556/3844], Loss: 0.0532\n",
      "Epoch [4/4], Step [1557/3844], Loss: 0.1755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/4], Step [1558/3844], Loss: 0.1433\n",
      "Epoch [4/4], Step [1559/3844], Loss: 0.0865\n",
      "Epoch [4/4], Step [1560/3844], Loss: 0.0765\n",
      "Epoch [4/4], Step [1561/3844], Loss: 0.0723\n",
      "Epoch [4/4], Step [1562/3844], Loss: 0.1379\n",
      "Epoch [4/4], Step [1563/3844], Loss: 0.0674\n",
      "Epoch [4/4], Step [1564/3844], Loss: 0.1756\n",
      "Epoch [4/4], Step [1565/3844], Loss: 0.0414\n",
      "Epoch [4/4], Step [1566/3844], Loss: 0.0910\n",
      "Epoch [4/4], Step [1567/3844], Loss: 0.0640\n",
      "Epoch [4/4], Step [1568/3844], Loss: 0.0594\n",
      "Epoch [4/4], Step [1569/3844], Loss: 0.0698\n",
      "Epoch [4/4], Step [1570/3844], Loss: 0.0704\n",
      "Epoch [4/4], Step [1571/3844], Loss: 0.1216\n",
      "Epoch [4/4], Step [1572/3844], Loss: 0.1116\n",
      "Epoch [4/4], Step [1573/3844], Loss: 0.0404\n",
      "Epoch [4/4], Step [1574/3844], Loss: 0.1567\n",
      "Epoch [4/4], Step [1575/3844], Loss: 0.1173\n",
      "Epoch [4/4], Step [1576/3844], Loss: 0.0775\n",
      "Epoch [4/4], Step [1577/3844], Loss: 0.1308\n",
      "Epoch [4/4], Step [1578/3844], Loss: 0.0963\n",
      "Epoch [4/4], Step [1579/3844], Loss: 0.1309\n",
      "Epoch [4/4], Step [1580/3844], Loss: 0.1536\n",
      "Epoch [4/4], Step [1581/3844], Loss: 0.0813\n",
      "Epoch [4/4], Step [1582/3844], Loss: 0.1046\n",
      "Epoch [4/4], Step [1583/3844], Loss: 0.1388\n",
      "Epoch [4/4], Step [1584/3844], Loss: 0.0746\n",
      "Epoch [4/4], Step [1585/3844], Loss: 0.1534\n",
      "Epoch [4/4], Step [1586/3844], Loss: 0.0782\n",
      "Epoch [4/4], Step [1587/3844], Loss: 0.1650\n",
      "Epoch [4/4], Step [1588/3844], Loss: 0.1383\n",
      "Epoch [4/4], Step [1589/3844], Loss: 0.0866\n",
      "Epoch [4/4], Step [1590/3844], Loss: 0.0654\n",
      "Epoch [4/4], Step [1591/3844], Loss: 0.1337\n",
      "Epoch [4/4], Step [1592/3844], Loss: 0.0767\n",
      "Epoch [4/4], Step [1593/3844], Loss: 0.1255\n",
      "Epoch [4/4], Step [1594/3844], Loss: 0.1148\n",
      "Epoch [4/4], Step [1595/3844], Loss: 0.1516\n",
      "Epoch [4/4], Step [1596/3844], Loss: 0.0460\n",
      "Epoch [4/4], Step [1597/3844], Loss: 0.1446\n",
      "Epoch [4/4], Step [1598/3844], Loss: 0.0765\n",
      "Epoch [4/4], Step [1599/3844], Loss: 0.1704\n",
      "Epoch [4/4], Step [1600/3844], Loss: 0.1468\n",
      "Epoch [4/4], Step [1601/3844], Loss: 0.0955\n",
      "Epoch [4/4], Step [1602/3844], Loss: 0.0717\n",
      "Epoch [4/4], Step [1603/3844], Loss: 0.1291\n",
      "Epoch [4/4], Step [1604/3844], Loss: 0.1023\n",
      "Epoch [4/4], Step [1605/3844], Loss: 0.0694\n",
      "Epoch [4/4], Step [1606/3844], Loss: 0.0712\n",
      "Epoch [4/4], Step [1607/3844], Loss: 0.1353\n",
      "Epoch [4/4], Step [1608/3844], Loss: 0.1291\n",
      "Epoch [4/4], Step [1609/3844], Loss: 0.0990\n",
      "Epoch [4/4], Step [1610/3844], Loss: 0.1019\n",
      "Epoch [4/4], Step [1611/3844], Loss: 0.1712\n",
      "Epoch [4/4], Step [1612/3844], Loss: 0.1136\n",
      "Epoch [4/4], Step [1613/3844], Loss: 0.0491\n",
      "Epoch [4/4], Step [1614/3844], Loss: 0.0754\n",
      "Epoch [4/4], Step [1615/3844], Loss: 0.0743\n",
      "Epoch [4/4], Step [1616/3844], Loss: 0.0735\n",
      "Epoch [4/4], Step [1617/3844], Loss: 0.1003\n",
      "Epoch [4/4], Step [1618/3844], Loss: 0.1344\n",
      "Epoch [4/4], Step [1619/3844], Loss: 0.0831\n",
      "Epoch [4/4], Step [1620/3844], Loss: 0.1052\n",
      "Epoch [4/4], Step [1621/3844], Loss: 0.1273\n",
      "Epoch [4/4], Step [1622/3844], Loss: 0.1173\n",
      "Epoch [4/4], Step [1623/3844], Loss: 0.1624\n",
      "Epoch [4/4], Step [1624/3844], Loss: 0.0702\n",
      "Epoch [4/4], Step [1625/3844], Loss: 0.0713\n",
      "Epoch [4/4], Step [1626/3844], Loss: 0.0666\n",
      "Epoch [4/4], Step [1627/3844], Loss: 0.1516\n",
      "Epoch [4/4], Step [1628/3844], Loss: 0.1003\n",
      "Epoch [4/4], Step [1629/3844], Loss: 0.1084\n",
      "Epoch [4/4], Step [1630/3844], Loss: 0.0643\n",
      "Epoch [4/4], Step [1631/3844], Loss: 0.0860\n",
      "Epoch [4/4], Step [1632/3844], Loss: 0.1573\n",
      "Epoch [4/4], Step [1633/3844], Loss: 0.0581\n",
      "Epoch [4/4], Step [1634/3844], Loss: 0.0942\n",
      "Epoch [4/4], Step [1635/3844], Loss: 0.1093\n",
      "Epoch [4/4], Step [1636/3844], Loss: 0.1553\n",
      "Epoch [4/4], Step [1637/3844], Loss: 0.0834\n",
      "Epoch [4/4], Step [1638/3844], Loss: 0.0801\n",
      "Epoch [4/4], Step [1639/3844], Loss: 0.0725\n",
      "Epoch [4/4], Step [1640/3844], Loss: 0.0789\n",
      "Epoch [4/4], Step [1641/3844], Loss: 0.1042\n",
      "Epoch [4/4], Step [1642/3844], Loss: 0.0895\n",
      "Epoch [4/4], Step [1643/3844], Loss: 0.1256\n",
      "Epoch [4/4], Step [1644/3844], Loss: 0.1540\n",
      "Epoch [4/4], Step [1645/3844], Loss: 0.0672\n",
      "Epoch [4/4], Step [1646/3844], Loss: 0.1009\n",
      "Epoch [4/4], Step [1647/3844], Loss: 0.0809\n",
      "Epoch [4/4], Step [1648/3844], Loss: 0.0896\n",
      "Epoch [4/4], Step [1649/3844], Loss: 0.0803\n",
      "Epoch [4/4], Step [1650/3844], Loss: 0.1035\n",
      "Epoch [4/4], Step [1651/3844], Loss: 0.0836\n",
      "Epoch [4/4], Step [1652/3844], Loss: 0.0961\n",
      "Epoch [4/4], Step [1653/3844], Loss: 0.0784\n",
      "Epoch [4/4], Step [1654/3844], Loss: 0.0747\n",
      "Epoch [4/4], Step [1655/3844], Loss: 0.1104\n",
      "Epoch [4/4], Step [1656/3844], Loss: 0.0665\n",
      "Epoch [4/4], Step [1657/3844], Loss: 0.1048\n",
      "Epoch [4/4], Step [1658/3844], Loss: 0.0567\n",
      "Epoch [4/4], Step [1659/3844], Loss: 0.1172\n",
      "Epoch [4/4], Step [1660/3844], Loss: 0.0751\n",
      "Epoch [4/4], Step [1661/3844], Loss: 0.1444\n",
      "Epoch [4/4], Step [1662/3844], Loss: 0.0938\n",
      "Epoch [4/4], Step [1663/3844], Loss: 0.0804\n",
      "Epoch [4/4], Step [1664/3844], Loss: 0.0808\n",
      "Epoch [4/4], Step [1665/3844], Loss: 0.1759\n",
      "Epoch [4/4], Step [1666/3844], Loss: 0.0537\n",
      "Epoch [4/4], Step [1667/3844], Loss: 0.1463\n",
      "Epoch [4/4], Step [1668/3844], Loss: 0.1773\n",
      "Epoch [4/4], Step [1669/3844], Loss: 0.0866\n",
      "Epoch [4/4], Step [1670/3844], Loss: 0.1213\n",
      "Epoch [4/4], Step [1671/3844], Loss: 0.0834\n",
      "Epoch [4/4], Step [1672/3844], Loss: 0.0764\n",
      "Epoch [4/4], Step [1673/3844], Loss: 0.0530\n",
      "Epoch [4/4], Step [1674/3844], Loss: 0.0408\n",
      "Epoch [4/4], Step [1675/3844], Loss: 0.0630\n",
      "Epoch [4/4], Step [1676/3844], Loss: 0.1085\n",
      "Epoch [4/4], Step [1677/3844], Loss: 0.0441\n",
      "Epoch [4/4], Step [1678/3844], Loss: 0.0686\n",
      "Epoch [4/4], Step [1679/3844], Loss: 0.1600\n",
      "Epoch [4/4], Step [1680/3844], Loss: 0.0994\n",
      "Epoch [4/4], Step [1681/3844], Loss: 0.0716\n",
      "Epoch [4/4], Step [1682/3844], Loss: 0.0515\n",
      "Epoch [4/4], Step [1683/3844], Loss: 0.1639\n",
      "Epoch [4/4], Step [1684/3844], Loss: 0.0886\n",
      "Epoch [4/4], Step [1685/3844], Loss: 0.1181\n",
      "Epoch [4/4], Step [1686/3844], Loss: 0.0751\n",
      "Epoch [4/4], Step [1687/3844], Loss: 0.1522\n",
      "Epoch [4/4], Step [1688/3844], Loss: 0.0803\n",
      "Epoch [4/4], Step [1689/3844], Loss: 0.0451\n",
      "Epoch [4/4], Step [1690/3844], Loss: 0.0632\n",
      "Epoch [4/4], Step [1691/3844], Loss: 0.1235\n",
      "Epoch [4/4], Step [1692/3844], Loss: 0.1755\n",
      "Epoch [4/4], Step [1693/3844], Loss: 0.1328\n",
      "Epoch [4/4], Step [1694/3844], Loss: 0.1115\n",
      "Epoch [4/4], Step [1695/3844], Loss: 0.0749\n",
      "Epoch [4/4], Step [1696/3844], Loss: 0.1719\n",
      "Epoch [4/4], Step [1697/3844], Loss: 0.0883\n",
      "Epoch [4/4], Step [1698/3844], Loss: 0.1050\n",
      "Epoch [4/4], Step [1699/3844], Loss: 0.1072\n",
      "Epoch [4/4], Step [1700/3844], Loss: 0.1171\n",
      "Epoch [4/4], Step [1701/3844], Loss: 0.0944\n",
      "Epoch [4/4], Step [1702/3844], Loss: 0.0960\n",
      "Epoch [4/4], Step [1703/3844], Loss: 0.1186\n",
      "Epoch [4/4], Step [1704/3844], Loss: 0.1305\n",
      "Epoch [4/4], Step [1705/3844], Loss: 0.0870\n",
      "Epoch [4/4], Step [1706/3844], Loss: 0.0948\n",
      "Epoch [4/4], Step [1707/3844], Loss: 0.1058\n",
      "Epoch [4/4], Step [1708/3844], Loss: 0.1298\n",
      "Epoch [4/4], Step [1709/3844], Loss: 0.1024\n",
      "Epoch [4/4], Step [1710/3844], Loss: 0.1393\n",
      "Epoch [4/4], Step [1711/3844], Loss: 0.0984\n",
      "Epoch [4/4], Step [1712/3844], Loss: 0.0665\n",
      "Epoch [4/4], Step [1713/3844], Loss: 0.0703\n",
      "Epoch [4/4], Step [1714/3844], Loss: 0.0748\n",
      "Epoch [4/4], Step [1715/3844], Loss: 0.0782\n",
      "Epoch [4/4], Step [1716/3844], Loss: 0.0757\n",
      "Epoch [4/4], Step [1717/3844], Loss: 0.1678\n",
      "Epoch [4/4], Step [1718/3844], Loss: 0.1291\n",
      "Epoch [4/4], Step [1719/3844], Loss: 0.0916\n",
      "Epoch [4/4], Step [1720/3844], Loss: 0.0732\n",
      "Epoch [4/4], Step [1721/3844], Loss: 0.0883\n",
      "Epoch [4/4], Step [1722/3844], Loss: 0.1158\n",
      "Epoch [4/4], Step [1723/3844], Loss: 0.0823\n",
      "Epoch [4/4], Step [1724/3844], Loss: 0.1568\n",
      "Epoch [4/4], Step [1725/3844], Loss: 0.1533\n",
      "Epoch [4/4], Step [1726/3844], Loss: 0.1031\n",
      "Epoch [4/4], Step [1727/3844], Loss: 0.0738\n",
      "Epoch [4/4], Step [1728/3844], Loss: 0.1020\n",
      "Epoch [4/4], Step [1729/3844], Loss: 0.1471\n",
      "Epoch [4/4], Step [1730/3844], Loss: 0.1201\n",
      "Epoch [4/4], Step [1731/3844], Loss: 0.0918\n",
      "Epoch [4/4], Step [1732/3844], Loss: 0.1143\n",
      "Epoch [4/4], Step [1733/3844], Loss: 0.0870\n",
      "Epoch [4/4], Step [1734/3844], Loss: 0.0873\n",
      "Epoch [4/4], Step [1735/3844], Loss: 0.0706\n",
      "Epoch [4/4], Step [1736/3844], Loss: 0.1042\n",
      "Epoch [4/4], Step [1737/3844], Loss: 0.1617\n",
      "Epoch [4/4], Step [1738/3844], Loss: 0.0753\n",
      "Epoch [4/4], Step [1739/3844], Loss: 0.1052\n",
      "Epoch [4/4], Step [1740/3844], Loss: 0.0635\n",
      "Epoch [4/4], Step [1741/3844], Loss: 0.1385\n",
      "Epoch [4/4], Step [1742/3844], Loss: 0.1311\n",
      "Epoch [4/4], Step [1743/3844], Loss: 0.0406\n",
      "Epoch [4/4], Step [1744/3844], Loss: 0.0836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/4], Step [1745/3844], Loss: 0.0541\n",
      "Epoch [4/4], Step [1746/3844], Loss: 0.1303\n",
      "Epoch [4/4], Step [1747/3844], Loss: 0.0722\n",
      "Epoch [4/4], Step [1748/3844], Loss: 0.0886\n",
      "Epoch [4/4], Step [1749/3844], Loss: 0.0873\n",
      "Epoch [4/4], Step [1750/3844], Loss: 0.1084\n",
      "Epoch [4/4], Step [1751/3844], Loss: 0.0796\n",
      "Epoch [4/4], Step [1752/3844], Loss: 0.0836\n",
      "Epoch [4/4], Step [1753/3844], Loss: 0.0543\n",
      "Epoch [4/4], Step [1754/3844], Loss: 0.1499\n",
      "Epoch [4/4], Step [1755/3844], Loss: 0.0476\n",
      "Epoch [4/4], Step [1756/3844], Loss: 0.0454\n",
      "Epoch [4/4], Step [1757/3844], Loss: 0.1163\n",
      "Epoch [4/4], Step [1758/3844], Loss: 0.1613\n",
      "Epoch [4/4], Step [1759/3844], Loss: 0.1132\n",
      "Epoch [4/4], Step [1760/3844], Loss: 0.0664\n",
      "Epoch [4/4], Step [1761/3844], Loss: 0.1149\n",
      "Epoch [4/4], Step [1762/3844], Loss: 0.0737\n",
      "Epoch [4/4], Step [1763/3844], Loss: 0.0755\n",
      "Epoch [4/4], Step [1764/3844], Loss: 0.0738\n",
      "Epoch [4/4], Step [1765/3844], Loss: 0.1132\n",
      "Epoch [4/4], Step [1766/3844], Loss: 0.1326\n",
      "Epoch [4/4], Step [1767/3844], Loss: 0.0755\n",
      "Epoch [4/4], Step [1768/3844], Loss: 0.1351\n",
      "Epoch [4/4], Step [1769/3844], Loss: 0.0789\n",
      "Epoch [4/4], Step [1770/3844], Loss: 0.1645\n",
      "Epoch [4/4], Step [1771/3844], Loss: 0.1228\n",
      "Epoch [4/4], Step [1772/3844], Loss: 0.0764\n",
      "Epoch [4/4], Step [1773/3844], Loss: 0.1458\n",
      "Epoch [4/4], Step [1774/3844], Loss: 0.0687\n",
      "Epoch [4/4], Step [1775/3844], Loss: 0.0866\n",
      "Epoch [4/4], Step [1776/3844], Loss: 0.1016\n",
      "Epoch [4/4], Step [1777/3844], Loss: 0.0491\n",
      "Epoch [4/4], Step [1778/3844], Loss: 0.1118\n",
      "Epoch [4/4], Step [1779/3844], Loss: 0.0929\n",
      "Epoch [4/4], Step [1780/3844], Loss: 0.1162\n",
      "Epoch [4/4], Step [1781/3844], Loss: 0.1283\n",
      "Epoch [4/4], Step [1782/3844], Loss: 0.0861\n",
      "Epoch [4/4], Step [1783/3844], Loss: 0.0679\n",
      "Epoch [4/4], Step [1784/3844], Loss: 0.0998\n",
      "Epoch [4/4], Step [1785/3844], Loss: 0.1236\n",
      "Epoch [4/4], Step [1786/3844], Loss: 0.0631\n",
      "Epoch [4/4], Step [1787/3844], Loss: 0.0352\n",
      "Epoch [4/4], Step [1788/3844], Loss: 0.0906\n",
      "Epoch [4/4], Step [1789/3844], Loss: 0.0520\n",
      "Epoch [4/4], Step [1790/3844], Loss: 0.1527\n",
      "Epoch [4/4], Step [1791/3844], Loss: 0.1742\n",
      "Epoch [4/4], Step [1792/3844], Loss: 0.0843\n",
      "Epoch [4/4], Step [1793/3844], Loss: 0.1601\n",
      "Epoch [4/4], Step [1794/3844], Loss: 0.1563\n",
      "Epoch [4/4], Step [1795/3844], Loss: 0.1458\n",
      "Epoch [4/4], Step [1796/3844], Loss: 0.1423\n",
      "Epoch [4/4], Step [1797/3844], Loss: 0.1510\n",
      "Epoch [4/4], Step [1798/3844], Loss: 0.0533\n",
      "Epoch [4/4], Step [1799/3844], Loss: 0.1014\n",
      "Epoch [4/4], Step [1800/3844], Loss: 0.1071\n",
      "Epoch [4/4], Step [1801/3844], Loss: 0.0647\n",
      "Epoch [4/4], Step [1802/3844], Loss: 0.1253\n",
      "Epoch [4/4], Step [1803/3844], Loss: 0.1128\n",
      "Epoch [4/4], Step [1804/3844], Loss: 0.0706\n",
      "Epoch [4/4], Step [1805/3844], Loss: 0.0792\n",
      "Epoch [4/4], Step [1806/3844], Loss: 0.0935\n",
      "Epoch [4/4], Step [1807/3844], Loss: 0.0628\n",
      "Epoch [4/4], Step [1808/3844], Loss: 0.1656\n",
      "Epoch [4/4], Step [1809/3844], Loss: 0.1530\n",
      "Epoch [4/4], Step [1810/3844], Loss: 0.1581\n",
      "Epoch [4/4], Step [1811/3844], Loss: 0.1159\n",
      "Epoch [4/4], Step [1812/3844], Loss: 0.1645\n",
      "Epoch [4/4], Step [1813/3844], Loss: 0.1128\n",
      "Epoch [4/4], Step [1814/3844], Loss: 0.0792\n",
      "Epoch [4/4], Step [1815/3844], Loss: 0.0768\n",
      "Epoch [4/4], Step [1816/3844], Loss: 0.1333\n",
      "Epoch [4/4], Step [1817/3844], Loss: 0.1091\n",
      "Epoch [4/4], Step [1818/3844], Loss: 0.0757\n",
      "Epoch [4/4], Step [1819/3844], Loss: 0.0918\n",
      "Epoch [4/4], Step [1820/3844], Loss: 0.0947\n",
      "Epoch [4/4], Step [1821/3844], Loss: 0.1344\n",
      "Epoch [4/4], Step [1822/3844], Loss: 0.1006\n",
      "Epoch [4/4], Step [1823/3844], Loss: 0.0671\n",
      "Epoch [4/4], Step [1824/3844], Loss: 0.1071\n",
      "Epoch [4/4], Step [1825/3844], Loss: 0.0566\n",
      "Epoch [4/4], Step [1826/3844], Loss: 0.1902\n",
      "Epoch [4/4], Step [1827/3844], Loss: 0.0860\n",
      "Epoch [4/4], Step [1828/3844], Loss: 0.0949\n",
      "Epoch [4/4], Step [1829/3844], Loss: 0.0846\n",
      "Epoch [4/4], Step [1830/3844], Loss: 0.0987\n",
      "Epoch [4/4], Step [1831/3844], Loss: 0.0692\n",
      "Epoch [4/4], Step [1832/3844], Loss: 0.0912\n",
      "Epoch [4/4], Step [1833/3844], Loss: 0.1305\n",
      "Epoch [4/4], Step [1834/3844], Loss: 0.1056\n",
      "Epoch [4/4], Step [1835/3844], Loss: 0.0762\n",
      "Epoch [4/4], Step [1836/3844], Loss: 0.0913\n",
      "Epoch [4/4], Step [1837/3844], Loss: 0.1346\n",
      "Epoch [4/4], Step [1838/3844], Loss: 0.1023\n",
      "Epoch [4/4], Step [1839/3844], Loss: 0.0710\n",
      "Epoch [4/4], Step [1840/3844], Loss: 0.1230\n",
      "Epoch [4/4], Step [1841/3844], Loss: 0.1117\n",
      "Epoch [4/4], Step [1842/3844], Loss: 0.0685\n",
      "Epoch [4/4], Step [1843/3844], Loss: 0.0639\n",
      "Epoch [4/4], Step [1844/3844], Loss: 0.1006\n",
      "Epoch [4/4], Step [1845/3844], Loss: 0.0955\n",
      "Epoch [4/4], Step [1846/3844], Loss: 0.1350\n",
      "Epoch [4/4], Step [1847/3844], Loss: 0.0842\n",
      "Epoch [4/4], Step [1848/3844], Loss: 0.0758\n",
      "Epoch [4/4], Step [1849/3844], Loss: 0.1220\n",
      "Epoch [4/4], Step [1850/3844], Loss: 0.1059\n",
      "Epoch [4/4], Step [1851/3844], Loss: 0.1432\n",
      "Epoch [4/4], Step [1852/3844], Loss: 0.0702\n",
      "Epoch [4/4], Step [1853/3844], Loss: 0.1039\n",
      "Epoch [4/4], Step [1854/3844], Loss: 0.0902\n",
      "Epoch [4/4], Step [1855/3844], Loss: 0.0631\n",
      "Epoch [4/4], Step [1856/3844], Loss: 0.0730\n",
      "Epoch [4/4], Step [1857/3844], Loss: 0.1302\n",
      "Epoch [4/4], Step [1858/3844], Loss: 0.0632\n",
      "Epoch [4/4], Step [1859/3844], Loss: 0.0905\n",
      "Epoch [4/4], Step [1860/3844], Loss: 0.0741\n",
      "Epoch [4/4], Step [1861/3844], Loss: 0.0728\n",
      "Epoch [4/4], Step [1862/3844], Loss: 0.1032\n",
      "Epoch [4/4], Step [1863/3844], Loss: 0.0627\n",
      "Epoch [4/4], Step [1864/3844], Loss: 0.0620\n",
      "Epoch [4/4], Step [1865/3844], Loss: 0.1157\n",
      "Epoch [4/4], Step [1866/3844], Loss: 0.1971\n",
      "Epoch [4/4], Step [1867/3844], Loss: 0.1402\n",
      "Epoch [4/4], Step [1868/3844], Loss: 0.0991\n",
      "Epoch [4/4], Step [1869/3844], Loss: 0.1208\n",
      "Epoch [4/4], Step [1870/3844], Loss: 0.1089\n",
      "Epoch [4/4], Step [1871/3844], Loss: 0.0760\n",
      "Epoch [4/4], Step [1872/3844], Loss: 0.1084\n",
      "Epoch [4/4], Step [1873/3844], Loss: 0.1069\n",
      "Epoch [4/4], Step [1874/3844], Loss: 0.1811\n",
      "Epoch [4/4], Step [1875/3844], Loss: 0.1276\n",
      "Epoch [4/4], Step [1876/3844], Loss: 0.1703\n",
      "Epoch [4/4], Step [1877/3844], Loss: 0.1243\n",
      "Epoch [4/4], Step [1878/3844], Loss: 0.0984\n",
      "Epoch [4/4], Step [1879/3844], Loss: 0.0749\n",
      "Epoch [4/4], Step [1880/3844], Loss: 0.1195\n",
      "Epoch [4/4], Step [1881/3844], Loss: 0.0800\n",
      "Epoch [4/4], Step [1882/3844], Loss: 0.0728\n",
      "Epoch [4/4], Step [1883/3844], Loss: 0.0713\n",
      "Epoch [4/4], Step [1884/3844], Loss: 0.0591\n",
      "Epoch [4/4], Step [1885/3844], Loss: 0.1517\n",
      "Epoch [4/4], Step [1886/3844], Loss: 0.1572\n",
      "Epoch [4/4], Step [1887/3844], Loss: 0.0803\n",
      "Epoch [4/4], Step [1888/3844], Loss: 0.0915\n",
      "Epoch [4/4], Step [1889/3844], Loss: 0.0966\n",
      "Epoch [4/4], Step [1890/3844], Loss: 0.1039\n",
      "Epoch [4/4], Step [1891/3844], Loss: 0.0710\n",
      "Epoch [4/4], Step [1892/3844], Loss: 0.0766\n",
      "Epoch [4/4], Step [1893/3844], Loss: 0.0825\n",
      "Epoch [4/4], Step [1894/3844], Loss: 0.1050\n",
      "Epoch [4/4], Step [1895/3844], Loss: 0.0777\n",
      "Epoch [4/4], Step [1896/3844], Loss: 0.1164\n",
      "Epoch [4/4], Step [1897/3844], Loss: 0.1280\n",
      "Epoch [4/4], Step [1898/3844], Loss: 0.1253\n",
      "Epoch [4/4], Step [1899/3844], Loss: 0.0768\n",
      "Epoch [4/4], Step [1900/3844], Loss: 0.1097\n",
      "Epoch [4/4], Step [1901/3844], Loss: 0.1382\n",
      "Epoch [4/4], Step [1902/3844], Loss: 0.0813\n",
      "Epoch [4/4], Step [1903/3844], Loss: 0.0511\n",
      "Epoch [4/4], Step [1904/3844], Loss: 0.1016\n",
      "Epoch [4/4], Step [1905/3844], Loss: 0.1017\n",
      "Epoch [4/4], Step [1906/3844], Loss: 0.0545\n",
      "Epoch [4/4], Step [1907/3844], Loss: 0.1326\n",
      "Epoch [4/4], Step [1908/3844], Loss: 0.0751\n",
      "Epoch [4/4], Step [1909/3844], Loss: 0.1454\n",
      "Epoch [4/4], Step [1910/3844], Loss: 0.0857\n",
      "Epoch [4/4], Step [1911/3844], Loss: 0.0442\n",
      "Epoch [4/4], Step [1912/3844], Loss: 0.0813\n",
      "Epoch [4/4], Step [1913/3844], Loss: 0.1222\n",
      "Epoch [4/4], Step [1914/3844], Loss: 0.0719\n",
      "Epoch [4/4], Step [1915/3844], Loss: 0.0959\n",
      "Epoch [4/4], Step [1916/3844], Loss: 0.1135\n",
      "Epoch [4/4], Step [1917/3844], Loss: 0.0895\n",
      "Epoch [4/4], Step [1918/3844], Loss: 0.0805\n",
      "Epoch [4/4], Step [1919/3844], Loss: 0.0804\n",
      "Epoch [4/4], Step [1920/3844], Loss: 0.1791\n",
      "Epoch [4/4], Step [1921/3844], Loss: 0.0836\n",
      "Epoch [4/4], Step [1922/3844], Loss: 0.1052\n",
      "Epoch [4/4], Step [1923/3844], Loss: 0.0582\n",
      "Epoch [4/4], Step [1924/3844], Loss: 0.0668\n",
      "Epoch [4/4], Step [1925/3844], Loss: 0.1190\n",
      "Epoch [4/4], Step [1926/3844], Loss: 0.0768\n",
      "Epoch [4/4], Step [1927/3844], Loss: 0.0751\n",
      "Epoch [4/4], Step [1928/3844], Loss: 0.0654\n",
      "Epoch [4/4], Step [1929/3844], Loss: 0.1379\n",
      "Epoch [4/4], Step [1930/3844], Loss: 0.0854\n",
      "Epoch [4/4], Step [1931/3844], Loss: 0.1501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/4], Step [1932/3844], Loss: 0.1129\n",
      "Epoch [4/4], Step [1933/3844], Loss: 0.0904\n",
      "Epoch [4/4], Step [1934/3844], Loss: 0.0734\n",
      "Epoch [4/4], Step [1935/3844], Loss: 0.0934\n",
      "Epoch [4/4], Step [1936/3844], Loss: 0.1090\n",
      "Epoch [4/4], Step [1937/3844], Loss: 0.1063\n",
      "Epoch [4/4], Step [1938/3844], Loss: 0.1547\n",
      "Epoch [4/4], Step [1939/3844], Loss: 0.0812\n",
      "Epoch [4/4], Step [1940/3844], Loss: 0.0499\n",
      "Epoch [4/4], Step [1941/3844], Loss: 0.0584\n",
      "Epoch [4/4], Step [1942/3844], Loss: 0.0746\n",
      "Epoch [4/4], Step [1943/3844], Loss: 0.0858\n",
      "Epoch [4/4], Step [1944/3844], Loss: 0.0929\n",
      "Epoch [4/4], Step [1945/3844], Loss: 0.0788\n",
      "Epoch [4/4], Step [1946/3844], Loss: 0.0605\n",
      "Epoch [4/4], Step [1947/3844], Loss: 0.0921\n",
      "Epoch [4/4], Step [1948/3844], Loss: 0.0327\n",
      "Epoch [4/4], Step [1949/3844], Loss: 0.1355\n",
      "Epoch [4/4], Step [1950/3844], Loss: 0.0743\n",
      "Epoch [4/4], Step [1951/3844], Loss: 0.1059\n",
      "Epoch [4/4], Step [1952/3844], Loss: 0.0522\n",
      "Epoch [4/4], Step [1953/3844], Loss: 0.0461\n",
      "Epoch [4/4], Step [1954/3844], Loss: 0.0567\n",
      "Epoch [4/4], Step [1955/3844], Loss: 0.0930\n",
      "Epoch [4/4], Step [1956/3844], Loss: 0.1311\n",
      "Epoch [4/4], Step [1957/3844], Loss: 0.1196\n",
      "Epoch [4/4], Step [1958/3844], Loss: 0.0795\n",
      "Epoch [4/4], Step [1959/3844], Loss: 0.0671\n",
      "Epoch [4/4], Step [1960/3844], Loss: 0.1343\n",
      "Epoch [4/4], Step [1961/3844], Loss: 0.0876\n",
      "Epoch [4/4], Step [1962/3844], Loss: 0.1678\n",
      "Epoch [4/4], Step [1963/3844], Loss: 0.0960\n",
      "Epoch [4/4], Step [1964/3844], Loss: 0.1790\n",
      "Epoch [4/4], Step [1965/3844], Loss: 0.0695\n",
      "Epoch [4/4], Step [1966/3844], Loss: 0.0897\n",
      "Epoch [4/4], Step [1967/3844], Loss: 0.0490\n",
      "Epoch [4/4], Step [1968/3844], Loss: 0.1171\n",
      "Epoch [4/4], Step [1969/3844], Loss: 0.1247\n",
      "Epoch [4/4], Step [1970/3844], Loss: 0.0735\n",
      "Epoch [4/4], Step [1971/3844], Loss: 0.0740\n",
      "Epoch [4/4], Step [1972/3844], Loss: 0.1294\n",
      "Epoch [4/4], Step [1973/3844], Loss: 0.1344\n",
      "Epoch [4/4], Step [1974/3844], Loss: 0.1545\n",
      "Epoch [4/4], Step [1975/3844], Loss: 0.0665\n",
      "Epoch [4/4], Step [1976/3844], Loss: 0.1246\n",
      "Epoch [4/4], Step [1977/3844], Loss: 0.1655\n",
      "Epoch [4/4], Step [1978/3844], Loss: 0.0822\n",
      "Epoch [4/4], Step [1979/3844], Loss: 0.0828\n",
      "Epoch [4/4], Step [1980/3844], Loss: 0.1668\n",
      "Epoch [4/4], Step [1981/3844], Loss: 0.1410\n",
      "Epoch [4/4], Step [1982/3844], Loss: 0.0800\n",
      "Epoch [4/4], Step [1983/3844], Loss: 0.1094\n",
      "Epoch [4/4], Step [1984/3844], Loss: 0.1485\n",
      "Epoch [4/4], Step [1985/3844], Loss: 0.0949\n",
      "Epoch [4/4], Step [1986/3844], Loss: 0.0688\n",
      "Epoch [4/4], Step [1987/3844], Loss: 0.1449\n",
      "Epoch [4/4], Step [1988/3844], Loss: 0.1303\n",
      "Epoch [4/4], Step [1989/3844], Loss: 0.0736\n",
      "Epoch [4/4], Step [1990/3844], Loss: 0.0945\n",
      "Epoch [4/4], Step [1991/3844], Loss: 0.1183\n",
      "Epoch [4/4], Step [1992/3844], Loss: 0.0669\n",
      "Epoch [4/4], Step [1993/3844], Loss: 0.0792\n",
      "Epoch [4/4], Step [1994/3844], Loss: 0.1291\n",
      "Epoch [4/4], Step [1995/3844], Loss: 0.0556\n",
      "Epoch [4/4], Step [1996/3844], Loss: 0.0608\n",
      "Epoch [4/4], Step [1997/3844], Loss: 0.0659\n",
      "Epoch [4/4], Step [1998/3844], Loss: 0.1104\n",
      "Epoch [4/4], Step [1999/3844], Loss: 0.0828\n",
      "Epoch [4/4], Step [2000/3844], Loss: 0.0900\n",
      "Epoch [4/4], Step [2001/3844], Loss: 0.1167\n",
      "Epoch [4/4], Step [2002/3844], Loss: 0.0804\n",
      "Epoch [4/4], Step [2003/3844], Loss: 0.1591\n",
      "Epoch [4/4], Step [2004/3844], Loss: 0.0793\n",
      "Epoch [4/4], Step [2005/3844], Loss: 0.1089\n",
      "Epoch [4/4], Step [2006/3844], Loss: 0.1506\n",
      "Epoch [4/4], Step [2007/3844], Loss: 0.1490\n",
      "Epoch [4/4], Step [2008/3844], Loss: 0.0676\n",
      "Epoch [4/4], Step [2009/3844], Loss: 0.1384\n",
      "Epoch [4/4], Step [2010/3844], Loss: 0.0854\n",
      "Epoch [4/4], Step [2011/3844], Loss: 0.0664\n",
      "Epoch [4/4], Step [2012/3844], Loss: 0.0605\n",
      "Epoch [4/4], Step [2013/3844], Loss: 0.1250\n",
      "Epoch [4/4], Step [2014/3844], Loss: 0.1641\n",
      "Epoch [4/4], Step [2015/3844], Loss: 0.1536\n",
      "Epoch [4/4], Step [2016/3844], Loss: 0.1189\n",
      "Epoch [4/4], Step [2017/3844], Loss: 0.0885\n",
      "Epoch [4/4], Step [2018/3844], Loss: 0.1461\n",
      "Epoch [4/4], Step [2019/3844], Loss: 0.0704\n",
      "Epoch [4/4], Step [2020/3844], Loss: 0.0821\n",
      "Epoch [4/4], Step [2021/3844], Loss: 0.1036\n",
      "Epoch [4/4], Step [2022/3844], Loss: 0.0822\n",
      "Epoch [4/4], Step [2023/3844], Loss: 0.1423\n",
      "Epoch [4/4], Step [2024/3844], Loss: 0.0570\n",
      "Epoch [4/4], Step [2025/3844], Loss: 0.1103\n",
      "Epoch [4/4], Step [2026/3844], Loss: 0.1057\n",
      "Epoch [4/4], Step [2027/3844], Loss: 0.1367\n",
      "Epoch [4/4], Step [2028/3844], Loss: 0.0657\n",
      "Epoch [4/4], Step [2029/3844], Loss: 0.1007\n",
      "Epoch [4/4], Step [2030/3844], Loss: 0.0676\n",
      "Epoch [4/4], Step [2031/3844], Loss: 0.0922\n",
      "Epoch [4/4], Step [2032/3844], Loss: 0.1336\n",
      "Epoch [4/4], Step [2033/3844], Loss: 0.0877\n",
      "Epoch [4/4], Step [2034/3844], Loss: 0.0875\n",
      "Epoch [4/4], Step [2035/3844], Loss: 0.0750\n",
      "Epoch [4/4], Step [2036/3844], Loss: 0.1006\n",
      "Epoch [4/4], Step [2037/3844], Loss: 0.0849\n",
      "Epoch [4/4], Step [2038/3844], Loss: 0.0779\n",
      "Epoch [4/4], Step [2039/3844], Loss: 0.0934\n",
      "Epoch [4/4], Step [2040/3844], Loss: 0.0770\n",
      "Epoch [4/4], Step [2041/3844], Loss: 0.1037\n",
      "Epoch [4/4], Step [2042/3844], Loss: 0.1221\n",
      "Epoch [4/4], Step [2043/3844], Loss: 0.0913\n",
      "Epoch [4/4], Step [2044/3844], Loss: 0.1115\n",
      "Epoch [4/4], Step [2045/3844], Loss: 0.1676\n",
      "Epoch [4/4], Step [2046/3844], Loss: 0.1672\n",
      "Epoch [4/4], Step [2047/3844], Loss: 0.0616\n",
      "Epoch [4/4], Step [2048/3844], Loss: 0.1486\n",
      "Epoch [4/4], Step [2049/3844], Loss: 0.1504\n",
      "Epoch [4/4], Step [2050/3844], Loss: 0.0732\n",
      "Epoch [4/4], Step [2051/3844], Loss: 0.0770\n",
      "Epoch [4/4], Step [2052/3844], Loss: 0.0435\n",
      "Epoch [4/4], Step [2053/3844], Loss: 0.0675\n",
      "Epoch [4/4], Step [2054/3844], Loss: 0.0553\n",
      "Epoch [4/4], Step [2055/3844], Loss: 0.1684\n",
      "Epoch [4/4], Step [2056/3844], Loss: 0.0930\n",
      "Epoch [4/4], Step [2057/3844], Loss: 0.0590\n",
      "Epoch [4/4], Step [2058/3844], Loss: 0.1020\n",
      "Epoch [4/4], Step [2059/3844], Loss: 0.1704\n",
      "Epoch [4/4], Step [2060/3844], Loss: 0.0483\n",
      "Epoch [4/4], Step [2061/3844], Loss: 0.0845\n",
      "Epoch [4/4], Step [2062/3844], Loss: 0.0979\n",
      "Epoch [4/4], Step [2063/3844], Loss: 0.1160\n",
      "Epoch [4/4], Step [2064/3844], Loss: 0.0881\n",
      "Epoch [4/4], Step [2065/3844], Loss: 0.1404\n",
      "Epoch [4/4], Step [2066/3844], Loss: 0.1091\n",
      "Epoch [4/4], Step [2067/3844], Loss: 0.0777\n",
      "Epoch [4/4], Step [2068/3844], Loss: 0.1287\n",
      "Epoch [4/4], Step [2069/3844], Loss: 0.0610\n",
      "Epoch [4/4], Step [2070/3844], Loss: 0.0860\n",
      "Epoch [4/4], Step [2071/3844], Loss: 0.1203\n",
      "Epoch [4/4], Step [2072/3844], Loss: 0.1208\n",
      "Epoch [4/4], Step [2073/3844], Loss: 0.1583\n",
      "Epoch [4/4], Step [2074/3844], Loss: 0.1035\n",
      "Epoch [4/4], Step [2075/3844], Loss: 0.0779\n",
      "Epoch [4/4], Step [2076/3844], Loss: 0.0845\n",
      "Epoch [4/4], Step [2077/3844], Loss: 0.0765\n",
      "Epoch [4/4], Step [2078/3844], Loss: 0.0908\n",
      "Epoch [4/4], Step [2079/3844], Loss: 0.0906\n",
      "Epoch [4/4], Step [2080/3844], Loss: 0.0677\n",
      "Epoch [4/4], Step [2081/3844], Loss: 0.0550\n",
      "Epoch [4/4], Step [2082/3844], Loss: 0.0778\n",
      "Epoch [4/4], Step [2083/3844], Loss: 0.1317\n",
      "Epoch [4/4], Step [2084/3844], Loss: 0.0548\n",
      "Epoch [4/4], Step [2085/3844], Loss: 0.1362\n",
      "Epoch [4/4], Step [2086/3844], Loss: 0.0556\n",
      "Epoch [4/4], Step [2087/3844], Loss: 0.0771\n",
      "Epoch [4/4], Step [2088/3844], Loss: 0.1509\n",
      "Epoch [4/4], Step [2089/3844], Loss: 0.0740\n",
      "Epoch [4/4], Step [2090/3844], Loss: 0.0903\n",
      "Epoch [4/4], Step [2091/3844], Loss: 0.1268\n",
      "Epoch [4/4], Step [2092/3844], Loss: 0.1432\n",
      "Epoch [4/4], Step [2093/3844], Loss: 0.0631\n",
      "Epoch [4/4], Step [2094/3844], Loss: 0.1321\n",
      "Epoch [4/4], Step [2095/3844], Loss: 0.1398\n",
      "Epoch [4/4], Step [2096/3844], Loss: 0.1366\n",
      "Epoch [4/4], Step [2097/3844], Loss: 0.0769\n",
      "Epoch [4/4], Step [2098/3844], Loss: 0.0993\n",
      "Epoch [4/4], Step [2099/3844], Loss: 0.0991\n",
      "Epoch [4/4], Step [2100/3844], Loss: 0.1265\n",
      "Epoch [4/4], Step [2101/3844], Loss: 0.1021\n",
      "Epoch [4/4], Step [2102/3844], Loss: 0.0650\n",
      "Epoch [4/4], Step [2103/3844], Loss: 0.0652\n",
      "Epoch [4/4], Step [2104/3844], Loss: 0.0588\n",
      "Epoch [4/4], Step [2105/3844], Loss: 0.1334\n",
      "Epoch [4/4], Step [2106/3844], Loss: 0.0694\n",
      "Epoch [4/4], Step [2107/3844], Loss: 0.0905\n",
      "Epoch [4/4], Step [2108/3844], Loss: 0.1036\n",
      "Epoch [4/4], Step [2109/3844], Loss: 0.0606\n",
      "Epoch [4/4], Step [2110/3844], Loss: 0.0669\n",
      "Epoch [4/4], Step [2111/3844], Loss: 0.0723\n",
      "Epoch [4/4], Step [2112/3844], Loss: 0.0937\n",
      "Epoch [4/4], Step [2113/3844], Loss: 0.0530\n",
      "Epoch [4/4], Step [2114/3844], Loss: 0.1092\n",
      "Epoch [4/4], Step [2115/3844], Loss: 0.1262\n",
      "Epoch [4/4], Step [2116/3844], Loss: 0.1483\n",
      "Epoch [4/4], Step [2117/3844], Loss: 0.1816\n",
      "Epoch [4/4], Step [2118/3844], Loss: 0.1601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/4], Step [2119/3844], Loss: 0.1588\n",
      "Epoch [4/4], Step [2120/3844], Loss: 0.0616\n",
      "Epoch [4/4], Step [2121/3844], Loss: 0.1414\n",
      "Epoch [4/4], Step [2122/3844], Loss: 0.1628\n",
      "Epoch [4/4], Step [2123/3844], Loss: 0.1035\n",
      "Epoch [4/4], Step [2124/3844], Loss: 0.0917\n",
      "Epoch [4/4], Step [2125/3844], Loss: 0.1518\n",
      "Epoch [4/4], Step [2126/3844], Loss: 0.1592\n",
      "Epoch [4/4], Step [2127/3844], Loss: 0.0690\n",
      "Epoch [4/4], Step [2128/3844], Loss: 0.1067\n",
      "Epoch [4/4], Step [2129/3844], Loss: 0.1022\n",
      "Epoch [4/4], Step [2130/3844], Loss: 0.0730\n",
      "Epoch [4/4], Step [2131/3844], Loss: 0.1296\n",
      "Epoch [4/4], Step [2132/3844], Loss: 0.0565\n",
      "Epoch [4/4], Step [2133/3844], Loss: 0.0510\n",
      "Epoch [4/4], Step [2134/3844], Loss: 0.0711\n",
      "Epoch [4/4], Step [2135/3844], Loss: 0.0561\n",
      "Epoch [4/4], Step [2136/3844], Loss: 0.0990\n",
      "Epoch [4/4], Step [2137/3844], Loss: 0.0605\n",
      "Epoch [4/4], Step [2138/3844], Loss: 0.0637\n",
      "Epoch [4/4], Step [2139/3844], Loss: 0.1218\n",
      "Epoch [4/4], Step [2140/3844], Loss: 0.0645\n",
      "Epoch [4/4], Step [2141/3844], Loss: 0.1246\n",
      "Epoch [4/4], Step [2142/3844], Loss: 0.0825\n",
      "Epoch [4/4], Step [2143/3844], Loss: 0.0675\n",
      "Epoch [4/4], Step [2144/3844], Loss: 0.1282\n",
      "Epoch [4/4], Step [2145/3844], Loss: 0.0872\n",
      "Epoch [4/4], Step [2146/3844], Loss: 0.0609\n",
      "Epoch [4/4], Step [2147/3844], Loss: 0.1244\n",
      "Epoch [4/4], Step [2148/3844], Loss: 0.0788\n",
      "Epoch [4/4], Step [2149/3844], Loss: 0.0798\n",
      "Epoch [4/4], Step [2150/3844], Loss: 0.1704\n",
      "Epoch [4/4], Step [2151/3844], Loss: 0.0929\n",
      "Epoch [4/4], Step [2152/3844], Loss: 0.0824\n",
      "Epoch [4/4], Step [2153/3844], Loss: 0.1653\n",
      "Epoch [4/4], Step [2154/3844], Loss: 0.1170\n",
      "Epoch [4/4], Step [2155/3844], Loss: 0.0914\n",
      "Epoch [4/4], Step [2156/3844], Loss: 0.1438\n",
      "Epoch [4/4], Step [2157/3844], Loss: 0.1177\n",
      "Epoch [4/4], Step [2158/3844], Loss: 0.1255\n",
      "Epoch [4/4], Step [2159/3844], Loss: 0.1035\n",
      "Epoch [4/4], Step [2160/3844], Loss: 0.1221\n",
      "Epoch [4/4], Step [2161/3844], Loss: 0.0971\n",
      "Epoch [4/4], Step [2162/3844], Loss: 0.1425\n",
      "Epoch [4/4], Step [2163/3844], Loss: 0.0713\n",
      "Epoch [4/4], Step [2164/3844], Loss: 0.0720\n",
      "Epoch [4/4], Step [2165/3844], Loss: 0.1336\n",
      "Epoch [4/4], Step [2166/3844], Loss: 0.0665\n",
      "Epoch [4/4], Step [2167/3844], Loss: 0.0626\n",
      "Epoch [4/4], Step [2168/3844], Loss: 0.1114\n",
      "Epoch [4/4], Step [2169/3844], Loss: 0.1329\n",
      "Epoch [4/4], Step [2170/3844], Loss: 0.0817\n",
      "Epoch [4/4], Step [2171/3844], Loss: 0.1651\n",
      "Epoch [4/4], Step [2172/3844], Loss: 0.1404\n",
      "Epoch [4/4], Step [2173/3844], Loss: 0.1398\n",
      "Epoch [4/4], Step [2174/3844], Loss: 0.1530\n",
      "Epoch [4/4], Step [2175/3844], Loss: 0.0403\n",
      "Epoch [4/4], Step [2176/3844], Loss: 0.0991\n",
      "Epoch [4/4], Step [2177/3844], Loss: 0.0815\n",
      "Epoch [4/4], Step [2178/3844], Loss: 0.0896\n",
      "Epoch [4/4], Step [2179/3844], Loss: 0.1554\n",
      "Epoch [4/4], Step [2180/3844], Loss: 0.0688\n",
      "Epoch [4/4], Step [2181/3844], Loss: 0.1190\n",
      "Epoch [4/4], Step [2182/3844], Loss: 0.1196\n",
      "Epoch [4/4], Step [2183/3844], Loss: 0.1154\n",
      "Epoch [4/4], Step [2184/3844], Loss: 0.0748\n",
      "Epoch [4/4], Step [2185/3844], Loss: 0.0878\n",
      "Epoch [4/4], Step [2186/3844], Loss: 0.1006\n",
      "Epoch [4/4], Step [2187/3844], Loss: 0.1691\n",
      "Epoch [4/4], Step [2188/3844], Loss: 0.1244\n",
      "Epoch [4/4], Step [2189/3844], Loss: 0.0605\n",
      "Epoch [4/4], Step [2190/3844], Loss: 0.0952\n",
      "Epoch [4/4], Step [2191/3844], Loss: 0.0909\n",
      "Epoch [4/4], Step [2192/3844], Loss: 0.1345\n",
      "Epoch [4/4], Step [2193/3844], Loss: 0.1502\n",
      "Epoch [4/4], Step [2194/3844], Loss: 0.0670\n",
      "Epoch [4/4], Step [2195/3844], Loss: 0.0637\n",
      "Epoch [4/4], Step [2196/3844], Loss: 0.0617\n",
      "Epoch [4/4], Step [2197/3844], Loss: 0.0972\n",
      "Epoch [4/4], Step [2198/3844], Loss: 0.1269\n",
      "Epoch [4/4], Step [2199/3844], Loss: 0.0597\n",
      "Epoch [4/4], Step [2200/3844], Loss: 0.0740\n",
      "Epoch [4/4], Step [2201/3844], Loss: 0.1486\n",
      "Epoch [4/4], Step [2202/3844], Loss: 0.0776\n",
      "Epoch [4/4], Step [2203/3844], Loss: 0.0728\n",
      "Epoch [4/4], Step [2204/3844], Loss: 0.0681\n",
      "Epoch [4/4], Step [2205/3844], Loss: 0.0494\n",
      "Epoch [4/4], Step [2206/3844], Loss: 0.0786\n",
      "Epoch [4/4], Step [2207/3844], Loss: 0.1221\n",
      "Epoch [4/4], Step [2208/3844], Loss: 0.0894\n",
      "Epoch [4/4], Step [2209/3844], Loss: 0.0949\n",
      "Epoch [4/4], Step [2210/3844], Loss: 0.1351\n",
      "Epoch [4/4], Step [2211/3844], Loss: 0.1612\n",
      "Epoch [4/4], Step [2212/3844], Loss: 0.1292\n",
      "Epoch [4/4], Step [2213/3844], Loss: 0.1270\n",
      "Epoch [4/4], Step [2214/3844], Loss: 0.1161\n",
      "Epoch [4/4], Step [2215/3844], Loss: 0.1059\n",
      "Epoch [4/4], Step [2216/3844], Loss: 0.0864\n",
      "Epoch [4/4], Step [2217/3844], Loss: 0.0911\n",
      "Epoch [4/4], Step [2218/3844], Loss: 0.1039\n",
      "Epoch [4/4], Step [2219/3844], Loss: 0.1091\n",
      "Epoch [4/4], Step [2220/3844], Loss: 0.0593\n",
      "Epoch [4/4], Step [2221/3844], Loss: 0.0929\n",
      "Epoch [4/4], Step [2222/3844], Loss: 0.0702\n",
      "Epoch [4/4], Step [2223/3844], Loss: 0.0683\n",
      "Epoch [4/4], Step [2224/3844], Loss: 0.0481\n",
      "Epoch [4/4], Step [2225/3844], Loss: 0.0725\n",
      "Epoch [4/4], Step [2226/3844], Loss: 0.0994\n",
      "Epoch [4/4], Step [2227/3844], Loss: 0.0953\n",
      "Epoch [4/4], Step [2228/3844], Loss: 0.1196\n",
      "Epoch [4/4], Step [2229/3844], Loss: 0.0818\n",
      "Epoch [4/4], Step [2230/3844], Loss: 0.1560\n",
      "Epoch [4/4], Step [2231/3844], Loss: 0.0920\n",
      "Epoch [4/4], Step [2232/3844], Loss: 0.0578\n",
      "Epoch [4/4], Step [2233/3844], Loss: 0.0949\n",
      "Epoch [4/4], Step [2234/3844], Loss: 0.1487\n",
      "Epoch [4/4], Step [2235/3844], Loss: 0.1489\n",
      "Epoch [4/4], Step [2236/3844], Loss: 0.0766\n",
      "Epoch [4/4], Step [2237/3844], Loss: 0.0787\n",
      "Epoch [4/4], Step [2238/3844], Loss: 0.0923\n",
      "Epoch [4/4], Step [2239/3844], Loss: 0.1829\n",
      "Epoch [4/4], Step [2240/3844], Loss: 0.0958\n",
      "Epoch [4/4], Step [2241/3844], Loss: 0.1058\n",
      "Epoch [4/4], Step [2242/3844], Loss: 0.0845\n",
      "Epoch [4/4], Step [2243/3844], Loss: 0.0952\n",
      "Epoch [4/4], Step [2244/3844], Loss: 0.1485\n",
      "Epoch [4/4], Step [2245/3844], Loss: 0.0876\n",
      "Epoch [4/4], Step [2246/3844], Loss: 0.1140\n",
      "Epoch [4/4], Step [2247/3844], Loss: 0.0620\n",
      "Epoch [4/4], Step [2248/3844], Loss: 0.0800\n",
      "Epoch [4/4], Step [2249/3844], Loss: 0.1700\n",
      "Epoch [4/4], Step [2250/3844], Loss: 0.1127\n",
      "Epoch [4/4], Step [2251/3844], Loss: 0.1001\n",
      "Epoch [4/4], Step [2252/3844], Loss: 0.0561\n",
      "Epoch [4/4], Step [2253/3844], Loss: 0.0688\n",
      "Epoch [4/4], Step [2254/3844], Loss: 0.0936\n",
      "Epoch [4/4], Step [2255/3844], Loss: 0.1305\n",
      "Epoch [4/4], Step [2256/3844], Loss: 0.1130\n",
      "Epoch [4/4], Step [2257/3844], Loss: 0.0801\n",
      "Epoch [4/4], Step [2258/3844], Loss: 0.0851\n",
      "Epoch [4/4], Step [2259/3844], Loss: 0.0942\n",
      "Epoch [4/4], Step [2260/3844], Loss: 0.1424\n",
      "Epoch [4/4], Step [2261/3844], Loss: 0.1166\n",
      "Epoch [4/4], Step [2262/3844], Loss: 0.0813\n",
      "Epoch [4/4], Step [2263/3844], Loss: 0.1041\n",
      "Epoch [4/4], Step [2264/3844], Loss: 0.1173\n",
      "Epoch [4/4], Step [2265/3844], Loss: 0.0743\n",
      "Epoch [4/4], Step [2266/3844], Loss: 0.0616\n",
      "Epoch [4/4], Step [2267/3844], Loss: 0.0621\n",
      "Epoch [4/4], Step [2268/3844], Loss: 0.1134\n",
      "Epoch [4/4], Step [2269/3844], Loss: 0.0617\n",
      "Epoch [4/4], Step [2270/3844], Loss: 0.0658\n",
      "Epoch [4/4], Step [2271/3844], Loss: 0.0905\n",
      "Epoch [4/4], Step [2272/3844], Loss: 0.1042\n",
      "Epoch [4/4], Step [2273/3844], Loss: 0.1606\n",
      "Epoch [4/4], Step [2274/3844], Loss: 0.1033\n",
      "Epoch [4/4], Step [2275/3844], Loss: 0.1031\n",
      "Epoch [4/4], Step [2276/3844], Loss: 0.1549\n",
      "Epoch [4/4], Step [2277/3844], Loss: 0.1144\n",
      "Epoch [4/4], Step [2278/3844], Loss: 0.1662\n",
      "Epoch [4/4], Step [2279/3844], Loss: 0.1055\n",
      "Epoch [4/4], Step [2280/3844], Loss: 0.1202\n",
      "Epoch [4/4], Step [2281/3844], Loss: 0.0705\n",
      "Epoch [4/4], Step [2282/3844], Loss: 0.0457\n",
      "Epoch [4/4], Step [2283/3844], Loss: 0.1092\n",
      "Epoch [4/4], Step [2284/3844], Loss: 0.0652\n",
      "Epoch [4/4], Step [2285/3844], Loss: 0.0797\n",
      "Epoch [4/4], Step [2286/3844], Loss: 0.0931\n",
      "Epoch [4/4], Step [2287/3844], Loss: 0.1542\n",
      "Epoch [4/4], Step [2288/3844], Loss: 0.0908\n",
      "Epoch [4/4], Step [2289/3844], Loss: 0.0948\n",
      "Epoch [4/4], Step [2290/3844], Loss: 0.1601\n",
      "Epoch [4/4], Step [2291/3844], Loss: 0.0680\n",
      "Epoch [4/4], Step [2292/3844], Loss: 0.0639\n",
      "Epoch [4/4], Step [2293/3844], Loss: 0.1929\n",
      "Epoch [4/4], Step [2294/3844], Loss: 0.1993\n",
      "Epoch [4/4], Step [2295/3844], Loss: 0.1462\n",
      "Epoch [4/4], Step [2296/3844], Loss: 0.0765\n",
      "Epoch [4/4], Step [2297/3844], Loss: 0.0989\n",
      "Epoch [4/4], Step [2298/3844], Loss: 0.0827\n",
      "Epoch [4/4], Step [2299/3844], Loss: 0.1442\n",
      "Epoch [4/4], Step [2300/3844], Loss: 0.1478\n",
      "Epoch [4/4], Step [2301/3844], Loss: 0.1061\n",
      "Epoch [4/4], Step [2302/3844], Loss: 0.1537\n",
      "Epoch [4/4], Step [2303/3844], Loss: 0.1067\n",
      "Epoch [4/4], Step [2304/3844], Loss: 0.1302\n",
      "Epoch [4/4], Step [2305/3844], Loss: 0.0889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/4], Step [2306/3844], Loss: 0.1223\n",
      "Epoch [4/4], Step [2307/3844], Loss: 0.1221\n",
      "Epoch [4/4], Step [2308/3844], Loss: 0.0648\n",
      "Epoch [4/4], Step [2309/3844], Loss: 0.1243\n",
      "Epoch [4/4], Step [2310/3844], Loss: 0.1291\n",
      "Epoch [4/4], Step [2311/3844], Loss: 0.1211\n",
      "Epoch [4/4], Step [2312/3844], Loss: 0.1052\n",
      "Epoch [4/4], Step [2313/3844], Loss: 0.1235\n",
      "Epoch [4/4], Step [2314/3844], Loss: 0.0757\n",
      "Epoch [4/4], Step [2315/3844], Loss: 0.0871\n",
      "Epoch [4/4], Step [2316/3844], Loss: 0.0625\n",
      "Epoch [4/4], Step [2317/3844], Loss: 0.0611\n",
      "Epoch [4/4], Step [2318/3844], Loss: 0.1070\n",
      "Epoch [4/4], Step [2319/3844], Loss: 0.0877\n",
      "Epoch [4/4], Step [2320/3844], Loss: 0.1031\n",
      "Epoch [4/4], Step [2321/3844], Loss: 0.0595\n",
      "Epoch [4/4], Step [2322/3844], Loss: 0.1434\n",
      "Epoch [4/4], Step [2323/3844], Loss: 0.1187\n",
      "Epoch [4/4], Step [2324/3844], Loss: 0.1265\n",
      "Epoch [4/4], Step [2325/3844], Loss: 0.0680\n",
      "Epoch [4/4], Step [2326/3844], Loss: 0.0560\n",
      "Epoch [4/4], Step [2327/3844], Loss: 0.1424\n",
      "Epoch [4/4], Step [2328/3844], Loss: 0.1109\n",
      "Epoch [4/4], Step [2329/3844], Loss: 0.0902\n",
      "Epoch [4/4], Step [2330/3844], Loss: 0.1227\n",
      "Epoch [4/4], Step [2331/3844], Loss: 0.0730\n",
      "Epoch [4/4], Step [2332/3844], Loss: 0.0870\n",
      "Epoch [4/4], Step [2333/3844], Loss: 0.0652\n",
      "Epoch [4/4], Step [2334/3844], Loss: 0.0751\n",
      "Epoch [4/4], Step [2335/3844], Loss: 0.1657\n",
      "Epoch [4/4], Step [2336/3844], Loss: 0.0646\n",
      "Epoch [4/4], Step [2337/3844], Loss: 0.0904\n",
      "Epoch [4/4], Step [2338/3844], Loss: 0.1246\n",
      "Epoch [4/4], Step [2339/3844], Loss: 0.0789\n",
      "Epoch [4/4], Step [2340/3844], Loss: 0.0954\n",
      "Epoch [4/4], Step [2341/3844], Loss: 0.0512\n",
      "Epoch [4/4], Step [2342/3844], Loss: 0.1098\n",
      "Epoch [4/4], Step [2343/3844], Loss: 0.1190\n",
      "Epoch [4/4], Step [2344/3844], Loss: 0.1092\n",
      "Epoch [4/4], Step [2345/3844], Loss: 0.0653\n",
      "Epoch [4/4], Step [2346/3844], Loss: 0.1658\n",
      "Epoch [4/4], Step [2347/3844], Loss: 0.1329\n",
      "Epoch [4/4], Step [2348/3844], Loss: 0.0716\n",
      "Epoch [4/4], Step [2349/3844], Loss: 0.1542\n",
      "Epoch [4/4], Step [2350/3844], Loss: 0.1137\n",
      "Epoch [4/4], Step [2351/3844], Loss: 0.0898\n",
      "Epoch [4/4], Step [2352/3844], Loss: 0.1385\n",
      "Epoch [4/4], Step [2353/3844], Loss: 0.0733\n",
      "Epoch [4/4], Step [2354/3844], Loss: 0.1130\n",
      "Epoch [4/4], Step [2355/3844], Loss: 0.1058\n",
      "Epoch [4/4], Step [2356/3844], Loss: 0.0626\n",
      "Epoch [4/4], Step [2357/3844], Loss: 0.1595\n",
      "Epoch [4/4], Step [2358/3844], Loss: 0.1005\n",
      "Epoch [4/4], Step [2359/3844], Loss: 0.1082\n",
      "Epoch [4/4], Step [2360/3844], Loss: 0.0777\n",
      "Epoch [4/4], Step [2361/3844], Loss: 0.1311\n",
      "Epoch [4/4], Step [2362/3844], Loss: 0.0716\n",
      "Epoch [4/4], Step [2363/3844], Loss: 0.1363\n",
      "Epoch [4/4], Step [2364/3844], Loss: 0.0987\n",
      "Epoch [4/4], Step [2365/3844], Loss: 0.1027\n",
      "Epoch [4/4], Step [2366/3844], Loss: 0.0649\n",
      "Epoch [4/4], Step [2367/3844], Loss: 0.0968\n",
      "Epoch [4/4], Step [2368/3844], Loss: 0.1422\n",
      "Epoch [4/4], Step [2369/3844], Loss: 0.1755\n",
      "Epoch [4/4], Step [2370/3844], Loss: 0.0698\n",
      "Epoch [4/4], Step [2371/3844], Loss: 0.0744\n",
      "Epoch [4/4], Step [2372/3844], Loss: 0.0915\n",
      "Epoch [4/4], Step [2373/3844], Loss: 0.0893\n",
      "Epoch [4/4], Step [2374/3844], Loss: 0.1021\n",
      "Epoch [4/4], Step [2375/3844], Loss: 0.1371\n",
      "Epoch [4/4], Step [2376/3844], Loss: 0.0546\n",
      "Epoch [4/4], Step [2377/3844], Loss: 0.0855\n",
      "Epoch [4/4], Step [2378/3844], Loss: 0.1001\n",
      "Epoch [4/4], Step [2379/3844], Loss: 0.1401\n",
      "Epoch [4/4], Step [2380/3844], Loss: 0.0736\n",
      "Epoch [4/4], Step [2381/3844], Loss: 0.0491\n",
      "Epoch [4/4], Step [2382/3844], Loss: 0.0668\n",
      "Epoch [4/4], Step [2383/3844], Loss: 0.0889\n",
      "Epoch [4/4], Step [2384/3844], Loss: 0.1057\n",
      "Epoch [4/4], Step [2385/3844], Loss: 0.1286\n",
      "Epoch [4/4], Step [2386/3844], Loss: 0.1172\n",
      "Epoch [4/4], Step [2387/3844], Loss: 0.0585\n",
      "Epoch [4/4], Step [2388/3844], Loss: 0.1137\n",
      "Epoch [4/4], Step [2389/3844], Loss: 0.1168\n",
      "Epoch [4/4], Step [2390/3844], Loss: 0.0602\n",
      "Epoch [4/4], Step [2391/3844], Loss: 0.1220\n",
      "Epoch [4/4], Step [2392/3844], Loss: 0.0750\n",
      "Epoch [4/4], Step [2393/3844], Loss: 0.0971\n",
      "Epoch [4/4], Step [2394/3844], Loss: 0.0725\n",
      "Epoch [4/4], Step [2395/3844], Loss: 0.1057\n",
      "Epoch [4/4], Step [2396/3844], Loss: 0.0889\n",
      "Epoch [4/4], Step [2397/3844], Loss: 0.1554\n",
      "Epoch [4/4], Step [2398/3844], Loss: 0.0928\n",
      "Epoch [4/4], Step [2399/3844], Loss: 0.0805\n",
      "Epoch [4/4], Step [2400/3844], Loss: 0.0731\n",
      "Epoch [4/4], Step [2401/3844], Loss: 0.1411\n",
      "Epoch [4/4], Step [2402/3844], Loss: 0.1643\n",
      "Epoch [4/4], Step [2403/3844], Loss: 0.1519\n",
      "Epoch [4/4], Step [2404/3844], Loss: 0.0625\n",
      "Epoch [4/4], Step [2405/3844], Loss: 0.1458\n",
      "Epoch [4/4], Step [2406/3844], Loss: 0.1327\n",
      "Epoch [4/4], Step [2407/3844], Loss: 0.0722\n",
      "Epoch [4/4], Step [2408/3844], Loss: 0.0685\n",
      "Epoch [4/4], Step [2409/3844], Loss: 0.0814\n",
      "Epoch [4/4], Step [2410/3844], Loss: 0.0636\n",
      "Epoch [4/4], Step [2411/3844], Loss: 0.1339\n",
      "Epoch [4/4], Step [2412/3844], Loss: 0.1616\n",
      "Epoch [4/4], Step [2413/3844], Loss: 0.0595\n",
      "Epoch [4/4], Step [2414/3844], Loss: 0.0669\n",
      "Epoch [4/4], Step [2415/3844], Loss: 0.1150\n",
      "Epoch [4/4], Step [2416/3844], Loss: 0.1560\n",
      "Epoch [4/4], Step [2417/3844], Loss: 0.0672\n",
      "Epoch [4/4], Step [2418/3844], Loss: 0.0587\n",
      "Epoch [4/4], Step [2419/3844], Loss: 0.1207\n",
      "Epoch [4/4], Step [2420/3844], Loss: 0.1042\n",
      "Epoch [4/4], Step [2421/3844], Loss: 0.0919\n",
      "Epoch [4/4], Step [2422/3844], Loss: 0.0702\n",
      "Epoch [4/4], Step [2423/3844], Loss: 0.0581\n",
      "Epoch [4/4], Step [2424/3844], Loss: 0.1280\n",
      "Epoch [4/4], Step [2425/3844], Loss: 0.0929\n",
      "Epoch [4/4], Step [2426/3844], Loss: 0.0732\n",
      "Epoch [4/4], Step [2427/3844], Loss: 0.0571\n",
      "Epoch [4/4], Step [2428/3844], Loss: 0.1007\n",
      "Epoch [4/4], Step [2429/3844], Loss: 0.0700\n",
      "Epoch [4/4], Step [2430/3844], Loss: 0.0950\n",
      "Epoch [4/4], Step [2431/3844], Loss: 0.0660\n",
      "Epoch [4/4], Step [2432/3844], Loss: 0.0546\n",
      "Epoch [4/4], Step [2433/3844], Loss: 0.0790\n",
      "Epoch [4/4], Step [2434/3844], Loss: 0.0939\n",
      "Epoch [4/4], Step [2435/3844], Loss: 0.0868\n",
      "Epoch [4/4], Step [2436/3844], Loss: 0.1197\n",
      "Epoch [4/4], Step [2437/3844], Loss: 0.1049\n",
      "Epoch [4/4], Step [2438/3844], Loss: 0.0878\n",
      "Epoch [4/4], Step [2439/3844], Loss: 0.0647\n",
      "Epoch [4/4], Step [2440/3844], Loss: 0.1100\n",
      "Epoch [4/4], Step [2441/3844], Loss: 0.1505\n",
      "Epoch [4/4], Step [2442/3844], Loss: 0.1660\n",
      "Epoch [4/4], Step [2443/3844], Loss: 0.0587\n",
      "Epoch [4/4], Step [2444/3844], Loss: 0.0524\n",
      "Epoch [4/4], Step [2445/3844], Loss: 0.0911\n",
      "Epoch [4/4], Step [2446/3844], Loss: 0.1390\n",
      "Epoch [4/4], Step [2447/3844], Loss: 0.0716\n",
      "Epoch [4/4], Step [2448/3844], Loss: 0.1323\n",
      "Epoch [4/4], Step [2449/3844], Loss: 0.0529\n",
      "Epoch [4/4], Step [2450/3844], Loss: 0.0733\n",
      "Epoch [4/4], Step [2451/3844], Loss: 0.0588\n",
      "Epoch [4/4], Step [2452/3844], Loss: 0.1133\n",
      "Epoch [4/4], Step [2453/3844], Loss: 0.0870\n",
      "Epoch [4/4], Step [2454/3844], Loss: 0.1512\n",
      "Epoch [4/4], Step [2455/3844], Loss: 0.0665\n",
      "Epoch [4/4], Step [2456/3844], Loss: 0.1613\n",
      "Epoch [4/4], Step [2457/3844], Loss: 0.0284\n",
      "Epoch [4/4], Step [2458/3844], Loss: 0.0363\n",
      "Epoch [4/4], Step [2459/3844], Loss: 0.1710\n",
      "Epoch [4/4], Step [2460/3844], Loss: 0.1474\n",
      "Epoch [4/4], Step [2461/3844], Loss: 0.1204\n",
      "Epoch [4/4], Step [2462/3844], Loss: 0.0407\n",
      "Epoch [4/4], Step [2463/3844], Loss: 0.1189\n",
      "Epoch [4/4], Step [2464/3844], Loss: 0.1536\n",
      "Epoch [4/4], Step [2465/3844], Loss: 0.0573\n",
      "Epoch [4/4], Step [2466/3844], Loss: 0.1413\n",
      "Epoch [4/4], Step [2467/3844], Loss: 0.1490\n",
      "Epoch [4/4], Step [2468/3844], Loss: 0.0619\n",
      "Epoch [4/4], Step [2469/3844], Loss: 0.1322\n",
      "Epoch [4/4], Step [2470/3844], Loss: 0.0828\n",
      "Epoch [4/4], Step [2471/3844], Loss: 0.1691\n",
      "Epoch [4/4], Step [2472/3844], Loss: 0.0837\n",
      "Epoch [4/4], Step [2473/3844], Loss: 0.0974\n",
      "Epoch [4/4], Step [2474/3844], Loss: 0.1631\n",
      "Epoch [4/4], Step [2475/3844], Loss: 0.0570\n",
      "Epoch [4/4], Step [2476/3844], Loss: 0.0882\n",
      "Epoch [4/4], Step [2477/3844], Loss: 0.0716\n",
      "Epoch [4/4], Step [2478/3844], Loss: 0.0622\n",
      "Epoch [4/4], Step [2479/3844], Loss: 0.0777\n",
      "Epoch [4/4], Step [2480/3844], Loss: 0.0789\n",
      "Epoch [4/4], Step [2481/3844], Loss: 0.1186\n",
      "Epoch [4/4], Step [2482/3844], Loss: 0.0848\n",
      "Epoch [4/4], Step [2483/3844], Loss: 0.1063\n",
      "Epoch [4/4], Step [2484/3844], Loss: 0.0851\n",
      "Epoch [4/4], Step [2485/3844], Loss: 0.1226\n",
      "Epoch [4/4], Step [2486/3844], Loss: 0.1228\n",
      "Epoch [4/4], Step [2487/3844], Loss: 0.1375\n",
      "Epoch [4/4], Step [2488/3844], Loss: 0.0945\n",
      "Epoch [4/4], Step [2489/3844], Loss: 0.0916\n",
      "Epoch [4/4], Step [2490/3844], Loss: 0.0783\n",
      "Epoch [4/4], Step [2491/3844], Loss: 0.0681\n",
      "Epoch [4/4], Step [2492/3844], Loss: 0.0923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/4], Step [2493/3844], Loss: 0.1133\n",
      "Epoch [4/4], Step [2494/3844], Loss: 0.0700\n",
      "Epoch [4/4], Step [2495/3844], Loss: 0.0934\n",
      "Epoch [4/4], Step [2496/3844], Loss: 0.1875\n",
      "Epoch [4/4], Step [2497/3844], Loss: 0.0627\n",
      "Epoch [4/4], Step [2498/3844], Loss: 0.0740\n",
      "Epoch [4/4], Step [2499/3844], Loss: 0.0815\n",
      "Epoch [4/4], Step [2500/3844], Loss: 0.0739\n",
      "Epoch [4/4], Step [2501/3844], Loss: 0.0868\n",
      "Epoch [4/4], Step [2502/3844], Loss: 0.0549\n",
      "Epoch [4/4], Step [2503/3844], Loss: 0.1158\n",
      "Epoch [4/4], Step [2504/3844], Loss: 0.0727\n",
      "Epoch [4/4], Step [2505/3844], Loss: 0.0807\n",
      "Epoch [4/4], Step [2506/3844], Loss: 0.0871\n",
      "Epoch [4/4], Step [2507/3844], Loss: 0.0924\n",
      "Epoch [4/4], Step [2508/3844], Loss: 0.0636\n",
      "Epoch [4/4], Step [2509/3844], Loss: 0.1104\n",
      "Epoch [4/4], Step [2510/3844], Loss: 0.0658\n",
      "Epoch [4/4], Step [2511/3844], Loss: 0.0922\n",
      "Epoch [4/4], Step [2512/3844], Loss: 0.0793\n",
      "Epoch [4/4], Step [2513/3844], Loss: 0.0820\n",
      "Epoch [4/4], Step [2514/3844], Loss: 0.1674\n",
      "Epoch [4/4], Step [2515/3844], Loss: 0.0882\n",
      "Epoch [4/4], Step [2516/3844], Loss: 0.0993\n",
      "Epoch [4/4], Step [2517/3844], Loss: 0.1457\n",
      "Epoch [4/4], Step [2518/3844], Loss: 0.1066\n",
      "Epoch [4/4], Step [2519/3844], Loss: 0.0799\n",
      "Epoch [4/4], Step [2520/3844], Loss: 0.0888\n",
      "Epoch [4/4], Step [2521/3844], Loss: 0.1233\n",
      "Epoch [4/4], Step [2522/3844], Loss: 0.0839\n",
      "Epoch [4/4], Step [2523/3844], Loss: 0.0807\n",
      "Epoch [4/4], Step [2524/3844], Loss: 0.1454\n",
      "Epoch [4/4], Step [2525/3844], Loss: 0.0884\n",
      "Epoch [4/4], Step [2526/3844], Loss: 0.1251\n",
      "Epoch [4/4], Step [2527/3844], Loss: 0.0629\n",
      "Epoch [4/4], Step [2528/3844], Loss: 0.1150\n",
      "Epoch [4/4], Step [2529/3844], Loss: 0.1078\n",
      "Epoch [4/4], Step [2530/3844], Loss: 0.0640\n",
      "Epoch [4/4], Step [2531/3844], Loss: 0.1195\n",
      "Epoch [4/4], Step [2532/3844], Loss: 0.0570\n",
      "Epoch [4/4], Step [2533/3844], Loss: 0.0923\n",
      "Epoch [4/4], Step [2534/3844], Loss: 0.1245\n",
      "Epoch [4/4], Step [2535/3844], Loss: 0.1096\n",
      "Epoch [4/4], Step [2536/3844], Loss: 0.1230\n",
      "Epoch [4/4], Step [2537/3844], Loss: 0.0976\n",
      "Epoch [4/4], Step [2538/3844], Loss: 0.0855\n",
      "Epoch [4/4], Step [2539/3844], Loss: 0.0878\n",
      "Epoch [4/4], Step [2540/3844], Loss: 0.1241\n",
      "Epoch [4/4], Step [2541/3844], Loss: 0.1078\n",
      "Epoch [4/4], Step [2542/3844], Loss: 0.1435\n",
      "Epoch [4/4], Step [2543/3844], Loss: 0.0896\n",
      "Epoch [4/4], Step [2544/3844], Loss: 0.1145\n",
      "Epoch [4/4], Step [2545/3844], Loss: 0.1326\n",
      "Epoch [4/4], Step [2546/3844], Loss: 0.0675\n",
      "Epoch [4/4], Step [2547/3844], Loss: 0.0853\n",
      "Epoch [4/4], Step [2548/3844], Loss: 0.0810\n",
      "Epoch [4/4], Step [2549/3844], Loss: 0.0756\n",
      "Epoch [4/4], Step [2550/3844], Loss: 0.1076\n",
      "Epoch [4/4], Step [2551/3844], Loss: 0.0651\n",
      "Epoch [4/4], Step [2552/3844], Loss: 0.0415\n",
      "Epoch [4/4], Step [2553/3844], Loss: 0.0818\n",
      "Epoch [4/4], Step [2554/3844], Loss: 0.0447\n",
      "Epoch [4/4], Step [2555/3844], Loss: 0.0861\n",
      "Epoch [4/4], Step [2556/3844], Loss: 0.1228\n",
      "Epoch [4/4], Step [2557/3844], Loss: 0.0846\n",
      "Epoch [4/4], Step [2558/3844], Loss: 0.1326\n",
      "Epoch [4/4], Step [2559/3844], Loss: 0.0508\n",
      "Epoch [4/4], Step [2560/3844], Loss: 0.1193\n",
      "Epoch [4/4], Step [2561/3844], Loss: 0.1396\n",
      "Epoch [4/4], Step [2562/3844], Loss: 0.0679\n",
      "Epoch [4/4], Step [2563/3844], Loss: 0.0447\n",
      "Epoch [4/4], Step [2564/3844], Loss: 0.1616\n",
      "Epoch [4/4], Step [2565/3844], Loss: 0.0876\n",
      "Epoch [4/4], Step [2566/3844], Loss: 0.0772\n",
      "Epoch [4/4], Step [2567/3844], Loss: 0.0824\n",
      "Epoch [4/4], Step [2568/3844], Loss: 0.1059\n",
      "Epoch [4/4], Step [2569/3844], Loss: 0.1001\n",
      "Epoch [4/4], Step [2570/3844], Loss: 0.0735\n",
      "Epoch [4/4], Step [2571/3844], Loss: 0.0883\n",
      "Epoch [4/4], Step [2572/3844], Loss: 0.0851\n",
      "Epoch [4/4], Step [2573/3844], Loss: 0.0602\n",
      "Epoch [4/4], Step [2574/3844], Loss: 0.0687\n",
      "Epoch [4/4], Step [2575/3844], Loss: 0.0697\n",
      "Epoch [4/4], Step [2576/3844], Loss: 0.1377\n",
      "Epoch [4/4], Step [2577/3844], Loss: 0.0745\n",
      "Epoch [4/4], Step [2578/3844], Loss: 0.1541\n",
      "Epoch [4/4], Step [2579/3844], Loss: 0.0582\n",
      "Epoch [4/4], Step [2580/3844], Loss: 0.0687\n",
      "Epoch [4/4], Step [2581/3844], Loss: 0.1614\n",
      "Epoch [4/4], Step [2582/3844], Loss: 0.1399\n",
      "Epoch [4/4], Step [2583/3844], Loss: 0.1512\n",
      "Epoch [4/4], Step [2584/3844], Loss: 0.1008\n",
      "Epoch [4/4], Step [2585/3844], Loss: 0.1083\n",
      "Epoch [4/4], Step [2586/3844], Loss: 0.0671\n",
      "Epoch [4/4], Step [2587/3844], Loss: 0.1371\n",
      "Epoch [4/4], Step [2588/3844], Loss: 0.0932\n",
      "Epoch [4/4], Step [2589/3844], Loss: 0.1212\n",
      "Epoch [4/4], Step [2590/3844], Loss: 0.1611\n",
      "Epoch [4/4], Step [2591/3844], Loss: 0.1017\n",
      "Epoch [4/4], Step [2592/3844], Loss: 0.1011\n",
      "Epoch [4/4], Step [2593/3844], Loss: 0.0882\n",
      "Epoch [4/4], Step [2594/3844], Loss: 0.0969\n",
      "Epoch [4/4], Step [2595/3844], Loss: 0.1149\n",
      "Epoch [4/4], Step [2596/3844], Loss: 0.1020\n",
      "Epoch [4/4], Step [2597/3844], Loss: 0.1012\n",
      "Epoch [4/4], Step [2598/3844], Loss: 0.1527\n",
      "Epoch [4/4], Step [2599/3844], Loss: 0.1103\n",
      "Epoch [4/4], Step [2600/3844], Loss: 0.0794\n",
      "Epoch [4/4], Step [2601/3844], Loss: 0.1047\n",
      "Epoch [4/4], Step [2602/3844], Loss: 0.0770\n",
      "Epoch [4/4], Step [2603/3844], Loss: 0.0767\n",
      "Epoch [4/4], Step [2604/3844], Loss: 0.0634\n",
      "Epoch [4/4], Step [2605/3844], Loss: 0.0742\n",
      "Epoch [4/4], Step [2606/3844], Loss: 0.0718\n",
      "Epoch [4/4], Step [2607/3844], Loss: 0.0591\n",
      "Epoch [4/4], Step [2608/3844], Loss: 0.1356\n",
      "Epoch [4/4], Step [2609/3844], Loss: 0.1336\n",
      "Epoch [4/4], Step [2610/3844], Loss: 0.0499\n",
      "Epoch [4/4], Step [2611/3844], Loss: 0.1248\n",
      "Epoch [4/4], Step [2612/3844], Loss: 0.0841\n",
      "Epoch [4/4], Step [2613/3844], Loss: 0.0444\n",
      "Epoch [4/4], Step [2614/3844], Loss: 0.1105\n",
      "Epoch [4/4], Step [2615/3844], Loss: 0.1267\n",
      "Epoch [4/4], Step [2616/3844], Loss: 0.1038\n",
      "Epoch [4/4], Step [2617/3844], Loss: 0.0819\n",
      "Epoch [4/4], Step [2618/3844], Loss: 0.1047\n",
      "Epoch [4/4], Step [2619/3844], Loss: 0.0804\n",
      "Epoch [4/4], Step [2620/3844], Loss: 0.1059\n",
      "Epoch [4/4], Step [2621/3844], Loss: 0.1575\n",
      "Epoch [4/4], Step [2622/3844], Loss: 0.0988\n",
      "Epoch [4/4], Step [2623/3844], Loss: 0.0828\n",
      "Epoch [4/4], Step [2624/3844], Loss: 0.0776\n",
      "Epoch [4/4], Step [2625/3844], Loss: 0.0660\n",
      "Epoch [4/4], Step [2626/3844], Loss: 0.0947\n",
      "Epoch [4/4], Step [2627/3844], Loss: 0.0253\n",
      "Epoch [4/4], Step [2628/3844], Loss: 0.1085\n",
      "Epoch [4/4], Step [2629/3844], Loss: 0.1369\n",
      "Epoch [4/4], Step [2630/3844], Loss: 0.1170\n",
      "Epoch [4/4], Step [2631/3844], Loss: 0.0438\n",
      "Epoch [4/4], Step [2632/3844], Loss: 0.1621\n",
      "Epoch [4/4], Step [2633/3844], Loss: 0.0846\n",
      "Epoch [4/4], Step [2634/3844], Loss: 0.0912\n",
      "Epoch [4/4], Step [2635/3844], Loss: 0.0725\n",
      "Epoch [4/4], Step [2636/3844], Loss: 0.0908\n",
      "Epoch [4/4], Step [2637/3844], Loss: 0.1353\n",
      "Epoch [4/4], Step [2638/3844], Loss: 0.1120\n",
      "Epoch [4/4], Step [2639/3844], Loss: 0.1491\n",
      "Epoch [4/4], Step [2640/3844], Loss: 0.1624\n",
      "Epoch [4/4], Step [2641/3844], Loss: 0.1886\n",
      "Epoch [4/4], Step [2642/3844], Loss: 0.0919\n",
      "Epoch [4/4], Step [2643/3844], Loss: 0.0821\n",
      "Epoch [4/4], Step [2644/3844], Loss: 0.1137\n",
      "Epoch [4/4], Step [2645/3844], Loss: 0.1497\n",
      "Epoch [4/4], Step [2646/3844], Loss: 0.0701\n",
      "Epoch [4/4], Step [2647/3844], Loss: 0.0786\n",
      "Epoch [4/4], Step [2648/3844], Loss: 0.1133\n",
      "Epoch [4/4], Step [2649/3844], Loss: 0.1329\n",
      "Epoch [4/4], Step [2650/3844], Loss: 0.1660\n",
      "Epoch [4/4], Step [2651/3844], Loss: 0.0731\n",
      "Epoch [4/4], Step [2652/3844], Loss: 0.1475\n",
      "Epoch [4/4], Step [2653/3844], Loss: 0.1497\n",
      "Epoch [4/4], Step [2654/3844], Loss: 0.0628\n",
      "Epoch [4/4], Step [2655/3844], Loss: 0.0911\n",
      "Epoch [4/4], Step [2656/3844], Loss: 0.1228\n",
      "Epoch [4/4], Step [2657/3844], Loss: 0.0960\n",
      "Epoch [4/4], Step [2658/3844], Loss: 0.1565\n",
      "Epoch [4/4], Step [2659/3844], Loss: 0.1551\n",
      "Epoch [4/4], Step [2660/3844], Loss: 0.0894\n",
      "Epoch [4/4], Step [2661/3844], Loss: 0.1118\n",
      "Epoch [4/4], Step [2662/3844], Loss: 0.1119\n",
      "Epoch [4/4], Step [2663/3844], Loss: 0.0740\n",
      "Epoch [4/4], Step [2664/3844], Loss: 0.1333\n",
      "Epoch [4/4], Step [2665/3844], Loss: 0.1669\n",
      "Epoch [4/4], Step [2666/3844], Loss: 0.0441\n",
      "Epoch [4/4], Step [2667/3844], Loss: 0.1539\n",
      "Epoch [4/4], Step [2668/3844], Loss: 0.0882\n",
      "Epoch [4/4], Step [2669/3844], Loss: 0.0696\n",
      "Epoch [4/4], Step [2670/3844], Loss: 0.1336\n",
      "Epoch [4/4], Step [2671/3844], Loss: 0.1095\n",
      "Epoch [4/4], Step [2672/3844], Loss: 0.1517\n",
      "Epoch [4/4], Step [2673/3844], Loss: 0.1346\n",
      "Epoch [4/4], Step [2674/3844], Loss: 0.1492\n",
      "Epoch [4/4], Step [2675/3844], Loss: 0.0868\n",
      "Epoch [4/4], Step [2676/3844], Loss: 0.0471\n",
      "Epoch [4/4], Step [2677/3844], Loss: 0.0622\n",
      "Epoch [4/4], Step [2678/3844], Loss: 0.1332\n",
      "Epoch [4/4], Step [2679/3844], Loss: 0.0636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/4], Step [2680/3844], Loss: 0.1350\n",
      "Epoch [4/4], Step [2681/3844], Loss: 0.1103\n",
      "Epoch [4/4], Step [2682/3844], Loss: 0.0860\n",
      "Epoch [4/4], Step [2683/3844], Loss: 0.0595\n",
      "Epoch [4/4], Step [2684/3844], Loss: 0.1100\n",
      "Epoch [4/4], Step [2685/3844], Loss: 0.0951\n",
      "Epoch [4/4], Step [2686/3844], Loss: 0.0703\n",
      "Epoch [4/4], Step [2687/3844], Loss: 0.1056\n",
      "Epoch [4/4], Step [2688/3844], Loss: 0.0979\n",
      "Epoch [4/4], Step [2689/3844], Loss: 0.1503\n",
      "Epoch [4/4], Step [2690/3844], Loss: 0.0741\n",
      "Epoch [4/4], Step [2691/3844], Loss: 0.1051\n",
      "Epoch [4/4], Step [2692/3844], Loss: 0.0870\n",
      "Epoch [4/4], Step [2693/3844], Loss: 0.0700\n",
      "Epoch [4/4], Step [2694/3844], Loss: 0.0750\n",
      "Epoch [4/4], Step [2695/3844], Loss: 0.0687\n",
      "Epoch [4/4], Step [2696/3844], Loss: 0.0751\n",
      "Epoch [4/4], Step [2697/3844], Loss: 0.1155\n",
      "Epoch [4/4], Step [2698/3844], Loss: 0.1056\n",
      "Epoch [4/4], Step [2699/3844], Loss: 0.0426\n",
      "Epoch [4/4], Step [2700/3844], Loss: 0.1502\n",
      "Epoch [4/4], Step [2701/3844], Loss: 0.1564\n",
      "Epoch [4/4], Step [2702/3844], Loss: 0.0612\n",
      "Epoch [4/4], Step [2703/3844], Loss: 0.0737\n",
      "Epoch [4/4], Step [2704/3844], Loss: 0.0925\n",
      "Epoch [4/4], Step [2705/3844], Loss: 0.0618\n",
      "Epoch [4/4], Step [2706/3844], Loss: 0.0503\n",
      "Epoch [4/4], Step [2707/3844], Loss: 0.0662\n",
      "Epoch [4/4], Step [2708/3844], Loss: 0.1687\n",
      "Epoch [4/4], Step [2709/3844], Loss: 0.1230\n",
      "Epoch [4/4], Step [2710/3844], Loss: 0.0667\n",
      "Epoch [4/4], Step [2711/3844], Loss: 0.0538\n",
      "Epoch [4/4], Step [2712/3844], Loss: 0.0806\n",
      "Epoch [4/4], Step [2713/3844], Loss: 0.0921\n",
      "Epoch [4/4], Step [2714/3844], Loss: 0.1100\n",
      "Epoch [4/4], Step [2715/3844], Loss: 0.1091\n",
      "Epoch [4/4], Step [2716/3844], Loss: 0.1012\n",
      "Epoch [4/4], Step [2717/3844], Loss: 0.0886\n",
      "Epoch [4/4], Step [2718/3844], Loss: 0.0918\n",
      "Epoch [4/4], Step [2719/3844], Loss: 0.1000\n",
      "Epoch [4/4], Step [2720/3844], Loss: 0.1598\n",
      "Epoch [4/4], Step [2721/3844], Loss: 0.1681\n",
      "Epoch [4/4], Step [2722/3844], Loss: 0.1044\n",
      "Epoch [4/4], Step [2723/3844], Loss: 0.0728\n",
      "Epoch [4/4], Step [2724/3844], Loss: 0.0757\n",
      "Epoch [4/4], Step [2725/3844], Loss: 0.0689\n",
      "Epoch [4/4], Step [2726/3844], Loss: 0.0788\n",
      "Epoch [4/4], Step [2727/3844], Loss: 0.1590\n",
      "Epoch [4/4], Step [2728/3844], Loss: 0.0714\n",
      "Epoch [4/4], Step [2729/3844], Loss: 0.1153\n",
      "Epoch [4/4], Step [2730/3844], Loss: 0.0986\n",
      "Epoch [4/4], Step [2731/3844], Loss: 0.0951\n",
      "Epoch [4/4], Step [2732/3844], Loss: 0.1417\n",
      "Epoch [4/4], Step [2733/3844], Loss: 0.1390\n",
      "Epoch [4/4], Step [2734/3844], Loss: 0.0597\n",
      "Epoch [4/4], Step [2735/3844], Loss: 0.1255\n",
      "Epoch [4/4], Step [2736/3844], Loss: 0.1022\n",
      "Epoch [4/4], Step [2737/3844], Loss: 0.1693\n",
      "Epoch [4/4], Step [2738/3844], Loss: 0.0871\n",
      "Epoch [4/4], Step [2739/3844], Loss: 0.1026\n",
      "Epoch [4/4], Step [2740/3844], Loss: 0.1576\n",
      "Epoch [4/4], Step [2741/3844], Loss: 0.0741\n",
      "Epoch [4/4], Step [2742/3844], Loss: 0.0849\n",
      "Epoch [4/4], Step [2743/3844], Loss: 0.1719\n",
      "Epoch [4/4], Step [2744/3844], Loss: 0.1391\n",
      "Epoch [4/4], Step [2745/3844], Loss: 0.0708\n",
      "Epoch [4/4], Step [2746/3844], Loss: 0.0966\n",
      "Epoch [4/4], Step [2747/3844], Loss: 0.1075\n",
      "Epoch [4/4], Step [2748/3844], Loss: 0.1023\n",
      "Epoch [4/4], Step [2749/3844], Loss: 0.0676\n",
      "Epoch [4/4], Step [2750/3844], Loss: 0.0804\n",
      "Epoch [4/4], Step [2751/3844], Loss: 0.0683\n",
      "Epoch [4/4], Step [2752/3844], Loss: 0.0643\n",
      "Epoch [4/4], Step [2753/3844], Loss: 0.1069\n",
      "Epoch [4/4], Step [2754/3844], Loss: 0.1433\n",
      "Epoch [4/4], Step [2755/3844], Loss: 0.1484\n",
      "Epoch [4/4], Step [2756/3844], Loss: 0.0620\n",
      "Epoch [4/4], Step [2757/3844], Loss: 0.0761\n",
      "Epoch [4/4], Step [2758/3844], Loss: 0.0981\n",
      "Epoch [4/4], Step [2759/3844], Loss: 0.0776\n",
      "Epoch [4/4], Step [2760/3844], Loss: 0.0467\n",
      "Epoch [4/4], Step [2761/3844], Loss: 0.0610\n",
      "Epoch [4/4], Step [2762/3844], Loss: 0.0819\n",
      "Epoch [4/4], Step [2763/3844], Loss: 0.1530\n",
      "Epoch [4/4], Step [2764/3844], Loss: 0.0604\n",
      "Epoch [4/4], Step [2765/3844], Loss: 0.0580\n",
      "Epoch [4/4], Step [2766/3844], Loss: 0.0664\n",
      "Epoch [4/4], Step [2767/3844], Loss: 0.0770\n",
      "Epoch [4/4], Step [2768/3844], Loss: 0.1469\n",
      "Epoch [4/4], Step [2769/3844], Loss: 0.0616\n",
      "Epoch [4/4], Step [2770/3844], Loss: 0.0848\n",
      "Epoch [4/4], Step [2771/3844], Loss: 0.0618\n",
      "Epoch [4/4], Step [2772/3844], Loss: 0.0997\n",
      "Epoch [4/4], Step [2773/3844], Loss: 0.1268\n",
      "Epoch [4/4], Step [2774/3844], Loss: 0.0483\n",
      "Epoch [4/4], Step [2775/3844], Loss: 0.1031\n",
      "Epoch [4/4], Step [2776/3844], Loss: 0.0633\n",
      "Epoch [4/4], Step [2777/3844], Loss: 0.0892\n",
      "Epoch [4/4], Step [2778/3844], Loss: 0.0902\n",
      "Epoch [4/4], Step [2779/3844], Loss: 0.0667\n",
      "Epoch [4/4], Step [2780/3844], Loss: 0.0862\n",
      "Epoch [4/4], Step [2781/3844], Loss: 0.0971\n",
      "Epoch [4/4], Step [2782/3844], Loss: 0.0825\n",
      "Epoch [4/4], Step [2783/3844], Loss: 0.0732\n",
      "Epoch [4/4], Step [2784/3844], Loss: 0.0651\n",
      "Epoch [4/4], Step [2785/3844], Loss: 0.1015\n",
      "Epoch [4/4], Step [2786/3844], Loss: 0.1569\n",
      "Epoch [4/4], Step [2787/3844], Loss: 0.0582\n",
      "Epoch [4/4], Step [2788/3844], Loss: 0.0621\n",
      "Epoch [4/4], Step [2789/3844], Loss: 0.1569\n",
      "Epoch [4/4], Step [2790/3844], Loss: 0.1281\n",
      "Epoch [4/4], Step [2791/3844], Loss: 0.0502\n",
      "Epoch [4/4], Step [2792/3844], Loss: 0.0909\n",
      "Epoch [4/4], Step [2793/3844], Loss: 0.0730\n",
      "Epoch [4/4], Step [2794/3844], Loss: 0.1241\n",
      "Epoch [4/4], Step [2795/3844], Loss: 0.0412\n",
      "Epoch [4/4], Step [2796/3844], Loss: 0.1131\n",
      "Epoch [4/4], Step [2797/3844], Loss: 0.0684\n",
      "Epoch [4/4], Step [2798/3844], Loss: 0.0532\n",
      "Epoch [4/4], Step [2799/3844], Loss: 0.1357\n",
      "Epoch [4/4], Step [2800/3844], Loss: 0.0862\n",
      "Epoch [4/4], Step [2801/3844], Loss: 0.1099\n",
      "Epoch [4/4], Step [2802/3844], Loss: 0.0659\n",
      "Epoch [4/4], Step [2803/3844], Loss: 0.0557\n",
      "Epoch [4/4], Step [2804/3844], Loss: 0.1144\n",
      "Epoch [4/4], Step [2805/3844], Loss: 0.0663\n",
      "Epoch [4/4], Step [2806/3844], Loss: 0.0525\n",
      "Epoch [4/4], Step [2807/3844], Loss: 0.0896\n",
      "Epoch [4/4], Step [2808/3844], Loss: 0.1572\n",
      "Epoch [4/4], Step [2809/3844], Loss: 0.0606\n",
      "Epoch [4/4], Step [2810/3844], Loss: 0.0832\n",
      "Epoch [4/4], Step [2811/3844], Loss: 0.0815\n",
      "Epoch [4/4], Step [2812/3844], Loss: 0.1212\n",
      "Epoch [4/4], Step [2813/3844], Loss: 0.1188\n",
      "Epoch [4/4], Step [2814/3844], Loss: 0.0391\n",
      "Epoch [4/4], Step [2815/3844], Loss: 0.1544\n",
      "Epoch [4/4], Step [2816/3844], Loss: 0.0782\n",
      "Epoch [4/4], Step [2817/3844], Loss: 0.1427\n",
      "Epoch [4/4], Step [2818/3844], Loss: 0.1368\n",
      "Epoch [4/4], Step [2819/3844], Loss: 0.0876\n",
      "Epoch [4/4], Step [2820/3844], Loss: 0.0891\n",
      "Epoch [4/4], Step [2821/3844], Loss: 0.1337\n",
      "Epoch [4/4], Step [2822/3844], Loss: 0.0759\n",
      "Epoch [4/4], Step [2823/3844], Loss: 0.0926\n",
      "Epoch [4/4], Step [2824/3844], Loss: 0.0941\n",
      "Epoch [4/4], Step [2825/3844], Loss: 0.0740\n",
      "Epoch [4/4], Step [2826/3844], Loss: 0.0833\n",
      "Epoch [4/4], Step [2827/3844], Loss: 0.0989\n",
      "Epoch [4/4], Step [2828/3844], Loss: 0.0768\n",
      "Epoch [4/4], Step [2829/3844], Loss: 0.0779\n",
      "Epoch [4/4], Step [2830/3844], Loss: 0.0823\n",
      "Epoch [4/4], Step [2831/3844], Loss: 0.1010\n",
      "Epoch [4/4], Step [2832/3844], Loss: 0.0633\n",
      "Epoch [4/4], Step [2833/3844], Loss: 0.0884\n",
      "Epoch [4/4], Step [2834/3844], Loss: 0.1115\n",
      "Epoch [4/4], Step [2835/3844], Loss: 0.0639\n",
      "Epoch [4/4], Step [2836/3844], Loss: 0.1259\n",
      "Epoch [4/4], Step [2837/3844], Loss: 0.1534\n",
      "Epoch [4/4], Step [2838/3844], Loss: 0.0666\n",
      "Epoch [4/4], Step [2839/3844], Loss: 0.1482\n",
      "Epoch [4/4], Step [2840/3844], Loss: 0.0811\n",
      "Epoch [4/4], Step [2841/3844], Loss: 0.0891\n",
      "Epoch [4/4], Step [2842/3844], Loss: 0.0729\n",
      "Epoch [4/4], Step [2843/3844], Loss: 0.0653\n",
      "Epoch [4/4], Step [2844/3844], Loss: 0.1753\n",
      "Epoch [4/4], Step [2845/3844], Loss: 0.1030\n",
      "Epoch [4/4], Step [2846/3844], Loss: 0.0748\n",
      "Epoch [4/4], Step [2847/3844], Loss: 0.1087\n",
      "Epoch [4/4], Step [2848/3844], Loss: 0.1718\n",
      "Epoch [4/4], Step [2849/3844], Loss: 0.1410\n",
      "Epoch [4/4], Step [2850/3844], Loss: 0.1400\n",
      "Epoch [4/4], Step [2851/3844], Loss: 0.1351\n",
      "Epoch [4/4], Step [2852/3844], Loss: 0.0498\n",
      "Epoch [4/4], Step [2853/3844], Loss: 0.1134\n",
      "Epoch [4/4], Step [2854/3844], Loss: 0.0543\n",
      "Epoch [4/4], Step [2855/3844], Loss: 0.0803\n",
      "Epoch [4/4], Step [2856/3844], Loss: 0.1380\n",
      "Epoch [4/4], Step [2857/3844], Loss: 0.0713\n",
      "Epoch [4/4], Step [2858/3844], Loss: 0.0736\n",
      "Epoch [4/4], Step [2859/3844], Loss: 0.0535\n",
      "Epoch [4/4], Step [2860/3844], Loss: 0.1095\n",
      "Epoch [4/4], Step [2861/3844], Loss: 0.1023\n",
      "Epoch [4/4], Step [2862/3844], Loss: 0.0594\n",
      "Epoch [4/4], Step [2863/3844], Loss: 0.0910\n",
      "Epoch [4/4], Step [2864/3844], Loss: 0.1245\n",
      "Epoch [4/4], Step [2865/3844], Loss: 0.1053\n",
      "Epoch [4/4], Step [2866/3844], Loss: 0.0560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/4], Step [2867/3844], Loss: 0.0771\n",
      "Epoch [4/4], Step [2868/3844], Loss: 0.1065\n",
      "Epoch [4/4], Step [2869/3844], Loss: 0.0803\n",
      "Epoch [4/4], Step [2870/3844], Loss: 0.0709\n",
      "Epoch [4/4], Step [2871/3844], Loss: 0.0553\n",
      "Epoch [4/4], Step [2872/3844], Loss: 0.0785\n",
      "Epoch [4/4], Step [2873/3844], Loss: 0.0444\n",
      "Epoch [4/4], Step [2874/3844], Loss: 0.0948\n",
      "Epoch [4/4], Step [2875/3844], Loss: 0.0985\n",
      "Epoch [4/4], Step [2876/3844], Loss: 0.0713\n",
      "Epoch [4/4], Step [2877/3844], Loss: 0.1495\n",
      "Epoch [4/4], Step [2878/3844], Loss: 0.0584\n",
      "Epoch [4/4], Step [2879/3844], Loss: 0.0969\n",
      "Epoch [4/4], Step [2880/3844], Loss: 0.1112\n",
      "Epoch [4/4], Step [2881/3844], Loss: 0.0582\n",
      "Epoch [4/4], Step [2882/3844], Loss: 0.0529\n",
      "Epoch [4/4], Step [2883/3844], Loss: 0.1277\n",
      "Epoch [4/4], Step [2884/3844], Loss: 0.1490\n",
      "Epoch [4/4], Step [2885/3844], Loss: 0.0992\n",
      "Epoch [4/4], Step [2886/3844], Loss: 0.0600\n",
      "Epoch [4/4], Step [2887/3844], Loss: 0.0835\n",
      "Epoch [4/4], Step [2888/3844], Loss: 0.1337\n",
      "Epoch [4/4], Step [2889/3844], Loss: 0.0729\n",
      "Epoch [4/4], Step [2890/3844], Loss: 0.0560\n",
      "Epoch [4/4], Step [2891/3844], Loss: 0.0852\n",
      "Epoch [4/4], Step [2892/3844], Loss: 0.0650\n",
      "Epoch [4/4], Step [2893/3844], Loss: 0.0818\n",
      "Epoch [4/4], Step [2894/3844], Loss: 0.0641\n",
      "Epoch [4/4], Step [2895/3844], Loss: 0.1317\n",
      "Epoch [4/4], Step [2896/3844], Loss: 0.0568\n",
      "Epoch [4/4], Step [2897/3844], Loss: 0.0951\n",
      "Epoch [4/4], Step [2898/3844], Loss: 0.0896\n",
      "Epoch [4/4], Step [2899/3844], Loss: 0.1066\n",
      "Epoch [4/4], Step [2900/3844], Loss: 0.1405\n",
      "Epoch [4/4], Step [2901/3844], Loss: 0.1286\n",
      "Epoch [4/4], Step [2902/3844], Loss: 0.1587\n",
      "Epoch [4/4], Step [2903/3844], Loss: 0.0854\n",
      "Epoch [4/4], Step [2904/3844], Loss: 0.0688\n",
      "Epoch [4/4], Step [2905/3844], Loss: 0.1605\n",
      "Epoch [4/4], Step [2906/3844], Loss: 0.0721\n",
      "Epoch [4/4], Step [2907/3844], Loss: 0.1496\n",
      "Epoch [4/4], Step [2908/3844], Loss: 0.0637\n",
      "Epoch [4/4], Step [2909/3844], Loss: 0.0565\n",
      "Epoch [4/4], Step [2910/3844], Loss: 0.0638\n",
      "Epoch [4/4], Step [2911/3844], Loss: 0.1177\n",
      "Epoch [4/4], Step [2912/3844], Loss: 0.0842\n",
      "Epoch [4/4], Step [2913/3844], Loss: 0.1232\n",
      "Epoch [4/4], Step [2914/3844], Loss: 0.0559\n",
      "Epoch [4/4], Step [2915/3844], Loss: 0.0575\n",
      "Epoch [4/4], Step [2916/3844], Loss: 0.0926\n",
      "Epoch [4/4], Step [2917/3844], Loss: 0.0425\n",
      "Epoch [4/4], Step [2918/3844], Loss: 0.0748\n",
      "Epoch [4/4], Step [2919/3844], Loss: 0.1659\n",
      "Epoch [4/4], Step [2920/3844], Loss: 0.0844\n",
      "Epoch [4/4], Step [2921/3844], Loss: 0.0659\n",
      "Epoch [4/4], Step [2922/3844], Loss: 0.1162\n",
      "Epoch [4/4], Step [2923/3844], Loss: 0.0659\n",
      "Epoch [4/4], Step [2924/3844], Loss: 0.1700\n",
      "Epoch [4/4], Step [2925/3844], Loss: 0.0610\n",
      "Epoch [4/4], Step [2926/3844], Loss: 0.0863\n",
      "Epoch [4/4], Step [2927/3844], Loss: 0.1515\n",
      "Epoch [4/4], Step [2928/3844], Loss: 0.0689\n",
      "Epoch [4/4], Step [2929/3844], Loss: 0.1467\n",
      "Epoch [4/4], Step [2930/3844], Loss: 0.0836\n",
      "Epoch [4/4], Step [2931/3844], Loss: 0.1199\n",
      "Epoch [4/4], Step [2932/3844], Loss: 0.1611\n",
      "Epoch [4/4], Step [2933/3844], Loss: 0.1374\n",
      "Epoch [4/4], Step [2934/3844], Loss: 0.1176\n",
      "Epoch [4/4], Step [2935/3844], Loss: 0.0715\n",
      "Epoch [4/4], Step [2936/3844], Loss: 0.0500\n",
      "Epoch [4/4], Step [2937/3844], Loss: 0.1440\n",
      "Epoch [4/4], Step [2938/3844], Loss: 0.0958\n",
      "Epoch [4/4], Step [2939/3844], Loss: 0.1071\n",
      "Epoch [4/4], Step [2940/3844], Loss: 0.0675\n",
      "Epoch [4/4], Step [2941/3844], Loss: 0.1464\n",
      "Epoch [4/4], Step [2942/3844], Loss: 0.1189\n",
      "Epoch [4/4], Step [2943/3844], Loss: 0.0811\n",
      "Epoch [4/4], Step [2944/3844], Loss: 0.0813\n",
      "Epoch [4/4], Step [2945/3844], Loss: 0.0698\n",
      "Epoch [4/4], Step [2946/3844], Loss: 0.0610\n",
      "Epoch [4/4], Step [2947/3844], Loss: 0.1123\n",
      "Epoch [4/4], Step [2948/3844], Loss: 0.1617\n",
      "Epoch [4/4], Step [2949/3844], Loss: 0.0634\n",
      "Epoch [4/4], Step [2950/3844], Loss: 0.1174\n",
      "Epoch [4/4], Step [2951/3844], Loss: 0.0959\n",
      "Epoch [4/4], Step [2952/3844], Loss: 0.1182\n",
      "Epoch [4/4], Step [2953/3844], Loss: 0.0745\n",
      "Epoch [4/4], Step [2954/3844], Loss: 0.0829\n",
      "Epoch [4/4], Step [2955/3844], Loss: 0.0536\n",
      "Epoch [4/4], Step [2956/3844], Loss: 0.1103\n",
      "Epoch [4/4], Step [2957/3844], Loss: 0.1483\n",
      "Epoch [4/4], Step [2958/3844], Loss: 0.0830\n",
      "Epoch [4/4], Step [2959/3844], Loss: 0.1228\n",
      "Epoch [4/4], Step [2960/3844], Loss: 0.0728\n",
      "Epoch [4/4], Step [2961/3844], Loss: 0.1154\n",
      "Epoch [4/4], Step [2962/3844], Loss: 0.1173\n",
      "Epoch [4/4], Step [2963/3844], Loss: 0.0697\n",
      "Epoch [4/4], Step [2964/3844], Loss: 0.0538\n",
      "Epoch [4/4], Step [2965/3844], Loss: 0.0913\n",
      "Epoch [4/4], Step [2966/3844], Loss: 0.1281\n",
      "Epoch [4/4], Step [2967/3844], Loss: 0.0900\n",
      "Epoch [4/4], Step [2968/3844], Loss: 0.0617\n",
      "Epoch [4/4], Step [2969/3844], Loss: 0.0926\n",
      "Epoch [4/4], Step [2970/3844], Loss: 0.0973\n",
      "Epoch [4/4], Step [2971/3844], Loss: 0.0773\n",
      "Epoch [4/4], Step [2972/3844], Loss: 0.0880\n",
      "Epoch [4/4], Step [2973/3844], Loss: 0.1267\n",
      "Epoch [4/4], Step [2974/3844], Loss: 0.1563\n",
      "Epoch [4/4], Step [2975/3844], Loss: 0.0943\n",
      "Epoch [4/4], Step [2976/3844], Loss: 0.1165\n",
      "Epoch [4/4], Step [2977/3844], Loss: 0.0729\n",
      "Epoch [4/4], Step [2978/3844], Loss: 0.0820\n",
      "Epoch [4/4], Step [2979/3844], Loss: 0.1194\n",
      "Epoch [4/4], Step [2980/3844], Loss: 0.0686\n",
      "Epoch [4/4], Step [2981/3844], Loss: 0.1224\n",
      "Epoch [4/4], Step [2982/3844], Loss: 0.0613\n",
      "Epoch [4/4], Step [2983/3844], Loss: 0.1474\n",
      "Epoch [4/4], Step [2984/3844], Loss: 0.0438\n",
      "Epoch [4/4], Step [2985/3844], Loss: 0.1137\n",
      "Epoch [4/4], Step [2986/3844], Loss: 0.0997\n",
      "Epoch [4/4], Step [2987/3844], Loss: 0.1043\n",
      "Epoch [4/4], Step [2988/3844], Loss: 0.0943\n",
      "Epoch [4/4], Step [2989/3844], Loss: 0.0830\n",
      "Epoch [4/4], Step [2990/3844], Loss: 0.1006\n",
      "Epoch [4/4], Step [2991/3844], Loss: 0.0992\n",
      "Epoch [4/4], Step [2992/3844], Loss: 0.1125\n",
      "Epoch [4/4], Step [2993/3844], Loss: 0.0904\n",
      "Epoch [4/4], Step [2994/3844], Loss: 0.1317\n",
      "Epoch [4/4], Step [2995/3844], Loss: 0.0987\n",
      "Epoch [4/4], Step [2996/3844], Loss: 0.0741\n",
      "Epoch [4/4], Step [2997/3844], Loss: 0.1276\n",
      "Epoch [4/4], Step [2998/3844], Loss: 0.0478\n",
      "Epoch [4/4], Step [2999/3844], Loss: 0.0716\n",
      "Epoch [4/4], Step [3000/3844], Loss: 0.1397\n",
      "Epoch [4/4], Step [3001/3844], Loss: 0.0329\n",
      "Epoch [4/4], Step [3002/3844], Loss: 0.0583\n",
      "Epoch [4/4], Step [3003/3844], Loss: 0.0711\n",
      "Epoch [4/4], Step [3004/3844], Loss: 0.0968\n",
      "Epoch [4/4], Step [3005/3844], Loss: 0.0801\n",
      "Epoch [4/4], Step [3006/3844], Loss: 0.1057\n",
      "Epoch [4/4], Step [3007/3844], Loss: 0.1200\n",
      "Epoch [4/4], Step [3008/3844], Loss: 0.0703\n",
      "Epoch [4/4], Step [3009/3844], Loss: 0.0827\n",
      "Epoch [4/4], Step [3010/3844], Loss: 0.0749\n",
      "Epoch [4/4], Step [3011/3844], Loss: 0.1000\n",
      "Epoch [4/4], Step [3012/3844], Loss: 0.1366\n",
      "Epoch [4/4], Step [3013/3844], Loss: 0.1039\n",
      "Epoch [4/4], Step [3014/3844], Loss: 0.0519\n",
      "Epoch [4/4], Step [3015/3844], Loss: 0.1256\n",
      "Epoch [4/4], Step [3016/3844], Loss: 0.0590\n",
      "Epoch [4/4], Step [3017/3844], Loss: 0.0514\n",
      "Epoch [4/4], Step [3018/3844], Loss: 0.0823\n",
      "Epoch [4/4], Step [3019/3844], Loss: 0.0438\n",
      "Epoch [4/4], Step [3020/3844], Loss: 0.1017\n",
      "Epoch [4/4], Step [3021/3844], Loss: 0.1094\n",
      "Epoch [4/4], Step [3022/3844], Loss: 0.1568\n",
      "Epoch [4/4], Step [3023/3844], Loss: 0.1246\n",
      "Epoch [4/4], Step [3024/3844], Loss: 0.0620\n",
      "Epoch [4/4], Step [3025/3844], Loss: 0.0796\n",
      "Epoch [4/4], Step [3026/3844], Loss: 0.0540\n",
      "Epoch [4/4], Step [3027/3844], Loss: 0.0995\n",
      "Epoch [4/4], Step [3028/3844], Loss: 0.0713\n",
      "Epoch [4/4], Step [3029/3844], Loss: 0.1261\n",
      "Epoch [4/4], Step [3030/3844], Loss: 0.0968\n",
      "Epoch [4/4], Step [3031/3844], Loss: 0.0705\n",
      "Epoch [4/4], Step [3032/3844], Loss: 0.1407\n",
      "Epoch [4/4], Step [3033/3844], Loss: 0.0619\n",
      "Epoch [4/4], Step [3034/3844], Loss: 0.1249\n",
      "Epoch [4/4], Step [3035/3844], Loss: 0.0930\n",
      "Epoch [4/4], Step [3036/3844], Loss: 0.0432\n",
      "Epoch [4/4], Step [3037/3844], Loss: 0.1266\n",
      "Epoch [4/4], Step [3038/3844], Loss: 0.0612\n",
      "Epoch [4/4], Step [3039/3844], Loss: 0.0440\n",
      "Epoch [4/4], Step [3040/3844], Loss: 0.0591\n",
      "Epoch [4/4], Step [3041/3844], Loss: 0.0688\n",
      "Epoch [4/4], Step [3042/3844], Loss: 0.0800\n",
      "Epoch [4/4], Step [3043/3844], Loss: 0.0587\n",
      "Epoch [4/4], Step [3044/3844], Loss: 0.1048\n",
      "Epoch [4/4], Step [3045/3844], Loss: 0.1130\n",
      "Epoch [4/4], Step [3046/3844], Loss: 0.1226\n",
      "Epoch [4/4], Step [3047/3844], Loss: 0.0936\n",
      "Epoch [4/4], Step [3048/3844], Loss: 0.0871\n",
      "Epoch [4/4], Step [3049/3844], Loss: 0.1552\n",
      "Epoch [4/4], Step [3050/3844], Loss: 0.0864\n",
      "Epoch [4/4], Step [3051/3844], Loss: 0.1508\n",
      "Epoch [4/4], Step [3052/3844], Loss: 0.1068\n",
      "Epoch [4/4], Step [3053/3844], Loss: 0.1296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/4], Step [3054/3844], Loss: 0.1411\n",
      "Epoch [4/4], Step [3055/3844], Loss: 0.0976\n",
      "Epoch [4/4], Step [3056/3844], Loss: 0.0826\n",
      "Epoch [4/4], Step [3057/3844], Loss: 0.1122\n",
      "Epoch [4/4], Step [3058/3844], Loss: 0.1125\n",
      "Epoch [4/4], Step [3059/3844], Loss: 0.0711\n",
      "Epoch [4/4], Step [3060/3844], Loss: 0.1021\n",
      "Epoch [4/4], Step [3061/3844], Loss: 0.1458\n",
      "Epoch [4/4], Step [3062/3844], Loss: 0.1120\n",
      "Epoch [4/4], Step [3063/3844], Loss: 0.1447\n",
      "Epoch [4/4], Step [3064/3844], Loss: 0.0922\n",
      "Epoch [4/4], Step [3065/3844], Loss: 0.0851\n",
      "Epoch [4/4], Step [3066/3844], Loss: 0.1612\n",
      "Epoch [4/4], Step [3067/3844], Loss: 0.1153\n",
      "Epoch [4/4], Step [3068/3844], Loss: 0.1569\n",
      "Epoch [4/4], Step [3069/3844], Loss: 0.1511\n",
      "Epoch [4/4], Step [3070/3844], Loss: 0.0820\n",
      "Epoch [4/4], Step [3071/3844], Loss: 0.0851\n",
      "Epoch [4/4], Step [3072/3844], Loss: 0.0687\n",
      "Epoch [4/4], Step [3073/3844], Loss: 0.0789\n",
      "Epoch [4/4], Step [3074/3844], Loss: 0.0875\n",
      "Epoch [4/4], Step [3075/3844], Loss: 0.1002\n",
      "Epoch [4/4], Step [3076/3844], Loss: 0.0684\n",
      "Epoch [4/4], Step [3077/3844], Loss: 0.1460\n",
      "Epoch [4/4], Step [3078/3844], Loss: 0.0874\n",
      "Epoch [4/4], Step [3079/3844], Loss: 0.0966\n",
      "Epoch [4/4], Step [3080/3844], Loss: 0.1193\n",
      "Epoch [4/4], Step [3081/3844], Loss: 0.1337\n",
      "Epoch [4/4], Step [3082/3844], Loss: 0.0612\n",
      "Epoch [4/4], Step [3083/3844], Loss: 0.0763\n",
      "Epoch [4/4], Step [3084/3844], Loss: 0.1199\n",
      "Epoch [4/4], Step [3085/3844], Loss: 0.0693\n",
      "Epoch [4/4], Step [3086/3844], Loss: 0.0895\n",
      "Epoch [4/4], Step [3087/3844], Loss: 0.1437\n",
      "Epoch [4/4], Step [3088/3844], Loss: 0.0737\n",
      "Epoch [4/4], Step [3089/3844], Loss: 0.1271\n",
      "Epoch [4/4], Step [3090/3844], Loss: 0.0953\n",
      "Epoch [4/4], Step [3091/3844], Loss: 0.1252\n",
      "Epoch [4/4], Step [3092/3844], Loss: 0.1716\n",
      "Epoch [4/4], Step [3093/3844], Loss: 0.0744\n",
      "Epoch [4/4], Step [3094/3844], Loss: 0.1267\n",
      "Epoch [4/4], Step [3095/3844], Loss: 0.0665\n",
      "Epoch [4/4], Step [3096/3844], Loss: 0.1014\n",
      "Epoch [4/4], Step [3097/3844], Loss: 0.0655\n",
      "Epoch [4/4], Step [3098/3844], Loss: 0.0594\n",
      "Epoch [4/4], Step [3099/3844], Loss: 0.0845\n",
      "Epoch [4/4], Step [3100/3844], Loss: 0.1237\n",
      "Epoch [4/4], Step [3101/3844], Loss: 0.1290\n",
      "Epoch [4/4], Step [3102/3844], Loss: 0.1008\n",
      "Epoch [4/4], Step [3103/3844], Loss: 0.1158\n",
      "Epoch [4/4], Step [3104/3844], Loss: 0.0377\n",
      "Epoch [4/4], Step [3105/3844], Loss: 0.1046\n",
      "Epoch [4/4], Step [3106/3844], Loss: 0.0729\n",
      "Epoch [4/4], Step [3107/3844], Loss: 0.1754\n",
      "Epoch [4/4], Step [3108/3844], Loss: 0.1115\n",
      "Epoch [4/4], Step [3109/3844], Loss: 0.0846\n",
      "Epoch [4/4], Step [3110/3844], Loss: 0.1144\n",
      "Epoch [4/4], Step [3111/3844], Loss: 0.1618\n",
      "Epoch [4/4], Step [3112/3844], Loss: 0.0465\n",
      "Epoch [4/4], Step [3113/3844], Loss: 0.0569\n",
      "Epoch [4/4], Step [3114/3844], Loss: 0.0891\n",
      "Epoch [4/4], Step [3115/3844], Loss: 0.0836\n",
      "Epoch [4/4], Step [3116/3844], Loss: 0.0551\n",
      "Epoch [4/4], Step [3117/3844], Loss: 0.1485\n",
      "Epoch [4/4], Step [3118/3844], Loss: 0.0956\n",
      "Epoch [4/4], Step [3119/3844], Loss: 0.1122\n",
      "Epoch [4/4], Step [3120/3844], Loss: 0.1212\n",
      "Epoch [4/4], Step [3121/3844], Loss: 0.1280\n",
      "Epoch [4/4], Step [3122/3844], Loss: 0.1363\n",
      "Epoch [4/4], Step [3123/3844], Loss: 0.0924\n",
      "Epoch [4/4], Step [3124/3844], Loss: 0.0673\n",
      "Epoch [4/4], Step [3125/3844], Loss: 0.1267\n",
      "Epoch [4/4], Step [3126/3844], Loss: 0.0939\n",
      "Epoch [4/4], Step [3127/3844], Loss: 0.0783\n",
      "Epoch [4/4], Step [3128/3844], Loss: 0.1169\n",
      "Epoch [4/4], Step [3129/3844], Loss: 0.0859\n",
      "Epoch [4/4], Step [3130/3844], Loss: 0.1657\n",
      "Epoch [4/4], Step [3131/3844], Loss: 0.0943\n",
      "Epoch [4/4], Step [3132/3844], Loss: 0.0687\n",
      "Epoch [4/4], Step [3133/3844], Loss: 0.0807\n",
      "Epoch [4/4], Step [3134/3844], Loss: 0.0857\n",
      "Epoch [4/4], Step [3135/3844], Loss: 0.0702\n",
      "Epoch [4/4], Step [3136/3844], Loss: 0.1043\n",
      "Epoch [4/4], Step [3137/3844], Loss: 0.0536\n",
      "Epoch [4/4], Step [3138/3844], Loss: 0.0678\n",
      "Epoch [4/4], Step [3139/3844], Loss: 0.0621\n",
      "Epoch [4/4], Step [3140/3844], Loss: 0.0751\n",
      "Epoch [4/4], Step [3141/3844], Loss: 0.1301\n",
      "Epoch [4/4], Step [3142/3844], Loss: 0.1564\n",
      "Epoch [4/4], Step [3143/3844], Loss: 0.0495\n",
      "Epoch [4/4], Step [3144/3844], Loss: 0.0938\n",
      "Epoch [4/4], Step [3145/3844], Loss: 0.0667\n",
      "Epoch [4/4], Step [3146/3844], Loss: 0.0578\n",
      "Epoch [4/4], Step [3147/3844], Loss: 0.0833\n",
      "Epoch [4/4], Step [3148/3844], Loss: 0.1580\n",
      "Epoch [4/4], Step [3149/3844], Loss: 0.1446\n",
      "Epoch [4/4], Step [3150/3844], Loss: 0.0731\n",
      "Epoch [4/4], Step [3151/3844], Loss: 0.1201\n",
      "Epoch [4/4], Step [3152/3844], Loss: 0.0649\n",
      "Epoch [4/4], Step [3153/3844], Loss: 0.1187\n",
      "Epoch [4/4], Step [3154/3844], Loss: 0.0898\n",
      "Epoch [4/4], Step [3155/3844], Loss: 0.1344\n",
      "Epoch [4/4], Step [3156/3844], Loss: 0.1239\n",
      "Epoch [4/4], Step [3157/3844], Loss: 0.1241\n",
      "Epoch [4/4], Step [3158/3844], Loss: 0.0881\n",
      "Epoch [4/4], Step [3159/3844], Loss: 0.1114\n",
      "Epoch [4/4], Step [3160/3844], Loss: 0.0813\n",
      "Epoch [4/4], Step [3161/3844], Loss: 0.0877\n",
      "Epoch [4/4], Step [3162/3844], Loss: 0.0730\n",
      "Epoch [4/4], Step [3163/3844], Loss: 0.1653\n",
      "Epoch [4/4], Step [3164/3844], Loss: 0.0970\n",
      "Epoch [4/4], Step [3165/3844], Loss: 0.0601\n",
      "Epoch [4/4], Step [3166/3844], Loss: 0.0717\n",
      "Epoch [4/4], Step [3167/3844], Loss: 0.1483\n",
      "Epoch [4/4], Step [3168/3844], Loss: 0.0851\n",
      "Epoch [4/4], Step [3169/3844], Loss: 0.0728\n",
      "Epoch [4/4], Step [3170/3844], Loss: 0.0850\n",
      "Epoch [4/4], Step [3171/3844], Loss: 0.0904\n",
      "Epoch [4/4], Step [3172/3844], Loss: 0.0807\n",
      "Epoch [4/4], Step [3173/3844], Loss: 0.0523\n",
      "Epoch [4/4], Step [3174/3844], Loss: 0.0659\n",
      "Epoch [4/4], Step [3175/3844], Loss: 0.0658\n",
      "Epoch [4/4], Step [3176/3844], Loss: 0.1005\n",
      "Epoch [4/4], Step [3177/3844], Loss: 0.0570\n",
      "Epoch [4/4], Step [3178/3844], Loss: 0.0665\n",
      "Epoch [4/4], Step [3179/3844], Loss: 0.0971\n",
      "Epoch [4/4], Step [3180/3844], Loss: 0.1299\n",
      "Epoch [4/4], Step [3181/3844], Loss: 0.0975\n",
      "Epoch [4/4], Step [3182/3844], Loss: 0.0867\n",
      "Epoch [4/4], Step [3183/3844], Loss: 0.1255\n",
      "Epoch [4/4], Step [3184/3844], Loss: 0.0788\n",
      "Epoch [4/4], Step [3185/3844], Loss: 0.1030\n",
      "Epoch [4/4], Step [3186/3844], Loss: 0.0893\n",
      "Epoch [4/4], Step [3187/3844], Loss: 0.0523\n",
      "Epoch [4/4], Step [3188/3844], Loss: 0.0640\n",
      "Epoch [4/4], Step [3189/3844], Loss: 0.0943\n",
      "Epoch [4/4], Step [3190/3844], Loss: 0.1108\n",
      "Epoch [4/4], Step [3191/3844], Loss: 0.1605\n",
      "Epoch [4/4], Step [3192/3844], Loss: 0.0663\n",
      "Epoch [4/4], Step [3193/3844], Loss: 0.0972\n",
      "Epoch [4/4], Step [3194/3844], Loss: 0.1366\n",
      "Epoch [4/4], Step [3195/3844], Loss: 0.0945\n",
      "Epoch [4/4], Step [3196/3844], Loss: 0.1537\n",
      "Epoch [4/4], Step [3197/3844], Loss: 0.0594\n",
      "Epoch [4/4], Step [3198/3844], Loss: 0.1093\n",
      "Epoch [4/4], Step [3199/3844], Loss: 0.0751\n",
      "Epoch [4/4], Step [3200/3844], Loss: 0.0862\n",
      "Epoch [4/4], Step [3201/3844], Loss: 0.0801\n",
      "Epoch [4/4], Step [3202/3844], Loss: 0.1017\n",
      "Epoch [4/4], Step [3203/3844], Loss: 0.0737\n",
      "Epoch [4/4], Step [3204/3844], Loss: 0.0704\n",
      "Epoch [4/4], Step [3205/3844], Loss: 0.0849\n",
      "Epoch [4/4], Step [3206/3844], Loss: 0.0969\n",
      "Epoch [4/4], Step [3207/3844], Loss: 0.0604\n",
      "Epoch [4/4], Step [3208/3844], Loss: 0.1723\n",
      "Epoch [4/4], Step [3209/3844], Loss: 0.0548\n",
      "Epoch [4/4], Step [3210/3844], Loss: 0.0976\n",
      "Epoch [4/4], Step [3211/3844], Loss: 0.0714\n",
      "Epoch [4/4], Step [3212/3844], Loss: 0.0629\n",
      "Epoch [4/4], Step [3213/3844], Loss: 0.0879\n",
      "Epoch [4/4], Step [3214/3844], Loss: 0.1537\n",
      "Epoch [4/4], Step [3215/3844], Loss: 0.1129\n",
      "Epoch [4/4], Step [3216/3844], Loss: 0.1469\n",
      "Epoch [4/4], Step [3217/3844], Loss: 0.1247\n",
      "Epoch [4/4], Step [3218/3844], Loss: 0.0891\n",
      "Epoch [4/4], Step [3219/3844], Loss: 0.0700\n",
      "Epoch [4/4], Step [3220/3844], Loss: 0.0564\n",
      "Epoch [4/4], Step [3221/3844], Loss: 0.0995\n",
      "Epoch [4/4], Step [3222/3844], Loss: 0.0400\n",
      "Epoch [4/4], Step [3223/3844], Loss: 0.1170\n",
      "Epoch [4/4], Step [3224/3844], Loss: 0.1536\n",
      "Epoch [4/4], Step [3225/3844], Loss: 0.0887\n",
      "Epoch [4/4], Step [3226/3844], Loss: 0.1230\n",
      "Epoch [4/4], Step [3227/3844], Loss: 0.1035\n",
      "Epoch [4/4], Step [3228/3844], Loss: 0.1006\n",
      "Epoch [4/4], Step [3229/3844], Loss: 0.0656\n",
      "Epoch [4/4], Step [3230/3844], Loss: 0.1125\n",
      "Epoch [4/4], Step [3231/3844], Loss: 0.0846\n",
      "Epoch [4/4], Step [3232/3844], Loss: 0.1809\n",
      "Epoch [4/4], Step [3233/3844], Loss: 0.0644\n",
      "Epoch [4/4], Step [3234/3844], Loss: 0.0572\n",
      "Epoch [4/4], Step [3235/3844], Loss: 0.1699\n",
      "Epoch [4/4], Step [3236/3844], Loss: 0.0563\n",
      "Epoch [4/4], Step [3237/3844], Loss: 0.1347\n",
      "Epoch [4/4], Step [3238/3844], Loss: 0.1488\n",
      "Epoch [4/4], Step [3239/3844], Loss: 0.0823\n",
      "Epoch [4/4], Step [3240/3844], Loss: 0.1244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/4], Step [3241/3844], Loss: 0.1357\n",
      "Epoch [4/4], Step [3242/3844], Loss: 0.0878\n",
      "Epoch [4/4], Step [3243/3844], Loss: 0.0588\n",
      "Epoch [4/4], Step [3244/3844], Loss: 0.0606\n",
      "Epoch [4/4], Step [3245/3844], Loss: 0.1633\n",
      "Epoch [4/4], Step [3246/3844], Loss: 0.1085\n",
      "Epoch [4/4], Step [3247/3844], Loss: 0.0900\n",
      "Epoch [4/4], Step [3248/3844], Loss: 0.0705\n",
      "Epoch [4/4], Step [3249/3844], Loss: 0.0893\n",
      "Epoch [4/4], Step [3250/3844], Loss: 0.0810\n",
      "Epoch [4/4], Step [3251/3844], Loss: 0.0798\n",
      "Epoch [4/4], Step [3252/3844], Loss: 0.1014\n",
      "Epoch [4/4], Step [3253/3844], Loss: 0.0684\n",
      "Epoch [4/4], Step [3254/3844], Loss: 0.0829\n",
      "Epoch [4/4], Step [3255/3844], Loss: 0.0908\n",
      "Epoch [4/4], Step [3256/3844], Loss: 0.0813\n",
      "Epoch [4/4], Step [3257/3844], Loss: 0.0581\n",
      "Epoch [4/4], Step [3258/3844], Loss: 0.0859\n",
      "Epoch [4/4], Step [3259/3844], Loss: 0.0601\n",
      "Epoch [4/4], Step [3260/3844], Loss: 0.1159\n",
      "Epoch [4/4], Step [3261/3844], Loss: 0.1124\n",
      "Epoch [4/4], Step [3262/3844], Loss: 0.0749\n",
      "Epoch [4/4], Step [3263/3844], Loss: 0.0600\n",
      "Epoch [4/4], Step [3264/3844], Loss: 0.0862\n",
      "Epoch [4/4], Step [3265/3844], Loss: 0.0741\n",
      "Epoch [4/4], Step [3266/3844], Loss: 0.1593\n",
      "Epoch [4/4], Step [3267/3844], Loss: 0.0731\n",
      "Epoch [4/4], Step [3268/3844], Loss: 0.0921\n",
      "Epoch [4/4], Step [3269/3844], Loss: 0.1293\n",
      "Epoch [4/4], Step [3270/3844], Loss: 0.1427\n",
      "Epoch [4/4], Step [3271/3844], Loss: 0.1007\n",
      "Epoch [4/4], Step [3272/3844], Loss: 0.1016\n",
      "Epoch [4/4], Step [3273/3844], Loss: 0.0743\n",
      "Epoch [4/4], Step [3274/3844], Loss: 0.0948\n",
      "Epoch [4/4], Step [3275/3844], Loss: 0.0676\n",
      "Epoch [4/4], Step [3276/3844], Loss: 0.1336\n",
      "Epoch [4/4], Step [3277/3844], Loss: 0.1290\n",
      "Epoch [4/4], Step [3278/3844], Loss: 0.1588\n",
      "Epoch [4/4], Step [3279/3844], Loss: 0.0850\n",
      "Epoch [4/4], Step [3280/3844], Loss: 0.0990\n",
      "Epoch [4/4], Step [3281/3844], Loss: 0.1326\n",
      "Epoch [4/4], Step [3282/3844], Loss: 0.0896\n",
      "Epoch [4/4], Step [3283/3844], Loss: 0.1567\n",
      "Epoch [4/4], Step [3284/3844], Loss: 0.1638\n",
      "Epoch [4/4], Step [3285/3844], Loss: 0.1354\n",
      "Epoch [4/4], Step [3286/3844], Loss: 0.1118\n",
      "Epoch [4/4], Step [3287/3844], Loss: 0.1571\n",
      "Epoch [4/4], Step [3288/3844], Loss: 0.0889\n",
      "Epoch [4/4], Step [3289/3844], Loss: 0.0788\n",
      "Epoch [4/4], Step [3290/3844], Loss: 0.1537\n",
      "Epoch [4/4], Step [3291/3844], Loss: 0.1160\n",
      "Epoch [4/4], Step [3292/3844], Loss: 0.1036\n",
      "Epoch [4/4], Step [3293/3844], Loss: 0.0751\n",
      "Epoch [4/4], Step [3294/3844], Loss: 0.0711\n",
      "Epoch [4/4], Step [3295/3844], Loss: 0.1080\n",
      "Epoch [4/4], Step [3296/3844], Loss: 0.0997\n",
      "Epoch [4/4], Step [3297/3844], Loss: 0.0952\n",
      "Epoch [4/4], Step [3298/3844], Loss: 0.0918\n",
      "Epoch [4/4], Step [3299/3844], Loss: 0.0897\n",
      "Epoch [4/4], Step [3300/3844], Loss: 0.0701\n",
      "Epoch [4/4], Step [3301/3844], Loss: 0.0947\n",
      "Epoch [4/4], Step [3302/3844], Loss: 0.1284\n",
      "Epoch [4/4], Step [3303/3844], Loss: 0.0739\n",
      "Epoch [4/4], Step [3304/3844], Loss: 0.1294\n",
      "Epoch [4/4], Step [3305/3844], Loss: 0.0817\n",
      "Epoch [4/4], Step [3306/3844], Loss: 0.0701\n",
      "Epoch [4/4], Step [3307/3844], Loss: 0.1101\n",
      "Epoch [4/4], Step [3308/3844], Loss: 0.1105\n",
      "Epoch [4/4], Step [3309/3844], Loss: 0.0639\n",
      "Epoch [4/4], Step [3310/3844], Loss: 0.0774\n",
      "Epoch [4/4], Step [3311/3844], Loss: 0.1231\n",
      "Epoch [4/4], Step [3312/3844], Loss: 0.0939\n",
      "Epoch [4/4], Step [3313/3844], Loss: 0.0608\n",
      "Epoch [4/4], Step [3314/3844], Loss: 0.1359\n",
      "Epoch [4/4], Step [3315/3844], Loss: 0.0689\n",
      "Epoch [4/4], Step [3316/3844], Loss: 0.1132\n",
      "Epoch [4/4], Step [3317/3844], Loss: 0.0745\n",
      "Epoch [4/4], Step [3318/3844], Loss: 0.1006\n",
      "Epoch [4/4], Step [3319/3844], Loss: 0.1093\n",
      "Epoch [4/4], Step [3320/3844], Loss: 0.1369\n",
      "Epoch [4/4], Step [3321/3844], Loss: 0.0905\n",
      "Epoch [4/4], Step [3322/3844], Loss: 0.1173\n",
      "Epoch [4/4], Step [3323/3844], Loss: 0.1654\n",
      "Epoch [4/4], Step [3324/3844], Loss: 0.1018\n",
      "Epoch [4/4], Step [3325/3844], Loss: 0.0822\n",
      "Epoch [4/4], Step [3326/3844], Loss: 0.0921\n",
      "Epoch [4/4], Step [3327/3844], Loss: 0.1110\n",
      "Epoch [4/4], Step [3328/3844], Loss: 0.1060\n",
      "Epoch [4/4], Step [3329/3844], Loss: 0.1191\n",
      "Epoch [4/4], Step [3330/3844], Loss: 0.1068\n",
      "Epoch [4/4], Step [3331/3844], Loss: 0.1126\n",
      "Epoch [4/4], Step [3332/3844], Loss: 0.0710\n",
      "Epoch [4/4], Step [3333/3844], Loss: 0.1213\n",
      "Epoch [4/4], Step [3334/3844], Loss: 0.0518\n",
      "Epoch [4/4], Step [3335/3844], Loss: 0.0545\n",
      "Epoch [4/4], Step [3336/3844], Loss: 0.0482\n",
      "Epoch [4/4], Step [3337/3844], Loss: 0.0855\n",
      "Epoch [4/4], Step [3338/3844], Loss: 0.1602\n",
      "Epoch [4/4], Step [3339/3844], Loss: 0.0842\n",
      "Epoch [4/4], Step [3340/3844], Loss: 0.0709\n",
      "Epoch [4/4], Step [3341/3844], Loss: 0.0975\n",
      "Epoch [4/4], Step [3342/3844], Loss: 0.1372\n",
      "Epoch [4/4], Step [3343/3844], Loss: 0.1099\n",
      "Epoch [4/4], Step [3344/3844], Loss: 0.0764\n",
      "Epoch [4/4], Step [3345/3844], Loss: 0.1026\n",
      "Epoch [4/4], Step [3346/3844], Loss: 0.0753\n",
      "Epoch [4/4], Step [3347/3844], Loss: 0.0515\n",
      "Epoch [4/4], Step [3348/3844], Loss: 0.1026\n",
      "Epoch [4/4], Step [3349/3844], Loss: 0.0729\n",
      "Epoch [4/4], Step [3350/3844], Loss: 0.1188\n",
      "Epoch [4/4], Step [3351/3844], Loss: 0.1078\n",
      "Epoch [4/4], Step [3352/3844], Loss: 0.0743\n",
      "Epoch [4/4], Step [3353/3844], Loss: 0.0856\n",
      "Epoch [4/4], Step [3354/3844], Loss: 0.1455\n",
      "Epoch [4/4], Step [3355/3844], Loss: 0.0833\n",
      "Epoch [4/4], Step [3356/3844], Loss: 0.0704\n",
      "Epoch [4/4], Step [3357/3844], Loss: 0.0786\n",
      "Epoch [4/4], Step [3358/3844], Loss: 0.0827\n",
      "Epoch [4/4], Step [3359/3844], Loss: 0.1007\n",
      "Epoch [4/4], Step [3360/3844], Loss: 0.0852\n",
      "Epoch [4/4], Step [3361/3844], Loss: 0.1463\n",
      "Epoch [4/4], Step [3362/3844], Loss: 0.0731\n",
      "Epoch [4/4], Step [3363/3844], Loss: 0.0897\n",
      "Epoch [4/4], Step [3364/3844], Loss: 0.0751\n",
      "Epoch [4/4], Step [3365/3844], Loss: 0.0956\n",
      "Epoch [4/4], Step [3366/3844], Loss: 0.1139\n",
      "Epoch [4/4], Step [3367/3844], Loss: 0.0520\n",
      "Epoch [4/4], Step [3368/3844], Loss: 0.0523\n",
      "Epoch [4/4], Step [3369/3844], Loss: 0.1513\n",
      "Epoch [4/4], Step [3370/3844], Loss: 0.0694\n",
      "Epoch [4/4], Step [3371/3844], Loss: 0.1210\n",
      "Epoch [4/4], Step [3372/3844], Loss: 0.1112\n",
      "Epoch [4/4], Step [3373/3844], Loss: 0.1043\n",
      "Epoch [4/4], Step [3374/3844], Loss: 0.0839\n",
      "Epoch [4/4], Step [3375/3844], Loss: 0.1171\n",
      "Epoch [4/4], Step [3376/3844], Loss: 0.1256\n",
      "Epoch [4/4], Step [3377/3844], Loss: 0.0853\n",
      "Epoch [4/4], Step [3378/3844], Loss: 0.0732\n",
      "Epoch [4/4], Step [3379/3844], Loss: 0.0375\n",
      "Epoch [4/4], Step [3380/3844], Loss: 0.1002\n",
      "Epoch [4/4], Step [3381/3844], Loss: 0.0677\n",
      "Epoch [4/4], Step [3382/3844], Loss: 0.0641\n",
      "Epoch [4/4], Step [3383/3844], Loss: 0.0649\n",
      "Epoch [4/4], Step [3384/3844], Loss: 0.0849\n",
      "Epoch [4/4], Step [3385/3844], Loss: 0.0716\n",
      "Epoch [4/4], Step [3386/3844], Loss: 0.1537\n",
      "Epoch [4/4], Step [3387/3844], Loss: 0.0849\n",
      "Epoch [4/4], Step [3388/3844], Loss: 0.0530\n",
      "Epoch [4/4], Step [3389/3844], Loss: 0.1038\n",
      "Epoch [4/4], Step [3390/3844], Loss: 0.0826\n",
      "Epoch [4/4], Step [3391/3844], Loss: 0.0674\n",
      "Epoch [4/4], Step [3392/3844], Loss: 0.1404\n",
      "Epoch [4/4], Step [3393/3844], Loss: 0.0944\n",
      "Epoch [4/4], Step [3394/3844], Loss: 0.0628\n",
      "Epoch [4/4], Step [3395/3844], Loss: 0.0406\n",
      "Epoch [4/4], Step [3396/3844], Loss: 0.0678\n",
      "Epoch [4/4], Step [3397/3844], Loss: 0.0879\n",
      "Epoch [4/4], Step [3398/3844], Loss: 0.0767\n",
      "Epoch [4/4], Step [3399/3844], Loss: 0.1107\n",
      "Epoch [4/4], Step [3400/3844], Loss: 0.1018\n",
      "Epoch [4/4], Step [3401/3844], Loss: 0.1102\n",
      "Epoch [4/4], Step [3402/3844], Loss: 0.1451\n",
      "Epoch [4/4], Step [3403/3844], Loss: 0.0631\n",
      "Epoch [4/4], Step [3404/3844], Loss: 0.0904\n",
      "Epoch [4/4], Step [3405/3844], Loss: 0.1221\n",
      "Epoch [4/4], Step [3406/3844], Loss: 0.0698\n",
      "Epoch [4/4], Step [3407/3844], Loss: 0.0984\n",
      "Epoch [4/4], Step [3408/3844], Loss: 0.0700\n",
      "Epoch [4/4], Step [3409/3844], Loss: 0.0811\n",
      "Epoch [4/4], Step [3410/3844], Loss: 0.0905\n",
      "Epoch [4/4], Step [3411/3844], Loss: 0.1199\n",
      "Epoch [4/4], Step [3412/3844], Loss: 0.0906\n",
      "Epoch [4/4], Step [3413/3844], Loss: 0.1063\n",
      "Epoch [4/4], Step [3414/3844], Loss: 0.0864\n",
      "Epoch [4/4], Step [3415/3844], Loss: 0.1167\n",
      "Epoch [4/4], Step [3416/3844], Loss: 0.0760\n",
      "Epoch [4/4], Step [3417/3844], Loss: 0.0861\n",
      "Epoch [4/4], Step [3418/3844], Loss: 0.0916\n",
      "Epoch [4/4], Step [3419/3844], Loss: 0.0826\n",
      "Epoch [4/4], Step [3420/3844], Loss: 0.1150\n",
      "Epoch [4/4], Step [3421/3844], Loss: 0.0739\n",
      "Epoch [4/4], Step [3422/3844], Loss: 0.1431\n",
      "Epoch [4/4], Step [3423/3844], Loss: 0.0436\n",
      "Epoch [4/4], Step [3424/3844], Loss: 0.0824\n",
      "Epoch [4/4], Step [3425/3844], Loss: 0.0920\n",
      "Epoch [4/4], Step [3426/3844], Loss: 0.0693\n",
      "Epoch [4/4], Step [3427/3844], Loss: 0.1035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/4], Step [3428/3844], Loss: 0.1635\n",
      "Epoch [4/4], Step [3429/3844], Loss: 0.0733\n",
      "Epoch [4/4], Step [3430/3844], Loss: 0.0857\n",
      "Epoch [4/4], Step [3431/3844], Loss: 0.0502\n",
      "Epoch [4/4], Step [3432/3844], Loss: 0.0551\n",
      "Epoch [4/4], Step [3433/3844], Loss: 0.1232\n",
      "Epoch [4/4], Step [3434/3844], Loss: 0.1140\n",
      "Epoch [4/4], Step [3435/3844], Loss: 0.0883\n",
      "Epoch [4/4], Step [3436/3844], Loss: 0.1389\n",
      "Epoch [4/4], Step [3437/3844], Loss: 0.1033\n",
      "Epoch [4/4], Step [3438/3844], Loss: 0.0861\n",
      "Epoch [4/4], Step [3439/3844], Loss: 0.1526\n",
      "Epoch [4/4], Step [3440/3844], Loss: 0.0716\n",
      "Epoch [4/4], Step [3441/3844], Loss: 0.1521\n",
      "Epoch [4/4], Step [3442/3844], Loss: 0.1158\n",
      "Epoch [4/4], Step [3443/3844], Loss: 0.1153\n",
      "Epoch [4/4], Step [3444/3844], Loss: 0.0940\n",
      "Epoch [4/4], Step [3445/3844], Loss: 0.0798\n",
      "Epoch [4/4], Step [3446/3844], Loss: 0.0659\n",
      "Epoch [4/4], Step [3447/3844], Loss: 0.1506\n",
      "Epoch [4/4], Step [3448/3844], Loss: 0.1766\n",
      "Epoch [4/4], Step [3449/3844], Loss: 0.0920\n",
      "Epoch [4/4], Step [3450/3844], Loss: 0.1657\n",
      "Epoch [4/4], Step [3451/3844], Loss: 0.0862\n",
      "Epoch [4/4], Step [3452/3844], Loss: 0.1241\n",
      "Epoch [4/4], Step [3453/3844], Loss: 0.0776\n",
      "Epoch [4/4], Step [3454/3844], Loss: 0.0748\n",
      "Epoch [4/4], Step [3455/3844], Loss: 0.1601\n",
      "Epoch [4/4], Step [3456/3844], Loss: 0.1062\n",
      "Epoch [4/4], Step [3457/3844], Loss: 0.0737\n",
      "Epoch [4/4], Step [3458/3844], Loss: 0.0739\n",
      "Epoch [4/4], Step [3459/3844], Loss: 0.0849\n",
      "Epoch [4/4], Step [3460/3844], Loss: 0.0806\n",
      "Epoch [4/4], Step [3461/3844], Loss: 0.0928\n",
      "Epoch [4/4], Step [3462/3844], Loss: 0.1162\n",
      "Epoch [4/4], Step [3463/3844], Loss: 0.1556\n",
      "Epoch [4/4], Step [3464/3844], Loss: 0.0909\n",
      "Epoch [4/4], Step [3465/3844], Loss: 0.0603\n",
      "Epoch [4/4], Step [3466/3844], Loss: 0.0849\n",
      "Epoch [4/4], Step [3467/3844], Loss: 0.1489\n",
      "Epoch [4/4], Step [3468/3844], Loss: 0.0899\n",
      "Epoch [4/4], Step [3469/3844], Loss: 0.0596\n",
      "Epoch [4/4], Step [3470/3844], Loss: 0.0991\n",
      "Epoch [4/4], Step [3471/3844], Loss: 0.0903\n",
      "Epoch [4/4], Step [3472/3844], Loss: 0.0878\n",
      "Epoch [4/4], Step [3473/3844], Loss: 0.1048\n",
      "Epoch [4/4], Step [3474/3844], Loss: 0.0560\n",
      "Epoch [4/4], Step [3475/3844], Loss: 0.0843\n",
      "Epoch [4/4], Step [3476/3844], Loss: 0.0920\n",
      "Epoch [4/4], Step [3477/3844], Loss: 0.0961\n",
      "Epoch [4/4], Step [3478/3844], Loss: 0.0822\n",
      "Epoch [4/4], Step [3479/3844], Loss: 0.0663\n",
      "Epoch [4/4], Step [3480/3844], Loss: 0.0997\n",
      "Epoch [4/4], Step [3481/3844], Loss: 0.1588\n",
      "Epoch [4/4], Step [3482/3844], Loss: 0.1246\n",
      "Epoch [4/4], Step [3483/3844], Loss: 0.0584\n",
      "Epoch [4/4], Step [3484/3844], Loss: 0.0988\n",
      "Epoch [4/4], Step [3485/3844], Loss: 0.0752\n",
      "Epoch [4/4], Step [3486/3844], Loss: 0.0992\n",
      "Epoch [4/4], Step [3487/3844], Loss: 0.0395\n",
      "Epoch [4/4], Step [3488/3844], Loss: 0.1605\n",
      "Epoch [4/4], Step [3489/3844], Loss: 0.0719\n",
      "Epoch [4/4], Step [3490/3844], Loss: 0.1071\n",
      "Epoch [4/4], Step [3491/3844], Loss: 0.1041\n",
      "Epoch [4/4], Step [3492/3844], Loss: 0.1213\n",
      "Epoch [4/4], Step [3493/3844], Loss: 0.0752\n",
      "Epoch [4/4], Step [3494/3844], Loss: 0.0884\n",
      "Epoch [4/4], Step [3495/3844], Loss: 0.1391\n",
      "Epoch [4/4], Step [3496/3844], Loss: 0.1257\n",
      "Epoch [4/4], Step [3497/3844], Loss: 0.0558\n",
      "Epoch [4/4], Step [3498/3844], Loss: 0.1036\n",
      "Epoch [4/4], Step [3499/3844], Loss: 0.1055\n",
      "Epoch [4/4], Step [3500/3844], Loss: 0.1618\n",
      "Epoch [4/4], Step [3501/3844], Loss: 0.0796\n",
      "Epoch [4/4], Step [3502/3844], Loss: 0.0817\n",
      "Epoch [4/4], Step [3503/3844], Loss: 0.0949\n",
      "Epoch [4/4], Step [3504/3844], Loss: 0.0602\n",
      "Epoch [4/4], Step [3505/3844], Loss: 0.1867\n",
      "Epoch [4/4], Step [3506/3844], Loss: 0.1124\n",
      "Epoch [4/4], Step [3507/3844], Loss: 0.1542\n",
      "Epoch [4/4], Step [3508/3844], Loss: 0.0605\n",
      "Epoch [4/4], Step [3509/3844], Loss: 0.0663\n",
      "Epoch [4/4], Step [3510/3844], Loss: 0.0937\n",
      "Epoch [4/4], Step [3511/3844], Loss: 0.0829\n",
      "Epoch [4/4], Step [3512/3844], Loss: 0.0815\n",
      "Epoch [4/4], Step [3513/3844], Loss: 0.0716\n",
      "Epoch [4/4], Step [3514/3844], Loss: 0.0770\n",
      "Epoch [4/4], Step [3515/3844], Loss: 0.0489\n",
      "Epoch [4/4], Step [3516/3844], Loss: 0.0451\n",
      "Epoch [4/4], Step [3517/3844], Loss: 0.0676\n",
      "Epoch [4/4], Step [3518/3844], Loss: 0.0808\n",
      "Epoch [4/4], Step [3519/3844], Loss: 0.0908\n",
      "Epoch [4/4], Step [3520/3844], Loss: 0.0757\n",
      "Epoch [4/4], Step [3521/3844], Loss: 0.1716\n",
      "Epoch [4/4], Step [3522/3844], Loss: 0.1035\n",
      "Epoch [4/4], Step [3523/3844], Loss: 0.0596\n",
      "Epoch [4/4], Step [3524/3844], Loss: 0.0606\n",
      "Epoch [4/4], Step [3525/3844], Loss: 0.1179\n",
      "Epoch [4/4], Step [3526/3844], Loss: 0.1264\n",
      "Epoch [4/4], Step [3527/3844], Loss: 0.0752\n",
      "Epoch [4/4], Step [3528/3844], Loss: 0.1530\n",
      "Epoch [4/4], Step [3529/3844], Loss: 0.1202\n",
      "Epoch [4/4], Step [3530/3844], Loss: 0.0797\n",
      "Epoch [4/4], Step [3531/3844], Loss: 0.1347\n",
      "Epoch [4/4], Step [3532/3844], Loss: 0.0658\n",
      "Epoch [4/4], Step [3533/3844], Loss: 0.1615\n",
      "Epoch [4/4], Step [3534/3844], Loss: 0.1137\n",
      "Epoch [4/4], Step [3535/3844], Loss: 0.0601\n",
      "Epoch [4/4], Step [3536/3844], Loss: 0.0873\n",
      "Epoch [4/4], Step [3537/3844], Loss: 0.0344\n",
      "Epoch [4/4], Step [3538/3844], Loss: 0.0746\n",
      "Epoch [4/4], Step [3539/3844], Loss: 0.0538\n",
      "Epoch [4/4], Step [3540/3844], Loss: 0.0737\n",
      "Epoch [4/4], Step [3541/3844], Loss: 0.0959\n",
      "Epoch [4/4], Step [3542/3844], Loss: 0.1000\n",
      "Epoch [4/4], Step [3543/3844], Loss: 0.1484\n",
      "Epoch [4/4], Step [3544/3844], Loss: 0.1824\n",
      "Epoch [4/4], Step [3545/3844], Loss: 0.0527\n",
      "Epoch [4/4], Step [3546/3844], Loss: 0.1014\n",
      "Epoch [4/4], Step [3547/3844], Loss: 0.0921\n",
      "Epoch [4/4], Step [3548/3844], Loss: 0.0839\n",
      "Epoch [4/4], Step [3549/3844], Loss: 0.0651\n",
      "Epoch [4/4], Step [3550/3844], Loss: 0.0775\n",
      "Epoch [4/4], Step [3551/3844], Loss: 0.1044\n",
      "Epoch [4/4], Step [3552/3844], Loss: 0.1307\n",
      "Epoch [4/4], Step [3553/3844], Loss: 0.0606\n",
      "Epoch [4/4], Step [3554/3844], Loss: 0.1052\n",
      "Epoch [4/4], Step [3555/3844], Loss: 0.0744\n",
      "Epoch [4/4], Step [3556/3844], Loss: 0.0587\n",
      "Epoch [4/4], Step [3557/3844], Loss: 0.1010\n",
      "Epoch [4/4], Step [3558/3844], Loss: 0.0720\n",
      "Epoch [4/4], Step [3559/3844], Loss: 0.0749\n",
      "Epoch [4/4], Step [3560/3844], Loss: 0.0593\n",
      "Epoch [4/4], Step [3561/3844], Loss: 0.0750\n",
      "Epoch [4/4], Step [3562/3844], Loss: 0.0975\n",
      "Epoch [4/4], Step [3563/3844], Loss: 0.1059\n",
      "Epoch [4/4], Step [3564/3844], Loss: 0.1614\n",
      "Epoch [4/4], Step [3565/3844], Loss: 0.0813\n",
      "Epoch [4/4], Step [3566/3844], Loss: 0.1113\n",
      "Epoch [4/4], Step [3567/3844], Loss: 0.0579\n",
      "Epoch [4/4], Step [3568/3844], Loss: 0.0657\n",
      "Epoch [4/4], Step [3569/3844], Loss: 0.1511\n",
      "Epoch [4/4], Step [3570/3844], Loss: 0.0776\n",
      "Epoch [4/4], Step [3571/3844], Loss: 0.1824\n",
      "Epoch [4/4], Step [3572/3844], Loss: 0.1132\n",
      "Epoch [4/4], Step [3573/3844], Loss: 0.0624\n",
      "Epoch [4/4], Step [3574/3844], Loss: 0.0760\n",
      "Epoch [4/4], Step [3575/3844], Loss: 0.0545\n",
      "Epoch [4/4], Step [3576/3844], Loss: 0.1090\n",
      "Epoch [4/4], Step [3577/3844], Loss: 0.1535\n",
      "Epoch [4/4], Step [3578/3844], Loss: 0.1616\n",
      "Epoch [4/4], Step [3579/3844], Loss: 0.0845\n",
      "Epoch [4/4], Step [3580/3844], Loss: 0.0390\n",
      "Epoch [4/4], Step [3581/3844], Loss: 0.0565\n",
      "Epoch [4/4], Step [3582/3844], Loss: 0.0812\n",
      "Epoch [4/4], Step [3583/3844], Loss: 0.1770\n",
      "Epoch [4/4], Step [3584/3844], Loss: 0.1500\n",
      "Epoch [4/4], Step [3585/3844], Loss: 0.1247\n",
      "Epoch [4/4], Step [3586/3844], Loss: 0.1528\n",
      "Epoch [4/4], Step [3587/3844], Loss: 0.1599\n",
      "Epoch [4/4], Step [3588/3844], Loss: 0.1710\n",
      "Epoch [4/4], Step [3589/3844], Loss: 0.0649\n",
      "Epoch [4/4], Step [3590/3844], Loss: 0.0823\n",
      "Epoch [4/4], Step [3591/3844], Loss: 0.0773\n",
      "Epoch [4/4], Step [3592/3844], Loss: 0.0994\n",
      "Epoch [4/4], Step [3593/3844], Loss: 0.1118\n",
      "Epoch [4/4], Step [3594/3844], Loss: 0.0706\n",
      "Epoch [4/4], Step [3595/3844], Loss: 0.0576\n",
      "Epoch [4/4], Step [3596/3844], Loss: 0.1231\n",
      "Epoch [4/4], Step [3597/3844], Loss: 0.1124\n",
      "Epoch [4/4], Step [3598/3844], Loss: 0.1007\n",
      "Epoch [4/4], Step [3599/3844], Loss: 0.1711\n",
      "Epoch [4/4], Step [3600/3844], Loss: 0.0882\n",
      "Epoch [4/4], Step [3601/3844], Loss: 0.0793\n",
      "Epoch [4/4], Step [3602/3844], Loss: 0.0803\n",
      "Epoch [4/4], Step [3603/3844], Loss: 0.1495\n",
      "Epoch [4/4], Step [3604/3844], Loss: 0.1116\n",
      "Epoch [4/4], Step [3605/3844], Loss: 0.0611\n",
      "Epoch [4/4], Step [3606/3844], Loss: 0.0724\n",
      "Epoch [4/4], Step [3607/3844], Loss: 0.1439\n",
      "Epoch [4/4], Step [3608/3844], Loss: 0.1785\n",
      "Epoch [4/4], Step [3609/3844], Loss: 0.0868\n",
      "Epoch [4/4], Step [3610/3844], Loss: 0.1175\n",
      "Epoch [4/4], Step [3611/3844], Loss: 0.0663\n",
      "Epoch [4/4], Step [3612/3844], Loss: 0.0810\n",
      "Epoch [4/4], Step [3613/3844], Loss: 0.0743\n",
      "Epoch [4/4], Step [3614/3844], Loss: 0.0636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/4], Step [3615/3844], Loss: 0.0883\n",
      "Epoch [4/4], Step [3616/3844], Loss: 0.1810\n",
      "Epoch [4/4], Step [3617/3844], Loss: 0.1349\n",
      "Epoch [4/4], Step [3618/3844], Loss: 0.0857\n",
      "Epoch [4/4], Step [3619/3844], Loss: 0.0753\n",
      "Epoch [4/4], Step [3620/3844], Loss: 0.0785\n",
      "Epoch [4/4], Step [3621/3844], Loss: 0.1276\n",
      "Epoch [4/4], Step [3622/3844], Loss: 0.0773\n",
      "Epoch [4/4], Step [3623/3844], Loss: 0.1400\n",
      "Epoch [4/4], Step [3624/3844], Loss: 0.0907\n",
      "Epoch [4/4], Step [3625/3844], Loss: 0.0849\n",
      "Epoch [4/4], Step [3626/3844], Loss: 0.0907\n",
      "Epoch [4/4], Step [3627/3844], Loss: 0.1596\n",
      "Epoch [4/4], Step [3628/3844], Loss: 0.0961\n",
      "Epoch [4/4], Step [3629/3844], Loss: 0.0968\n",
      "Epoch [4/4], Step [3630/3844], Loss: 0.0795\n",
      "Epoch [4/4], Step [3631/3844], Loss: 0.0758\n",
      "Epoch [4/4], Step [3632/3844], Loss: 0.0922\n",
      "Epoch [4/4], Step [3633/3844], Loss: 0.0978\n",
      "Epoch [4/4], Step [3634/3844], Loss: 0.0556\n",
      "Epoch [4/4], Step [3635/3844], Loss: 0.1067\n",
      "Epoch [4/4], Step [3636/3844], Loss: 0.1026\n",
      "Epoch [4/4], Step [3637/3844], Loss: 0.1421\n",
      "Epoch [4/4], Step [3638/3844], Loss: 0.1462\n",
      "Epoch [4/4], Step [3639/3844], Loss: 0.0923\n",
      "Epoch [4/4], Step [3640/3844], Loss: 0.1191\n",
      "Epoch [4/4], Step [3641/3844], Loss: 0.0615\n",
      "Epoch [4/4], Step [3642/3844], Loss: 0.0381\n",
      "Epoch [4/4], Step [3643/3844], Loss: 0.1202\n",
      "Epoch [4/4], Step [3644/3844], Loss: 0.0793\n",
      "Epoch [4/4], Step [3645/3844], Loss: 0.1042\n",
      "Epoch [4/4], Step [3646/3844], Loss: 0.0782\n",
      "Epoch [4/4], Step [3647/3844], Loss: 0.0697\n",
      "Epoch [4/4], Step [3648/3844], Loss: 0.1289\n",
      "Epoch [4/4], Step [3649/3844], Loss: 0.1301\n",
      "Epoch [4/4], Step [3650/3844], Loss: 0.0875\n",
      "Epoch [4/4], Step [3651/3844], Loss: 0.0821\n",
      "Epoch [4/4], Step [3652/3844], Loss: 0.1567\n",
      "Epoch [4/4], Step [3653/3844], Loss: 0.0846\n",
      "Epoch [4/4], Step [3654/3844], Loss: 0.1407\n",
      "Epoch [4/4], Step [3655/3844], Loss: 0.0391\n",
      "Epoch [4/4], Step [3656/3844], Loss: 0.0631\n",
      "Epoch [4/4], Step [3657/3844], Loss: 0.0890\n",
      "Epoch [4/4], Step [3658/3844], Loss: 0.0987\n",
      "Epoch [4/4], Step [3659/3844], Loss: 0.1058\n",
      "Epoch [4/4], Step [3660/3844], Loss: 0.1008\n",
      "Epoch [4/4], Step [3661/3844], Loss: 0.0524\n",
      "Epoch [4/4], Step [3662/3844], Loss: 0.0896\n",
      "Epoch [4/4], Step [3663/3844], Loss: 0.0966\n",
      "Epoch [4/4], Step [3664/3844], Loss: 0.0838\n",
      "Epoch [4/4], Step [3665/3844], Loss: 0.0667\n",
      "Epoch [4/4], Step [3666/3844], Loss: 0.0754\n",
      "Epoch [4/4], Step [3667/3844], Loss: 0.1275\n",
      "Epoch [4/4], Step [3668/3844], Loss: 0.1162\n",
      "Epoch [4/4], Step [3669/3844], Loss: 0.1505\n",
      "Epoch [4/4], Step [3670/3844], Loss: 0.1296\n",
      "Epoch [4/4], Step [3671/3844], Loss: 0.0861\n",
      "Epoch [4/4], Step [3672/3844], Loss: 0.0745\n",
      "Epoch [4/4], Step [3673/3844], Loss: 0.0660\n",
      "Epoch [4/4], Step [3674/3844], Loss: 0.0738\n",
      "Epoch [4/4], Step [3675/3844], Loss: 0.1501\n",
      "Epoch [4/4], Step [3676/3844], Loss: 0.0758\n",
      "Epoch [4/4], Step [3677/3844], Loss: 0.1582\n",
      "Epoch [4/4], Step [3678/3844], Loss: 0.0743\n",
      "Epoch [4/4], Step [3679/3844], Loss: 0.1000\n",
      "Epoch [4/4], Step [3680/3844], Loss: 0.0715\n",
      "Epoch [4/4], Step [3681/3844], Loss: 0.1075\n",
      "Epoch [4/4], Step [3682/3844], Loss: 0.1155\n",
      "Epoch [4/4], Step [3683/3844], Loss: 0.1249\n",
      "Epoch [4/4], Step [3684/3844], Loss: 0.1362\n",
      "Epoch [4/4], Step [3685/3844], Loss: 0.1433\n",
      "Epoch [4/4], Step [3686/3844], Loss: 0.0805\n",
      "Epoch [4/4], Step [3687/3844], Loss: 0.0823\n",
      "Epoch [4/4], Step [3688/3844], Loss: 0.0791\n",
      "Epoch [4/4], Step [3689/3844], Loss: 0.0815\n",
      "Epoch [4/4], Step [3690/3844], Loss: 0.0515\n",
      "Epoch [4/4], Step [3691/3844], Loss: 0.1360\n",
      "Epoch [4/4], Step [3692/3844], Loss: 0.1008\n",
      "Epoch [4/4], Step [3693/3844], Loss: 0.1100\n",
      "Epoch [4/4], Step [3694/3844], Loss: 0.0810\n",
      "Epoch [4/4], Step [3695/3844], Loss: 0.0680\n",
      "Epoch [4/4], Step [3696/3844], Loss: 0.1704\n",
      "Epoch [4/4], Step [3697/3844], Loss: 0.0778\n",
      "Epoch [4/4], Step [3698/3844], Loss: 0.0896\n",
      "Epoch [4/4], Step [3699/3844], Loss: 0.0649\n",
      "Epoch [4/4], Step [3700/3844], Loss: 0.0427\n",
      "Epoch [4/4], Step [3701/3844], Loss: 0.0680\n",
      "Epoch [4/4], Step [3702/3844], Loss: 0.0190\n",
      "Epoch [4/4], Step [3703/3844], Loss: 0.0806\n",
      "Epoch [4/4], Step [3704/3844], Loss: 0.0883\n",
      "Epoch [4/4], Step [3705/3844], Loss: 0.0835\n",
      "Epoch [4/4], Step [3706/3844], Loss: 0.0732\n",
      "Epoch [4/4], Step [3707/3844], Loss: 0.0645\n",
      "Epoch [4/4], Step [3708/3844], Loss: 0.1181\n",
      "Epoch [4/4], Step [3709/3844], Loss: 0.0990\n",
      "Epoch [4/4], Step [3710/3844], Loss: 0.0883\n",
      "Epoch [4/4], Step [3711/3844], Loss: 0.1574\n",
      "Epoch [4/4], Step [3712/3844], Loss: 0.0560\n",
      "Epoch [4/4], Step [3713/3844], Loss: 0.1149\n",
      "Epoch [4/4], Step [3714/3844], Loss: 0.1063\n",
      "Epoch [4/4], Step [3715/3844], Loss: 0.0831\n",
      "Epoch [4/4], Step [3716/3844], Loss: 0.0858\n",
      "Epoch [4/4], Step [3717/3844], Loss: 0.0692\n",
      "Epoch [4/4], Step [3718/3844], Loss: 0.1124\n",
      "Epoch [4/4], Step [3719/3844], Loss: 0.0700\n",
      "Epoch [4/4], Step [3720/3844], Loss: 0.0771\n",
      "Epoch [4/4], Step [3721/3844], Loss: 0.0943\n",
      "Epoch [4/4], Step [3722/3844], Loss: 0.0439\n",
      "Epoch [4/4], Step [3723/3844], Loss: 0.0609\n",
      "Epoch [4/4], Step [3724/3844], Loss: 0.0828\n",
      "Epoch [4/4], Step [3725/3844], Loss: 0.0597\n",
      "Epoch [4/4], Step [3726/3844], Loss: 0.0579\n",
      "Epoch [4/4], Step [3727/3844], Loss: 0.0762\n",
      "Epoch [4/4], Step [3728/3844], Loss: 0.0902\n",
      "Epoch [4/4], Step [3729/3844], Loss: 0.0536\n",
      "Epoch [4/4], Step [3730/3844], Loss: 0.1205\n",
      "Epoch [4/4], Step [3731/3844], Loss: 0.1566\n",
      "Epoch [4/4], Step [3732/3844], Loss: 0.0785\n",
      "Epoch [4/4], Step [3733/3844], Loss: 0.0776\n",
      "Epoch [4/4], Step [3734/3844], Loss: 0.0818\n",
      "Epoch [4/4], Step [3735/3844], Loss: 0.1004\n",
      "Epoch [4/4], Step [3736/3844], Loss: 0.1249\n",
      "Epoch [4/4], Step [3737/3844], Loss: 0.0931\n",
      "Epoch [4/4], Step [3738/3844], Loss: 0.1046\n",
      "Epoch [4/4], Step [3739/3844], Loss: 0.1270\n",
      "Epoch [4/4], Step [3740/3844], Loss: 0.0786\n",
      "Epoch [4/4], Step [3741/3844], Loss: 0.0547\n",
      "Epoch [4/4], Step [3742/3844], Loss: 0.0996\n",
      "Epoch [4/4], Step [3743/3844], Loss: 0.0580\n",
      "Epoch [4/4], Step [3744/3844], Loss: 0.1276\n",
      "Epoch [4/4], Step [3745/3844], Loss: 0.1072\n",
      "Epoch [4/4], Step [3746/3844], Loss: 0.1737\n",
      "Epoch [4/4], Step [3747/3844], Loss: 0.0838\n",
      "Epoch [4/4], Step [3748/3844], Loss: 0.1280\n",
      "Epoch [4/4], Step [3749/3844], Loss: 0.1312\n",
      "Epoch [4/4], Step [3750/3844], Loss: 0.1218\n",
      "Epoch [4/4], Step [3751/3844], Loss: 0.0884\n",
      "Epoch [4/4], Step [3752/3844], Loss: 0.0995\n",
      "Epoch [4/4], Step [3753/3844], Loss: 0.0746\n",
      "Epoch [4/4], Step [3754/3844], Loss: 0.0649\n",
      "Epoch [4/4], Step [3755/3844], Loss: 0.0597\n",
      "Epoch [4/4], Step [3756/3844], Loss: 0.0876\n",
      "Epoch [4/4], Step [3757/3844], Loss: 0.1292\n",
      "Epoch [4/4], Step [3758/3844], Loss: 0.1478\n",
      "Epoch [4/4], Step [3759/3844], Loss: 0.0503\n",
      "Epoch [4/4], Step [3760/3844], Loss: 0.0650\n",
      "Epoch [4/4], Step [3761/3844], Loss: 0.1078\n",
      "Epoch [4/4], Step [3762/3844], Loss: 0.1180\n",
      "Epoch [4/4], Step [3763/3844], Loss: 0.0776\n",
      "Epoch [4/4], Step [3764/3844], Loss: 0.0988\n",
      "Epoch [4/4], Step [3765/3844], Loss: 0.1041\n",
      "Epoch [4/4], Step [3766/3844], Loss: 0.0877\n",
      "Epoch [4/4], Step [3767/3844], Loss: 0.1142\n",
      "Epoch [4/4], Step [3768/3844], Loss: 0.1119\n",
      "Epoch [4/4], Step [3769/3844], Loss: 0.0662\n",
      "Epoch [4/4], Step [3770/3844], Loss: 0.0658\n",
      "Epoch [4/4], Step [3771/3844], Loss: 0.0997\n",
      "Epoch [4/4], Step [3772/3844], Loss: 0.0792\n",
      "Epoch [4/4], Step [3773/3844], Loss: 0.0899\n",
      "Epoch [4/4], Step [3774/3844], Loss: 0.1176\n",
      "Epoch [4/4], Step [3775/3844], Loss: 0.0797\n",
      "Epoch [4/4], Step [3776/3844], Loss: 0.0799\n",
      "Epoch [4/4], Step [3777/3844], Loss: 0.1367\n",
      "Epoch [4/4], Step [3778/3844], Loss: 0.0602\n",
      "Epoch [4/4], Step [3779/3844], Loss: 0.1012\n",
      "Epoch [4/4], Step [3780/3844], Loss: 0.0822\n",
      "Epoch [4/4], Step [3781/3844], Loss: 0.0876\n",
      "Epoch [4/4], Step [3782/3844], Loss: 0.1240\n",
      "Epoch [4/4], Step [3783/3844], Loss: 0.0894\n",
      "Epoch [4/4], Step [3784/3844], Loss: 0.0858\n",
      "Epoch [4/4], Step [3785/3844], Loss: 0.0889\n",
      "Epoch [4/4], Step [3786/3844], Loss: 0.0858\n",
      "Epoch [4/4], Step [3787/3844], Loss: 0.0776\n",
      "Epoch [4/4], Step [3788/3844], Loss: 0.1230\n",
      "Epoch [4/4], Step [3789/3844], Loss: 0.1106\n",
      "Epoch [4/4], Step [3790/3844], Loss: 0.0996\n",
      "Epoch [4/4], Step [3791/3844], Loss: 0.0839\n",
      "Epoch [4/4], Step [3792/3844], Loss: 0.0998\n",
      "Epoch [4/4], Step [3793/3844], Loss: 0.0629\n",
      "Epoch [4/4], Step [3794/3844], Loss: 0.0765\n",
      "Epoch [4/4], Step [3795/3844], Loss: 0.0756\n",
      "Epoch [4/4], Step [3796/3844], Loss: 0.1593\n",
      "Epoch [4/4], Step [3797/3844], Loss: 0.1151\n",
      "Epoch [4/4], Step [3798/3844], Loss: 0.0993\n",
      "Epoch [4/4], Step [3799/3844], Loss: 0.0900\n",
      "Epoch [4/4], Step [3800/3844], Loss: 0.0681\n",
      "Epoch [4/4], Step [3801/3844], Loss: 0.0694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/4], Step [3802/3844], Loss: 0.0749\n",
      "Epoch [4/4], Step [3803/3844], Loss: 0.0977\n",
      "Epoch [4/4], Step [3804/3844], Loss: 0.1631\n",
      "Epoch [4/4], Step [3805/3844], Loss: 0.1505\n",
      "Epoch [4/4], Step [3806/3844], Loss: 0.1611\n",
      "Epoch [4/4], Step [3807/3844], Loss: 0.0496\n",
      "Epoch [4/4], Step [3808/3844], Loss: 0.0872\n",
      "Epoch [4/4], Step [3809/3844], Loss: 0.0526\n",
      "Epoch [4/4], Step [3810/3844], Loss: 0.1061\n",
      "Epoch [4/4], Step [3811/3844], Loss: 0.1200\n",
      "Epoch [4/4], Step [3812/3844], Loss: 0.0936\n",
      "Epoch [4/4], Step [3813/3844], Loss: 0.0640\n",
      "Epoch [4/4], Step [3814/3844], Loss: 0.1163\n",
      "Epoch [4/4], Step [3815/3844], Loss: 0.0969\n",
      "Epoch [4/4], Step [3816/3844], Loss: 0.0516\n",
      "Epoch [4/4], Step [3817/3844], Loss: 0.1079\n",
      "Epoch [4/4], Step [3818/3844], Loss: 0.0669\n",
      "Epoch [4/4], Step [3819/3844], Loss: 0.1300\n",
      "Epoch [4/4], Step [3820/3844], Loss: 0.0600\n",
      "Epoch [4/4], Step [3821/3844], Loss: 0.0653\n",
      "Epoch [4/4], Step [3822/3844], Loss: 0.0665\n",
      "Epoch [4/4], Step [3823/3844], Loss: 0.1178\n",
      "Epoch [4/4], Step [3824/3844], Loss: 0.0675\n",
      "Epoch [4/4], Step [3825/3844], Loss: 0.0687\n",
      "Epoch [4/4], Step [3826/3844], Loss: 0.1465\n",
      "Epoch [4/4], Step [3827/3844], Loss: 0.1583\n",
      "Epoch [4/4], Step [3828/3844], Loss: 0.1041\n",
      "Epoch [4/4], Step [3829/3844], Loss: 0.0874\n",
      "Epoch [4/4], Step [3830/3844], Loss: 0.0986\n",
      "Epoch [4/4], Step [3831/3844], Loss: 0.0813\n",
      "Epoch [4/4], Step [3832/3844], Loss: 0.0995\n",
      "Epoch [4/4], Step [3833/3844], Loss: 0.1066\n",
      "Epoch [4/4], Step [3834/3844], Loss: 0.1716\n",
      "Epoch [4/4], Step [3835/3844], Loss: 0.0447\n",
      "Epoch [4/4], Step [3836/3844], Loss: 0.0863\n",
      "Epoch [4/4], Step [3837/3844], Loss: 0.0754\n",
      "Epoch [4/4], Step [3838/3844], Loss: 0.1295\n",
      "Epoch [4/4], Step [3839/3844], Loss: 0.0619\n",
      "Epoch [4/4], Step [3840/3844], Loss: 0.1012\n",
      "Epoch [4/4], Step [3841/3844], Loss: 0.0717\n",
      "Epoch [4/4], Step [3842/3844], Loss: 0.0777\n",
      "Epoch [4/4], Step [3843/3844], Loss: 0.0892\n",
      "\n",
      "train-loss: 0.1291,\n",
      "Validation [4/4], Step [0/379], Loss: 0.0318\n",
      "Validation [4/4], Step [1/379], Loss: 0.0174\n",
      "Validation [4/4], Step [2/379], Loss: 0.0376\n",
      "Validation [4/4], Step [3/379], Loss: 0.0280\n",
      "Validation [4/4], Step [4/379], Loss: 0.0498\n",
      "Validation [4/4], Step [5/379], Loss: 0.0251\n",
      "Validation [4/4], Step [6/379], Loss: 0.0352\n",
      "Validation [4/4], Step [7/379], Loss: 0.0288\n",
      "Validation [4/4], Step [8/379], Loss: 0.0341\n",
      "Validation [4/4], Step [9/379], Loss: 0.0305\n",
      "Validation [4/4], Step [10/379], Loss: 0.0421\n",
      "Validation [4/4], Step [11/379], Loss: 0.0170\n",
      "Validation [4/4], Step [12/379], Loss: 0.0266\n",
      "Validation [4/4], Step [13/379], Loss: 0.0232\n",
      "Validation [4/4], Step [14/379], Loss: 0.0217\n",
      "Validation [4/4], Step [15/379], Loss: 0.0320\n",
      "Validation [4/4], Step [16/379], Loss: 0.0312\n",
      "Validation [4/4], Step [17/379], Loss: 0.0300\n",
      "Validation [4/4], Step [18/379], Loss: 0.0278\n",
      "Validation [4/4], Step [19/379], Loss: 0.0466\n",
      "Validation [4/4], Step [20/379], Loss: 0.0215\n",
      "Validation [4/4], Step [21/379], Loss: 0.0204\n",
      "Validation [4/4], Step [22/379], Loss: 0.0285\n",
      "Validation [4/4], Step [23/379], Loss: 0.0250\n",
      "Validation [4/4], Step [24/379], Loss: 0.0334\n",
      "Validation [4/4], Step [25/379], Loss: 0.0124\n",
      "Validation [4/4], Step [26/379], Loss: 0.0232\n",
      "Validation [4/4], Step [27/379], Loss: 0.0276\n",
      "Validation [4/4], Step [28/379], Loss: 0.0328\n",
      "Validation [4/4], Step [29/379], Loss: 0.0165\n",
      "Validation [4/4], Step [30/379], Loss: 0.0197\n",
      "Validation [4/4], Step [31/379], Loss: 0.0221\n",
      "Validation [4/4], Step [32/379], Loss: 0.0307\n",
      "Validation [4/4], Step [33/379], Loss: 0.0481\n",
      "Validation [4/4], Step [34/379], Loss: 0.0272\n",
      "Validation [4/4], Step [35/379], Loss: 0.0356\n",
      "Validation [4/4], Step [36/379], Loss: 0.0222\n",
      "Validation [4/4], Step [37/379], Loss: 0.0234\n",
      "Validation [4/4], Step [38/379], Loss: 0.0283\n",
      "Validation [4/4], Step [39/379], Loss: 0.0418\n",
      "Validation [4/4], Step [40/379], Loss: 0.0357\n",
      "Validation [4/4], Step [41/379], Loss: 0.0234\n",
      "Validation [4/4], Step [42/379], Loss: 0.0193\n",
      "Validation [4/4], Step [43/379], Loss: 0.0266\n",
      "Validation [4/4], Step [44/379], Loss: 0.0248\n",
      "Validation [4/4], Step [45/379], Loss: 0.0317\n",
      "Validation [4/4], Step [46/379], Loss: 0.0490\n",
      "Validation [4/4], Step [47/379], Loss: 0.0423\n",
      "Validation [4/4], Step [48/379], Loss: 0.0249\n",
      "Validation [4/4], Step [49/379], Loss: 0.0268\n",
      "Validation [4/4], Step [50/379], Loss: 0.0251\n",
      "Validation [4/4], Step [51/379], Loss: 0.0329\n",
      "Validation [4/4], Step [52/379], Loss: 0.0209\n",
      "Validation [4/4], Step [53/379], Loss: 0.0224\n",
      "Validation [4/4], Step [54/379], Loss: 0.0262\n",
      "Validation [4/4], Step [55/379], Loss: 0.0347\n",
      "Validation [4/4], Step [56/379], Loss: 0.0297\n",
      "Validation [4/4], Step [57/379], Loss: 0.0168\n",
      "Validation [4/4], Step [58/379], Loss: 0.0237\n",
      "Validation [4/4], Step [59/379], Loss: 0.0222\n",
      "Validation [4/4], Step [60/379], Loss: 0.0369\n",
      "Validation [4/4], Step [61/379], Loss: 0.0275\n",
      "Validation [4/4], Step [62/379], Loss: 0.0191\n",
      "Validation [4/4], Step [63/379], Loss: 0.0168\n",
      "Validation [4/4], Step [64/379], Loss: 0.0370\n",
      "Validation [4/4], Step [65/379], Loss: 0.0332\n",
      "Validation [4/4], Step [66/379], Loss: 0.0180\n",
      "Validation [4/4], Step [67/379], Loss: 0.0224\n",
      "Validation [4/4], Step [68/379], Loss: 0.0399\n",
      "Validation [4/4], Step [69/379], Loss: 0.0322\n",
      "Validation [4/4], Step [70/379], Loss: 0.0223\n",
      "Validation [4/4], Step [71/379], Loss: 0.0437\n",
      "Validation [4/4], Step [72/379], Loss: 0.0277\n",
      "Validation [4/4], Step [73/379], Loss: 0.0194\n",
      "Validation [4/4], Step [74/379], Loss: 0.0322\n",
      "Validation [4/4], Step [75/379], Loss: 0.0340\n",
      "Validation [4/4], Step [76/379], Loss: 0.0240\n",
      "Validation [4/4], Step [77/379], Loss: 0.0332\n",
      "Validation [4/4], Step [78/379], Loss: 0.0216\n",
      "Validation [4/4], Step [79/379], Loss: 0.0414\n",
      "Validation [4/4], Step [80/379], Loss: 0.0500\n",
      "Validation [4/4], Step [81/379], Loss: 0.0304\n",
      "Validation [4/4], Step [82/379], Loss: 0.0370\n",
      "Validation [4/4], Step [83/379], Loss: 0.0141\n",
      "Validation [4/4], Step [84/379], Loss: 0.0197\n",
      "Validation [4/4], Step [85/379], Loss: 0.0347\n",
      "Validation [4/4], Step [86/379], Loss: 0.0292\n",
      "Validation [4/4], Step [87/379], Loss: 0.0336\n",
      "Validation [4/4], Step [88/379], Loss: 0.0316\n",
      "Validation [4/4], Step [89/379], Loss: 0.0273\n",
      "Validation [4/4], Step [90/379], Loss: 0.0174\n",
      "Validation [4/4], Step [91/379], Loss: 0.0181\n",
      "Validation [4/4], Step [92/379], Loss: 0.0516\n",
      "Validation [4/4], Step [93/379], Loss: 0.0316\n",
      "Validation [4/4], Step [94/379], Loss: 0.0264\n",
      "Validation [4/4], Step [95/379], Loss: 0.0265\n",
      "Validation [4/4], Step [96/379], Loss: 0.0251\n",
      "Validation [4/4], Step [97/379], Loss: 0.0251\n",
      "Validation [4/4], Step [98/379], Loss: 0.0286\n",
      "Validation [4/4], Step [99/379], Loss: 0.0154\n",
      "Validation [4/4], Step [100/379], Loss: 0.0245\n",
      "Validation [4/4], Step [101/379], Loss: 0.0358\n",
      "Validation [4/4], Step [102/379], Loss: 0.0460\n",
      "Validation [4/4], Step [103/379], Loss: 0.0185\n",
      "Validation [4/4], Step [104/379], Loss: 0.0283\n",
      "Validation [4/4], Step [105/379], Loss: 0.0321\n",
      "Validation [4/4], Step [106/379], Loss: 0.0241\n",
      "Validation [4/4], Step [107/379], Loss: 0.0331\n",
      "Validation [4/4], Step [108/379], Loss: 0.0190\n",
      "Validation [4/4], Step [109/379], Loss: 0.0153\n",
      "Validation [4/4], Step [110/379], Loss: 0.0377\n",
      "Validation [4/4], Step [111/379], Loss: 0.0314\n",
      "Validation [4/4], Step [112/379], Loss: 0.0222\n",
      "Validation [4/4], Step [113/379], Loss: 0.0362\n",
      "Validation [4/4], Step [114/379], Loss: 0.0316\n",
      "Validation [4/4], Step [115/379], Loss: 0.0231\n",
      "Validation [4/4], Step [116/379], Loss: 0.0311\n",
      "Validation [4/4], Step [117/379], Loss: 0.0261\n",
      "Validation [4/4], Step [118/379], Loss: 0.0319\n",
      "Validation [4/4], Step [119/379], Loss: 0.0186\n",
      "Validation [4/4], Step [120/379], Loss: 0.0234\n",
      "Validation [4/4], Step [121/379], Loss: 0.0344\n",
      "Validation [4/4], Step [122/379], Loss: 0.0223\n",
      "Validation [4/4], Step [123/379], Loss: 0.0195\n",
      "Validation [4/4], Step [124/379], Loss: 0.0237\n",
      "Validation [4/4], Step [125/379], Loss: 0.0448\n",
      "Validation [4/4], Step [126/379], Loss: 0.0345\n",
      "Validation [4/4], Step [127/379], Loss: 0.0225\n",
      "Validation [4/4], Step [128/379], Loss: 0.0526\n",
      "Validation [4/4], Step [129/379], Loss: 0.0231\n",
      "Validation [4/4], Step [130/379], Loss: 0.0334\n",
      "Validation [4/4], Step [131/379], Loss: 0.0199\n",
      "Validation [4/4], Step [132/379], Loss: 0.0159\n",
      "Validation [4/4], Step [133/379], Loss: 0.0228\n",
      "Validation [4/4], Step [134/379], Loss: 0.0335\n",
      "Validation [4/4], Step [135/379], Loss: 0.0273\n",
      "Validation [4/4], Step [136/379], Loss: 0.0218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation [4/4], Step [137/379], Loss: 0.0225\n",
      "Validation [4/4], Step [138/379], Loss: 0.0222\n",
      "Validation [4/4], Step [139/379], Loss: 0.0314\n",
      "Validation [4/4], Step [140/379], Loss: 0.0178\n",
      "Validation [4/4], Step [141/379], Loss: 0.0275\n",
      "Validation [4/4], Step [142/379], Loss: 0.0268\n",
      "Validation [4/4], Step [143/379], Loss: 0.0213\n",
      "Validation [4/4], Step [144/379], Loss: 0.0330\n",
      "Validation [4/4], Step [145/379], Loss: 0.0406\n",
      "Validation [4/4], Step [146/379], Loss: 0.0276\n",
      "Validation [4/4], Step [147/379], Loss: 0.0546\n",
      "Validation [4/4], Step [148/379], Loss: 0.0303\n",
      "Validation [4/4], Step [149/379], Loss: 0.0385\n",
      "Validation [4/4], Step [150/379], Loss: 0.0145\n",
      "Validation [4/4], Step [151/379], Loss: 0.0412\n",
      "Validation [4/4], Step [152/379], Loss: 0.0273\n",
      "Validation [4/4], Step [153/379], Loss: 0.0170\n",
      "Validation [4/4], Step [154/379], Loss: 0.0315\n",
      "Validation [4/4], Step [155/379], Loss: 0.0341\n",
      "Validation [4/4], Step [156/379], Loss: 0.0468\n",
      "Validation [4/4], Step [157/379], Loss: 0.0222\n",
      "Validation [4/4], Step [158/379], Loss: 0.0365\n",
      "Validation [4/4], Step [159/379], Loss: 0.0290\n",
      "Validation [4/4], Step [160/379], Loss: 0.0296\n",
      "Validation [4/4], Step [161/379], Loss: 0.0257\n",
      "Validation [4/4], Step [162/379], Loss: 0.0276\n",
      "Validation [4/4], Step [163/379], Loss: 0.0300\n",
      "Validation [4/4], Step [164/379], Loss: 0.0161\n",
      "Validation [4/4], Step [165/379], Loss: 0.0225\n",
      "Validation [4/4], Step [166/379], Loss: 0.0370\n",
      "Validation [4/4], Step [167/379], Loss: 0.0291\n",
      "Validation [4/4], Step [168/379], Loss: 0.0456\n",
      "Validation [4/4], Step [169/379], Loss: 0.0325\n",
      "Validation [4/4], Step [170/379], Loss: 0.0268\n",
      "Validation [4/4], Step [171/379], Loss: 0.0166\n",
      "Validation [4/4], Step [172/379], Loss: 0.0341\n",
      "Validation [4/4], Step [173/379], Loss: 0.0253\n",
      "Validation [4/4], Step [174/379], Loss: 0.0382\n",
      "Validation [4/4], Step [175/379], Loss: 0.0234\n",
      "Validation [4/4], Step [176/379], Loss: 0.0296\n",
      "Validation [4/4], Step [177/379], Loss: 0.0437\n",
      "Validation [4/4], Step [178/379], Loss: 0.0169\n",
      "Validation [4/4], Step [179/379], Loss: 0.0164\n",
      "Validation [4/4], Step [180/379], Loss: 0.0372\n",
      "Validation [4/4], Step [181/379], Loss: 0.0207\n",
      "Validation [4/4], Step [182/379], Loss: 0.0217\n",
      "Validation [4/4], Step [183/379], Loss: 0.0205\n",
      "Validation [4/4], Step [184/379], Loss: 0.0410\n",
      "Validation [4/4], Step [185/379], Loss: 0.0248\n",
      "Validation [4/4], Step [186/379], Loss: 0.0174\n",
      "Validation [4/4], Step [187/379], Loss: 0.0257\n",
      "Validation [4/4], Step [188/379], Loss: 0.0362\n",
      "Validation [4/4], Step [189/379], Loss: 0.0312\n",
      "Validation [4/4], Step [190/379], Loss: 0.0253\n",
      "Validation [4/4], Step [191/379], Loss: 0.0322\n",
      "Validation [4/4], Step [192/379], Loss: 0.0231\n",
      "Validation [4/4], Step [193/379], Loss: 0.0424\n",
      "Validation [4/4], Step [194/379], Loss: 0.0365\n",
      "Validation [4/4], Step [195/379], Loss: 0.0338\n",
      "Validation [4/4], Step [196/379], Loss: 0.0379\n",
      "Validation [4/4], Step [197/379], Loss: 0.0283\n",
      "Validation [4/4], Step [198/379], Loss: 0.0475\n",
      "Validation [4/4], Step [199/379], Loss: 0.0158\n",
      "Validation [4/4], Step [200/379], Loss: 0.0309\n",
      "Validation [4/4], Step [201/379], Loss: 0.0341\n",
      "Validation [4/4], Step [202/379], Loss: 0.0290\n",
      "Validation [4/4], Step [203/379], Loss: 0.0229\n",
      "Validation [4/4], Step [204/379], Loss: 0.0315\n",
      "Validation [4/4], Step [205/379], Loss: 0.0438\n",
      "Validation [4/4], Step [206/379], Loss: 0.0284\n",
      "Validation [4/4], Step [207/379], Loss: 0.0225\n",
      "Validation [4/4], Step [208/379], Loss: 0.0164\n",
      "Validation [4/4], Step [209/379], Loss: 0.0247\n",
      "Validation [4/4], Step [210/379], Loss: 0.0335\n",
      "Validation [4/4], Step [211/379], Loss: 0.0322\n",
      "Validation [4/4], Step [212/379], Loss: 0.0206\n",
      "Validation [4/4], Step [213/379], Loss: 0.0453\n",
      "Validation [4/4], Step [214/379], Loss: 0.0459\n",
      "Validation [4/4], Step [215/379], Loss: 0.0308\n",
      "Validation [4/4], Step [216/379], Loss: 0.0293\n",
      "Validation [4/4], Step [217/379], Loss: 0.0222\n",
      "Validation [4/4], Step [218/379], Loss: 0.0354\n",
      "Validation [4/4], Step [219/379], Loss: 0.0282\n",
      "Validation [4/4], Step [220/379], Loss: 0.0271\n",
      "Validation [4/4], Step [221/379], Loss: 0.0153\n",
      "Validation [4/4], Step [222/379], Loss: 0.0306\n",
      "Validation [4/4], Step [223/379], Loss: 0.0366\n",
      "Validation [4/4], Step [224/379], Loss: 0.0262\n",
      "Validation [4/4], Step [225/379], Loss: 0.0284\n",
      "Validation [4/4], Step [226/379], Loss: 0.0248\n",
      "Validation [4/4], Step [227/379], Loss: 0.0169\n",
      "Validation [4/4], Step [228/379], Loss: 0.0412\n",
      "Validation [4/4], Step [229/379], Loss: 0.0233\n",
      "Validation [4/4], Step [230/379], Loss: 0.0254\n",
      "Validation [4/4], Step [231/379], Loss: 0.0183\n",
      "Validation [4/4], Step [232/379], Loss: 0.0423\n",
      "Validation [4/4], Step [233/379], Loss: 0.0422\n",
      "Validation [4/4], Step [234/379], Loss: 0.0221\n",
      "Validation [4/4], Step [235/379], Loss: 0.0336\n",
      "Validation [4/4], Step [236/379], Loss: 0.0400\n",
      "Validation [4/4], Step [237/379], Loss: 0.0215\n",
      "Validation [4/4], Step [238/379], Loss: 0.0395\n",
      "Validation [4/4], Step [239/379], Loss: 0.0386\n",
      "Validation [4/4], Step [240/379], Loss: 0.0154\n",
      "Validation [4/4], Step [241/379], Loss: 0.0169\n",
      "Validation [4/4], Step [242/379], Loss: 0.0460\n",
      "Validation [4/4], Step [243/379], Loss: 0.0301\n",
      "Validation [4/4], Step [244/379], Loss: 0.0208\n",
      "Validation [4/4], Step [245/379], Loss: 0.0281\n",
      "Validation [4/4], Step [246/379], Loss: 0.0304\n",
      "Validation [4/4], Step [247/379], Loss: 0.0247\n",
      "Validation [4/4], Step [248/379], Loss: 0.0276\n",
      "Validation [4/4], Step [249/379], Loss: 0.0283\n",
      "Validation [4/4], Step [250/379], Loss: 0.0360\n",
      "Validation [4/4], Step [251/379], Loss: 0.0396\n",
      "Validation [4/4], Step [252/379], Loss: 0.0375\n",
      "Validation [4/4], Step [253/379], Loss: 0.0304\n",
      "Validation [4/4], Step [254/379], Loss: 0.0259\n",
      "Validation [4/4], Step [255/379], Loss: 0.0363\n",
      "Validation [4/4], Step [256/379], Loss: 0.0185\n",
      "Validation [4/4], Step [257/379], Loss: 0.0334\n",
      "Validation [4/4], Step [258/379], Loss: 0.0334\n",
      "Validation [4/4], Step [259/379], Loss: 0.0200\n",
      "Validation [4/4], Step [260/379], Loss: 0.0250\n",
      "Validation [4/4], Step [261/379], Loss: 0.0275\n",
      "Validation [4/4], Step [262/379], Loss: 0.0294\n",
      "Validation [4/4], Step [263/379], Loss: 0.0375\n",
      "Validation [4/4], Step [264/379], Loss: 0.0189\n",
      "Validation [4/4], Step [265/379], Loss: 0.0319\n",
      "Validation [4/4], Step [266/379], Loss: 0.0357\n",
      "Validation [4/4], Step [267/379], Loss: 0.0275\n",
      "Validation [4/4], Step [268/379], Loss: 0.0176\n",
      "Validation [4/4], Step [269/379], Loss: 0.0283\n",
      "Validation [4/4], Step [270/379], Loss: 0.0253\n",
      "Validation [4/4], Step [271/379], Loss: 0.0241\n",
      "Validation [4/4], Step [272/379], Loss: 0.0279\n",
      "Validation [4/4], Step [273/379], Loss: 0.0313\n",
      "Validation [4/4], Step [274/379], Loss: 0.0529\n",
      "Validation [4/4], Step [275/379], Loss: 0.0370\n",
      "Validation [4/4], Step [276/379], Loss: 0.0146\n",
      "Validation [4/4], Step [277/379], Loss: 0.0248\n",
      "Validation [4/4], Step [278/379], Loss: 0.0239\n",
      "Validation [4/4], Step [279/379], Loss: 0.0181\n",
      "Validation [4/4], Step [280/379], Loss: 0.0319\n",
      "Validation [4/4], Step [281/379], Loss: 0.0351\n",
      "Validation [4/4], Step [282/379], Loss: 0.0130\n",
      "Validation [4/4], Step [283/379], Loss: 0.0190\n",
      "Validation [4/4], Step [284/379], Loss: 0.0329\n",
      "Validation [4/4], Step [285/379], Loss: 0.0248\n",
      "Validation [4/4], Step [286/379], Loss: 0.0213\n",
      "Validation [4/4], Step [287/379], Loss: 0.0212\n",
      "Validation [4/4], Step [288/379], Loss: 0.0260\n",
      "Validation [4/4], Step [289/379], Loss: 0.0395\n",
      "Validation [4/4], Step [290/379], Loss: 0.0176\n",
      "Validation [4/4], Step [291/379], Loss: 0.0245\n",
      "Validation [4/4], Step [292/379], Loss: 0.0303\n",
      "Validation [4/4], Step [293/379], Loss: 0.0211\n",
      "Validation [4/4], Step [294/379], Loss: 0.0325\n",
      "Validation [4/4], Step [295/379], Loss: 0.0228\n",
      "Validation [4/4], Step [296/379], Loss: 0.0272\n",
      "Validation [4/4], Step [297/379], Loss: 0.0212\n",
      "Validation [4/4], Step [298/379], Loss: 0.0274\n",
      "Validation [4/4], Step [299/379], Loss: 0.0326\n",
      "Validation [4/4], Step [300/379], Loss: 0.0201\n",
      "Validation [4/4], Step [301/379], Loss: 0.0274\n",
      "Validation [4/4], Step [302/379], Loss: 0.0370\n",
      "Validation [4/4], Step [303/379], Loss: 0.0163\n",
      "Validation [4/4], Step [304/379], Loss: 0.0216\n",
      "Validation [4/4], Step [305/379], Loss: 0.0178\n",
      "Validation [4/4], Step [306/379], Loss: 0.0272\n",
      "Validation [4/4], Step [307/379], Loss: 0.0242\n",
      "Validation [4/4], Step [308/379], Loss: 0.0273\n",
      "Validation [4/4], Step [309/379], Loss: 0.0189\n",
      "Validation [4/4], Step [310/379], Loss: 0.0188\n",
      "Validation [4/4], Step [311/379], Loss: 0.0269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation [4/4], Step [312/379], Loss: 0.0335\n",
      "Validation [4/4], Step [313/379], Loss: 0.0433\n",
      "Validation [4/4], Step [314/379], Loss: 0.0174\n",
      "Validation [4/4], Step [315/379], Loss: 0.0209\n",
      "Validation [4/4], Step [316/379], Loss: 0.0187\n",
      "Validation [4/4], Step [317/379], Loss: 0.0250\n",
      "Validation [4/4], Step [318/379], Loss: 0.0239\n",
      "Validation [4/4], Step [319/379], Loss: 0.0284\n",
      "Validation [4/4], Step [320/379], Loss: 0.0149\n",
      "Validation [4/4], Step [321/379], Loss: 0.0235\n",
      "Validation [4/4], Step [322/379], Loss: 0.0177\n",
      "Validation [4/4], Step [323/379], Loss: 0.0289\n",
      "Validation [4/4], Step [324/379], Loss: 0.0199\n",
      "Validation [4/4], Step [325/379], Loss: 0.0310\n",
      "Validation [4/4], Step [326/379], Loss: 0.0318\n",
      "Validation [4/4], Step [327/379], Loss: 0.0217\n",
      "Validation [4/4], Step [328/379], Loss: 0.0301\n",
      "Validation [4/4], Step [329/379], Loss: 0.0251\n",
      "Validation [4/4], Step [330/379], Loss: 0.0181\n",
      "Validation [4/4], Step [331/379], Loss: 0.0337\n",
      "Validation [4/4], Step [332/379], Loss: 0.0547\n",
      "Validation [4/4], Step [333/379], Loss: 0.0253\n",
      "Validation [4/4], Step [334/379], Loss: 0.0323\n",
      "Validation [4/4], Step [335/379], Loss: 0.0385\n",
      "Validation [4/4], Step [336/379], Loss: 0.0454\n",
      "Validation [4/4], Step [337/379], Loss: 0.0197\n",
      "Validation [4/4], Step [338/379], Loss: 0.0364\n",
      "Validation [4/4], Step [339/379], Loss: 0.0264\n",
      "Validation [4/4], Step [340/379], Loss: 0.0206\n",
      "Validation [4/4], Step [341/379], Loss: 0.0223\n",
      "Validation [4/4], Step [342/379], Loss: 0.0268\n",
      "Validation [4/4], Step [343/379], Loss: 0.0287\n",
      "Validation [4/4], Step [344/379], Loss: 0.0197\n",
      "Validation [4/4], Step [345/379], Loss: 0.0274\n",
      "Validation [4/4], Step [346/379], Loss: 0.0222\n",
      "Validation [4/4], Step [347/379], Loss: 0.0245\n",
      "Validation [4/4], Step [348/379], Loss: 0.0191\n",
      "Validation [4/4], Step [349/379], Loss: 0.0357\n",
      "Validation [4/4], Step [350/379], Loss: 0.0356\n",
      "Validation [4/4], Step [351/379], Loss: 0.0340\n",
      "Validation [4/4], Step [352/379], Loss: 0.0353\n",
      "Validation [4/4], Step [353/379], Loss: 0.0287\n",
      "Validation [4/4], Step [354/379], Loss: 0.0233\n",
      "Validation [4/4], Step [355/379], Loss: 0.0175\n",
      "Validation [4/4], Step [356/379], Loss: 0.0317\n",
      "Validation [4/4], Step [357/379], Loss: 0.0220\n",
      "Validation [4/4], Step [358/379], Loss: 0.0336\n",
      "Validation [4/4], Step [359/379], Loss: 0.0224\n",
      "Validation [4/4], Step [360/379], Loss: 0.0239\n",
      "Validation [4/4], Step [361/379], Loss: 0.0381\n",
      "Validation [4/4], Step [362/379], Loss: 0.0243\n",
      "Validation [4/4], Step [363/379], Loss: 0.0278\n",
      "Validation [4/4], Step [364/379], Loss: 0.0239\n",
      "Validation [4/4], Step [365/379], Loss: 0.0501\n",
      "Validation [4/4], Step [366/379], Loss: 0.0237\n",
      "Validation [4/4], Step [367/379], Loss: 0.0611\n",
      "Validation [4/4], Step [368/379], Loss: 0.0332\n",
      "Validation [4/4], Step [369/379], Loss: 0.0265\n",
      "Validation [4/4], Step [370/379], Loss: 0.0205\n",
      "Validation [4/4], Step [371/379], Loss: 0.0306\n",
      "Validation [4/4], Step [372/379], Loss: 0.0142\n",
      "Validation [4/4], Step [373/379], Loss: 0.0387\n",
      "Validation [4/4], Step [374/379], Loss: 0.0187\n",
      "Validation [4/4], Step [375/379], Loss: 0.0252\n",
      "Validation [4/4], Step [376/379], Loss: 0.0301\n",
      "Validation [4/4], Step [377/379], Loss: 0.0464\n",
      "Validation [4/4], Step [378/379], Loss: 0.0265\n",
      "validation loss: 0.0496, \n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Wall time: 10h 2min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.L1Loss() ##nn.MSELoss() ##  # Easy to interpret #\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001) #,weight_decay=1e-5 #optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "n_epochs = 4\n",
    "print_every = 1\n",
    "valid_loss_min = np.Inf\n",
    "val_loss = []\n",
    "train_loss = []\n",
    "total_step = len(train_dataloader)\n",
    "\n",
    "nan_batches = []\n",
    "\n",
    "run = True\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    print(f'Epoch {epoch}\\n')\n",
    "    \n",
    "    # Work through batches\n",
    "    for batch_idx, data in enumerate(train_dataloader): #data: (['idx', 'rgb', 'speed', 'steer', 'throttle', 'brake'])\n",
    "\n",
    "        loss = forward_pass(data)\n",
    "        \n",
    "        # Backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_value = loss.item()\n",
    "        \n",
    "        \"\"\"\n",
    "        if np.isnan(loss_value):\n",
    "            print(\"nan\", batch_idx)\n",
    "            nan_batches.append((batch_idx, data))\n",
    "         \"\"\"   \n",
    "        \n",
    "        running_loss += loss_value\n",
    "        if (batch_idx) % print_every == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch, n_epochs, batch_idx, total_step, loss_value ))\n",
    "        \"\"\"\n",
    "        et = time.time()\n",
    "        print(et-at)\n",
    "        at = time.time()\n",
    "        \"\"\"\n",
    "        \n",
    "    # Epoch finished, evaluate network and save if network_learned\n",
    "    train_loss.append(running_loss/total_step)\n",
    "    print(f'\\ntrain-loss: {np.mean(train_loss):.4f},') # TODO SOLVE NAN ISSUES\n",
    "    batch_loss = 0\n",
    "\n",
    "    \n",
    "    # Evaluation on Test set, skipped for now\n",
    "  \n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        \n",
    "        val_total_step = len(test_dataloader)\n",
    "        \n",
    "        for batch_idx, data in enumerate(test_dataloader):\n",
    "            \n",
    "            loss = forward_pass(data, False)\n",
    "            \n",
    "            loss_value = loss.item()\n",
    "            \n",
    "            if (batch_idx) % print_every == 0:\n",
    "                print ('Validation [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                       .format(epoch, n_epochs, batch_idx, val_total_step, loss_value ))\n",
    "            \n",
    "            batch_loss += loss_value\n",
    "        val_loss.append(batch_loss/len(test_dataloader))\n",
    "        mean_val_loss = np.mean(val_loss)\n",
    "        \n",
    "        print(f'validation loss: {mean_val_loss:.4f}, \\n') # TODO SOLVE NAN ISSUES\n",
    "\n",
    "        network_learned = mean_val_loss < valid_loss_min\n",
    "        if True:#network_learned:\n",
    "            valid_loss_min = mean_val_loss\n",
    "            torch.save(net.state_dict(), 'resnet'+\"_E-\"+str(epoch)+\"_noise_branched\"+'.pth')\n",
    "            #torch.save(net.state_dict(), \"resnet_E-6.pth\")\n",
    "            print('Improvement-Detected, save-model')\n",
    "\n",
    "    # Back to training\n",
    "    net.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85942e9",
   "metadata": {},
   "source": [
    "### Test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ecda41",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "iterator = iter(test_dataloader)\n",
    "#print(next(iter(test_dataloader)).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b96dc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iterator)\n",
    "#data\n",
    "\n",
    "X_rgb = transform_norm(torch.squeeze(data[\"rgb\"])).float().to(device)\n",
    "labels = data[\"command\"]\n",
    "labels = torch.where(labels == -1, torch.tensor(0), labels).to(torch.int64) # Replace by -1 by 0\n",
    "# Convert the labels to a one hot encoded tensor\n",
    "one_hot = torch.nn.functional.one_hot(labels, num_classes=7).to(device)\n",
    "X_cmd = torch.squeeze(one_hot).float().to(device)\n",
    "X_spd = ((data[\"speed\"]-speed_mean)/speed_std).float().to(device)\n",
    "#print(np.mean(X_spd.cpu().numpy()))\n",
    "\n",
    "target_ = (data[\"throttle\"], data[\"steer\"], data[\"brake\"])\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    outputs_ = net(X_rgb, X_cmd, X_spd)\n",
    "    \n",
    "# Durchschnittlicher abs. fehler\n",
    "for i in [0,1,2]:\n",
    "    print(np.mean(abs(outputs_[i].cpu().numpy()-target_[i].cpu().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b81953",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015a3ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(outputs_[0].cpu().numpy()-target_[0].cpu().numpy(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c4f638",
   "metadata": {},
   "source": [
    "Bias Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074bc0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance \n",
    "\n",
    "for i in [0,1,2]:\n",
    "    outputs = (outputs_[i].cpu().numpy())\n",
    "    #print(outputs)\n",
    "    mean_outputs = np.mean(outputs_[i].cpu().numpy())\n",
    "    #print(mean_outputs)\n",
    "    diff = (outputs-mean_outputs)**2\n",
    "    #print(diff)\n",
    "    value = np.mean(diff)\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da6a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias\n",
    "for i in [0,1,2]:\n",
    "    targets = (target_[i].cpu().numpy())\n",
    "    #print(outputs)\n",
    "    mean_outputs = np.mean(outputs_[i].cpu().numpy())\n",
    "    #print(mean_outputs)\n",
    "    diff = outputs-mean_outputs\n",
    "    #print(diff)\n",
    "    value = np.mean(diff)\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d580060",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0,1,2]:\n",
    "    print(np.mean(abs(target_[i].cpu().numpy())))\n",
    "    print(np.std(abs(target_[i].cpu().numpy())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd372c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "i =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88953edc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.round(outputs_[i].cpu().numpy(),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd39c1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.round(target_[i].cpu().numpy(),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab4158b",
   "metadata": {},
   "source": [
    "### IMG Processing\n",
    "\n",
    "BGR is now standard FOR carla agent and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dbd043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "idx, batch = next(enumerate(test_dataloader))\n",
    "print(batch[\"rgb\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd55e6d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = batch[\"rgb\"][0]#.shape\n",
    "img = img.numpy().astype(np.uint8).reshape(160,960,3)\n",
    "print(img.shape)\n",
    "\n",
    "#img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # NUR HIER, NICHT IN CARLA AGENT\n",
    "print(img.shape)\n",
    "print(type(img))\n",
    "transform = transforms.Compose([transforms.ToPILImage()])\n",
    "\n",
    "tensor = transform(img)\n",
    "\n",
    "#print(type(tensor))\n",
    "\n",
    "tensor.show()\n",
    "\n",
    "#torch.tensor(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20307478",
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_img = img.astype(np.uint8).reshape(160,960,3)\n",
    "transform = transforms.Compose([transforms.ToPILImage()])\n",
    "print(pil_img.shape)\n",
    "pil_img = transform(pil_img)\n",
    "pil_img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b4b228",
   "metadata": {},
   "source": [
    "TEST Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec50160",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = transform_norm(torch.squeeze(data[\"rgb\"],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a21ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.squeeze(transform_norm(data[\"rgb\"])).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683d06c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(64):\n",
    "    print(np.mean(tensor.numpy()[i], axis = (1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd1c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(tensor.numpy(), axis = (0,2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc09d0c",
   "metadata": {},
   "source": [
    "### adding Navigation and speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13bbeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "iterator = iter(test_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56111d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iterator)\n",
    "#data[\"speed\"]\n",
    "#data[\"command\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fd7382",
   "metadata": {},
   "source": [
    "Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22295af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Assume labels is a 1D tensor with values from 0 to 6\n",
    "\n",
    "labels = data[\"command\"]\n",
    "labels = torch.where(labels == -1, torch.tensor(0), labels) # Replace by -1 by 0\n",
    "labels = labels.to(torch.int64)\n",
    "\n",
    "# Convert the labels to a one hot encoded tensor\n",
    "one_hot = torch.nn.functional.one_hot(labels, num_classes=7)\n",
    "one_hot = torch.squeeze(one_hot)\n",
    "\n",
    "print(one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799272fb",
   "metadata": {},
   "source": [
    "Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce212d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc mean over trainingsset\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "print(len(train_dataloader))\n",
    "iterator = iter(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c1a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "summe = []\n",
    "for batch_idx, data in enumerate(train_dataloader):\n",
    "    #print(data)\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    summe.append(np.mean(data[\"speed\"].numpy()))\n",
    "    i += 1\n",
    "    if i >= 1000:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cd4153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(summe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de90cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(summe)) # 2.2078979146598274\n",
    "print(np.std(summe)) # 0.22455625005948113\n",
    "speed_mean = np.mean(summe)\n",
    "speed_std = np.std(summe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f20dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iterator)\n",
    "#print(np.round(batch[\"speed\"].numpy(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd855f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "(batch[\"speed\"]-speed_mean)/speed_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1cce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(((batch[\"speed\"]-speed_mean)/speed_std).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7c659b",
   "metadata": {},
   "source": [
    "### Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6c193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc mean over trainingsset\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "print(len(train_dataloader))\n",
    "iterator = iter(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92caf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "steer = []\n",
    "throttle = []\n",
    "brake = []\n",
    "for batch_idx, data in enumerate(train_dataloader):\n",
    "    #print(data)\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    steer.append(np.mean(data[\"steer\"].numpy()))\n",
    "    throttle.append(np.mean(data[\"throttle\"].numpy()))\n",
    "    brake.append(np.mean(data[\"brake\"].numpy()))\n",
    "    i += 1\n",
    "    if i >= 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b198de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(steer))\n",
    "print(np.mean(throttle))\n",
    "print(np.mean(brake))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7177fc92",
   "metadata": {},
   "source": [
    "### Vanishing/Exploding Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac119fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for name, param in net.thr_head.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.cpu().numpy())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba6bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in net.spd_input.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, np.max(abs(param.data.cpu().numpy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0f44f0",
   "metadata": {},
   "source": [
    "## Saving and Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eecda0",
   "metadata": {},
   "source": [
    "Not suited for leaderboard agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f516f764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(net, 'rgb_resnet.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a81a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = torch.load('rgb_resnet.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e10b82",
   "metadata": {},
   "source": [
    "suited for leaderboard agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55596f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"rgb_resnet.pth\")\n",
    "torch.save(optimizer.state_dict(), \"rgb_resnet_optimizer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc5d256",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.join(os.getenv(\"GITLAB_ROOT\"),\n",
    "                                           \"models\", \"resnet_baseline\", \"weights\",\n",
    "                                           \"Resnet_Baseline_V3\")  # TODO Has to be defined\n",
    "path = os.path.join(root, \"resnet_E-5.pth\")\n",
    "print(path)\n",
    "net = MyResnet()\n",
    "net.load_state_dict(torch.load(path)) # TODO Change to some model checkpoint\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8568190",
   "metadata": {},
   "source": [
    "## Testing Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef6d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "idx, X = next(enumerate(test_dataloader))\n",
    "img = transform_norm(X[\"rgb\"])\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339784d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.squeeze(img,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e33ce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "#print(len(test_dataloader))\n",
    "at = 0\n",
    "for batch_idx, data in enumerate(test_dataloader):\n",
    "    # further preprocessing\n",
    "    X_rgb = transform_norm(torch.squeeze(data[\"rgb\"])).float()\n",
    "    if False:#augument:\n",
    "        X_rgb = transform_augument(X_rgb)\n",
    "    labels = data[\"command\"]\n",
    "    labels = torch.where(labels == -1, torch.tensor(0), labels).to(torch.int64) # Replace by -1 by 0\n",
    "    # Convert the labels to a one hot encoded tensor\n",
    "    one_hot = torch.nn.functional.one_hot(labels, num_classes=7)\n",
    "    X_cmd = torch.squeeze(one_hot).float()\n",
    "    X_spd = ((data[\"speed\"]-speed_mean)/speed_std).float()\n",
    "    \n",
    "    Y_throttle = data[\"throttle\"].float()\n",
    "    Y_steer = data[\"steer\"].float()\n",
    "    Y_brake = data[\"brake\"].float()\n",
    "\n",
    "    # move to GPU\n",
    "    X_rgb = to_cuda_if_possible(X_rgb)\n",
    "    X_cmd = to_cuda_if_possible(X_cmd)\n",
    "    X_spd = to_cuda_if_possible(X_spd)\n",
    "    \n",
    "    Y_throttle = to_cuda_if_possible(Y_throttle)\n",
    "    Y_steer = to_cuda_if_possible(Y_steer)\n",
    "    Y_brake = to_cuda_if_possible(Y_brake)\n",
    "    \n",
    "    et = time.time()\n",
    "    print(et-at)\n",
    "    at = time.time()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96bcd38",
   "metadata": {},
   "source": [
    "#### Training secounds per batch\n",
    "\n",
    "1.8778209686279297\n",
    "1.7550039291381836\n",
    "1.9759962558746338\n",
    "2.018435001373291"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613a0284",
   "metadata": {},
   "source": [
    "#### Only dataloader and preprocessing secounds per batch\n",
    "1.235999584197998\n",
    "1.2680015563964844\n",
    "1.3483715057373047\n",
    "1.2585253715515137\n",
    "1.1267704963684082\n",
    "1.124000072479248\n",
    "1.2410008907318115\n",
    "1.2269997596740723\n",
    "1.200000286102295\n",
    "1.267998456954956\n",
    "1.2166194915771484\n",
    "1.2077960968017578\n",
    "1.2405602931976318\n",
    "1.2019383907318115"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
