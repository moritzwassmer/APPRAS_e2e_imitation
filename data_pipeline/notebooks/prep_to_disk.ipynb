{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julianvonklitzing/miniforge3/envs/carla/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "sys.path.append(\"..\")\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from utils import train_test_split, create_metadata_df\n",
    "from dataset_xy import CARLADatasetXY\n",
    "from dataset import CARLADataset\n",
    "from data_preprocessing import preprocessing, transform_lidar_bev\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal of this notebook is to develop a method that saves the data from df_train, df_test1 and df_test2 preprocessed and in as few folders as possible. Furthermore the data from df_train shall be stored in shuffled order such that we don't have to explicitly shuffle anymore while training to prevent random reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = os.path.join(\"..\", \"..\", \"data\", \"data\")\n",
    "path_data = os.path.join(\"..\", \"..\", \"data\", \"train_set\")\n",
    "\n",
    "config_xy = {\"used_inputs\": [\"rgb\", \"lidar\", \"measurements\"], \n",
    "        \"used_measurements\": [\"speed\", \"steer\", \"throttle\", \"brake\", \"command\"],\n",
    "        \"y\": [\"brake\", \"steer\", \"throttle\"],\n",
    "        \"seq_len\": 1\n",
    "        }\n",
    "        \n",
    "df_meta_data = create_metadata_df(path_data, config_xy[\"used_inputs\"])\n",
    "dataset = CARLADatasetXY(root_dir=path_data, df_meta_data=df_meta_data, config=config_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dataset=dataset, batch_size=64, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:02<00:00,  4.79it/s]\n"
     ]
    }
   ],
   "source": [
    "for x,y in tqdm(dl):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_config = {\n",
    "    \"train\": ['Town00', 'Town01', 'Town02', 'Town03', 'Town04', 'Town05', 'Town07', 'Town08', 'Town09', 'Town10'],\n",
    "    \"test\": ['Town06']\n",
    "}\n",
    "\n",
    "df_train, df_test_1, df_test_2 = train_test_split(df_meta_data, towns_intersect=train_test_config)\n",
    "\n",
    "np.random.seed(42)\n",
    "indices_rand = np.random.choice(list(range(len(df_train))), size=len(df_train), replace=False)\n",
    "df_train_shuffled = df_train.loc[indices_rand].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = CARLADatasetXY(root_dir=path_data, df_meta_data=df_train_shuffled, config=config_xy)\n",
    "dataset_test_1 = CARLADatasetXY(root_dir=path_data, df_meta_data=df_test_1, config=config_xy)\n",
    "dataset_test_2 = CARLADatasetXY(root_dir=path_data, df_meta_data=df_test_2, config=config_xy)\n",
    "dataset_map = {\"train_set\": dataset_train, \"test_set_1\": dataset_test_1, \"test_set_2\": dataset_test_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_destination = os.path.join(\"..\", \"..\", \"data\")\n",
    "normalize = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 845/205535 [00:14<57:20, 59.50it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39minput\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrgb\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     26\u001b[0m         data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor(data)\n\u001b[0;32m---> 27\u001b[0m     data \u001b[39m=\u001b[39m preprocessing[\u001b[39minput\u001b[39;49m](data)\n\u001b[1;32m     28\u001b[0m data_suffix \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m0\u001b[39m\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m (number_set_len \u001b[39m-\u001b[39m idx_len)\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(idx)\u001b[39m}\u001b[39;00m\u001b[39m.npy\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m path_data_save \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path_dataset_input, data_suffix)\n",
      "File \u001b[0;32m~/Documents/GitHub/end2endappras/data_pipeline/notebooks/../data_preprocessing.py:53\u001b[0m, in \u001b[0;36mtransform_lidar_bev\u001b[0;34m(points, sr, fr, hr, res)\u001b[0m\n\u001b[1;32m     49\u001b[0m z_points \u001b[39m=\u001b[39m z_points[indices]\n\u001b[1;32m     52\u001b[0m \u001b[39m# CONVERT TO PIXEL POSITION VALUES - Based on resolution\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m x_img \u001b[39m=\u001b[39m (\u001b[39m-\u001b[39;49my_points \u001b[39m/\u001b[39;49m res)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mint32)  \u001b[39m# x axis is -y in LIDAR\u001b[39;00m\n\u001b[1;32m     54\u001b[0m y_img \u001b[39m=\u001b[39m (\u001b[39m-\u001b[39mx_points \u001b[39m/\u001b[39m res)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mint32)  \u001b[39m# y axis is -x in LIDAR\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# SHIFT PIXELS TO HAVE MINIMUM BE (0,0)\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m# floor and ceil used to prevent anything being rounded to below 0 after shift\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for dataset_key in dataset_map:\n",
    "    \n",
    "    path_dataset = os.path.join(dir_destination, dataset_key)\n",
    "    if not os.path.exists(path_dataset):\n",
    "        os.makedirs(path_dataset)\n",
    "\n",
    "    dataset = dataset_map[dataset_key]\n",
    "    df_meta_data = dataset.df_meta_data\n",
    "    number_set_len = len(str(len(df_meta_data)))\n",
    "\n",
    "    for idx in tqdm(range(len(df_meta_data))):\n",
    "        idx_len = len(str(idx))\n",
    "        for input in dataset.used_inputs:\n",
    "            path_dataset_input = os.path.join(path_dataset, input)\n",
    "            # Will only be created once at the first iteration for a dataset\n",
    "            if not os.path.exists(path_dataset_input):\n",
    "                os.makedirs(path_dataset_input)\n",
    "            # Load, potentially preprocess and safe input data\n",
    "            if input in preprocessing.keys():\n",
    "                # Load data\n",
    "                path_data_load = os.path.join(df_meta_data[\"dir\"][idx], input, df_meta_data[input][idx])\n",
    "                data = dataset.load_data_from_path(path_data_load)\n",
    "                # Normalize/ Preprocess\n",
    "                if normalize:\n",
    "                    if input == \"rgb\":\n",
    "                        data = torch.Tensor(data)\n",
    "                    data = preprocessing[input](data)\n",
    "                data_suffix = f\"{'0'* (number_set_len - idx_len)}{str(idx)}.npy\"\n",
    "                path_data_save = os.path.join(path_dataset_input, data_suffix)\n",
    "                with open(path_data_save, 'wb') as f:\n",
    "                    np.save(f, data)\n",
    "            # Copy measurements\n",
    "            if input == \"measurements\":\n",
    "                path_data_source = os.path.join(df_meta_data[\"dir\"][idx], input, df_meta_data[input][idx])\n",
    "                data_suffix = f\"{'0'* (number_set_len - idx_len)}{str(idx)}.json\"\n",
    "                path_data_destination = os.path.join(path_dataset_input, data_suffix)\n",
    "                shutil.copy(path_data_source, path_data_destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "585.182976"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of entire preprocessed dataset (actually lidar still needs to be normalized) in GB\n",
    "((0.461 + 1.8) * len(df_meta_data)) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:05:16) \n[Clang 12.0.1 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc80d0638afb8ec7c43f4b834002a598fcddbd6e8bf5db40ad8cba47e68e6a97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
