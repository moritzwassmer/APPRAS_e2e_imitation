{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "Find out if the Dataset implementation, specifically the get_item() method is to slow (single thread). <br>\n",
    "From former experiments it could be shown that it takes around 42 min (to be repeated to be sure!) to load x,y batches using the DataLoader for loading rgb and measurements for the entire Dataset. Possible spots of inefficiency in the current implementation:\n",
    "1. To many for loops & if statements in get_item() \n",
    "2. Data structure input_idx that get created (every time) in get_item()\n",
    "3. Path generation every time by accessing the DataFrame and joining\n",
    "\n",
    "\n",
    "<br>\n",
    "Now \"hardcoded\", specific, non-generalizable approach to get an optimal single thread benchmark: <br>\n",
    "\n",
    "1. only consider rgb and the measuremnts needed\n",
    "2. hardcoded/fully-precomputed paths\n",
    "3. no loops\n",
    "4. create x, y\n",
    "--> 35min 27s\n",
    "\n",
    "Remark: Only pure DataLoading without preprocessing is tested!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julianvonklitzing/miniforge3/envs/carla/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "sys.path.append(\"..\")\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import train_test_split, create_metadata_df\n",
    "from dataset_xy import CARLADatasetXY\n",
    "from data_preprocessing import preprocessing\n",
    "from dataset_xy_opt import CARLADatasetXYOpt\n",
    "import cv2\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = os.path.join(\"..\", \"..\", \"data\", \"data\")\n",
    "\n",
    "config_xy = {\"used_inputs\": [\"rgb\", \"measurements\"], \n",
    "        \"used_measurements\": [\"speed\", \"steer\", \"throttle\", \"brake\", \"command\"],\n",
    "        \"y\": [\"brake\", \"steer\", \"throttle\"],\n",
    "        \"seq_len\": 1\n",
    "        }\n",
    "\n",
    "# Create df_meta \n",
    "df_meta_data = create_metadata_df(path_data, config_xy[\"used_inputs\"])\n",
    "\n",
    "# Create Dataset & DataLoader\n",
    "dataset = CARLADatasetXY(root_dir=path_data, df_meta_data=df_meta_data, config=config_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dir</th>\n",
       "      <th>rgb</th>\n",
       "      <th>measurements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../data/data/cycl_dataset_23_11/Routes_non-...</td>\n",
       "      <td>0000.png</td>\n",
       "      <td>0000.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../data/data/cycl_dataset_23_11/Routes_non-...</td>\n",
       "      <td>0001.png</td>\n",
       "      <td>0001.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../data/data/cycl_dataset_23_11/Routes_non-...</td>\n",
       "      <td>0002.png</td>\n",
       "      <td>0002.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../data/data/cycl_dataset_23_11/Routes_non-...</td>\n",
       "      <td>0003.png</td>\n",
       "      <td>0003.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../data/data/cycl_dataset_23_11/Routes_non-...</td>\n",
       "      <td>0004.png</td>\n",
       "      <td>0004.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258836</th>\n",
       "      <td>../../data/data/dirt_dataset_23_11/Routes_Scen...</td>\n",
       "      <td>0189.png</td>\n",
       "      <td>0189.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258837</th>\n",
       "      <td>../../data/data/dirt_dataset_23_11/Routes_Scen...</td>\n",
       "      <td>0190.png</td>\n",
       "      <td>0190.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258838</th>\n",
       "      <td>../../data/data/dirt_dataset_23_11/Routes_Scen...</td>\n",
       "      <td>0191.png</td>\n",
       "      <td>0191.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258839</th>\n",
       "      <td>../../data/data/dirt_dataset_23_11/Routes_Scen...</td>\n",
       "      <td>0192.png</td>\n",
       "      <td>0192.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258840</th>\n",
       "      <td>../../data/data/dirt_dataset_23_11/Routes_Scen...</td>\n",
       "      <td>0193.png</td>\n",
       "      <td>0193.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258841 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      dir       rgb  \\\n",
       "0       ../../data/data/cycl_dataset_23_11/Routes_non-...  0000.png   \n",
       "1       ../../data/data/cycl_dataset_23_11/Routes_non-...  0001.png   \n",
       "2       ../../data/data/cycl_dataset_23_11/Routes_non-...  0002.png   \n",
       "3       ../../data/data/cycl_dataset_23_11/Routes_non-...  0003.png   \n",
       "4       ../../data/data/cycl_dataset_23_11/Routes_non-...  0004.png   \n",
       "...                                                   ...       ...   \n",
       "258836  ../../data/data/dirt_dataset_23_11/Routes_Scen...  0189.png   \n",
       "258837  ../../data/data/dirt_dataset_23_11/Routes_Scen...  0190.png   \n",
       "258838  ../../data/data/dirt_dataset_23_11/Routes_Scen...  0191.png   \n",
       "258839  ../../data/data/dirt_dataset_23_11/Routes_Scen...  0192.png   \n",
       "258840  ../../data/data/dirt_dataset_23_11/Routes_Scen...  0193.png   \n",
       "\n",
       "       measurements  \n",
       "0         0000.json  \n",
       "1         0001.json  \n",
       "2         0002.json  \n",
       "3         0003.json  \n",
       "4         0004.json  \n",
       "...             ...  \n",
       "258836    0189.json  \n",
       "258837    0190.json  \n",
       "258838    0191.json  \n",
       "258839    0192.json  \n",
       "258840    0193.json  \n",
       "\n",
       "[258841 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths are completely precomputed and must not be computed again\n",
    "df_paths_rgb = df_meta_data[\"dir\"] + os.sep + \"rgb\" + os.sep + df_meta_data[\"rgb\"]\n",
    "df_paths_measurements = df_meta_data[\"dir\"] + os.sep + \"measurements\" + os.sep + df_meta_data[\"measurements\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 258841/258841 [35:27<00:00, 121.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# When using num_workers= 0 in DataLoader this is essentially what is happening\n",
    "def run_baseline():\n",
    "    for i in tqdm(range(len(df_meta_data))):\n",
    "\n",
    "        x_sample = dict()\n",
    "        y_sample = dict()\n",
    "        img = cv2.imread(df_paths_rgb.loc[i])\n",
    "        # reshape to #channels; height; width\n",
    "        img = img.reshape([3] + list(img.shape)[:-1])\n",
    "\n",
    "        with open(df_paths_measurements.loc[i], 'r') as f:\n",
    "            measurements = json.load(f)\n",
    "        speed = measurements[\"speed\"]\n",
    "        throttle = measurements[\"throttle\"]\n",
    "        command = measurements[\"command\"]\n",
    "        steer = measurements[\"steer\"]\n",
    "\n",
    "        x_sample[\"rgb\"] = img\n",
    "        x_sample[\"speed\"] = speed\n",
    "        x_sample[\"command\"] = command\n",
    "        y_sample[\"throttle\"] = throttle\n",
    "        y_sample[\"command\"] = command\n",
    "    y_sample[\"steer\"] = steer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self implemented parallel PandasDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rgb(path):\n",
    "    img = cv2.imread(df_paths_rgb.loc[i])\n",
    "        # reshape to #channels; height; width\n",
    "    img = img.reshape([3] + list(img.shape)[:-1])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_measurements(path):\n",
    "    with open(path, 'r') as f:\n",
    "        measurements = json.load(f)\n",
    "    # speed = measurements[\"speed\"]\n",
    "    # throttle = measurements[\"throttle\"]\n",
    "    # command = measurements[\"command\"]\n",
    "    # steer = measurements[\"steer\"]\n",
    "    # return speed, throttle, command, steer\n",
    "    return measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:31<00:00,  3.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# 31.6 --> so also not faster\n",
    "def pandas_data_loader():\n",
    "    for i in tqdm(range(100)):   #int(len(df_meta_data))\n",
    "        batch_size = 64\n",
    "        batch_rand_idxs = np.random.randint(0, len(df_meta_data), size=batch_size)\n",
    "\n",
    "        df_rgb = df_paths_rgb.loc[batch_rand_idxs].apply(load_rgb)\n",
    "        rgb_np = np.stack(df_rgb.values)\n",
    "        rgb_torch = torch.tensor(rgb_np)\n",
    "\n",
    "        df_measurements = df_paths_measurements.loc[batch_rand_idxs].apply(load_measurements)\n",
    "\n",
    "        df_speed = df_measurements.apply(lambda x: x[\"speed\"])\n",
    "        speed_np = df_speed.to_numpy()\n",
    "        speed_torch = torch.tensor(rgb_np)\n",
    "\n",
    "        df_command = df_measurements.apply(lambda x: x[\"command\"])\n",
    "        command_np = df_command.to_numpy()\n",
    "        command_torch = torch.tensor(rgb_np)\n",
    "\n",
    "        df_throttle = df_measurements.apply(lambda x: x[\"throttle\"])\n",
    "        throttle_np = df_throttle.to_numpy()\n",
    "        throttle_torch = torch.tensor(rgb_np)\n",
    "\n",
    "        df_steer = df_measurements.apply(lambda x: x[\"steer\"])\n",
    "        steer_np = df_steer.to_numpy()\n",
    "        steer_torch = torch.tensor(rgb_np)\n",
    "\n",
    "        df_brake = df_measurements.apply(lambda x: x[\"brake\"])\n",
    "        brake_np = df_brake.to_numpy()\n",
    "        brake_torch = torch.tensor(brake_np)\n",
    "\n",
    "        x_sample = {\"rgb\": rgb_torch, \"speed\": speed_torch, \"command\": command_torch}\n",
    "        y_sample = {\"steer\": steer_torch, \"throttle\": throttle_torch, \"brake\": brake_torch}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test specialized DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_data_2 = df_meta_data.head(64 * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_opt = CARLADatasetXYOpt(df_meta_data_2)\n",
    "dl_opt = DataLoader(dataset=ds_opt, batch_size=64, num_workers=4, sampler=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:33<00:00,  2.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# worker=0   52.9s\n",
    "# worker=2  32.1s\n",
    "# worker=4  33.8s (but until 97% it went really quick)\n",
    "# still need to test it how it performs in training loop!\n",
    "for x, y in tqdm(dl_opt):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset = CARLADatasetXY(root_dir=path_data, df_meta_data=df_meta_data_2, config=config_xy)\n",
    "dl = DataLoader(dataset=ds_opt, batch_size=64, num_workers=0, sampler=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:32<00:00,  3.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# 32.2s seems like this new/specialized isn't better than the old/generalized DataLoader\n",
    "for x, y in tqdm(dl):\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test DataLoader speed with preprocessed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = os.path.join(\"..\", \"..\", \"data\", \"data_prep\")\n",
    "\n",
    "config_xy = {\"used_inputs\": [\"rgb\", \"measurements\"], \n",
    "        \"used_measurements\": [\"speed\", \"steer\", \"throttle\", \"brake\", \"command\"],\n",
    "        \"y\": [\"brake\", \"steer\", \"throttle\"],\n",
    "        \"seq_len\": 1\n",
    "        }\n",
    "\n",
    "# Create df_meta \n",
    "df_meta_data = create_metadata_df(path_data, config_xy[\"used_inputs\"])\n",
    "df_meta_data_2 = df_meta_data.head(64*100)\n",
    "\n",
    "# Create Dataset & DataLoader\n",
    "dataset = CARLADatasetXY(root_dir=path_data, df_meta_data=df_meta_data_2, config=config_xy)\n",
    "dl_npz = DataLoader(dataset=dataset, batch_size=64, num_workers=4, sampler=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:42<00:00,  2.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# 42.2s so longer than with with .png files\n",
    "for x, y in tqdm(dl_npz):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc80d0638afb8ec7c43f4b834002a598fcddbd6e8bf5db40ad8cba47e68e6a97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
