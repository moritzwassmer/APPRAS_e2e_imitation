{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julianvonklitzing/miniforge3/envs/carla/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# original size 258866 # 258841 # 258816\n",
    "import sys\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "sys.path.append(\"..\")\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import train_test_split, create_metadata_df\n",
    "from dataset_xy import CARLADatasetXY\n",
    "import json\n",
    "from send2trash import send2trash\n",
    "import shutil"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move sensor folders that we are not using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.join(\"..\", \"..\", \"data\", \"data\")\n",
    "keep_input = [\"lidar\", \"rgb\", \"measurements\"] # \"lidar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_unused_sensors_to_new_folder(root_dir, keep_input):\n",
    "    for (root, dirs, files) in os.walk(root_dir, topdown=True):\n",
    "        # Current folder contains the files\n",
    "        if not dirs:\n",
    "            dir, input_type = os.path.split(root)\n",
    "            if input_type not in keep_input:\n",
    "                path_parts = root.split(os.sep)\n",
    "                idx_data_first = path_parts.index(\"data\")\n",
    "                path_parts[idx_data_first + 1] += \" unused\"\n",
    "                dir_new = os.path.join(*path_parts)\n",
    "                if not os.path.exists(dir_new):\n",
    "                    os.makedirs(dir_new)\n",
    "                shutil.move(root, dir_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move folders back into the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.join(\"..\", \"..\", \"data\", \"data unused\")\n",
    "#root_dir = \"/Users/julianvonklitzing/Documents/GitHub/end2endappras/data/data unused\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (root, dirs, files) in os.walk(root_dir, topdown=True):\n",
    "    # Current folder contains the files\n",
    "    if not dirs:\n",
    "        dir, input_type = os.path.split(root)\n",
    "        dir_parts = dir.split(\"/\")\n",
    "        idx = dir_parts.index(\"data\") # idx of first data\n",
    "        dir_parts[idx + 1] = \"data\"\n",
    "        dir_new = os.path.join(*dir_parts)\n",
    "        shutil.move(root, dir_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move/ Delete _prep folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_unused_sensors_to_new_folder(root_dir, keep_input):\n",
    "    for (root, dirs, files) in os.walk(root_dir, topdown=True):\n",
    "        # Current folder contains the files\n",
    "        if not dirs:\n",
    "            dir, input_type = os.path.split(root)\n",
    "            if input_type not in keep_input:\n",
    "                path_parts = root.split(os.sep)\n",
    "                idx_data_first = path_parts.index(\"data\")\n",
    "                path_parts[idx_data_first + 1] += \" unused\"\n",
    "                dir_new = os.path.join(*path_parts)\n",
    "                if not os.path.exists(dir_new):\n",
    "                    os.makedirs(dir_new)\n",
    "                shutil.move(root, dir_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_sensor_folders(root_dir, keep_input):\n",
    "    for (root, dirs, files) in os.walk(root_dir, topdown=True):\n",
    "        # Current folder contains the files\n",
    "        if not dirs:\n",
    "            dir, input_type = os.path.split(root)\n",
    "            if input_type not in keep_input:\n",
    "                shutil.rmtree(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = os.path.join(\"..\", \"..\", \"data\", \"data\")\n",
    "# keep_input = [\"lidar\", \"lidar_prep\", \"rgb\", \"measurements\"] # \"lidar\"\n",
    "\n",
    "# delete_sensor_folders(root_dir, keep_input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete entries with NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = os.path.join(\"..\", \"..\", \"data\", \"data\")\n",
    "\n",
    "config_xy = {\"used_inputs\": [\"measurements\"], \n",
    "        \"used_measurements\": [\"speed\", \"steer\", \"throttle\", \"brake\", \"command\"],\n",
    "        \"y\": [\"brake\", \"steer\", \"throttle\"],\n",
    "        \"seq_len\": 1\n",
    "        }\n",
    "\n",
    "# Create df_meta \n",
    "df_meta_data = create_metadata_df(path_data, config_xy[\"used_inputs\"])\n",
    "\n",
    "# Create Dataset & DataLoader\n",
    "dataset = CARLADatasetXY(root_dir=path_data, df_meta_data=df_meta_data, config=config_xy)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=64, num_workers=0, sampler=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = os.path.join(\"..\", \"..\", \"data\", \"data unused\")\n",
    "\n",
    "config_xy = {\"used_inputs\": [\"lidar\"], \n",
    "        \"used_measurements\": [\"speed\", \"steer\", \"throttle\", \"brake\", \"command\"],\n",
    "        \"y\": [\"brake\", \"steer\", \"throttle\"],\n",
    "        \"seq_len\": 1\n",
    "        }\n",
    "\n",
    "# Create df_meta \n",
    "df_meta_data_lidar = create_metadata_df(path_data, config_xy[\"used_inputs\"])\n",
    "\n",
    "# Create Dataset & DataLoader\n",
    "# dataset = CARLADatasetXY(root_dir=path_data, df_meta_data=df_meta_data, config=config_xy)\n",
    "# dataloader = DataLoader(dataset=dataset, batch_size=64, num_workers=0, sampler=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dir</th>\n",
       "      <th>lidar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../data/data unused/cycl_dataset_23_11/Rout...</td>\n",
       "      <td>0000.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../data/data unused/cycl_dataset_23_11/Rout...</td>\n",
       "      <td>0001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../data/data unused/cycl_dataset_23_11/Rout...</td>\n",
       "      <td>0002.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../data/data unused/cycl_dataset_23_11/Rout...</td>\n",
       "      <td>0003.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../data/data unused/cycl_dataset_23_11/Rout...</td>\n",
       "      <td>0004.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258811</th>\n",
       "      <td>../../data/data unused/dirt_dataset_23_11/Rout...</td>\n",
       "      <td>0189.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258812</th>\n",
       "      <td>../../data/data unused/dirt_dataset_23_11/Rout...</td>\n",
       "      <td>0190.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258813</th>\n",
       "      <td>../../data/data unused/dirt_dataset_23_11/Rout...</td>\n",
       "      <td>0191.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258814</th>\n",
       "      <td>../../data/data unused/dirt_dataset_23_11/Rout...</td>\n",
       "      <td>0192.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258815</th>\n",
       "      <td>../../data/data unused/dirt_dataset_23_11/Rout...</td>\n",
       "      <td>0193.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258816 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      dir     lidar\n",
       "0       ../../data/data unused/cycl_dataset_23_11/Rout...  0000.npy\n",
       "1       ../../data/data unused/cycl_dataset_23_11/Rout...  0001.npy\n",
       "2       ../../data/data unused/cycl_dataset_23_11/Rout...  0002.npy\n",
       "3       ../../data/data unused/cycl_dataset_23_11/Rout...  0003.npy\n",
       "4       ../../data/data unused/cycl_dataset_23_11/Rout...  0004.npy\n",
       "...                                                   ...       ...\n",
       "258811  ../../data/data unused/dirt_dataset_23_11/Rout...  0189.npy\n",
       "258812  ../../data/data unused/dirt_dataset_23_11/Rout...  0190.npy\n",
       "258813  ../../data/data unused/dirt_dataset_23_11/Rout...  0191.npy\n",
       "258814  ../../data/data unused/dirt_dataset_23_11/Rout...  0192.npy\n",
       "258815  ../../data/data unused/dirt_dataset_23_11/Rout...  0193.npy\n",
       "\n",
       "[258816 rows x 2 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta_data_lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_data[\"num\"] = df_meta_data[\"measurements\"].apply(lambda x: x.split(\".\")[0])\n",
    "df_meta_data[\"dir\"] = df_meta_data[\"dir\"].apply(lambda x: os.path.join(*x.split(os.sep)[4:]))\n",
    "\n",
    "df_meta_data_lidar[\"num\"] = df_meta_data_lidar[\"lidar\"].apply(lambda x: x.split(\".\")[0])\n",
    "df_meta_data_lidar[\"dir\"] = df_meta_data_lidar[\"dir\"].apply(lambda x: os.path.join(*x.split(os.sep)[4:]))\n",
    "df_meta_data_lidar = df_meta_data_lidar.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df_meta_data_lidar.merge(right=df_meta_data, on=[\"dir\", \"num\"], how=\"outer\",indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>dir</th>\n",
       "      <th>lidar</th>\n",
       "      <th>num</th>\n",
       "      <th>measurements</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cycl_dataset_23_11/Routes_non-straight-junctio...</td>\n",
       "      <td>0000.npy</td>\n",
       "      <td>0000</td>\n",
       "      <td>0000.json</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>cycl_dataset_23_11/Routes_non-straight-junctio...</td>\n",
       "      <td>0001.npy</td>\n",
       "      <td>0001</td>\n",
       "      <td>0001.json</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>cycl_dataset_23_11/Routes_non-straight-junctio...</td>\n",
       "      <td>0002.npy</td>\n",
       "      <td>0002</td>\n",
       "      <td>0002.json</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>cycl_dataset_23_11/Routes_non-straight-junctio...</td>\n",
       "      <td>0003.npy</td>\n",
       "      <td>0003</td>\n",
       "      <td>0003.json</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cycl_dataset_23_11/Routes_non-straight-junctio...</td>\n",
       "      <td>0004.npy</td>\n",
       "      <td>0004</td>\n",
       "      <td>0004.json</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258861</th>\n",
       "      <td>258861</td>\n",
       "      <td>dirt_dataset_23_11/Routes_Scenario1_Town01_cur...</td>\n",
       "      <td>0189.npy</td>\n",
       "      <td>0189</td>\n",
       "      <td>0189.json</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258862</th>\n",
       "      <td>258862</td>\n",
       "      <td>dirt_dataset_23_11/Routes_Scenario1_Town01_cur...</td>\n",
       "      <td>0190.npy</td>\n",
       "      <td>0190</td>\n",
       "      <td>0190.json</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258863</th>\n",
       "      <td>258863</td>\n",
       "      <td>dirt_dataset_23_11/Routes_Scenario1_Town01_cur...</td>\n",
       "      <td>0191.npy</td>\n",
       "      <td>0191</td>\n",
       "      <td>0191.json</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258864</th>\n",
       "      <td>258864</td>\n",
       "      <td>dirt_dataset_23_11/Routes_Scenario1_Town01_cur...</td>\n",
       "      <td>0192.npy</td>\n",
       "      <td>0192</td>\n",
       "      <td>0192.json</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258865</th>\n",
       "      <td>258865</td>\n",
       "      <td>dirt_dataset_23_11/Routes_Scenario1_Town01_cur...</td>\n",
       "      <td>0193.npy</td>\n",
       "      <td>0193</td>\n",
       "      <td>0193.json</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258866 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                                dir     lidar  \\\n",
       "0            0  cycl_dataset_23_11/Routes_non-straight-junctio...  0000.npy   \n",
       "1            1  cycl_dataset_23_11/Routes_non-straight-junctio...  0001.npy   \n",
       "2            2  cycl_dataset_23_11/Routes_non-straight-junctio...  0002.npy   \n",
       "3            3  cycl_dataset_23_11/Routes_non-straight-junctio...  0003.npy   \n",
       "4            4  cycl_dataset_23_11/Routes_non-straight-junctio...  0004.npy   \n",
       "...        ...                                                ...       ...   \n",
       "258861  258861  dirt_dataset_23_11/Routes_Scenario1_Town01_cur...  0189.npy   \n",
       "258862  258862  dirt_dataset_23_11/Routes_Scenario1_Town01_cur...  0190.npy   \n",
       "258863  258863  dirt_dataset_23_11/Routes_Scenario1_Town01_cur...  0191.npy   \n",
       "258864  258864  dirt_dataset_23_11/Routes_Scenario1_Town01_cur...  0192.npy   \n",
       "258865  258865  dirt_dataset_23_11/Routes_Scenario1_Town01_cur...  0193.npy   \n",
       "\n",
       "         num measurements _merge  \n",
       "0       0000    0000.json   both  \n",
       "1       0001    0001.json   both  \n",
       "2       0002    0002.json   both  \n",
       "3       0003    0003.json   both  \n",
       "4       0004    0004.json   both  \n",
       "...      ...          ...    ...  \n",
       "258861  0189    0189.json   both  \n",
       "258862  0190    0190.json   both  \n",
       "258863  0191    0191.json   both  \n",
       "258864  0192    0192.json   both  \n",
       "258865  0193    0193.json   both  \n",
       "\n",
       "[258866 rows x 6 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_lidar_to_delete = df_merge[df_merge[\"_merge\"] == \"left_only\"].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurements_to_df(dataloader):\n",
    "    idxs, speed, steer, throttle, brake, command = [], [], [], [], [], []\n",
    "    for idx, (x, y) in tqdm(enumerate(dataloader)):\n",
    "        idxs.append(idx)\n",
    "        speed += x['speed'].flatten().tolist()\n",
    "        command += x['command'].flatten().tolist()\n",
    "        steer += y['steer'].flatten().tolist()\n",
    "        throttle += y['throttle'].flatten().tolist()\n",
    "        brake += y['brake'].flatten().tolist()\n",
    "\n",
    "    df_measurements = pd.DataFrame({\"speed\": speed, \"command\": command, \"steer\": steer, \"throttle\": throttle, \"brake\": brake}, index=list(range(len(speed))))\n",
    "    df_measurements.to_pickle(\"measurements_.pickle\")\n",
    "    return df_measurements\n",
    "\n",
    "def remove_entries_at_indices(idx_nan_list, df_meta_entire):\n",
    "    count_files_deleted = 0\n",
    "    for idx_nan in idx_nan_list:\n",
    "        path_nan = os.path.join(df_meta_entire.loc[idx_nan][\"dir\"], \"measurements\", df_meta_entire.loc[idx_nan][\"measurements\"])\n",
    "        with open(path_nan, 'r') as f:\n",
    "            measurements = json.load(f)\n",
    "        if not np.isnan(measurements[\"steer\"]):\n",
    "            print(\"Break: indexes do not fit!\")\n",
    "            break\n",
    "        dir = df_meta_entire[\"dir\"].loc[idx_nan]\n",
    "        dirs_sensors = os.listdir(dir)\n",
    "        number_entry = df_meta_entire[\"measurements\"].loc[idx_nan].split(\".\")[0]\n",
    "        for dir_sensor in dirs_sensors:\n",
    "            if not dir_sensor.startswith(\".\"):\n",
    "                files = os.listdir(os.path.join(dir, dir_sensor))\n",
    "                for file in files:\n",
    "                    if file.startswith(number_entry):\n",
    "                        count_files_deleted += 1\n",
    "                        # os.remove(os.path.join(dir, dir_sensor, file))\n",
    "                        send2trash(os.path.join(dir, dir_sensor, file))\n",
    "    return count_files_deleted\n",
    "\n",
    "def remove_steer_nan_entries(df_meta_entire, dataloader):\n",
    "    df_measurements = measurements_to_df(dataloader)\n",
    "    print(\"df_measurements was created\")\n",
    "    indices_nan = df_meta_data[df_measurements[\"steer\"].isna()].index.tolist()\n",
    "    count_files_deleted = remove_entries_at_indices(indices_nan, df_meta_entire)\n",
    "    return count_files_deleted"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove invalid entries of Noise Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.join(\"..\", \"..\", \"data\", \"Noise-Dataset\")\n",
    "keep_input = [\"lidar\", \"rgb\", \"measurements\"] # \"lidar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unused_sensors_to_new_folder(root_dir, keep_input):\n",
    "    for (root, dirs, files) in os.walk(root_dir, topdown=True):\n",
    "        # Current folder contains the files\n",
    "        if not dirs:\n",
    "            dir, input_type = os.path.split(root)\n",
    "            if input_type not in keep_input:\n",
    "                shutil.rmtree(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_not_rgb_existent_files(root_dir):\n",
    "        for (root, dirs, files) in os.walk(root_dir, topdown=True):\n",
    "            # Current folder contains the files\n",
    "            if not dirs:\n",
    "                dir, input_type = os.path.split(root)\n",
    "                if input_type not in keep_input:\n",
    "                    shutil.rmtree(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_unused_sensors_to_new_folder(root_dir, keep_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route12_02_01_19_12_29/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route26_02_01_21_55_45/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route12_02_01_21_14_01/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route30_02_01_22_13_52/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town02_Scenario8_route15_02_01_17_42_20/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route10_02_01_21_08_27/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route2_02_01_18_42_57/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route13_02_01_19_14_37/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route9_02_01_21_06_08/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route1_02_01_18_40_52/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route40_02_01_22_43_31/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route26_02_01_19_53_36/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town02_Scenario8_route7_02_01_17_20_44/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route15_02_01_19_23_26/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town02_Scenario8_route14_02_01_17_37_43/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route4_02_01_20_53_39/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route3_02_01_18_45_23/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town02_Scenario8_route1_02_01_17_00_44/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town01_Scenario3_route1_02_01_18_03_46/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route25_02_01_19_47_48/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town01_Scenario3_route0_02_01_17_55_55/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route39_02_01_22_41_17/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route31_02_01_22_17_09/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route14_02_01_19_16_20/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town02_Scenario8_route10_02_01_17_29_16/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route6_02_01_20_58_49/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route22_02_01_19_40_42/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route28_02_01_22_05_10/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route5_02_01_20_56_12/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route11_02_01_21_10_54/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route14_02_01_21_18_43/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route3_02_01_20_50_57/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route21_02_01_19_38_55/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route16_02_01_19_25_37/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route35_02_01_22_26_53/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route0_02_01_20_42_52/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route7_02_01_21_01_05/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route8_02_01_19_00_08/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route10_02_01_19_07_20/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route29_02_01_20_06_47/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route21_02_01_21_37_24/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route31_02_01_20_18_13/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route0_02_01_18_38_26/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route33_02_01_20_27_25/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route36_02_01_22_32_49/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route30_02_01_20_12_07/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route18_02_01_21_30_09/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town02_Scenario8_route13_02_01_17_35_40/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town01_Scenario3_route4_02_01_18_15_03/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town02_Scenario8_route11_02_01_17_31_39/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route17_02_01_21_27_17/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route5_02_01_18_51_07/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route23_02_01_19_43_31/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route19_02_01_21_32_21/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route38_02_01_22_38_26/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route6_02_01_18_53_15/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route8_02_01_21_03_32/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town02_Scenario8_route0_02_01_16_54_37/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route33_02_01_22_21_39/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route19_02_01_19_33_07/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route22_02_01_21_40_01/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route2_02_01_20_48_17/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town02_Scenario8_route12_02_01_17_33_47/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route24_02_01_21_45_00/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route13_02_01_21_16_12/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route15_02_01_21_20_58/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town02_Scenario8_route5_02_01_17_14_00/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town02_Scenario8_route2_02_01_17_03_27/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route27_02_01_21_58_44/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route1_02_01_20_45_36/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route24_02_01_19_45_07/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route16_02_01_21_23_53/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town02_Scenario8_route6_02_01_17_18_19/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route32_02_01_20_24_24/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route28_02_01_20_00_14/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route25_02_01_21_49_59/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route32_02_01_20_20_22/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town02_Scenario8_route3_02_01_17_07_11/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route20_02_01_19_36_50/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route11_02_01_19_09_24/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town02_Scenario8_route8_02_01_17_22_56/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route34_02_01_22_24_08/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route9_02_01_19_01_59/lidar\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route9_02_01_19_01_59/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route17_02_01_19_28_01/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route29_02_01_22_08_43/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town01_Scenario3_route3_02_01_18_13_21/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town02_Scenario8_route9_02_01_17_27_10/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route18_02_01_19_30_58/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route27_02_01_19_57_44/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route37_02_01_22_35_53/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route32_02_01_22_19_28/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town01_Scenario3_route2_02_01_18_06_10/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town01_Scenario3_route5_02_01_18_21_38/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town02_Scenario8_route4_02_01_17_09_26/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route20_02_01_21_35_07/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route4_02_01_18_48_07/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town03_Scenario9_route7_02_01_18_56_38/measurements\n",
      "Varying number files among input types: ../../data/Noise-Dataset/Town04_Scenario7_route23_02_01_21_42_32/measurements\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['measurements'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m create_metadata_df(root_dir, [\u001b[39m\"\u001b[39;49m\u001b[39mrgb\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mlidar\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mmeasurements\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[0;32m~/Documents/GitHub/end2endappras/data_pipeline/notebooks/../utils.py:71\u001b[0m, in \u001b[0;36mcreate_metadata_df\u001b[0;34m(root_dir, used_inputs)\u001b[0m\n\u001b[1;32m     69\u001b[0m df_temp_list\u001b[39m.\u001b[39mappend(df_temp)\n\u001b[1;32m     70\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(df_temp_list, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)        \n\u001b[0;32m---> 71\u001b[0m \u001b[39mreturn\u001b[39;00m df[[\u001b[39m\"\u001b[39;49m\u001b[39mdir\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m+\u001b[39;49m used_inputs]\n",
      "File \u001b[0;32m~/miniforge3/envs/carla/lib/python3.8/site-packages/pandas/core/frame.py:3811\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3810\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3811\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3813\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/carla/lib/python3.8/site-packages/pandas/core/indexes/base.py:6113\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6111\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6113\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6115\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6116\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6117\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/carla/lib/python3.8/site-packages/pandas/core/indexes/base.py:6176\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6175\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 6176\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['measurements'] not in index\""
     ]
    }
   ],
   "source": [
    "create_metadata_df(root_dir, [\"rgb\", \"lidar\", \"measurements\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc80d0638afb8ec7c43f4b834002a598fcddbd6e8bf5db40ad8cba47e68e6a97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
