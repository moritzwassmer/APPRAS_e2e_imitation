{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original size 258866 # 258841 # 258816\n",
    "import sys\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "sys.path.append(\"..\")\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import create_metadata_df, measurements_to_df\n",
    "from dataset_xy import CARLADatasetXY\n",
    "import json\n",
    "from send2trash import send2trash\n",
    "import shutil"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move sensor folders that we are not using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.join(\"..\", \"..\", \"data\", \"data\")\n",
    "path_data = os.path.join(\"..\", \"..\", \"..\", \"end2endappras\",\"data\", \"data\")\n",
    "keep_input = [\"lidar\", \"rgb\", \"measurements\"] # \"lidar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_unused_sensors_to_new_folder(root_dir, keep_input):\n",
    "    for (root, dirs, files) in os.walk(root_dir, topdown=True):\n",
    "        # Current folder contains the files\n",
    "        if not dirs:\n",
    "            dir, input_type = os.path.split(root)\n",
    "            if input_type not in keep_input:\n",
    "                path_parts = root.split(os.sep)\n",
    "                idx_data_first = path_parts.index(\"data\")\n",
    "                path_parts[idx_data_first + 1] += \" unused\"\n",
    "                dir_new = os.path.join(*path_parts)\n",
    "                if not os.path.exists(dir_new):\n",
    "                    os.makedirs(dir_new)\n",
    "                shutil.move(root, dir_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move folders back into the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = os.path.join(\"..\", \"..\", \"data\", \"data unused\")\n",
    "root_dir = \"/Users/julianvonklitzing/Documents/GitHub/end2endappras/data/data unused\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move():\n",
    "    for (root, dirs, files) in os.walk(root_dir, topdown=True):\n",
    "        # Current folder contains the files\n",
    "        if not dirs:\n",
    "            dir, input_type = os.path.split(root)\n",
    "            dir_parts = dir.split(\"/\")\n",
    "            idx = dir_parts.index(\"data\") # idx of first data\n",
    "            dir_parts[idx + 1] = \"data\"\n",
    "            dir_new = os.path.join(*dir_parts)\n",
    "            shutil.move(root, dir_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move/ Delete _prep folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_unused_sensors_to_new_folder(root_dir, keep_input):\n",
    "    for (root, dirs, files) in os.walk(root_dir, topdown=True):\n",
    "        # Current folder contains the files\n",
    "        if not dirs:\n",
    "            dir, input_type = os.path.split(root)\n",
    "            if input_type not in keep_input:\n",
    "                path_parts = root.split(os.sep)\n",
    "                idx_data_first = path_parts.index(\"data\")\n",
    "                path_parts[idx_data_first + 1] += \" unused\"\n",
    "                dir_new = os.path.join(*path_parts)\n",
    "                if not os.path.exists(dir_new):\n",
    "                    os.makedirs(dir_new)\n",
    "                shutil.move(root, dir_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_sensor_folders(root_dir, inputs_to_be_deleted):\n",
    "    for (root, dirs, files) in os.walk(root_dir, topdown=True):\n",
    "        # Current folder contains the files\n",
    "        if not dirs:\n",
    "            dir, input_type = os.path.split(root)\n",
    "            if input_type in inputs_to_be_deleted:\n",
    "                shutil.rmtree(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = os.path.join(\"..\", \"..\", \"data\", \"data\")\n",
    "# inputs_to_be_deleted = [\"lidar_bev\"] # \"lidar\"\n",
    "# delete_sensor_folders(root_dir, inputs_to_be_deleted)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete entries with NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = os.path.join(\"..\", \"..\", \"data\", \"data\")\n",
    "\n",
    "config_xy = {\"used_inputs\": [\"measurements\"], \n",
    "        \"used_measurements\": [\"speed\", \"steer\", \"throttle\", \"brake\", \"command\"],\n",
    "        \"y\": [\"brake\", \"steer\", \"throttle\"],\n",
    "        \"seq_len\": 1\n",
    "        }\n",
    "\n",
    "# Create df_meta \n",
    "df_meta_data = create_metadata_df(path_data, config_xy[\"used_inputs\"])\n",
    "\n",
    "# Create Dataset & DataLoader\n",
    "dataset = CARLADatasetXY(root_dir=path_data, df_meta_data=df_meta_data, config=config_xy)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=64, num_workers=0, sampler=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 258841/258841 [01:49<00:00, 2368.21it/s]\n"
     ]
    }
   ],
   "source": [
    "df_measurements = measurements_to_df(df_meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_measurements_nans = df_measurements.isna()\n",
    "df_measurements_nans[\"waypoints\"] = df_measurements[\"waypoints\"].apply(lambda x: np.any(np.isnan(np.array(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dir</th>\n",
       "      <th>speed</th>\n",
       "      <th>command</th>\n",
       "      <th>steer</th>\n",
       "      <th>throttle</th>\n",
       "      <th>brake</th>\n",
       "      <th>theta</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x_command</th>\n",
       "      <th>y_command</th>\n",
       "      <th>waypoints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dir, speed, command, steer, throttle, brake, theta, x, y, x_command, y_command, waypoints]\n",
       "Index: []"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_measurements_nans[np.any(df_measurements_nans, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_entries_at_indices(idx_nan_list, df_meta_entire):\n",
    "    count_files_deleted = 0\n",
    "    for idx_nan in idx_nan_list:\n",
    "        path_nan = os.path.join(df_meta_entire.loc[idx_nan][\"dir\"], \"measurements\", df_meta_entire.loc[idx_nan][\"measurements\"])\n",
    "        with open(path_nan, 'r') as f:\n",
    "            measurements = json.load(f)\n",
    "        if not np.isnan(measurements[\"steer\"]):\n",
    "            print(\"Break: indexes do not fit!\")\n",
    "            break\n",
    "        dir = df_meta_entire[\"dir\"].loc[idx_nan]\n",
    "        dirs_sensors = os.listdir(dir)\n",
    "        number_entry = df_meta_entire[\"measurements\"].loc[idx_nan].split(\".\")[0]\n",
    "        for dir_sensor in dirs_sensors:\n",
    "            if not dir_sensor.startswith(\".\"):\n",
    "                files = os.listdir(os.path.join(dir, dir_sensor))\n",
    "                for file in files:\n",
    "                    if file.startswith(number_entry):\n",
    "                        count_files_deleted += 1\n",
    "                        # os.remove(os.path.join(dir, dir_sensor, file))\n",
    "                        send2trash(os.path.join(dir, dir_sensor, file))\n",
    "    return count_files_deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove_entries_at_indices(idx_nan_list, df_meta_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove invalid entries of Noise Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.join(\"..\", \"..\", \"data\", \"Noise-Dataset\", \"Noise-Dataset2\")\n",
    "keep_input = [\"lidar\", \"rgb\", \"measurements\"] # \"lidar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unused_sensors_to_new_folder(root_dir, keep_input):\n",
    "    for (root, dirs, files) in os.walk(root_dir, topdown=True):\n",
    "        # Current folder contains the files\n",
    "        if not dirs:\n",
    "            dir, input_type = os.path.split(root)\n",
    "            if input_type not in keep_input:\n",
    "                shutil.rmtree(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_not_rgb_existent_files(root_dir):\n",
    "    for (root, dirs, files) in os.walk(root_dir, topdown=True):\n",
    "        # Current folder contains the files\n",
    "        if not dirs:\n",
    "            dir, input_type = os.path.split(root)\n",
    "            if input_type == \"rgb\":\n",
    "                file_numbers_rgb = [filename.split(\".\")[0] for filename in files]\n",
    "                # Delete measurements files not in rgb\n",
    "                file_numbers_measurements = [filename.split(\".\")[0] for filename in os.listdir(os.path.join(dir, \"measurements\"))]\n",
    "                for file_number in file_numbers_measurements:\n",
    "                    if file_number not in file_numbers_rgb:\n",
    "                        os.remove(os.path.join(dir,\"measurements\", f\"{file_number}.json\"))\n",
    "                # Delete lidar files not in rgb\n",
    "                file_numbers_lidar = [filename.split(\".\")[0] for filename in os.listdir(os.path.join(dir, \"lidar\"))]\n",
    "                for file_number in file_numbers_lidar:\n",
    "                    if file_number not in file_numbers_rgb:\n",
    "                        os.remove(os.path.join(dir,\"lidar\", f\"{file_number}.npy\"))                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_unused_sensors_to_new_folder(root_dir, keep_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_all_not_rgb_existent_files(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_data_noisy = create_metadata_df(root_dir, [\"rgb\", \"lidar\", \"measurements\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dir</th>\n",
       "      <th>rgb</th>\n",
       "      <th>lidar</th>\n",
       "      <th>measurements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../data/Noise-Dataset/Noise-Dataset2/Town02...</td>\n",
       "      <td>0010.png</td>\n",
       "      <td>0010.npy</td>\n",
       "      <td>0010.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../data/Noise-Dataset/Noise-Dataset2/Town02...</td>\n",
       "      <td>0011.png</td>\n",
       "      <td>0011.npy</td>\n",
       "      <td>0011.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../data/Noise-Dataset/Noise-Dataset2/Town02...</td>\n",
       "      <td>0012.png</td>\n",
       "      <td>0012.npy</td>\n",
       "      <td>0012.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../data/Noise-Dataset/Noise-Dataset2/Town02...</td>\n",
       "      <td>0013.png</td>\n",
       "      <td>0013.npy</td>\n",
       "      <td>0013.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../data/Noise-Dataset/Noise-Dataset2/Town02...</td>\n",
       "      <td>0014.png</td>\n",
       "      <td>0014.npy</td>\n",
       "      <td>0014.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8108</th>\n",
       "      <td>../../data/Noise-Dataset/Noise-Dataset2/Town07...</td>\n",
       "      <td>0035.png</td>\n",
       "      <td>0035.npy</td>\n",
       "      <td>0035.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8109</th>\n",
       "      <td>../../data/Noise-Dataset/Noise-Dataset2/Town07...</td>\n",
       "      <td>0036.png</td>\n",
       "      <td>0036.npy</td>\n",
       "      <td>0036.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8110</th>\n",
       "      <td>../../data/Noise-Dataset/Noise-Dataset2/Town07...</td>\n",
       "      <td>0037.png</td>\n",
       "      <td>0037.npy</td>\n",
       "      <td>0037.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8111</th>\n",
       "      <td>../../data/Noise-Dataset/Noise-Dataset2/Town07...</td>\n",
       "      <td>0038.png</td>\n",
       "      <td>0038.npy</td>\n",
       "      <td>0038.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8112</th>\n",
       "      <td>../../data/Noise-Dataset/Noise-Dataset2/Town07...</td>\n",
       "      <td>0039.png</td>\n",
       "      <td>0039.npy</td>\n",
       "      <td>0039.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8113 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    dir       rgb     lidar  \\\n",
       "0     ../../data/Noise-Dataset/Noise-Dataset2/Town02...  0010.png  0010.npy   \n",
       "1     ../../data/Noise-Dataset/Noise-Dataset2/Town02...  0011.png  0011.npy   \n",
       "2     ../../data/Noise-Dataset/Noise-Dataset2/Town02...  0012.png  0012.npy   \n",
       "3     ../../data/Noise-Dataset/Noise-Dataset2/Town02...  0013.png  0013.npy   \n",
       "4     ../../data/Noise-Dataset/Noise-Dataset2/Town02...  0014.png  0014.npy   \n",
       "...                                                 ...       ...       ...   \n",
       "8108  ../../data/Noise-Dataset/Noise-Dataset2/Town07...  0035.png  0035.npy   \n",
       "8109  ../../data/Noise-Dataset/Noise-Dataset2/Town07...  0036.png  0036.npy   \n",
       "8110  ../../data/Noise-Dataset/Noise-Dataset2/Town07...  0037.png  0037.npy   \n",
       "8111  ../../data/Noise-Dataset/Noise-Dataset2/Town07...  0038.png  0038.npy   \n",
       "8112  ../../data/Noise-Dataset/Noise-Dataset2/Town07...  0039.png  0039.npy   \n",
       "\n",
       "     measurements  \n",
       "0       0010.json  \n",
       "1       0011.json  \n",
       "2       0012.json  \n",
       "3       0013.json  \n",
       "4       0014.json  \n",
       "...           ...  \n",
       "8108    0035.json  \n",
       "8109    0036.json  \n",
       "8110    0037.json  \n",
       "8111    0038.json  \n",
       "8112    0039.json  \n",
       "\n",
       "[8113 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta_data_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_data = create_metadata_df(root_dir, [\"rgb\", \"lidar\", \"measurements\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014195769835798327"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Of all data together, the noisy data is only 1.4%\n",
    "len(df_meta_data_noisy) / (len(df_meta_data) + len(df_meta_data_noisy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc80d0638afb8ec7c43f4b834002a598fcddbd6e8bf5db40ad8cba47e68e6a97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
