{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julianvonklitzing/miniforge3/envs/carla/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# original size 258866 # 258841 # 258816\n",
    "import sys\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "sys.path.append(\"..\")\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import train_test_split, create_metadata_df\n",
    "from dataset_xy import CARLADatasetXY\n",
    "import json\n",
    "from send2trash import send2trash\n",
    "import shutil"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move sensor folders that we are not using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.join(\"..\", \"..\", \"data\", \"data\")\n",
    "keep_input = [\"lidar\", \"rgb\", \"measurements\"] # \"lidar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_unused_sensors_to_new_folder(root_dir, keep_input):\n",
    "    for (root, dirs, files) in os.walk(root_dir, topdown=True):\n",
    "        # Current folder contains the files\n",
    "        if not dirs:\n",
    "            dir, input_type = os.path.split(root)\n",
    "            if input_type not in keep_input:\n",
    "                path_parts = root.split(os.sep)\n",
    "                idx_data_first = path_parts.index(\"data\")\n",
    "                path_parts[idx_data_first + 1] += \" unused\"\n",
    "                dir_new = os.path.join(*path_parts)\n",
    "                if not os.path.exists(dir_new):\n",
    "                    os.makedirs(dir_new)\n",
    "                shutil.move(root, dir_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move folders back into the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.join(\"..\", \"..\", \"data\", \"data unused\")\n",
    "#root_dir = \"/Users/julianvonklitzing/Documents/GitHub/end2endappras/data/data unused\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (root, dirs, files) in os.walk(root_dir, topdown=True):\n",
    "    # Current folder contains the files\n",
    "    if not dirs:\n",
    "        dir, input_type = os.path.split(root)\n",
    "        dir_parts = dir.split(\"/\")\n",
    "        idx = dir_parts.index(\"data\") # idx of first data\n",
    "        dir_parts[idx + 1] = \"data\"\n",
    "        dir_new = os.path.join(*dir_parts)\n",
    "        shutil.move(root, dir_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move/ Delete _prep folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_unused_sensors_to_new_folder(root_dir, keep_input):\n",
    "    for (root, dirs, files) in os.walk(root_dir, topdown=True):\n",
    "        # Current folder contains the files\n",
    "        if not dirs:\n",
    "            dir, input_type = os.path.split(root)\n",
    "            if input_type not in keep_input:\n",
    "                path_parts = root.split(os.sep)\n",
    "                idx_data_first = path_parts.index(\"data\")\n",
    "                path_parts[idx_data_first + 1] += \" unused\"\n",
    "                dir_new = os.path.join(*path_parts)\n",
    "                if not os.path.exists(dir_new):\n",
    "                    os.makedirs(dir_new)\n",
    "                shutil.move(root, dir_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_sensor_folders(root_dir, keep_input):\n",
    "    for (root, dirs, files) in os.walk(root_dir, topdown=True):\n",
    "        # Current folder contains the files\n",
    "        if not dirs:\n",
    "            dir, input_type = os.path.split(root)\n",
    "            if input_type not in keep_input:\n",
    "                shutil.rmtree(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = os.path.join(\"..\", \"..\", \"data\", \"data\")\n",
    "# keep_input = [\"lidar\", \"lidar_prep\", \"rgb\", \"measurements\"] # \"lidar\"\n",
    "\n",
    "# delete_sensor_folders(root_dir, keep_input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete entries with NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = os.path.join(\"..\", \"..\", \"data\", \"data\")\n",
    "\n",
    "config_xy = {\"used_inputs\": [\"measurements\"], \n",
    "        \"used_measurements\": [\"speed\", \"steer\", \"throttle\", \"brake\", \"command\"],\n",
    "        \"y\": [\"brake\", \"steer\", \"throttle\"],\n",
    "        \"seq_len\": 1\n",
    "        }\n",
    "\n",
    "# Create df_meta \n",
    "df_meta_data = create_metadata_df(path_data, config_xy[\"used_inputs\"])\n",
    "\n",
    "# Create Dataset & DataLoader\n",
    "dataset = CARLADatasetXY(root_dir=path_data, df_meta_data=df_meta_data, config=config_xy)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=64, num_workers=0, sampler=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = os.path.join(\"..\", \"..\", \"data\", \"data unused\")\n",
    "\n",
    "config_xy = {\"used_inputs\": [\"lidar\"], \n",
    "        \"used_measurements\": [\"speed\", \"steer\", \"throttle\", \"brake\", \"command\"],\n",
    "        \"y\": [\"brake\", \"steer\", \"throttle\"],\n",
    "        \"seq_len\": 1\n",
    "        }\n",
    "\n",
    "# Create df_meta \n",
    "df_meta_data_lidar = create_metadata_df(path_data, config_xy[\"used_inputs\"])\n",
    "\n",
    "# Create Dataset & DataLoader\n",
    "# dataset = CARLADatasetXY(root_dir=path_data, df_meta_data=df_meta_data, config=config_xy)\n",
    "# dataloader = DataLoader(dataset=dataset, batch_size=64, num_workers=0, sampler=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dir</th>\n",
       "      <th>lidar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../data/data unused/cycl_dataset_23_11/Rout...</td>\n",
       "      <td>0000.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../data/data unused/cycl_dataset_23_11/Rout...</td>\n",
       "      <td>0001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../data/data unused/cycl_dataset_23_11/Rout...</td>\n",
       "      <td>0002.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../data/data unused/cycl_dataset_23_11/Rout...</td>\n",
       "      <td>0003.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../data/data unused/cycl_dataset_23_11/Rout...</td>\n",
       "      <td>0004.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258811</th>\n",
       "      <td>../../data/data unused/dirt_dataset_23_11/Rout...</td>\n",
       "      <td>0189.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258812</th>\n",
       "      <td>../../data/data unused/dirt_dataset_23_11/Rout...</td>\n",
       "      <td>0190.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258813</th>\n",
       "      <td>../../data/data unused/dirt_dataset_23_11/Rout...</td>\n",
       "      <td>0191.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258814</th>\n",
       "      <td>../../data/data unused/dirt_dataset_23_11/Rout...</td>\n",
       "      <td>0192.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258815</th>\n",
       "      <td>../../data/data unused/dirt_dataset_23_11/Rout...</td>\n",
       "      <td>0193.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258816 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      dir     lidar\n",
       "0       ../../data/data unused/cycl_dataset_23_11/Rout...  0000.npy\n",
       "1       ../../data/data unused/cycl_dataset_23_11/Rout...  0001.npy\n",
       "2       ../../data/data unused/cycl_dataset_23_11/Rout...  0002.npy\n",
       "3       ../../data/data unused/cycl_dataset_23_11/Rout...  0003.npy\n",
       "4       ../../data/data unused/cycl_dataset_23_11/Rout...  0004.npy\n",
       "...                                                   ...       ...\n",
       "258811  ../../data/data unused/dirt_dataset_23_11/Rout...  0189.npy\n",
       "258812  ../../data/data unused/dirt_dataset_23_11/Rout...  0190.npy\n",
       "258813  ../../data/data unused/dirt_dataset_23_11/Rout...  0191.npy\n",
       "258814  ../../data/data unused/dirt_dataset_23_11/Rout...  0192.npy\n",
       "258815  ../../data/data unused/dirt_dataset_23_11/Rout...  0193.npy\n",
       "\n",
       "[258816 rows x 2 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta_data_lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_data[\"num\"] = df_meta_data[\"measurements\"].apply(lambda x: x.split(\".\")[0])\n",
    "df_meta_data[\"dir\"] = df_meta_data[\"dir\"].apply(lambda x: os.path.join(*x.split(os.sep)[4:]))\n",
    "\n",
    "df_meta_data_lidar[\"num\"] = df_meta_data_lidar[\"lidar\"].apply(lambda x: x.split(\".\")[0])\n",
    "df_meta_data_lidar[\"dir\"] = df_meta_data_lidar[\"dir\"].apply(lambda x: os.path.join(*x.split(os.sep)[4:]))\n",
    "df_meta_data_lidar = df_meta_data_lidar.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df_meta_data_lidar.merge(right=df_meta_data, on=[\"dir\", \"num\"], how=\"outer\",indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>dir</th>\n",
       "      <th>lidar</th>\n",
       "      <th>num</th>\n",
       "      <th>measurements</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cycl_dataset_23_11/Routes_non-straight-junctio...</td>\n",
       "      <td>0000.npy</td>\n",
       "      <td>0000</td>\n",
       "      <td>0000.json</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>cycl_dataset_23_11/Routes_non-straight-junctio...</td>\n",
       "      <td>0001.npy</td>\n",
       "      <td>0001</td>\n",
       "      <td>0001.json</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>cycl_dataset_23_11/Routes_non-straight-junctio...</td>\n",
       "      <td>0002.npy</td>\n",
       "      <td>0002</td>\n",
       "      <td>0002.json</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>cycl_dataset_23_11/Routes_non-straight-junctio...</td>\n",
       "      <td>0003.npy</td>\n",
       "      <td>0003</td>\n",
       "      <td>0003.json</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cycl_dataset_23_11/Routes_non-straight-junctio...</td>\n",
       "      <td>0004.npy</td>\n",
       "      <td>0004</td>\n",
       "      <td>0004.json</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258861</th>\n",
       "      <td>258861</td>\n",
       "      <td>dirt_dataset_23_11/Routes_Scenario1_Town01_cur...</td>\n",
       "      <td>0189.npy</td>\n",
       "      <td>0189</td>\n",
       "      <td>0189.json</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258862</th>\n",
       "      <td>258862</td>\n",
       "      <td>dirt_dataset_23_11/Routes_Scenario1_Town01_cur...</td>\n",
       "      <td>0190.npy</td>\n",
       "      <td>0190</td>\n",
       "      <td>0190.json</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258863</th>\n",
       "      <td>258863</td>\n",
       "      <td>dirt_dataset_23_11/Routes_Scenario1_Town01_cur...</td>\n",
       "      <td>0191.npy</td>\n",
       "      <td>0191</td>\n",
       "      <td>0191.json</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258864</th>\n",
       "      <td>258864</td>\n",
       "      <td>dirt_dataset_23_11/Routes_Scenario1_Town01_cur...</td>\n",
       "      <td>0192.npy</td>\n",
       "      <td>0192</td>\n",
       "      <td>0192.json</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258865</th>\n",
       "      <td>258865</td>\n",
       "      <td>dirt_dataset_23_11/Routes_Scenario1_Town01_cur...</td>\n",
       "      <td>0193.npy</td>\n",
       "      <td>0193</td>\n",
       "      <td>0193.json</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258866 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                                dir     lidar  \\\n",
       "0            0  cycl_dataset_23_11/Routes_non-straight-junctio...  0000.npy   \n",
       "1            1  cycl_dataset_23_11/Routes_non-straight-junctio...  0001.npy   \n",
       "2            2  cycl_dataset_23_11/Routes_non-straight-junctio...  0002.npy   \n",
       "3            3  cycl_dataset_23_11/Routes_non-straight-junctio...  0003.npy   \n",
       "4            4  cycl_dataset_23_11/Routes_non-straight-junctio...  0004.npy   \n",
       "...        ...                                                ...       ...   \n",
       "258861  258861  dirt_dataset_23_11/Routes_Scenario1_Town01_cur...  0189.npy   \n",
       "258862  258862  dirt_dataset_23_11/Routes_Scenario1_Town01_cur...  0190.npy   \n",
       "258863  258863  dirt_dataset_23_11/Routes_Scenario1_Town01_cur...  0191.npy   \n",
       "258864  258864  dirt_dataset_23_11/Routes_Scenario1_Town01_cur...  0192.npy   \n",
       "258865  258865  dirt_dataset_23_11/Routes_Scenario1_Town01_cur...  0193.npy   \n",
       "\n",
       "         num measurements _merge  \n",
       "0       0000    0000.json   both  \n",
       "1       0001    0001.json   both  \n",
       "2       0002    0002.json   both  \n",
       "3       0003    0003.json   both  \n",
       "4       0004    0004.json   both  \n",
       "...      ...          ...    ...  \n",
       "258861  0189    0189.json   both  \n",
       "258862  0190    0190.json   both  \n",
       "258863  0191    0191.json   both  \n",
       "258864  0192    0192.json   both  \n",
       "258865  0193    0193.json   both  \n",
       "\n",
       "[258866 rows x 6 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_lidar_to_delete = df_merge[df_merge[\"_merge\"] == \"left_only\"].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurements_to_df(dataloader):\n",
    "    idxs, speed, steer, throttle, brake, command = [], [], [], [], [], []\n",
    "    for idx, (x, y) in tqdm(enumerate(dataloader)):\n",
    "        idxs.append(idx)\n",
    "        speed += x['speed'].flatten().tolist()\n",
    "        command += x['command'].flatten().tolist()\n",
    "        steer += y['steer'].flatten().tolist()\n",
    "        throttle += y['throttle'].flatten().tolist()\n",
    "        brake += y['brake'].flatten().tolist()\n",
    "\n",
    "    df_measurements = pd.DataFrame({\"speed\": speed, \"command\": command, \"steer\": steer, \"throttle\": throttle, \"brake\": brake}, index=list(range(len(speed))))\n",
    "    df_measurements.to_pickle(\"measurements_.pickle\")\n",
    "    return df_measurements\n",
    "\n",
    "def remove_entries_at_indices(idx_nan_list, df_meta_entire):\n",
    "    count_files_deleted = 0\n",
    "    for idx_nan in idx_nan_list:\n",
    "        path_nan = os.path.join(df_meta_entire.loc[idx_nan][\"dir\"], \"measurements\", df_meta_entire.loc[idx_nan][\"measurements\"])\n",
    "        with open(path_nan, 'r') as f:\n",
    "            measurements = json.load(f)\n",
    "        if not np.isnan(measurements[\"steer\"]):\n",
    "            print(\"Break: indexes do not fit!\")\n",
    "            break\n",
    "        dir = df_meta_entire[\"dir\"].loc[idx_nan]\n",
    "        dirs_sensors = os.listdir(dir)\n",
    "        number_entry = df_meta_entire[\"measurements\"].loc[idx_nan].split(\".\")[0]\n",
    "        for dir_sensor in dirs_sensors:\n",
    "            if not dir_sensor.startswith(\".\"):\n",
    "                files = os.listdir(os.path.join(dir, dir_sensor))\n",
    "                for file in files:\n",
    "                    if file.startswith(number_entry):\n",
    "                        count_files_deleted += 1\n",
    "                        # os.remove(os.path.join(dir, dir_sensor, file))\n",
    "                        send2trash(os.path.join(dir, dir_sensor, file))\n",
    "    return count_files_deleted\n",
    "\n",
    "def remove_steer_nan_entries(df_meta_entire, dataloader):\n",
    "    df_measurements = measurements_to_df(dataloader)\n",
    "    print(\"df_measurements was created\")\n",
    "    indices_nan = df_meta_data[df_measurements[\"steer\"].isna()].index.tolist()\n",
    "    count_files_deleted = remove_entries_at_indices(indices_nan, df_meta_entire)\n",
    "    return count_files_deleted"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove invalid entries of Noise Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.join(\"..\", \"..\", \"data\", \"Noise-Dataset\")\n",
    "keep_input = [\"lidar\", \"rgb\", \"measurements\"] # \"lidar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unused_sensors_to_new_folder(root_dir, keep_input):\n",
    "    for (root, dirs, files) in os.walk(root_dir, topdown=True):\n",
    "        # Current folder contains the files\n",
    "        if not dirs:\n",
    "            dir, input_type = os.path.split(root)\n",
    "            if input_type not in keep_input:\n",
    "                shutil.rmtree(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_not_rgb_existent_files(root_dir):\n",
    "    for (root, dirs, files) in os.walk(root_dir, topdown=True):\n",
    "        # Current folder contains the files\n",
    "        if not dirs:\n",
    "            dir, input_type = os.path.split(root)\n",
    "            if input_type == \"rgb\":\n",
    "                file_numbers_rgb = [filename.split(\".\")[0] for filename in files]\n",
    "                # Delete measurements files not in rgb\n",
    "                file_numbers_measurements = [filename.split(\".\")[0] for filename in os.listdir(os.path.join(dir, \"measurements\"))]\n",
    "                for file_number in file_numbers_measurements:\n",
    "                    if file_number not in file_numbers_rgb:\n",
    "                        os.remove(os.path.join(dir,\"measurements\", f\"{file_number}.json\"))\n",
    "                # Delete lidar files not in rgb\n",
    "                file_numbers_lidar = [filename.split(\".\")[0] for filename in os.listdir(os.path.join(dir, \"lidar\"))]\n",
    "                for file_number in file_numbers_lidar:\n",
    "                    if file_number not in file_numbers_rgb:\n",
    "                        os.remove(os.path.join(dir,\"lidar\", f\"{file_number}.npy\"))                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_unused_sensors_to_new_folder(root_dir, keep_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_all_not_rgb_existent_files(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_data_noisy = create_metadata_df(root_dir, [\"rgb\", \"lidar\", \"measurements\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_data = create_metadata_df(root_dir, [\"rgb\", \"lidar\", \"measurements\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014195769835798327"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Of all data together, the noisy data is only 1.4%\n",
    "len(df_meta_data_noisy) / (len(df_meta_data) + len(df_meta_data_noisy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc80d0638afb8ec7c43f4b834002a598fcddbd6e8bf5db40ad8cba47e68e6a97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
