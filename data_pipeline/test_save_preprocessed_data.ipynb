{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julianvonklitzing/miniforge3/envs/carla/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data_sampler import WeightedSampler\n",
    "from dataset import CARLADataset, CARLADatasetMultiProcessing\n",
    "from data_preprocessing import preprocessing\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from zipfile import ZipFile, ZIP_DEFLATED\n",
    "import zipfile\n",
    "import shutil\n",
    "import tarfile\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess rgb files and save them as zipped/compressed torch tensors to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_file(path_source, path_destination):\n",
    "   path_pwd = os.getcwd()\n",
    "   directory, file_name = os.path.split(path_source)\n",
    "   file_name_zip = file_name + \".zip\"\n",
    "   os.chdir(directory)\n",
    "   with ZipFile(file_name_zip, 'w', ZIP_DEFLATED) as zip:\n",
    "      zip.write(file_name)\n",
    "   os.chdir(path_pwd)\n",
    "   # old_file = os.path.join(directory, file_name_zip)\n",
    "   # shutil.copy(old_file, path_destination)\n",
    "   # os.remove(old_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file(file_path):\n",
    "    path_pwd = os.getcwd()\n",
    "    directory, file_name = os.path.split(file_path)\n",
    "    file_name_zip = file_name + \".zip\"\n",
    "    os.chdir(directory)\n",
    "\n",
    "\n",
    "    with ZipFile(file_name, 'r') as zip:\n",
    "        #file_name = os.path.splitext(path_source)[0].split(os.sep)[-1]\n",
    "        # zip.extract(file_name, path_destination)\n",
    "        zip.extractall() # path=path_destination\n",
    "    \n",
    "    os.chdir(path_pwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Varying number files among input types: ../data/Dataset Ege/Town10HD_Scenario10_route16_11_28_18_26_19/rgb_prep_zip\n",
      "217\n"
     ]
    }
   ],
   "source": [
    "path_data = os.path.join(\"..\", \"data\", \"Dataset Ege\")\n",
    "# path_data = os.path.join(\"..\", \"data\", \"data\")\n",
    "\n",
    "\n",
    "config = {\"used_inputs\": [\"rgb\", \"measurements\"], \n",
    "        \"used_measurements\": [\"speed\", \"steer\", \"throttle\"],\n",
    "        \"seq_len\": 1\n",
    "        }\n",
    "\n",
    "dataset = CARLADataset(root_dir=path_data, config=config)\n",
    "print(dataset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [00:22<00:00,  9.68it/s]\n"
     ]
    }
   ],
   "source": [
    "df_meta = dataset.df_meta_data\n",
    "for idx in tqdm(range(len(df_meta))):\n",
    "    dir_name_zip = os.path.join(df_meta.iloc[idx][\"dir\"], \"rgb_prep_zip\")\n",
    "    if not os.path.exists(dir_name_zip):\n",
    "        os.makedirs(dir_name_zip)\n",
    "    path = os.path.join(df_meta.iloc[idx][0], \"rgb\", df_meta.iloc[idx][1])\n",
    "    img_np = dataset.load_data_from_path(path)\n",
    "    img_torch = torch.Tensor(img_np)\n",
    "    img_torch_prep = preprocessing[\"rgb\"](img_torch)\n",
    "    filename_torch = os.path.join(dir_name_zip, f\"{df_meta.iloc[idx]['rgb'].split('.')[0]}.pt\")\n",
    "    torch.save(img_torch_prep, filename_torch)\n",
    "    compress_file(filename_torch, dir_name_zip)\n",
    "    os.remove(filename_torch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess rgb files and save them (high storage demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [00:02<00:00, 91.49it/s]\n"
     ]
    }
   ],
   "source": [
    "df_meta = dataset.df_meta_data\n",
    "for idx in tqdm(range(len(df_meta))):\n",
    "    dir_name_zip = os.path.join(df_meta.iloc[idx][\"dir\"], \"rgb_prep\")\n",
    "    if not os.path.exists(dir_name_zip):\n",
    "        os.makedirs(dir_name_zip)\n",
    "    path = os.path.join(df_meta.iloc[idx][0], \"rgb\", df_meta.iloc[idx][1])\n",
    "    img_np = dataset.load_data_from_path(path)\n",
    "    img_torch = torch.Tensor(img_np)\n",
    "    img_torch_prep = preprocessing[\"rgb\"](img_torch)\n",
    "    filename_torch = os.path.join(dir_name_zip, f\"{df_meta.iloc[idx]['rgb'].split('.')[0]}.pt\")\n",
    "    torch.save(img_torch_prep, filename_torch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the approaches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"used_inputs\": [\"rgb\", \"measurements\"], \n",
    "        \"used_measurements\": [\"speed\", \"steer\", \"throttle\"],\n",
    "        \"seq_len\": 1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CARLADataset(root_dir=path_data, config=config)\n",
    "weighted_sampler = WeightedSampler(dataset=dataset)\n",
    "dl = DataLoader(dataset=dataset, batch_size=16, num_workers=0, sampler=weighted_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [00:01<00:00, 171.97it/s]\n"
     ]
    }
   ],
   "source": [
    "df_meta = dataset.df_meta_data\n",
    "for idx in tqdm(range(len(df_meta))):\n",
    "    path = os.path.join(df_meta.iloc[idx][0], \"rgb\", df_meta.iloc[idx][1])\n",
    "    img_np = dataset.load_data_from_path(path)\n",
    "    img_torch = torch.Tensor(img_np)\n",
    "    img_torch_prep = preprocessing[\"rgb\"](img_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:01<00:00, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Unfair to use DataLoader (with batches) because for other approaches the Dataset class was not adjusted (time consuming)\n",
    "count = 0\n",
    "for batch in tqdm(dl):\n",
    "    # preprocessing\n",
    "    for key in preprocessing:\n",
    "        batch[key] = preprocessing[key](batch[key])\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing from disk and compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"used_inputs\": [\"rgb_prep_zip\", \"measurements\"], \n",
    "        \"used_measurements\": [\"speed\", \"steer\", \"throttle\"],\n",
    "        \"seq_len\": 1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CARLADataset(root_dir=path_data, config=config)\n",
    "weighted_sampler = WeightedSampler(dataset=dataset)\n",
    "dl = DataLoader(dataset=dataset, batch_size=16, num_workers=0, sampler=weighted_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [00:02<00:00, 81.08it/s]\n"
     ]
    }
   ],
   "source": [
    "df_meta = dataset.df_meta_data\n",
    "for idx in tqdm(range(len(df_meta))):\n",
    "    path_compressed = os.path.join(df_meta.iloc[idx][0], \"rgb_prep_zip\", df_meta.iloc[idx][1])\n",
    "    path_decompressed = os.path.splitext(path_compressed)[0]\n",
    "    extract_file(path_compressed)\n",
    "    img_torch = torch.load(path_decompressed)\n",
    "    os.remove(path_decompressed)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [00:00<00:00, 685.09it/s]\n"
     ]
    }
   ],
   "source": [
    "config = {\"used_inputs\": [\"rgb_prep\", \"measurements\"], \n",
    "        \"used_measurements\": [\"speed\", \"steer\", \"throttle\"],\n",
    "        \"seq_len\": 1\n",
    "        }\n",
    "\n",
    "dataset = CARLADataset(root_dir=path_data, config=config)\n",
    "weighted_sampler = WeightedSampler(dataset=dataset)\n",
    "dl = DataLoader(dataset=dataset, batch_size=16, num_workers=0, sampler=weighted_sampler)\n",
    "\n",
    "df_meta = dataset.df_meta_data\n",
    "for idx in tqdm(range(len(df_meta))):\n",
    "    path = os.path.join(df_meta.iloc[idx][0], \"rgb_prep\", df_meta.iloc[idx][1])\n",
    "    img_torch = torch.load(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move sensor data that isn't used to other directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = os.path.join(\"..\", \"data\", \"Dataset Ege\")\n",
    "root_dir = os.path.join(\"..\", \"data\", \"data\")\n",
    "keep_input = [\"lidar\", \"rgb\", \"measurements\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (root, dirs, files) in os.walk(root_dir, topdown=True):\n",
    "    # Current folder contains the files\n",
    "    if not dirs:\n",
    "        dir, input_type = os.path.split(root)\n",
    "        if input_type not in keep_input:\n",
    "            dir_new = os.path.join(os.path.split(dir)[0] + \" unused\", os.path.split(dir)[1])\n",
    "            # path_split = dir.split(os.sep)\n",
    "            # path_split[2] = path_split[2] + \" unused\"\n",
    "            # dir_new = os.path.join(*path_split)\n",
    "            if not os.path.exists(dir_new):\n",
    "                os.makedirs(dir_new)\n",
    "            shutil.move(root, dir_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outdated functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_file(file_path, dest_path):\n",
    "  path_pwd = os.getcwd()\n",
    "  # Extract the directory and file name from the file path\n",
    "  directory, file_name = os.path.split(file_path)\n",
    "  os.chdir(directory)\n",
    "  # Compress the file using shutil.make_archive\n",
    "  shutil.make_archive(file_name, 'zip', directory, file_name) # directory, file_name\n",
    "  os.chdir(path_pwd)\n",
    "  old_file = os.path.join(directory, file_name + '.zip')\n",
    "  # shutil.copy(old_file, dest_path)\n",
    "  # os.remove(old_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file(file_path):\n",
    "    with ZipFile(path_source, 'r') as zip:\n",
    "        file_name = os.path.splitext(path_source)[0].split(os.sep)[-1]\n",
    "        zip.printdir()\n",
    "        # zip.extract(file_name, path_destination)\n",
    "        zip.extractall() # path=path_destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file(file_path):\n",
    "    path_pwd = os.getcwd()\n",
    "    directory, file_name = os.path.split(file_path)\n",
    "    os.chdir(directory)\n",
    "    shutil.unpack_archive(file_name, directory, \"zip\")\n",
    "    os.chdir(path_pwd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc80d0638afb8ec7c43f4b834002a598fcddbd6e8bf5db40ad8cba47e68e6a97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
